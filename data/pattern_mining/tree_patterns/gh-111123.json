[
    {
        "blob_id": "a4790f330127b42f990458a9422f08d636909335",
        "matched_blocks": [
            [
                141,
                159,
                "        try:\n            date_obj = datetime.strptime(date_string, date_format)\n        except ValueError:\n            continue\n        else:\n            # If format does not include the day, use last day of the month\n            # instead of first, because the first is usually out of range.\n            if '%d' not in date_format:\n                period = 'month'\n                date_obj = date_obj.replace(\n                    day=get_last_day_of_month(date_obj.year, date_obj.month))\n\n            if not ('%y' in date_format or '%Y' in date_format):\n                today = datetime.today()\n                date_obj = date_obj.replace(year=today.year)\n\n            date_obj = apply_timezone_from_settings(date_obj, settings)\n\n            return {'date_obj': date_obj, 'period': period}"
            ]
        ]
    },
    {
        "blob_id": "64d2708c0db94febed6b0bed6c21691c51bc0c65",
        "matched_blocks": [
            [
                125,
                131,
                "        try:\n            os.remove(self._config_path)\n        except:\n            self.logger.error(\"Unable to remove existing config file.\")\n        else:\n            new_config = configparser.ConfigParser()\n            self._make_new(new_config)            "
            ]
        ]
    },
    {
        "blob_id": "29d8bb89fb956abdb5a2884c9d6f580bcb0f4977",
        "matched_blocks": [
            [
                272,
                288,
                "    try:\n        res = import_urllib.urlopen(req, timeout=timeout)\n        return HttpResponse(res.code, res.msg, res.headers, res.read())\n    except import_urllib.URLError as e:\n        try:\n            if hasattr(e, \"reason\"):\n                reason = e.reason\n            else:\n                reason = None\n            return HttpResponse(e.code, e.msg, e.headers, e.read(), reason)\n        except Exception as e:\n            print(\"Req failed wih response.init:\", e)\n            errMsg = \"Unknown Error\"\n            return HttpResponse(-3, errMsg, {}, errMsg, repr(e))\n    else:\n        errMsg = \"Unknown Error\"\n        return HttpResponse(-4, errMsg, {}, errMsg, errMsg)"
            ]
        ]
    },
    {
        "blob_id": "0d669d2399fcf8e70e16dd7f0b8d162ac849a762",
        "matched_blocks": [
            [
                576,
                634,
                "                    try:\n                        # NOTE: For code passed to eval or exec, there is no\n                        # difference between locals and globals. Only pass in\n                        # one dict, otherwise there is weird behavior\n                        with cap:\n                            # We can execute each part using exec or eval.  If\n                            # a doctest part has `compile_mode=eval` we\n                            # exepect it to return an object with a repr that\n                            # can compared to a \"want\" statement.\n                            # print('part.compile_mode = {!r}'.format(part.compile_mode))\n                            if part.compile_mode == 'eval':\n                                # print('test_globals = {}'.format(sorted(test_globals.keys())))\n                                got_eval = eval(code, test_globals)\n                                # if EVAL_MIGHT_RETURN_COROUTINE:\n                                #     import types\n                                #     if isinstance(got_eval, types.CoroutineType):\n                                #         # In 3.9-rc (2020-mar-31) it looks like\n                                #         # eval sometimes returns coroutines. I\n                                #         # found no docs on this. Not sure if it\n                                #         # will be mainlined, but this seems to\n                                #         # fix it.\n                                #         import asyncio\n                                #         got_eval =  asyncio.run(got_eval)\n                            else:\n                                exec(code, test_globals)\n\n                        # Record any standard output and \"got_eval\" produced by\n                        # this doctest_part.\n                        self.logged_evals[partx] = got_eval\n                        self.logged_stdout[partx] = cap.text\n                    except Exception:\n                        if part.want:\n                            # A failure may be expected if the traceback\n                            # matches the part's want statement.\n                            exception = sys.exc_info()\n                            traceback.format_exception_only(*exception[:2])\n                            exc_got = traceback.format_exception_only(*exception[:2])[-1]\n                            want = part.want\n                            checker.check_exception(exc_got, want, runstate)\n                        else:\n                            raise\n                    else:\n                        \"\"\"\n                        TODO:\n                            [ ] - Delay got-want failure until the end of the\n                            doctest. Allow the rest of the code to run.  If\n                            multiple errors occur, show them both.\n                        \"\"\"\n                        if part.want:\n                            got_stdout = cap.text\n                            if not runstate['IGNORE_WANT']:\n                                part.check(got_stdout, got_eval, runstate,\n                                           unmatched=self._unmatched_stdout)\n                            # Clear unmatched output when a check passes\n                            self._unmatched_stdout = []\n                        else:\n                            # If a part doesnt have a want allow its output to\n                            # be matched by the next part.\n                            self._unmatched_stdout.append(cap.text)"
            ]
        ]
    },
    {
        "blob_id": "5d10c9e904f81aa5fe519aed35a603ff4cf68be3",
        "matched_blocks": [
            [
                187,
                197,
                "            try:\n                dtsuite = doctest.DocTestSuite(\n                    mod,\n                    optionflags=doctest.NORMALIZE_WHITESPACE,\n                    setUp=self.doctest_setUp,\n                    tearDown=self.doctest_tearDown\n                )\n            except ValueError:\n                pass\n            else:\n                suites.append(dtsuite)"
            ]
        ]
    },
    {
        "blob_id": "68357d1fed30e9fd6465e7187291dea3730cc99a",
        "matched_blocks": [
            [
                3,
                10,
                "try:\n    import mando\nexcept ImportError as e:\n    version = e.version\n    deps = ['argparse']\nelse:\n    version = mando.__version__\n    deps = []"
            ]
        ]
    },
    {
        "blob_id": "ea8164b4642f2b34caee3e38a6a1205bba11fd64",
        "matched_blocks": [
            [
                158,
                166,
                "            try:\n                sqla = InSqlAssoc(GAF_VERSION[version], [1,4], lambda x:  _to_goa(x, version))\n            except ImportError:\n                print >> sys.stderr, \"Error: To use in_mem_sql association you need to have sqlite3 bindings installed.\"\n            else:\n                for row in tsv_iter:\n                    if not row[0].startswith('!'):\n                        sqla.add_row(row)\n                return sqla"
            ]
        ]
    },
    {
        "blob_id": "028f7254014e7380449a4821a74148ff30b6914b",
        "matched_blocks": [
            [
                123,
                194,
                "                    try:\n                        r2 = requests.get(url_baidu_detail, headers=Header, verify=False, timeout=8)\n                    except Exception as e:\n                        logging.warning(e)\n                    else:\n                        if r2:\n                            if r2.apparent_encoding == \"utf-8\" or r2.apparent_encoding.startswith(\n                                    \"UTF-8\") or r2.apparent_encoding == \"utf8\":\n                                r2.encoding = \"utf-8\"\n                            elif r2.apparent_encoding == \"GB2312\" or r2.apparent_encoding.startswith(\n                                    \"ISO-8859\") or r2.apparent_encoding.startswith(\"Windows\"):\n                                r2.encoding = \"gbk\"\n                            if r2:\n                                print(r2.url)\n                                if supervisory[0] in r2.url and flag_jd == False:\n                                    flag_jd = True\n                                    index_id = 0\n                                    index_id = l.xpath(\"@id\")\n                                    if len(index_id) > 0:\n                                        index_id = int(index_id[0])\n                                    logging.info(\"\u5173\u952e\u5b57{}-- jd \u8be6\u60c5\u9875url\uff1a{}\".format(keyword, r2.url))\n                                    dicts = {}\n                                    dicts[\"tag\"] = \"jd\"\n                                    dicts[\"keyword\"] = keyword\n                                    if \"...\" in title:\n                                        html = getXpath(r2.text)\n                                        title = html.xpath('''//head/title/text()''')\n                                        if len(title) > 0:\n                                            title = title[0]\n                                    dicts[\"title\"] = title\n                                    dicts[\"url\"] = r2.url\n                                    dicts[\"index\"] = index_id\n                                    insert_db(dicts)\n                                if supervisory[1] in r2.url and flag_1688 == False:\n                                    flag_1688 = True\n                                    index_id = 0\n                                    index_id = l.xpath(\"@id\")\n                                    if len(index_id) > 0:\n                                        index_id = int(index_id[0])\n                                    logging.info(\"\u5173\u952e\u5b57{}-- 1688 \u8be6\u60c5\u9875url\uff1a{}\".format(keyword, r2.url))\n                                    dicts = {}\n                                    dicts[\"tag\"] = \"1688\"\n                                    dicts[\"keyword\"] = keyword\n                                    if \"...\" in title:\n                                        html = getXpath(r2.text)\n                                        title = html.xpath('''//head/title/text()''')\n                                        if len(title) > 0:\n                                            title = title[0]\n                                    dicts[\"title\"] = title\n                                    dicts[\"url\"] = r2.url\n                                    dicts[\"index\"] = index_id\n                                    insert_db(dicts)\n                                if supervisory[2] in r2.url and flag_b2bbaidu == False:\n                                    flag_b2bbaidu = True\n                                    index_id = 0\n                                    index_id = l.xpath(\"@id\")\n                                    if len(index_id) > 0:\n                                        index_id = int(index_id[0])\n                                    logging.info(\"\u5173\u952e\u5b57{}-- b2bbaidu \u8be6\u60c5\u9875url\uff1a{}\".format(keyword, r2.url))\n                                    dicts = {}\n                                    dicts[\"tag\"] = \"b2b.baidu.com\"\n                                    dicts[\"keyword\"] = keyword\n                                    if \"...\" in title:\n                                        html = getXpath(r2.text)\n                                        title = html.xpath('''//head/title/text()''')\n                                        if len(title) > 0:\n                                            title = title[0]\n\n                                    dicts[\"title\"] = title\n                                    dicts[\"url\"] = r2.url\n                                    dicts[\"index\"] = index_id\n                                    insert_db(dicts)"
            ]
        ]
    },
    {
        "blob_id": "75adc57efa8196a7a552998412254bf7156fa4ad",
        "matched_blocks": [
            [
                219,
                224,
                "        try:\n            get = _imagingcms.get_display_profile\n        except AttributeError:\n            return None\n        else:\n            profile = get()"
            ]
        ]
    },
    {
        "blob_id": "5a832218bf38530ac70376758bca84c80cd4039e",
        "matched_blocks": [
            [
                82,
                88,
                "        try:\n            self.executor.setup(self)\n        except Exception:\n            # The caller is responsible for logging the exception if required\n            self.send_message(\"init_failed\")\n        else:\n            self.send_message(\"init_succeeded\")"
            ],
            [
                218,
                232,
                "        try:\n            if self.init_timer is not None:\n                self.init_timer.start()\n            self.logger.debug(\"Starting browser with settings %r\" % self.browser_settings)\n            self.browser.start(group_metadata=group_metadata, **self.browser_settings)\n            self.browser_pid = self.browser.pid()\n        except Exception:\n            self.logger.warning(\"Failure during init %s\" % traceback.format_exc())\n            if self.init_timer is not None:\n                self.init_timer.cancel()\n            self.logger.error(traceback.format_exc())\n            succeeded = False\n        else:\n            succeeded = True\n            self.started = True"
            ],
            [
                423,
                461,
                "        try:\n            command, data = self.command_queue.get(True, 1)\n            self.logger.debug(\"Got command: %r\" % command)\n        except IOError:\n            self.logger.error(\"Got IOError from poll\")\n            return RunnerManagerState.restarting(0)\n        except Empty:\n            if (self.debug_info and self.debug_info.interactive and\n                self.browser.started and not self.browser.is_alive()):\n                self.logger.debug(\"Debugger exited\")\n                return RunnerManagerState.stop()\n\n            if (isinstance(self.state, RunnerManagerState.running) and\n                not self.test_runner_proc.is_alive()):\n                if not self.command_queue.empty():\n                    # We got a new message so process that\n                    return\n\n                # If we got to here the runner presumably shut down\n                # unexpectedly\n                self.logger.info(\"Test runner process shut down\")\n\n                if self.state.test is not None:\n                    # This could happen if the test runner crashed for some other\n                    # reason\n                    # Need to consider the unlikely case where one test causes the\n                    # runner process to repeatedly die\n                    self.logger.critical(\"Last test did not complete\")\n                    return RunnerManagerState.error()\n                self.logger.warning(\"More tests found, but runner process died, restarting\")\n                return RunnerManagerState.restarting(0)\n        else:\n            f = (dispatch.get(self.state.__class__, {}).get(command) or\n                 dispatch.get(None, {}).get(command))\n            if not f:\n                self.logger.warning(\"Got command %s in state %s\" %\n                                    (command, self.state.__class__.__name__))\n                return\n            return f(*data)"
            ],
            [
                108,
                116,
                "            try:\n                rv = commands[command](*args)\n            except Exception:\n                self.send_message(\"error\",\n                                  \"Error running command %s with arguments %r:\\n%s\" %\n                                  (command, args, traceback.format_exc()))\n            else:\n                if rv is Stop:\n                    break"
            ],
            [
                742,
                755,
                "            try:\n                cmd, data = self.command_queue.get_nowait()\n            except Empty:\n                break\n            else:\n                if cmd == \"log\":\n                    self.log(*data)\n                elif cmd == \"runner_teardown\":\n                    # It's OK for the \"runner_teardown\" message to be left in\n                    # the queue during cleanup, as we will already have tried\n                    # to stop the TestRunner in `stop_runner`.\n                    pass\n                else:\n                    self.logger.warning(\"Command left in command_queue during cleanup: %r, %r\" % (cmd, data))"
            ]
        ]
    },
    {
        "blob_id": "71407aaec402bf1a1f60abe21963c767a1d948b5",
        "matched_blocks": [
            [
                35,
                40,
                "try:\n    from PIL import Image  # noqa\nexcept ImportError:\n    PILLOW_IS_INSTALLED = False\nelse:\n    PILLOW_IS_INSTALLED = True"
            ]
        ]
    },
    {
        "blob_id": "fca3ab1a894ead14dc84fdcd629eef27db3e74de",
        "matched_blocks": [
            [
                327,
                352,
                "        try:\n            run_and_check(command_block, \"\".join(line for _, line in lines))\n        except UnmatchedLine as e:\n            print(format_failed_test(\n                \"shtest %d - failure (line %s):\"\n                % (block_nb + 1,\n                   (\"%s-%s\" % (start_line_nb, stop_line_nb))\n                   if start_line_nb != stop_line_nb else\n                   start_line_nb),\n                command_block,\n                e.args[0],\n                e.args[1]))\n            exit(1)\n        except Ignored as e:\n            print(\"shtest %d - ignored (line %s): %s\"\n                  % (block_nb + 1,\n                     ((\"%s-%s\" % (start_line_nb, stop_line_nb))\n                     if start_line_nb != stop_line_nb else\n                     start_line_nb),\n                     \" \".join(e.args)))\n        else:\n            print(\"shtest %d - success (line %s)\"\n                  % (block_nb + 1,\n                     (\"%s-%s\" % (start_line_nb, stop_line_nb))\n                     if start_line_nb != stop_line_nb else\n                     start_line_nb))"
            ]
        ]
    },
    {
        "blob_id": "95da0414284b1f8b0e0e098a72c08e474d19c39a",
        "matched_blocks": [
            [
                28,
                33,
                "        try:\n            self.client.connect(hostname=server['hostname'], username=server['username'], password=server['password'], timeout=2)\n        except:\n            self.msg = '\u8fdc\u7a0b\u8fde\u63a5\u5931\u8d25\u3002'\n        else:\n            self.msg = '\u8fdc\u7a0b\u8fde\u63a5\u6210\u529f\u3002'"
            ]
        ]
    },
    {
        "blob_id": "120ab67bf9db50d5b17f6192812e1eb729d8ee35",
        "matched_blocks": [
            [
                129,
                134,
                "          try:\n            r.get()\n          except ThriftLintError as e:\n            errors.append(str(e))\n          else:\n            vt.update()"
            ]
        ]
    },
    {
        "blob_id": "97c0f769b6cf5e65cc439aeb31a3fe3a98d4a8cc",
        "matched_blocks": [
            [
                990,
                1016,
                "            try:\n                self.firewall_driver.unfilter_instance(instance,\n                                                    network_info=network_info)\n            except libvirt.libvirtError as e:\n                try:\n                    state = self.get_info(instance)['state']\n                except exception.InstanceNotFound:\n                    state = power_state.SHUTDOWN\n\n                if state != power_state.SHUTDOWN:\n                    LOG.warn(_(\"Instance may be still running, destroy \"\n                               \"it again.\"), instance=instance)\n                    self._destroy(instance)\n                else:\n                    retry = False\n                    errcode = e.get_error_code()\n                    LOG.exception(_('Error from libvirt during unfilter. '\n                                'Code=%(errcode)s Error=%(e)s') %\n                              {'errcode': errcode, 'e': e},\n                              instance=instance)\n                    reason = \"Error unfiltering instance.\"\n                    raise exception.InstanceTerminationFailure(reason=reason)\n            except Exception:\n                retry = False\n                raise\n            else:\n                retry = False"
            ],
            [
                3839,
                3847,
                "                try:\n                    vcpus = dom.vcpus()\n                except libvirt.libvirtError as e:\n                    LOG.warn(_(\"couldn't obtain the vpu count from domain id:\"\n                               \" %(id)s, exception: %(ex)s\") %\n                               {\"id\": dom_id, \"ex\": e})\n                else:\n                    if vcpus is not None and len(vcpus) > 1:\n                        total += len(vcpus[1])"
            ]
        ]
    },
    {
        "blob_id": "c9b1515850d9fd52729c2940ff14a76ca7067f48",
        "matched_blocks": [
            [
                26,
                60,
                "            try:    # Main Menu\n                CLEAR()\n                print(border + '\\n\\tNumber Guessing Game!\\n' + '\\tby Carlos A. Marin\\n' + border + '\\n\\n') \n                print(border2 + '\\n\u2588 1. Play Game  \u2588 2. #1 player!  \u2588 3. Quit Game  \u2588\\n' + border2)\n                selection = int(input('\\n\\nEnter one of the corresponding numbers: '))\n            except ValueError:\n                CLEAR()\n                INVALID_OPTION()\n                continue\n            else:\n                if selection == 1:    # Play/Replay\n                    replay, high_score, high_score_player = game_instance(high_score, high_score_player) \n                    if replay:\n                        continue \n                    else:  \n                        game_running = False\n                        champion(high_score, high_score_player)\n                        break\n                elif selection == 2:    # High Score Board\n                    menu_high_score(high_score, high_score_player)\n                elif selection == 3:    # Quit\n                    asking_to_quit = True\n                    while asking_to_quit:\n                        CLEAR()\n                        quitting = menu_end_game()\n                        if quitting: \n                            champion(high_score, high_score_player)\n                            game_running, title_looping = False, False\n                        else:\n                            pass\n                        break\n                elif selection not in range(1,4):   # invalid selection.\n                    CLEAR()\n                    INVALID_OPTION()\n                    CLEAR()"
            ]
        ]
    },
    {
        "blob_id": "9f70e7d693a790e118fb08e999d58986e447a0d3",
        "matched_blocks": [
            [
                4,
                9,
                "try: \n    win32serviceutil.QueryServiceStatus('MysticLight2_Service')\nexcept:\n    print(\"Windows service NOT installed\")\nelse:\n    print(\"Windows service installed\")"
            ]
        ]
    },
    {
        "blob_id": "0acd863d75ed2a23366a1723960b38e8e7866ac9",
        "matched_blocks": [
            [
                148,
                158,
                "\t\ttry:\n\t\t\tindex = self._dict[value]\n\t\texcept KeyError:\n\t\t\traise ValueError\n\t\telse:\n\t\t\tstart = self._fix_neg_index(start)\n\t\t\tend = self._fix_end_index(end)\n\t\t\tif start <= index < end:\n\t\t\t\treturn index\n\t\t\telse:\n\t\t\t\traise ValueError"
            ],
            [
                414,
                419,
                "\t\ttry:\n\t\t\tindex = self._dict[value]\n\t\texcept KeyError:\n\t\t\traise ValueError('Value \"%s\" is not present.')\n\t\telse:\n\t\t\tdel self[index]"
            ],
            [
                277,
                286,
                "\t\t\ttry:\n\t\t\t\telem_index = self._dict[elem]\n\t\t\texcept KeyError:\n\t\t\t\tif raise_errors:\n\t\t\t\t\traise ValueError('Passed values contain elements not in self')\n\t\t\telse:\n\t\t\t\tif elem_index in indices_to_delete:\n\t\t\t\t\tif raise_errors:\n\t\t\t\t\t\traise ValueError('Passed vales contain duplicates')\n\t\t\t\tindices_to_delete.add(elem_index)"
            ]
        ]
    },
    {
        "blob_id": "afc681c375368f6eb304e34f5b8467c467624142",
        "matched_blocks": [
            [
                14,
                21,
                "    try:\n        x = next(g)\n        print('g==%d' % x)\n    except StopIteration as e:\n        print(\"generator return value:\", e.value)\n        break\n    else:\n        pass"
            ]
        ]
    },
    {
        "blob_id": "9800274aa785d86910a45c4ec7c59a8ed687722e",
        "matched_blocks": [
            [
                119,
                125,
                "        try:\n            assert self.mode == \"classification\"\n        except AssertionError:\n            raise NotImplementedError('Not supported for regression explanations.')\n        else:\n            ans = self.top_labels if self.top_labels else self.local_exp.keys()\n            return list(ans)"
            ]
        ]
    },
    {
        "blob_id": "23b9d302ab52d35d1cb3fdd270c785503d99aacb",
        "matched_blocks": [
            [
                63,
                76,
                "                try:\n                    level = int(level)\n                except:\n                    self.cancel((FinishingType.DIALOG), cancel_reason_msg='Invalid skill level returned from client.')\n                    return\n                else:\n                    tracker = sim.get_tracker(skill)\n                    stat = tracker.get_statistic(skill, add=True)\n                    if stat is None:\n                        self.cancel((FinishingType.FAILED_TESTS), cancel_reason_msg='Unable to add Skill due to entitlement restriction.')\n                        return\n                    if self.set_almost_level_up:\n                        skill_value = stat.get_skill_value_for_level(level) - 50\n                        tracker.set_value(skill, skill_value)"
            ]
        ]
    },
    {
        "blob_id": "25d8a958489f172d8b4dc0de07244709afe0657c",
        "matched_blocks": [
            [
                39,
                62,
                "try:\n    # Auto-save job;\n    save = driver.find_element_by_class_name(\"jobs-save-button\")\n    save.click()\n    sleep(2)\n\n    # Auto-apply for a job:\n    apply = driver.find_element_by_class_name(name=\"jobs-apply-button\")\n    apply.click()\n    sleep(1)\n\n    # Auto-fill phone number:\nexcept NoSuchElementException:\n    print(\"1 Job was not found\")\n\nelse:\n    phone = driver.find_element_by_id(\n        id_=\"urn:li:fs_easyApplyFormElement:(urn:li:fs_normalized_jobPosting:2328433260,15578714,phoneNumber~nationalNumber)\")\n    phone.send_keys(\"123456789\")\n    sleep(1)\n\n    # Auto-click Next button\n    next_button = driver.find_element_by_tag_name(name=\"button\")\n    next_button.click()"
            ]
        ]
    },
    {
        "blob_id": "e476d1f0c7ece849b3293e4a80cace40630faf9d",
        "matched_blocks": [
            [
                1018,
                1032,
                "        try:\n            generate.generate_rig(context, metarig)\n        except MetarigError as rig_exception:\n            import traceback\n            traceback.print_exc()\n\n            rigify_report_exception(self, rig_exception)\n        except Exception as rig_exception:\n            import traceback\n            traceback.print_exc()\n\n            self.report({'ERROR'}, 'Generation has thrown an exception: ' + str(rig_exception))\n        else:\n            target_rig = get_rigify_target_rig(metarig.data)\n            self.report({'INFO'}, f'Successfully generated: \"{target_rig.name}\"')"
            ],
            [
                1101,
                1107,
                "        try:\n            rig = rig_lists.rigs[self.metarig_type][\"module\"]\n            create_sample = rig.create_sample\n        except (ImportError, AttributeError, KeyError):\n            raise Exception(\"rig type '\" + self.metarig_type + \"' has no sample.\")\n        else:\n            create_sample(context.active_object)"
            ],
            [
                855,
                882,
                "            try:\n                rig = rig_lists.rigs[rig_name]['module']\n            except (ImportError, AttributeError, KeyError):\n                row = layout.row()\n                box = row.box()\n                box.label(text=\"ERROR: type \\\"%s\\\" does not exist!\" % rig_name, icon='ERROR')\n            else:\n                if hasattr(rig.Rig, 'parameters_ui'):\n                    rig = rig.Rig\n\n                try:\n                    param_cb = rig.parameters_ui\n\n                    # Ignore the known empty base method\n                    if getattr(param_cb, '__func__', None) == \\\n                            getattr(base_rig.BaseRig.parameters_ui, '__func__'):\n                        param_cb = None\n                except AttributeError:\n                    param_cb = None\n\n                if param_cb is None:\n                    col = layout.column()\n                    col.label(text=\"No options\")\n                else:\n                    col = layout.column()\n                    col.label(text=\"Options:\")\n                    box = layout.box()\n                    param_cb(box, get_rigify_params(bone))"
            ]
        ]
    },
    {
        "blob_id": "3528380cff77001beec0163795d68717740f5da0",
        "matched_blocks": [
            [
                48,
                53,
                "        try:\n            u = brentq(fu, k1, k2, disp=False)\n        except ValueError:\n            continue\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "be40015a757231d98d2320faf0efe805d98a9a3d",
        "matched_blocks": [
            [
                429,
                434,
                "            try:\n                c = Company.objects.get(pk = id)\n            except Company.DoesNotExist:\n                f  = CompanyForm(param_dict)\n            else:\n                    f = CompanyForm(param_dict, instance = c)"
            ],
            [
                530,
                535,
                "            try:\n                ie = InvoiceEntity.objects.get(pk = id)\n            except InvoiceEntity.DoesNotExist:\n                f = InvoiceEntityForm(param_dict)\n            else:\n                f = InvoiceEntityForm(param_dict, instance = ie)"
            ],
            [
                613,
                618,
                "            try:\n                ide = InvoiceDetail.objects.get(pk = id)\n            except InvoiceDetail.DoesNotExist:\n                f = InvoiceDetailForm(param_dict)\n            else:\n                f = InvoiceDetailForm(param_dict, instance = ide)"
            ]
        ]
    },
    {
        "blob_id": "b3f6e06ec271a24acb23628e036addff72b6bd18",
        "matched_blocks": [
            [
                121,
                149,
                "        try:\n            element_name = reference_to_qname(self.elem.attrib['ref'], self.namespaces)\n        except KeyError:\n            # No 'ref' attribute ==> 'name' attribute required.\n            self.qualified = self.elem.get('form', self.schema.element_form_default) == 'qualified'\n            try:\n                if self.is_global or self.qualified:\n                    self.name = get_qname(self.target_namespace, self.elem.attrib['name'])\n                else:\n                    self.name = self.elem.attrib['name']\n            except KeyError:\n                self._parse_error(\"missing both 'name' and 'ref' attributes.\")\n\n            if self.is_global:\n                if 'minOccurs' in self.elem.attrib:\n                    self._parse_error(\"attribute 'minOccurs' not allowed for a global element.\")\n                if 'maxOccurs' in self.elem.attrib:\n                    self._parse_error(\"attribute 'maxOccurs' not allowed for a global element.\")\n        else:\n            # Reference to a global element\n            if self.is_global:\n                self._parse_error(\"an element reference can't be global.\")\n            for attribute in ('name', 'type', 'nillable', 'default', 'fixed', 'form', 'block'):\n                if attribute in self.elem.attrib:\n                    self._parse_error(\"attribute %r is not allowed when element reference is used.\" % attribute)\n            xsd_element = self.maps.lookup_element(element_name)\n            self.name = xsd_element.name\n            self.type = xsd_element.type\n            self.qualified = xsd_element.qualified"
            ],
            [
                205,
                232,
                "        try:\n            head_element = self.maps.lookup_element(qname)\n        except KeyError:\n            self._parse_error(\"unknown substitutionGroup %r\" % substitution_group)\n        else:\n            final = head_element.final\n            if final is None:\n                final = self.schema.final_default\n\n            if final == '#all' or 'extension' in final and 'restriction' in final:\n                self._parse_error(\"head element %r cannot be substituted.\" % head_element)\n            elif self.type == head_element.type or self.type.name == XSD_ANY_TYPE:\n                pass\n            elif 'extension' in final and not self.type.is_derived(head_element.type, 'extension'):\n                self._parse_error(\n                    \"%r type is not of the same or an extension of the head element %r type.\"\n                    % (self, head_element)\n                )\n            elif 'restriction' in final and not self.type.is_derived(head_element.type, 'restriction'):\n                self._parse_error(\n                    \"%r type is not of the same or a restriction of the head element %r type.\"\n                    % (self, head_element)\n                )\n            elif not self.type.is_derived(head_element.type):\n                self._parse_error(\n                    \"%r type is not of the same or a derivation of the head element %r type.\"\n                    % (self, head_element)\n                )"
            ],
            [
                451,
                489,
                "            try:\n                tag = elem[index].tag\n            except TypeError:\n                # elem is a lxml.etree.Element and elem[index] is a <class 'lxml.etree._Comment'>:\n                # in this case elem[index].tag is a <cyfunction Comment>, not subscriptable. So\n                # decode nothing and take the next.\n                pass\n            except IndexError:\n                if validation != 'skip' and model_occurs == 0 and self.min_occurs > 0:\n                    error = XMLSchemaChildrenValidationError(self, elem, index, self.prefixed_name)\n                    yield self._validation_error(error, validation)\n                else:\n                    yield index\n                return\n            else:\n                if tag == self.name:\n                    yield self, elem[index]\n                elif not self.qualified and tag == get_qname(self.target_namespace, self.name):\n                    yield self, elem[index]\n                elif self.name in self.maps.substitution_groups:\n                    for e in self.schema.substitution_groups[self.name]:\n                        if tag == e.name:\n                            yield e, elem[index]\n                            break\n                    else:\n                        if validation != 'skip' and model_occurs == 0 and self.min_occurs > 0:\n                            error = XMLSchemaChildrenValidationError(self, elem, index, self.prefixed_name)\n                            yield self._validation_error(error, validation)\n                        else:\n                            yield index\n                        return\n\n                else:\n                    if validation != 'skip' and model_occurs == 0 and self.min_occurs > 0:\n                        error = XMLSchemaChildrenValidationError(self, elem, index, self.prefixed_name)\n                        yield self._validation_error(error, validation)\n                    else:\n                        yield index\n                    return"
            ]
        ]
    },
    {
        "blob_id": "afc8ca87b00e403047ba909fd9db183eb1914e28",
        "matched_blocks": [
            [
                161,
                169,
                "    try:\n        # pylint: disable-next=import-outside-toplevel\n        import MySQLdb.converters as MySQLdb_converters\n    except ImportError:\n        pass\n    else:\n        MySQLdb_converters.conversions[\n            HAFakeDatetime\n        ] = MySQLdb_converters.DateTime2literal"
            ]
        ]
    },
    {
        "blob_id": "fa8160655f29d23f7a4674f26b66153cc3c04efc",
        "matched_blocks": [
            [
                75,
                88,
                "        try:\n            log.info(f\"\u8bf7\u6c42\u671f\u671b\u8fd4\u56de\u7801\uff1a{case.expected_code}\uff0c\u8bf7\u6c42\u5b9e\u9645\u8fd4\u56de\u7801\uff1a{res_code}\")\n            self.assertEqual(case.expected_code, res_code)\n            if case.check_sql:\n                case.check_sql = sub_conf(case.check_sql)\n                new_status = self.mysql.find_one(case.check_sql)[0]\n                log.info(f\"\u5ba1\u6838\u540e\u8be5\u6807\u671f\u671b\u72b6\u6001\uff1a{eval(case.data)['status']}\uff0c\u5ba1\u6838\u540e\u8be5\u6807\u5b9e\u9645\u72b6\u6001\uff1a{new_status}\")\n                self.assertEqual(eval(case.data)[\"status\"], new_status)\n        except AssertionError as e:\n            result = \"\u672a\u901a\u8fc7\"\n            log.exception(e)\n            raise e\n        else:\n            result = \"\u901a\u8fc7\""
            ]
        ]
    },
    {
        "blob_id": "b874247bc7250254be315256308819b4f715e819",
        "matched_blocks": [
            [
                96,
                101,
                "            try:\n                ObjectId(d)\n            except ValidationError as e:\n                current_app.logger.exception(e)\n            else:\n                ret.append(d)"
            ]
        ]
    },
    {
        "blob_id": "39ca496b4f97ca8ca3e91ec6b85c7e6d83811447",
        "matched_blocks": [
            [
                668,
                680,
                "        try:\n            if method == \"POST\":\n                f = urlopen(req, data=request_data)\n            else:\n                f = urlopen(req)\n        except HTTPError as e:\n            message = \"HTTP %s: %s\" % (e.code, e.reason)\n        else:\n            # Parse the response\n            try:\n                response = json.load(f)\n            except ValueError as e:\n                message = sys.exc_info()[1]"
            ]
        ]
    },
    {
        "blob_id": "d46afcf0a7717281f0e1c4ad41cb9648f502ea42",
        "matched_blocks": [
            [
                1216,
                1227,
                "      try:\n        ret = conversion_func(\n            value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n      except (TypeError, ValueError):\n        # Could not coerce the conversion to use the preferred dtype.\n        pass\n      else:\n        if (ret is not NotImplemented and\n            ret.dtype.base_dtype != preferred_dtype.base_dtype):\n          raise TypeError(\"convert_to_tensor did not convert to \"\n                          \"the preferred dtype: %s vs %s \" %\n                          (ret.dtype.base_dtype, preferred_dtype.base_dtype))"
            ],
            [
                3466,
                3474,
                "      try:\n        container_attr = op.get_attr(\"container\")\n      except ValueError:\n        # \"container\" attribute is not in OpDef\n        pass\n      else:\n        if not container_attr:\n          op._set_attr(\"container\", attr_value_pb2.AttrValue(  # pylint: disable=protected-access\n              s=compat.as_bytes(self._container)))"
            ]
        ]
    },
    {
        "blob_id": "dfb5039d76388d0ca22ae58a137310e8788dca7a",
        "matched_blocks": [
            [
                178,
                189,
                "\ttry:\n\t\tcls = Task.classes[name]\n\texcept KeyError:\n\t\tpass\n\telse:\n\t\tcls.no_gccdeps_post_run = cls.post_run\n\t\tcls.no_gccdeps_scan = cls.scan\n\t\tcls.no_gccdeps_sig_implicit_deps = cls.sig_implicit_deps\n\n\t\tcls.post_run = post_run\n\t\tcls.scan = scan\n\t\tcls.sig_implicit_deps = sig_implicit_deps"
            ]
        ]
    },
    {
        "blob_id": "edd449ccfc50d0d27492a36069888f01d62ffa9b",
        "matched_blocks": [
            [
                1067,
                1129,
                "            try:\n                if work and not continuous:\n                    self.logger.info('Request \"%s\" already split - Resuming' % inbound['RequestName'])\n                else:\n                    work, totalStats, rejectedWork = self._splitWork(inbound['WMSpec'], data=inbound['Inputs'],\n                                                                     mask=inbound['Mask'], inbound=inbound,\n                                                                     continuous=continuous)\n\n                    # save inbound work to signal we have completed queueing\n                    self.backend.insertElements(work, parent=inbound)  # if this fails, rerunning will pick up here\n\n                    if not continuous:\n                        # Update to Acquired when it's the first processing of inbound work\n                        self.backend.updateInboxElements(inbound.id, Status='Acquired')\n\n                    # store the inputs in the global queue inbox workflow element\n                    if not self.params.get('LocalQueueFlag'):\n                        processedInputs = []\n                        for unit in work:\n                            processedInputs.extend(unit['Inputs'].keys())\n                        if processedInputs or rejectedWork:\n                            chunkSize = 20\n                            chunkProcessed = processedInputs[:chunkSize]\n                            chunkRejected = rejectedWork[:chunkSize]\n                            # TODO:Make this a POST update, instead of several PUT\n                            while processedInputs or rejectedWork:\n                                self.backend.updateInboxElements(inbound.id, ProcessedInputs=chunkProcessed,\n                                                                 RejectedInputs=chunkRejected,\n                                                                 options={'incremental': True})\n                                processedInputs = processedInputs[chunkSize:]\n                                rejectedWork = rejectedWork[chunkSize:]\n                                chunkProcessed = processedInputs[:chunkSize]\n                                chunkRejected = rejectedWork[:chunkSize]\n                        # if global queue, then update workflow stats to request mgr couch doc\n                        # remove the \"UnittestFlag\" - need to create the reqmgrSvc emulator\n                        if not self.params.get(\"UnittestFlag\", False):\n                            self.reqmgrSvc.updateRequestStats(inbound['WMSpec'].name(), totalStats)\n\n            except TERMINAL_EXCEPTIONS as ex:\n                if not continuous:\n                    # Only fail on first splitting\n                    self.logger.info('Failing workflow \"%s\": %s' % (inbound['RequestName'], str(ex)))\n                    self.backend.updateInboxElements(inbound.id, Status='Failed')\n                    if throw:\n                        raise\n            except Exception as ex:\n                if continuous:\n                    continue\n                # if request has been failing for too long permanently fail it.\n                # last update time was when element was assigned to this queue\n                if (float(inbound.updatetime) + self.params['QueueRetryTime']) < time.time():\n                    self.logger.info('Failing workflow \"%s\" as not queued in %d secs: %s' % (inbound['RequestName'],\n                                                                                             self.params[\n                                                                                                 'QueueRetryTime'],\n                                                                                             str(ex)))\n                    self.backend.updateInboxElements(inbound.id, Status='Failed')\n                else:\n                    self.logger.info('Exception splitting work for wmspec \"%s\": %s' % (inbound['RequestName'], str(ex)))\n                if throw:\n                    raise\n                continue\n            else:\n                result.extend(work)"
            ]
        ]
    },
    {
        "blob_id": "dff1d0b04701e64a7c2a7d88a152a506dd7ffa08",
        "matched_blocks": [
            [
                51,
                57,
                "        try:\n            bars_list = self.latest_symbol_data[symbol]\n        except KeyError:\n            print('\u8be5\u671f\u6743\u5728\u5386\u53f2\u6570\u636e\u4e2d\u4e0d\u5b58\u5728')\n            raise\n        else:\n            return bars_list[-1]"
            ],
            [
                61,
                67,
                "        try:\n            bars_list = self.latest_symbol_data[symbol]\n        except KeyError:\n            print('\u8be5\u671f\u6743\u5728\u5386\u53f2\u6570\u636e\u4e2d\u4e0d\u5b58\u5728')\n            raise\n        else:\n            return bars_list[-N:]"
            ],
            [
                71,
                77,
                "        try:\n            bars_list = self.latest_symbol_data[symbol]\n        except KeyError:\n            print('\u8be5\u671f\u6743\u5728\u5386\u53f2\u6570\u636e\u4e2d\u4e0d\u5b58\u5728')\n            raise\n        else:\n            return bars_list[-1][0]"
            ],
            [
                81,
                87,
                "        try:\n            bars_list = self.latest_symbol_data[symbol]\n        except KeyError:\n            print('\u8be5\u671f\u6743\u5728\u5386\u53f2\u6570\u636e\u4e2d\u4e0d\u5b58\u5728')\n            raise\n        else:\n            return getattr(bars_list[-1][1], val_type)"
            ],
            [
                91,
                97,
                "        try:\n            bars_list = self.get_latest_bars(symbol, N)\n        except KeyError:\n            print('\u8be5\u671f\u6743\u5728\u5386\u53f2\u6570\u636e\u4e2d\u4e0d\u5b58\u5728')\n            raise\n        else:\n            return np.array([getattr(b[1], val_type) for b in bars_list])"
            ],
            [
                102,
                108,
                "            try:\n                bar = next(self._get_new_bar(s))\n            except StopIteration:\n                self.continue_backtest = False\n            else:\n                if bar is not None:\n                    self.latest_symbol_data[s].append(bar)"
            ]
        ]
    },
    {
        "blob_id": "e6f51b04e362267f3c2c2555c5394eb5c42ea078",
        "matched_blocks": [
            [
                13,
                27,
                "            try:\n                if '><BOT><' in line.line:\n                    continue\n\n                parser.parse_line(\n                    line.ip_address, line.line,\n                    save_unknown=False)\n            except Exception as e:\n                raise\n            else:\n                continue\n                delete = raw_input('delete? (y/N)')\n                # TODO - remove question\n                if delete.strip().lower() == 'y':\n                    line.delete()"
            ]
        ]
    },
    {
        "blob_id": "1f9a0fd102eee43bc52330776362f15d9527ce8b",
        "matched_blocks": [
            [
                141,
                146,
                "try:\n    import sphinxcontrib.spelling  # noqa\nexcept ImportError:\n    pass\nelse:\n    extensions.append(\"sphinxcontrib.spelling\")"
            ]
        ]
    },
    {
        "blob_id": "1303b75afc237145713c6df58b638375ce540aac",
        "matched_blocks": [
            [
                1065,
                1073,
                "        try:\n            stage_base = model.getstage(base)\n        except ValueError:\n            messages.append(\"invalid base index spec: %r\" % (base,))\n        else:\n            if stage_base is None:\n                messages.append(\"base index %r does not exist\" %(base,))\n            else:\n                newbases.append(stage_base.name)"
            ]
        ]
    },
    {
        "blob_id": "36a3ad6e74b2107f1ce2b6010ca07d97786d0356",
        "matched_blocks": [
            [
                490,
                517,
                "            try:\n                cursor.execute(query, [\n                    case.case_id,\n                    case,\n                    transactions_to_save,\n                    indices_to_save_or_update,\n                    attachments_to_save,\n                    index_ids_to_delete,\n                    attachment_ids_to_delete\n                ])\n                result = fetchone_as_namedtuple(cursor)\n                case.id = result.case_pk\n                case.clear_tracked_models()\n            except InternalError as e:\n                if logging.root.isEnabledFor(logging.DEBUG):\n                    msg = 'save_case_and_related_models called with args: \\n{}, {}, {}, {} ,{} ,{}'.format(\n                        case_adapter(case).getquoted(),\n                        [case_transaction_adapter(t).getquoted() for t in transactions_to_save],\n                        [case_index_adapter(i).getquoted() for i in indices_to_save_or_update],\n                        [case_attachment_adapter(a).getquoted() for a in attachments_to_save],\n                        index_ids_to_delete,\n                        attachment_ids_to_delete\n                    )\n                    logging.debug(msg)\n                raise CaseSaveError(e)\n            else:\n                for attachment in case.get_tracked_models_to_delete(CaseAttachmentSQL):\n                    attachment.delete_content()"
            ]
        ]
    },
    {
        "blob_id": "246e1b2cf0d380f81cd362844ad269f57e6c1473",
        "matched_blocks": [
            [
                216,
                221,
                "        try:\n            old_tenant = Tenant.objects.get(pk=data['oauthId'])\n        except Tenant.DoesNotExist:\n            pass\n        else:\n            old_tenant.delete()"
            ]
        ]
    },
    {
        "blob_id": "0770d2c11aa10133b98c39627fe8b603309d2098",
        "matched_blocks": [
            [
                12,
                27,
                "    try:\n        mqhost = \"35.197.19.215\"\n        mqport = 31706\n        credentials = PlainCredentials(\"user\", \"rabbit-password\")\n        rabbit = BlockingConnection(ConnectionParameters(\n            host=mqhost,\n            port=mqport,\n            virtual_host=\"crawler\",\n            connection_attempts=10,\n            retry_delay=1,\n            credentials=credentials))\n    except Exception as e:\n        print(\"connect_to_MQ crawler Failed connect to MQ\")\n        print(e)\n    else:\n        print('connect_to_MQ crawler - Successfully connected to MQ host {}'.format(mqhost))"
            ]
        ]
    },
    {
        "blob_id": "9cfb04bb3c7e12f3fc6d5f421c4c9b4cb3385195",
        "matched_blocks": [
            [
                7536,
                7541,
                "    try:\n        len(seq)\n    except TypeError:\n        return list(seq)\n    else:\n        return seq"
            ],
            [
                5676,
                5690,
                "        try:\n            loc = self.get_loc(label)\n        except (KeyError, TypeError):\n            # KeyError -> No exact match, try for padded\n            # TypeError -> passed e.g. non-hashable, fall through to get\n            #  the tested exception message\n            indexer = self.get_indexer([label], method=\"pad\")\n            if indexer.ndim > 1 or indexer.size > 1:\n                raise TypeError(\"asof requires scalar valued input\")\n            loc = indexer.item()\n            if loc == -1:\n                return self._na_value\n        else:\n            if isinstance(loc, slice):\n                loc = loc.indices(len(self))[-1]"
            ],
            [
                3523,
                3537,
                "            try:\n                res_indexer, indexer, _ = self._inner_indexer(other)\n            except TypeError:\n                # non-comparable; should only be for object dtype\n                pass\n            else:\n                # TODO: algos.unique1d should preserve DTA/TDA\n                if is_numeric_dtype(self):\n                    # This is faster, because Index.unique() checks for uniqueness\n                    # before calculating the unique values.\n                    res = algos.unique1d(res_indexer)\n                else:\n                    result = self.take(indexer)\n                    res = result.drop_duplicates()\n                return ensure_wrapped_if_datetimelike(res)"
            ],
            [
                6784,
                6791,
                "            try:\n                ts_start = Timestamp(start)\n                ts_end = Timestamp(end)\n            except (ValueError, TypeError):\n                pass\n            else:\n                if not tz_compare(ts_start.tzinfo, ts_end.tzinfo):\n                    raise ValueError(\"Both dates must have the same UTC offset\")"
            ]
        ]
    },
    {
        "blob_id": "02d251a76b26d931a530632a76341533223e7a48",
        "matched_blocks": [
            [
                175,
                180,
                "        try:\n            a.pos\n        except AttributeError:\n            pass\n        else:\n            assert False"
            ]
        ]
    },
    {
        "blob_id": "56f6d10093beb624fc3c3315f321c81dc738c8c0",
        "matched_blocks": [
            [
                345,
                365,
                "                try:\n                    check_array(X, dtype=np.int)\n                except ValueError:\n                    self._legacy_mode = False\n                    self._categories = 'auto'\n                else:\n                    msg = (\n                        \"The handling of integer data will change in version \"\n                        \"0.22. Currently, the categories are determined \"\n                        \"based on the range [0, max(values)], while in the \"\n                        \"future they will be determined based on the unique \"\n                        \"values.\\nIf you want the future behaviour and \"\n                        \"silence this warning, you can specify \"\n                        \"\\\"categories='auto'\\\".\\n\"\n                        \"In case you used a LabelEncoder before this \"\n                        \"OneHotEncoder to convert the categories to integers, \"\n                        \"then you can now use the OneHotEncoder directly.\"\n                    )\n                    warnings.warn(msg, FutureWarning)\n                    self._legacy_mode = True\n                    self._n_values = 'auto'"
            ]
        ]
    },
    {
        "blob_id": "5af24da10e11fccc1343cc0d16e6ac4ca6982dda",
        "matched_blocks": [
            [
                231,
                239,
                "        try:\n            pms_data = pms5003.read()\n        except pmsReadTimeoutError:\n            logging.warn(\"Failed to read PMS5003\")\n        else:\n            save_data(7, float(pms_data.pm_ug_per_m3(1.0)))\n            save_data(8, float(pms_data.pm_ug_per_m3(2.5)))\n            save_data(9, float(pms_data.pm_ug_per_m3(10)))\n            display_everything()"
            ]
        ]
    },
    {
        "blob_id": "09dd43029927a441b357dfb67a390c25dd502a97",
        "matched_blocks": [
            [
                251,
                318,
                "    try:\n        page_list = pages_module.page_sequence\n    except:\n        helper.add_error(\n            '{}.py is missing the variable page_sequence.'.format(\n                views_or_pages),\n            numeric_id=21\n        )\n        return\n    else:\n        for i, ViewCls in enumerate(page_list):\n            # there is no good reason to include Page in page_sequence.\n            # As for WaitPage: even though it works fine currently\n            # and can save the effort of subclassing,\n            # we should restrict it, because:\n            # - one user had \"class WaitPage(Page):\".\n            # - if someone makes \"class WaitPage(WaitPage):\", they might\n            #   not realize why it's inheriting the extra behavior.\n            # overall, I think the small inconvenience of having to subclass\n            # once per app\n            # is outweighed by the unexpected behavior if someone subclasses\n            # it without understanding inheritance.\n            # BUT: built-in Trust game had a wait page called WaitPage.\n            # that was fixed on Aug 24, 2017, need to wait a while...\n            # see below in ensure_no_misspelled_attributes,\n            # we can get rid of a check there also\n            if ViewCls.__name__ == 'Page':\n                msg = (\n                    \"page_sequence cannot contain \"\n                    \"a class called 'Page'.\"\n                )\n                helper.add_error(msg, numeric_id=22)\n            if ViewCls.__name__ == 'WaitPage':\n                msg = (\n                    \"page_sequence cannot contain \"\n                    \"a class called 'WaitPage'.\"\n                )\n                helper.add_warning(msg, numeric_id=221)\n\n            if issubclass(ViewCls, WaitPage):\n                if ViewCls.group_by_arrival_time:\n                    if i > 0:\n                        helper.add_error(\n                            '\"{}\" has group_by_arrival_time=True, so '\n                            'it must be placed first in page_sequence.'.format(\n                                ViewCls.__name__), numeric_id=23)\n                    if ViewCls.wait_for_all_groups:\n                        helper.add_error(\n                            'Page \"{}\" has group_by_arrival_time=True, so '\n                            'it cannot have wait_for_all_groups=True also.'.format(\n                                ViewCls.__name__), numeric_id=24)\n                # alternative technique is to not define the method on WaitPage\n                # and then use hasattr, but I want to keep all complexity\n                # out of views.abstract\n                elif (\n                            ViewCls.get_players_for_group != WaitPage.get_players_for_group):\n                    helper.add_error(\n                        'Page \"{}\" defines get_players_for_group, '\n                        'but in order to use this method, you must set '\n                        'group_by_arrival_time=True'.format(\n                            ViewCls.__name__), numeric_id=25)\n            elif issubclass(ViewCls, Page):\n                pass  # ok\n            else:\n                msg = '\"{}\" is not a valid page'.format(ViewCls)\n                helper.add_error(msg, numeric_id=26)\n\n            ensure_no_misspelled_attributes(ViewCls, helper)"
            ],
            [
                145,
                199,
                "                try:\n                    attr_value = getattr(Model, attr_name)\n                    _type = type(attr_value)\n                except AttributeError:\n                    # I got \"The 'q_country' attribute can only be accessed\n                    # from Player instances.\"\n                    # can just filter/ignore these.\n                    pass\n                else:\n                    if _type in model_field_substitutes.keys():\n                        msg = (\n                            'NonModelFieldAttr: '\n                            '{} has attribute \"{}\", which is not a model field, '\n                            'and will therefore not be saved '\n                            'to the database.'.format(Model.__name__,\n                                                      attr_name))\n\n                        helper.add_error(\n                            msg,\n                            numeric_id=111,\n                            hint='Consider changing to \"{} = models.{}(initial={})\"'.format(\n                                attr_name, model_field_substitutes[_type],\n                                repr(getattr(Model, attr_name)))\n                        )\n                    # if people just need an iterable of choices for a model field,\n                    # they should use a tuple, not list or dict\n                    elif _type in {list, dict, set}:\n                        warning = (\n                            'MutableModelClassAttr: '\n                            '{ModelName}.{attr} is a {type_name}. '\n                            'Modifying it during a session (e.g. appending or setting values) '\n                            'will have unpredictable results; '\n                            'you should use '\n                            'session.vars or participant.vars instead. '\n                            'Or, if this {type_name} is read-only, '\n                            \"then it's recommended to move it outside of this class \"\n                            '(e.g. put it in Constants).'\n                        ).format(ModelName=Model.__name__,\n                                 attr=attr_name,\n                                 type_name=_type.__name__)\n\n                        helper.add_error(warning, numeric_id=112)\n                    # isinstance(X, type) means X is a class, not instance\n                    elif (isinstance(attr_value, type) and\n                              issubclass(attr_value,\n                                         django.db.models.fields.Field)):\n                        msg = (\n                            '{}.{} is missing parentheses.'\n                        ).format(Model.__name__, attr_name)\n                        helper.add_error(\n                            msg, numeric_id=113,\n                            hint=(\n                                'Consider changing to \"{} = models.{}()\"'\n                            ).format(attr_name, attr_value.__name__)\n                        )"
            ]
        ]
    },
    {
        "blob_id": "0f1183e97da07bd5f49d57e484c565872ba37049",
        "matched_blocks": [
            [
                8,
                24,
                "try:\n    import pygtk\n    pygtk.require(\"2.0\")\nexcept:\n    skip = \"GTK 2.0 not available\"\nelse:\n    try:\n        import gtk\n    except ImportError:\n        skip = \"GTK 2.0 not available\"\n    except RuntimeError:\n        skip = \"Old version of GTK 2.0 requires DISPLAY, and we don't have one.\"\n    else:\n        if gtk.gtk_version[0] == 1:\n            skip = \"Requested GTK 2.0, but 1.0 was already imported.\"\n        else:\n            from twisted.manhole.ui.gtk2manhole import ConsoleInput"
            ],
            [
                14,
                24,
                "    try:\n        import gtk\n    except ImportError:\n        skip = \"GTK 2.0 not available\"\n    except RuntimeError:\n        skip = \"Old version of GTK 2.0 requires DISPLAY, and we don't have one.\"\n    else:\n        if gtk.gtk_version[0] == 1:\n            skip = \"Requested GTK 2.0, but 1.0 was already imported.\"\n        else:\n            from twisted.manhole.ui.gtk2manhole import ConsoleInput"
            ]
        ]
    },
    {
        "blob_id": "0a4ad504f4b56f616a7509a5be3662c878de56ac",
        "matched_blocks": [
            [
                88,
                98,
                "        try:\n            cell_student_number = self.tableWidget.item(self.row, 0).text()\n            self.window = QtWidgets.QMainWindow()\n            self.ui = updatewindow(self)\n            self.ui.setupUi(self.window)\n            self.ui.insertData(cell_student_number)\n            self.window.show()\n        except:\n            pass\n        else:\n            return"
            ]
        ]
    },
    {
        "blob_id": "4f42a7ae7350057cc525ee09756fdd24e97a4ba4",
        "matched_blocks": [
            [
                30,
                35,
                "    try:\n        wallet = Wallet.objects.get(user__email=email)\n    except Wallet.DoesNotExist:\n        raise NotFound(f'There is no data for user with email {email}')\n    else:\n        return wallet"
            ],
            [
                107,
                119,
                "    try:\n        rate = Rate.objects.values_list(\n            'rate', flat=True\n        ).get(\n            asset=base_asset,\n            quote=quote_asset,\n        )\n    except Rate.DoesNotExist:\n        raise NotFound(\n            f'Rates for {base_asset} and {quote_asset} currencies not found'\n        )\n    else:\n        return rate * amount / settings.MULTIPLICITY"
            ]
        ]
    },
    {
        "blob_id": "89847b62912e707f2f6ae4a27d21d693a1b10d3b",
        "matched_blocks": [
            [
                44,
                49,
                "            try:\n                handle = int(tag.value, 16)\n            except ValueError:\n                print('invalid handle at line number %d' % iterator.lineno)\n            else:\n                handles.append(handle)"
            ]
        ]
    },
    {
        "blob_id": "67ac08d0353b696c9bbdb0a34b1eeb8d8dd15ac5",
        "matched_blocks": [
            [
                6,
                21,
                "    try:\n        fh = open(\"test_doc/io.txt\", \"r\")\n        try:\n            readline = fh.readline()\n        finally:\n            print('\u5173\u95ed\u6587\u4ef6')\n            fh.write(\"\")  # \u6b64\u5904\u51fa\u9519\u4f1a\u88ab\u5916\u9762\u7684except\u6355\u6349\n            # fh.close()\n    # except: # \u4f1a\u6355\u83b7\u6240\u6709\u5f02\u5e38\n    except (IOError, SyntaxError):\n        print('error:\u6ca1\u6709\u627e\u5230\u5bf9\u5e94\u6587\u4ef6\u6216\u6587\u4ef6\u5939')\n    # except BaseException:  # \u6240\u6709\u5f02\u5e38\u7684\u57fa\u7c7b\n    #     print(\"\u83b7\u53d6\u6240\u6709\u5f02\u5e38\")\n    else:  # \u5982\u679c\u6ca1\u6709\u51fa\u73b0\u5f02\u5e38\n        fh.close()\n        print(fh.closed)"
            ]
        ]
    },
    {
        "blob_id": "48730b554266d5b07e5fccf53e63ab5aaf815f20",
        "matched_blocks": [
            [
                30,
                36,
                "        try: resp = urllib.request.urlopen(url + data)\n        except urllib.error.URLError as e:\n            log.error('Wolfram failed - ({}) reason: {}'.format(e.code, e.reason))\n        except urllib.error.HTTPError as e:\n            log.error('Wolfram failed - ({}) reason: {}'.format(e.code, e.reason))\n        else:\n            text_return = resp.read()"
            ]
        ]
    },
    {
        "blob_id": "6da511645e7a197feda5f07313d5b595c8da81ab",
        "matched_blocks": [
            [
                24,
                65,
                "        try:\n            if Url.query.count() > current_app.config['URL_LIMIT']:\n                raise Exception(f\"URL\u8d85\u9650\u4e86\uff01\u8bf7\u5148\u6e05\u7a7a\uff01[{Url.query.count()}/{current_app.config['URL_LIMIT']}]\")\n            urls = form.urls.data.split('\\n')\n            headers = {\n                'User-Agent':\n                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36'\n            }\n            responses = [\n                requests.get(url.strip(), headers=headers) for url in urls\n            ]\n            if form.search.data:\n                if form.use_regex.data is True:\n                    extracted_urls = [\n                        links(resp, pattern=form.search.data)\n                        for resp in responses\n                    ]\n                else:\n                    extracted_urls = [\n                        links(resp, search=form.search.data)\n                        for resp in responses\n                    ]\n            else:\n                extracted_urls = [links(resp) for resp in responses]\n            extracted_urls = list(flatten(extracted_urls))\n            if len(extracted_urls) == 0:\n                raise Exception('\u554a\u561e\uff1f\u5565\u90fd\u6ca1\u6355\u6349\u5230\u54e6U_U')\n        except Exception as e:\n            flash(e, 'danger')\n        else:\n            flash(\n                Markup(\n                    f\"\u6210\u529f\u6355\u83b7\u5230{len(extracted_urls)}\u6761url XD <a href={url_for('main.show_urls')}>\u7acb\u5373\u67e5\u770b</a>\"\n                ), 'success')\n            for extracted_url in extracted_urls:\n                if not Url.query.filter_by(body=extracted_url).first():\n                    url = Url(\n                        body=extracted_url,\n                        owner=current_user._get_current_object())\n                    db.session.add(url)\n            db.session.commit()\n            return redirect(url_for('main.extract'))"
            ]
        ]
    },
    {
        "blob_id": "095063eb58ea91e18b1b4834b8eb7a36dfa144c3",
        "matched_blocks": [
            [
                350,
                359,
                "        try:\n            assert isinstance(other, Key)\n            assert set(self.__dict__.keys()) == set(other.__dict__.keys())\n\n            for key in self.public_members:\n                assert getattr(other, key) == getattr(self, key)\n        except AssertionError:\n            return False\n        else:\n            return True"
            ],
            [
                516,
                528,
                "        try:\n            self.d = self.key.d\n        except AttributeError:\n            pass\n        else:\n            for param in [\"p\", \"q\"]:\n                try:\n                    val = getattr(self.key, param)\n                except AttributeError:\n                    pass\n                else:\n                    if val:\n                        setattr(self, param, val)"
            ],
            [
                934,
                939,
                "        try:\n            v = getattr(key, attr)\n        except AttributeError:\n            pass\n        else:\n            setattr(c, attr, v)"
            ],
            [
                334,
                340,
                "            try:\n                _ = base64url_to_long(item)\n            except Exception:\n                return False\n            else:\n                if [e for e in ['+', '/', '='] if e in item]:\n                    return False"
            ],
            [
                372,
                377,
                "            try:\n                _val = ser[elem]\n            except KeyError:  # should never happen with the required set\n                pass\n            else:\n                _se.append('\"{}\":{}'.format(elem, json.dumps(_val)))"
            ],
            [
                522,
                528,
                "                try:\n                    val = getattr(self.key, param)\n                except AttributeError:\n                    pass\n                else:\n                    if val:\n                        setattr(self, param, val)"
            ],
            [
                452,
                457,
                "                        try:\n                            val = long(deser(item))\n                        except Exception:\n                            raise\n                        else:\n                            setattr(self, param, val)"
            ]
        ]
    },
    {
        "blob_id": "5b9c0e206b86e2585a80ab29c9c40d176a3f73ae",
        "matched_blocks": [
            [
                596,
                607,
                "                    try:\n                        include_config_loader = ConfigFileLoader(include_file_name_full, path_list = config_loader.path_list)\n                        self._read_config(include_config_loader)\n\n                    except ConfigLoadFormatException:\n                        raise\n\n                    except ConfigLoadException:\n                        log.debug(\"Skipped optional config: '{}'\".format(include_file_name_full))\n\n                    else:\n                        log.info(\"Included optional config: {} into {}\".format(include_config_loader.names, config_loader.names))"
            ]
        ]
    },
    {
        "blob_id": "2cd1a3aee02fc7aea93ed6ed2048b5d58f70e9ed",
        "matched_blocks": [
            [
                7,
                29,
                "try:\n    conexao = sqlite3.connect('data/pessoa.db')\nexcept Exception as err: \n    print('Erro ao conectar com o banco de dados')\nelse:\n    cursor = conexao.cursor()\n    \n    nome = \"Joana\"\n    sobrenome = \"Zanelato\"\n    cpf = 211111\n    idade = 30\n    estado = 'SP'\n    \n    sql_string = f\"\"\"\n        insert into pessoa(cpf,nome,sobrenome,idade,estado)\n        values({cpf},\"{nome}\",\"{sobrenome}\",{idade},\"{estado}\");\n    \"\"\"\n    \n    cursor.execute(sql_string)\n    \n    conexao.commit()\n    \n    conexao.close()"
            ]
        ]
    },
    {
        "blob_id": "b1bf853d8d3b7fd71de686100a600d46555171c6",
        "matched_blocks": [
            [
                20,
                26,
                "    try:\n        ch = int(input(\"1.add\\n2.sub\\n3.mul\\n4.div\\n5.mod\\ninput- \").strip())\n    except ValueError as e:\n        print(\"error!!!!!.......\",e)\n        main()\n    else:\n        print()"
            ],
            [
                27,
                33,
                "    try:\n        x = int(input(\"enter a no. - \").strip())\n        y = int(input(\"enter a no. - \").strip())\n    except Exception as e:\n        print(\"there was an error.....\",e)\n    else:\n        print()"
            ]
        ]
    },
    {
        "blob_id": "4f96b031d9f3387eccf4999dad0b6f4a5bea4b30",
        "matched_blocks": [
            [
                2,
                11,
                "    try:\n        import uvloop  # noqa\n    except ImportError:  # pragma: no cover\n        from uvicorn.loops.asyncio import asyncio_setup as loop_setup\n\n        loop_setup()\n    else:\n        from uvicorn.loops.uvloop import uvloop_setup\n\n        uvloop_setup()"
            ]
        ]
    },
    {
        "blob_id": "927997fed91afc709b135d2ba691baae52e11531",
        "matched_blocks": [
            [
                257,
                275,
                "        try:\n            for name,par in self.ui_params.items():\n                self.flu_par.add(name, value=float(par[0].text()), vary=par[1].isChecked(),\n                                       min=self.par_limits[name][0], max=self.par_limits[name][1],\n                                       expr=None, brute_step=None)\n        except ValueError as VE:\n            print(\"ValueError: \", VE)\n        else:\n            # fitting (if any) parameters for reflectivity\n            self.ref_par = lm.Parameters()\n                # add tuples:       (NAME       VALUE   VARY MIN  MAX  EXPR BRUTE_STEP)\n            self.ref_par.add_many( ('rho_t', self.sys_par['rho_top'], 0, None, None, None, None),\n                                   ('rho_b', self.sys_par['rho_bot'], 0, None, None, None, None),\n                                   ('mu_t', self.sys_par['mu_top_inc'], 0, None, None, None, None),\n                                   ('mu_b', self.sys_par['mu_bot_inc'], 0, None, None, None, None),\n                                   ('sigma0', 3.0, 0, None, None, None, None),\n                                   ('q_off', 0, 0, None, None, None, None ))\n            # info of element in the system\n            self.flu_elements = [['Eu', 1, 0.947]]  # name, composition, Ionic Radius(A)"
            ],
            [
                299,
                319,
                "        try:\n            for p, u in self.ui_par_limits.items():\n                if u[0].isChecked():\n                    try:\n                        self.par_limits[p][0] = float(u[1].text())\n                        self.par_limits[p][1] = float(u[2].text())\n                        assert self.par_limits[p][1] >= self.par_limits[p][0]\n                    except ValueError as e:\n                        print(\"{} Please provide a valid limit for '{}'. \".format(e,u[0].text()))\n                        raise\n                    except AssertionError:\n                        print(\"Max should be larger than Min for {}\".format(u[0].text()))\n                        raise\n                else:\n                    self.par_limits[p][0] = None\n                    self.par_limits[p][1] = None\n        except:\n            print(\"An Error occurs... See above\")\n        else:\n            self.updatePar()\n            ui.close()"
            ]
        ]
    },
    {
        "blob_id": "ac8326632e14a837ba69f1e47791e2ff74ab7812",
        "matched_blocks": [
            [
                292,
                306,
                "    try:\n        metadata = state_dict._metadata  # pyre-ignore\n    except AttributeError:\n        pass\n    else:\n        for key in list(metadata.keys()):\n            # for the metadata dict, the key can be:\n            # '': for the DDP module, which we want to remove.\n            # 'module': for the actual model.\n            # 'module.xx.xx': for the rest.\n\n            if len(key) == 0:\n                continue\n            newkey = key[len(prefix) :]\n            metadata[newkey] = metadata.pop(key)"
            ]
        ]
    },
    {
        "blob_id": "e5872ed4ca8e02a9a0750f1e91cec14e04750c8c",
        "matched_blocks": [
            [
                7,
                12,
                "try:\n    from django.contrib.auth import get_user_model\nexcept ImportError: # django < 1.5\n    from django.contrib.auth.models import User\nelse:\n    User = get_user_model()"
            ]
        ]
    },
    {
        "blob_id": "10b3d96a6b4da11496ed42598ece3a082b4a4470",
        "matched_blocks": [
            [
                50,
                83,
                "        try:\n            subst1.try_add_variable('i2.2.1.0', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 141698\n            if len(subjects) >= 1 and isinstance(subjects[0], Pow):\n                tmp3 = subjects.popleft()\n                subjects4 = deque(tmp3._args)\n                # State 141699\n                if len(subjects4) >= 1:\n                    tmp5 = subjects4.popleft()\n                    subst2 = Substitution(subst1)\n                    try:\n                        subst2.try_add_variable('i2.2.1.1', tmp5)\n                    except ValueError:\n                        pass\n                    else:\n                        pass\n                        # State 141700\n                        if len(subjects4) >= 1 and subjects4[0] == Integer(2):\n                            tmp7 = subjects4.popleft()\n                            # State 141701\n                            if len(subjects4) == 0:\n                                pass\n                                # State 141702\n                                if len(subjects) == 0:\n                                    pass\n                                    # 1: e*x**2\n                                    yield 1, subst2\n                            subjects4.appendleft(tmp7)\n                    subjects4.appendleft(tmp5)\n                subjects.appendleft(tmp3)"
            ],
            [
                64,
                81,
                "                    try:\n                        subst2.try_add_variable('i2.2.1.1', tmp5)\n                    except ValueError:\n                        pass\n                    else:\n                        pass\n                        # State 141700\n                        if len(subjects4) >= 1 and subjects4[0] == Integer(2):\n                            tmp7 = subjects4.popleft()\n                            # State 141701\n                            if len(subjects4) == 0:\n                                pass\n                                # State 141702\n                                if len(subjects) == 0:\n                                    pass\n                                    # 1: e*x**2\n                                    yield 1, subst2\n                            subjects4.appendleft(tmp7)"
            ]
        ]
    },
    {
        "blob_id": "8acd1637330128bc4aa2bb2f6886e3724127399a",
        "matched_blocks": [
            [
                9,
                16,
                "try:\n    valor = int(input()) / int(input())\nexcept ZeroDivisionError:\n    print('ai dento')\nexcept Exception as e:\n    print('outra coisa: ', e)\nelse:\n    print(valor)"
            ]
        ]
    },
    {
        "blob_id": "c2d557f9617ade508b0f786bc98966f87dce0824",
        "matched_blocks": [
            [
                1014,
                1029,
                "                try:\n                    tok = next(token_stream)\n                    tok, body = agentspeak.parser.parse_plan_body(tok, token_stream, log)\n                except StopIteration:\n                    log.throw()\n                    break\n                else:\n                    log.throw()\n                    tokens = list(token_stream)\n\n                    intention.instr = Instruction(noop)\n                    body.accept(BuildInstructionsVisitor(variables, actions, intention.instr, log))\n                    log.throw()\n                    agent.intentions.append(collections.deque([intention]))\n                    env.run_agent(agent)\n                    dump_variables(variables, intention.scope)"
            ]
        ]
    },
    {
        "blob_id": "9376779f91d45b267f60903eaf65ee08c95ce691",
        "matched_blocks": [
            [
                47,
                67,
                "            try:\n                '''\n                Queue.Queue\u961f\u5217\u8bbe\u7f6e\u4e86\u7ebf\u7a0b\u540c\u6b65\u7b56\u7565\uff0c\u5e76\u4e14\u53ef\u4ee5\u8bbe\u7f6etimeout\u3002\n                \u4e00\u76f4block\uff0c\u76f4\u5230requestQueue\u6709\u503c\uff0c\u6216\u8005\u8d85\u65f6\n                '''\n                request = self._requestQueue.get(True,self._poll_timeout)\n            except queue.Empty:\n                continue\n            else:\n                '''\u4e4b\u6240\u4ee5\u5728\u8fd9\u91cc\u518d\u6b21\u5224\u65addimissed\uff0c\u662f\u56e0\u4e3a\u4e4b\u524d\u7684timeout\u65f6\u95f4\u91cc\uff0c\u5f88\u6709\u53ef\u80fd\uff0c\u8be5\u7ebf\u7a0b\u88abdismiss\u6389\u4e86'''\n                if self._dismissed.is_set():\n                    self._requestQueue.put(request)\n                    break\n                try:\n                    '''\u6267\u884ccallable\uff0c\u8bb2\u8bf7\u6c42\u548c\u7ed3\u679c\u4ee5tuple\u7684\u65b9\u5f0f\u653e\u5165requestQueue'''\n                    result = request.callable(*request.args,**request.kwds)\n                    self._resultQueue.put((request,result))\n                except:\n                    '''\u5f02\u5e38\u5904\u7406'''\n                    request.exception = True\n                    self._resultQueue.put((request,sys.exc_info()))"
            ]
        ]
    },
    {
        "blob_id": "4e07b5a78385e2b29b6a7918536818810e2dfe13",
        "matched_blocks": [
            [
                58,
                63,
                "    try:\n        user = client.whoami()\n    except Exception as e:\n        print(u'{} (code: {})'.format(e.message, e.status_code))\n    else:\n        print_user(user)"
            ]
        ]
    },
    {
        "blob_id": "fd516308250294597d09414187548c5b16ed7003",
        "matched_blocks": [
            [
                7,
                14,
                "try:\n    import jwt\nexcept ImportError:\n    pass\nelse:\n    from jwt.exceptions import \\\n        InvalidTokenError as JWTInvalidTokenError, \\\n        InvalidKeyError as JWTInvalidKeyError"
            ],
            [
                15,
                24,
                "try:\n    import cryptography\nexcept ImportError:\n    pass\nelse:\n    from cryptography.hazmat.backends import \\\n        default_backend as crypto_default_backend\n    from cryptography.hazmat.primitives.serialization import \\\n        load_pem_private_key\n    from cryptography.hazmat.primitives import serialization"
            ]
        ]
    },
    {
        "blob_id": "fca1bcf354fe869e6e449600029b6272e85497ec",
        "matched_blocks": [
            [
                54,
                70,
                "    try:\n        container = client.containers.get(container_name)\n\n    # the current container is not running (cant be found) -> False\n    except docker.errors.NotFound as ex:\n        return False\n\n    # APIErrors can happen\n    except docker.errors.APIError as ex:\n        print(f\"{ex.explanation}\")\n        client.close()\n        sys.exit()\n          \n    # check container status here, means that current container is probably running\n    else:\n        container_state = container.attrs[\"State\"]\n        return container_state[\"Status\"] == RUNNING"
            ]
        ]
    },
    {
        "blob_id": "fe8bcf713a878e1f1e6a4abbe2f105d84eeebb7d",
        "matched_blocks": [
            [
                55,
                64,
                "        try:\n            predict_process_sent = sent if isinstance(sent, list) and len(sent) == 1 else [sent]\n            entities = NER.extract_sentences_entity(predict_process_sent)\n            if len(entities[0]) != 4:\n                raise Exception\n        except Exception as e:\n            print(e)\n            entities_dict = dict(zip(keys, ([], [], [], [])))\n        else:\n            entities_dict = dict(zip(keys, [dict(Counter(entity).most_common(n=top_n)) for entity in entities[0]]))"
            ]
        ]
    },
    {
        "blob_id": "24cfb3eb70c2eb608ec3cfc5b92e3b34cc31b853",
        "matched_blocks": [
            [
                42,
                55,
                "try:\n    afwdataDir = lsst.utils.getPackageDir(\"afwdata\")\nexcept pexExcept.NotFoundError:\n    afwdataDir = None\n    dataDir = None\nelse:\n    dataDir = os.path.join(afwdataDir, \"data\")\n    originalExposureName = \"medexp.fits\"\n    originalExposurePath = os.path.join(dataDir, originalExposureName)\n    subExposureName = \"medsub.fits\"\n    subExposurePath = os.path.join(dataDir, originalExposureName)\n    originalFullExposureName = os.path.join(\n        \"CFHT\", \"D4\", \"cal-53535-i-797722_1.fits\")\n    originalFullExposurePath = os.path.join(dataDir, originalFullExposureName)"
            ]
        ]
    },
    {
        "blob_id": "353ed80414f204b7d5cc04a9db00bef1a1a5fc5e",
        "matched_blocks": [
            [
                38,
                100,
                "try:\n  cnx = mysql.connector.connect(user='root', password='',\n                                host='localhost',\n                                database='rc_data')\nexcept mysql.connector.Error as err:\n\n    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n        print(\"Something is wrong with your user name or password\")\n    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n        print(\"Database does not exist\")\n    else:\n        print(err)\nelse:\n    print(\"Connection successful\")\n\n    #Iterate over .dat files\n    for file in lsFiles:\n        #Check if file ends with \".dat\"\n        if not file[-4:] == \".dat\":\n            pass\n        else:\n            lsHeader = []\n            boolHeader = True\n            boolFirstLine = True\n            #open file and read one line at a time\n            fullPath = os.path.join(pathDataFolder, file)\n            for line in open(fullPath,'r'):\n                sLine = line.rstrip()\n                if sLine[0] == \"#\" and boolFirstLine == True:\n                    sSiteKey = sLine.split(\" \")[-1]\n                    boolFirstLine = False\n                elif sLine[0] != \"#\" and boolHeader == True:\n                    sHeader = sLine\n                    #print(sHeader)\n                    lsHeader = sHeader.split(\",\")\n                    lsHeader[0] = \"date_time\"\n                    lsHeader.insert(0,'Site_Key')\n                    boolHeader = False\n                elif sLine[0] != \"#\":\n                    try:\n                        sLine = sSiteKey + \",\" + sLine\n                        lsLine = sLine.split(\",\")\n                        #Format date_time\n                        try:\n                            dtTemp = datetime.datetime.strptime(lsLine[1], \"%Y-%m-%d %H:%M\")\n                            lsLine[1] = dtTemp.strftime(\"%Y-%m-%d %H:%M:00\")\n                        except:\n                            pass\n                        cur = cnx.cursor()\n                        query = 'INSERT INTO climate ({0}) VALUES ({1})'\n                        sTemp = \"%s,\"\n                        sTemp2 = sTemp * len(lsLine)\n                        sTemp3 = sTemp2[:-1]\n                        query = query.format(','.join(lsHeader), sTemp3)\n                        #print(query)\n                        #print(len(sLine))\n                        if len(sLine) > 10:\n                            cur.execute(query, lsLine)\n\n                    except:\n                        print(\"### Did not execute \" + sLine)\n        cnx.commit()\n    cnx.close()"
            ]
        ]
    },
    {
        "blob_id": "f767f7f9a0616ee56667ee71b1bc16ea76db7445",
        "matched_blocks": [
            [
                169,
                174,
                "                try:\n                    tables[i][column]\n                except KeyError as e:\n                    matrix[i].append('')\n                else:\n                    matrix[i].append(tables[i][column])"
            ]
        ]
    },
    {
        "blob_id": "6d8d8ec47c4fb465c5648c2790c614cf85f950bf",
        "matched_blocks": [
            [
                72,
                77,
                "try:\n    from mezzanine.utils.conf import set_dynamic_settings\nexcept ImportError:\n    pass\nelse:\n    set_dynamic_settings(globals())"
            ]
        ]
    },
    {
        "blob_id": "84eb73b720c06c5905ba2c8dab271fb8ace0e255",
        "matched_blocks": [
            [
                8,
                19,
                "        try:\n            user = User.objects.get(\n                Q(username__iexact=username) |\n                Q(email__iexact=username)\n            )\n        except User.DoesNotExist:\n            return None\n        except User.MultipleObjectsReturned:\n            return User.objects.filter(email=username).order_by('id').first()\n        else:\n            if user.check_password(password) and self.user_can_authenticate(user):\n                return user"
            ]
        ]
    },
    {
        "blob_id": "f7cca0f27dc654d18a64745742e65e023e979ba5",
        "matched_blocks": [
            [
                106,
                113,
                "try:\n    import torch_xla\n    import torch_xla.core.xla_model as xm\n    import torch_xla.distributed.xla_multiprocessing as xmp\nexcept ImportError:\n    XLA_AVAILABLE = False\nelse:\n    XLA_AVAILABLE = True"
            ],
            [
                115,
                120,
                "try:\n    import horovod.torch as hvd\nexcept ImportError:\n    HOROVOD_AVAILABLE = False\nelse:\n    HOROVOD_AVAILABLE = True"
            ]
        ]
    },
    {
        "blob_id": "1a6bfaf08c47fd3c264806e82e4cd4d4d0d29f05",
        "matched_blocks": [
            [
                92,
                103,
                "\t\ttry:\n\t\t\tuser = User.objects.get( username = username )\n\t\t\tshops = Shop.objects.filter( user = user )\n\t\t\twish_list = UserWishList.objects.filter( users = user )\n\t\texcept ObjectDoesNotExist:\n\t\t\tprofile = None\n\t\t\tuser = None\n\t\telse:\n\t\t\ttry:\n\t\t\t\tprofile = UserProfile.objects.get( user = user )\n\t\t\texcept ObjectDoesNotExist:\n\t\t\t\tprofile = None\t\t"
            ]
        ]
    },
    {
        "blob_id": "bb8cc3ee05f4aaa49bf40ba83000c29ee0ae6e18",
        "matched_blocks": [
            [
                1007,
                1024,
                "        try:\n            nameidx = names.index(fname)\n        except ValueError:\n            #... we haven't: just add the description to the current list\n            ndtype.append((fname, fdtype))\n        else:\n            # collision\n            _, cdtype = ndtype[nameidx]\n            if fname in key:\n                # The current field is part of the key: take the largest dtype\n                ndtype[nameidx] = (fname, max(fdtype, cdtype))\n            else:\n                # The current field is not part of the key: add the suffixes,\n                # and place the new field adjacent to the old one\n                ndtype[nameidx:nameidx + 1] = [\n                    (fname + r1postfix, cdtype),\n                    (fname + r2postfix, fdtype)\n                ]"
            ]
        ]
    },
    {
        "blob_id": "0357d9d0e350cac1f172cef7d1ec31f1bba99d1f",
        "matched_blocks": [
            [
                36,
                42,
                "        try:\n            self.wait().until(EC.presence_of_element_located((By.XPATH,'//div[@class=\"store-user\"]')))\n        except Exception:\n            time.sleep(3)\n            self._login()\n        else:\n            return"
            ]
        ]
    },
    {
        "blob_id": "c9fbe3e6b3a3bd3fe9cb95899cab08356f4250c5",
        "matched_blocks": [
            [
                16,
                27,
                "try:\n    with open(filename) as file_object:\n        name = json.load(file_object)\nexcept FileNotFoundError as error:\n    # \u6ca1\u6709\u627e\u5230\u6587\u4ef6 \u662f\u7b2c\u4e00\u6b21\u6267\u884c\u7a0b\u5e8f\n    # \u5f00\u59cb \u7528\u6237\u767b\u5f55\u7684\u64cd\u4f5c\n    name = input('\u8bf7\u521b\u5efa\u4e00\u4e2a\u6635\u79f0')\n    # \u628a\u8f93\u5165\u7684\u5185\u5bb9\u5b58\u50a8\u5230\u6307\u5b9a\u6587\u4ef6\u4e2d\n    with open(filename, 'w') as file_object:\n        json.dump(name, file_object)\nelse:\n    print(name + '\u6b22\u8fce\u56de\u6765~')"
            ]
        ]
    },
    {
        "blob_id": "2d71fd559c985dcae2bf16c1b401cbf436784f82",
        "matched_blocks": [
            [
                82,
                91,
                "        try:\n            user = users.create_user(db_sess,\n                                     data[\"password\"],\n                                     data[\"full_name\"], data[\"email\"],\n                                     int(data[\"expires\"]) if \"expires\" in data else None)\n        except AlreadyExists:\n            raise HTTPError(httplib.CONFLICT, \"Email already exists\")\n        else:\n            db_sess.commit()\n            self.do_login(user)"
            ],
            [
                121,
                133,
                "        try:\n            token = users.get_token(db_sess, address)\n            db_sess.commit()\n        except ValueError:\n            # To avoid revealing who subscribes to our service to\n            # third parties, this must behave identically to the case\n            # where the email is recognised.\n            _log.info(\"Silently ignoring unrecognised email\")\n        else:\n            user = users.get_details(db_sess, address)\n            urlbase = self.request.protocol + \"://\" + self.request.host + \\\n                settings.EMAIL_RECOVERY_PATH\n            mail.send_recovery_message(urlbase, user[\"email\"], user[\"full_name\"], token)"
            ]
        ]
    },
    {
        "blob_id": "28b5f273d0e04b143c9cd5bb9d092bf1a50eedb1",
        "matched_blocks": [
            [
                180,
                185,
                "    try:\n        reshow = fig.canvas.manager.reshow\n    except AttributeError:\n        raise NotImplementedError()\n    else:\n        reshow()"
            ]
        ]
    },
    {
        "blob_id": "b839707730f670e808bad0a62fbb3a68c7489e4f",
        "matched_blocks": [
            [
                2,
                13,
                "    try:\n        num = int(input('Input the numerator: ')) \n        den = int(input('Input the denomerator: ')) \n        print('%d//%d = %d'%(num, den, num//den))\n    except Exception as e:\n        print('Exception occurs: ' + str(e)) \n        print('Try next input..')\n    except ZeroDivisionError:\n        print(' Devision or modulo by zero occurs!!') \n        print(' Try next input..')\n    else:\n        print('Very good, next input..')"
            ]
        ]
    },
    {
        "blob_id": "9faa73d6fdc57c6afa324b9859809810d325c65f",
        "matched_blocks": [
            [
                51,
                57,
                "    try:\n        seq = TestDataEmptyArray.get_array()\n        result = minimum_index(seq)\n    except ValueError as e:\n        pass\n    else:\n        assert False"
            ]
        ]
    },
    {
        "blob_id": "3b4c3ebcc95f6891385346ebc2ece840427a93c5",
        "matched_blocks": [
            [
                102,
                109,
                "        try:\n            import casadef\n        except ImportError:\n            pass\n        else:\n            data = os.path.join (os.path.dirname (casadef.task_directory), 'data')\n            if not os.path.isdir (data):\n                data = None"
            ]
        ]
    },
    {
        "blob_id": "dd08c64d1aa30f40729cc03daa124792afc3ed14",
        "matched_blocks": [
            [
                314,
                397,
                "            try:\n                #-----------------------------------------------------------\n                # Find the ANT-dongles of this type\n                # Note: filter on idVendor=0x0fcf is removed\n                #-----------------------------------------------------------\n                self.Message = \"No (free) ANT-dongle found\"\n                devAntDongles = usb.core.find(find_all=True, idProduct=ant_pid)\n            except Exception as e:\n                logfile.Console(\"GetDongle - Exception: %s\" % e)\n                if \"AttributeError\" in str(e):\n                    self.Message = \"GetDongle - Could not find dongle: \" + str(e)\n                elif \"No backend\" in str(e):\n                    self.Message = \"GetDongle - No backend, check libusb: \" + str(e)\n                else:\n                    self.Message = \"GetDongle: \" + str(e)\n            else:\n                #-----------------------------------------------------------\n                # Try all dongles of this type (as returned by usb.core.find)\n                #-----------------------------------------------------------\n                for self.devAntDongle in devAntDongles:\n                    if debug.on(debug.Function):\n                        s = \"GetDongle - Try dongle: manufacturer=%7s, product=%15s, vendor=%6s, product=%6s(%s)\" %\\\n                            (self.devAntDongle.manufacturer, self.devAntDongle.product, \\\n                            hex(self.devAntDongle.idVendor), hex(self.devAntDongle.idProduct), \\\n                            self.devAntDongle.idProduct)\n                        logfile.Console(s.replace('\\0',''))\n                    if debug.on(debug.Data1 | debug.Function):\n                        logfile.Print (self.devAntDongle)\n                        # prints \"DEVICE ID 0fcf:1009 on Bus 000 Address 001 =================\"\n                        # But .Bus and .Address not found for logging\n                    #-------------------------------------------------------\n                    # Initialize the dongle\n                    #-------------------------------------------------------\n                    try:                                   # check if in use\n                        #-------------------------------------------------------\n                        # As suggested by @ElDonad Elie Donadio\n                        #-------------------------------------------------------\n                        if os.name == 'posix':\n                            if debug.on(debug.Function): logfile.Write(\"GetDongle - Detach kernel drivers\")\n                            for config in self.devAntDongle:\n                                for i in range(config.bNumInterfaces):\n                                    if self.devAntDongle.is_kernel_driver_active(i):\n                                        self.devAntDongle.detach_kernel_driver(i)\n                        #-------------------------------------------------------\n                        if debug.on(debug.Function): logfile.Write (\"GetDongle - Set configuration\")\n                        self.devAntDongle.set_configuration()\n\n\n                        reset_string = msg4A_ResetSystem()  # reset string probe\n                                                            # same as ResetDongle()\n                                                            # done here to have explicit error-handling.\n                        if debug.on(debug.Function): logfile.Write (\"GetDongle - Send reset string to dongle\")\n                        self.devAntDongle.write(0x01, reset_string)\n                        time.sleep(0.500)                           # after reset, 500ms before next action\n\n\n                        if debug.on(debug.Function): logfile.Write (\"GetDongle - Read answer\")\n                        reply = self.Read(False)\n\n\n                        if debug.on(debug.Function): logfile.Write (\"GetDongle - Check for an ANT+ reply\")\n                        self.Message = \"No expected reply from dongle\"\n                        for s in reply:\n                            synch, length, id, _info, _checksum, _rest, _c, _d = DecomposeMessage(s)\n                            if synch==0xa4 and length==0x01 and id==0x6f:\n                                found_available_ant_stick = True\n                                self.Message = \"Using %s dongle\" %  self.devAntDongle.manufacturer # dongle[1]\n                                self.Message = self.Message.replace('\\0','')          # .manufacturer is NULL-terminated\n                                if 'CYCPLUS' in self.Message:\n                                    self.Cycplus = True\n\n                    except usb.core.USBError as e:                  # cannot write to ANT dongle\n                        if debug.on(debug.Data1 | debug.Function):\n                            logfile.Write (\"GetDongle - Exception: %s\" % e)\n                        self.Message = \"GetDongle - ANT dongle in use\"\n\n                    except Exception as e:\n                        logfile.Console(\"GetDongle - Exception: %s\" % e)\n                        self.Message = \"GetDongle: \" + str(e)\n\n                    #-------------------------------------------------------\n                    # If found, don't try the next ANT-dongle of this type\n                    #-------------------------------------------------------\n                    if found_available_ant_stick: break"
            ]
        ]
    },
    {
        "blob_id": "175a95df1b171942b913d77561029a1915f14dea",
        "matched_blocks": [
            [
                36,
                48,
                "    try:\n        import pypandoc\n    except ImportError:\n        print('Pypandoc not installed, using default description.')\n        longdesc = shortdesc\n    else:\n        # Convert using pypandoc.\n        try:\n            longdesc = pypandoc.convert('README.md', 'rst')\n        except EnvironmentError:\n            # No readme file, no fresh conversion.\n            print('Pypandoc readme conversion failed, using default desc.')\n            longdesc = shortdesc"
            ]
        ]
    },
    {
        "blob_id": "37174ab51eac747f46c0d8aa873a7562a247f817",
        "matched_blocks": [
            [
                61,
                66,
                "    try:\n        s.encode(encoding='utf-8').decode('ascii')\n    except UnicodeDecodeError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "abb42875e1b068997227a4f9fe42b13fc2e92114",
        "matched_blocks": [
            [
                393,
                402,
                "    try:\n        if options.socks:\n            shell = MiniShell(c, threads)\n            shell.cmdloop()\n        else:\n            sys.stdin.read()\n    except KeyboardInterrupt:\n        pass\n    else:\n        pass"
            ],
            [
                100,
                113,
                "        try:\n            proxy_handler = ProxyHandler({})\n            opener = build_opener(proxy_handler)\n            response = Request(url)\n            r = opener.open(response)\n            result = r.read()\n            items = json.loads(result)\n        except Exception as e:\n            logging.error(\"ERROR: %s\" % str(e))\n        else:\n            if len(items) > 0:\n                self.printTable(items, header=headers)\n            else:\n                logging.info('No Relays Available!')"
            ]
        ]
    },
    {
        "blob_id": "776ab1816ec3b1f23fccaf2c0aec1567c6b033c6",
        "matched_blocks": [
            [
                175,
                182,
                "  try:\n    f = p_leanpkg.open()\n  except FileNotFoundError:\n    pass\n  else:\n    with f:\n      parsed_toml = toml.loads(f.read())\n    return parsed_toml['package']['name']"
            ],
            [
                186,
                193,
                "  try:\n    f = p_leanpkg.open()\n  except FileNotFoundError:\n    pass\n  else:\n    with f:\n      parsed_toml = toml.loads(f.read())\n    return parsed_toml['package']['name']"
            ],
            [
                212,
                217,
                "      try:\n        rel_path = fname.relative_to(p)\n      except ValueError:\n        pass\n      else:\n        return cls(name, rel_path.with_suffix('').parts, fname)"
            ]
        ]
    },
    {
        "blob_id": "3ab6d509befcf96a113cf0b124e9e032be32006b",
        "matched_blocks": [
            [
                12,
                18,
                "try:\n    if b == 0:\n        raise ZeroDivision(\"Division by zero\")\nexcept ZeroDivision as message:\n    print(message)\nelse:\n    print(f\"Result: {a / b}\")"
            ]
        ]
    },
    {
        "blob_id": "419649ef0a3a851bf3fd44aded78a625acb47f10",
        "matched_blocks": [
            [
                685,
                699,
                "        try:\n            raw = cext.proc_memory_maps(self.pid)\n        except OSError as err:\n            # XXX - can't use wrap_exceptions decorator as we're\n            # returning a generator; probably needs refactoring.\n            if err.errno in ACCESS_DENIED_SET:\n                raise AccessDenied(self.pid, self._name)\n            if err.errno == errno.ESRCH:\n                raise NoSuchProcess(self.pid, self._name)\n            raise\n        else:\n            for addr, perm, path, rss in raw:\n                path = convert_dos_path(path)\n                addr = hex(addr)\n                yield (addr, perm, path, rss)"
            ]
        ]
    },
    {
        "blob_id": "705619e9ca2c6df5a7fcbb040e77003bf1b85bce",
        "matched_blocks": [
            [
                4156,
                4173,
                "                try:\n                    resource.import_xml(File,\n                                        stylesheet=stylesheet,\n                                        ignore_errors=form_vars_get(\"ignore_errors\", False))\n                except:\n                    response.error = str(sys.exc_info()[1])\n                    return output\n                else:\n                    if not resource.error:\n                        if len(resource.import_created):\n                            alert_id = resource.import_created[0]\n                        elif len(resource.import_updated):\n                            alert_id = resource.import_updated[0]\n                        response.confirmation = T(\"Alert successfully imported.\")\n                        redirect(URL(c=\"cap\", f=\"alert\", args=[alert_id]))\n                    else:\n                        response.information = resource.error\n                        return output"
            ]
        ]
    },
    {
        "blob_id": "e573961b6b4a97dad46ad243b21fea47ffb59910",
        "matched_blocks": [
            [
                159,
                171,
                "        try:\n            user = Entity()\n            user.PartitionKey = microsoft.get('organization').data['value'][0]['id']\n            user.RowKey = microsoft.get('me').data['id']\n            confirmed = \",\".join(confirmed_data) if len(confirmed_data) > 0 else ''\n            suggested = \",\".join(other_data) if len(other_data) > 0 else ''\n            user.confirmedSkills = json.dumps(confirmed)\n            user.suggestedSkills = json.dumps(suggested)\n            table_service.insert_or_merge_entity('users', user)\n        except:\n            return json.dumps({'success': False}), 500, {'ContentType': 'application/json'}\n        else:\n            return json.dumps({'success': True}), 200, {'ContentType': 'application/json'}"
            ]
        ]
    },
    {
        "blob_id": "34537e63014e90915b087f8e7ab45e39eba4a445",
        "matched_blocks": [
            [
                28,
                112,
                "\t\ttry:\n\t\t\tfrom structures import Config\n\t\t\tconfig = Config()\n\t\t\tif create:\n\t\t\t\tdriver.get(f\"https://web.whatsapp.com/send?phone={name}\")\n\t\t\t\tWebDriverWait(driver, 200).until(\n\t\t\t\t\tEC.presence_of_element_located((By.CSS_SELECTOR, \".\"+config.whatsapp[\"class_ready_checks\"])))\n\t\t\telse:\n\t\t\t\t# Since this will be run on a different instance of python\n\t\t\t\t# there is a need to import all the libs we need, except those who already were imported on the whatsapp loop\n\t\t\t\timport difflib\n\n\t\t\t\t# Look for the search bar and then click it\n\t\t\t\tsearch = driver.find_element_by_css_selector(\".\"+config.whatsapp[\"class_message_box\"])\n\t\t\t\tsearch.click()\n\t\t\t\t# Send the Target user's name (or in this case, their phone name or contact name.)\n\t\t\t\tsearch.send_keys(name)\n\n\t\t\t\t# Check for alphabetical characters on the user's name\n\t\t\t\tif not re.search('[a-zA-Z]', name):\n\t\t\t\t\t# If there isn't any characters matched by this regex, just proceed by sending and enter keystroke\n\t\t\t\t\tsearch.send_keys(Keys.ENTER)\n\t\t\t\telse:\n\t\t\t\t\t# If there is letters on the user's name, check every single result for the perfect match, since\n\t\t\t\t\t# whatsapp will also return conversations with non-saved contacts which may have the target user's name\n\t\t\t\t\t# on their settings.\n\t\t\t\t\t# BY THE WAY: This code may be very inefficient, since it is old and I haven't got the time to re-do it.\n\t\t\t\t\t_try = 0\n\t\t\t\t\t_try_again = True\n\t\t\t\t\tWebDriverWait(driver, 1000).until(\n\t\t\t\t\t\tEC.presence_of_element_located((By.CSS_SELECTOR, \".matched-text\")))\n\n\t\t\t\t\twhile _try_again and _try < 5:\n\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\ta = difflib.get_close_matches(name, [element.text for element in\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t driver.find_elements_by_xpath(\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t f\"//*[@class='matched-text {config.whatsapp['class_match_search']}']\")])[0]\n\t\t\t\t\t\t\tfor element in driver.find_elements_by_xpath(\"//*[@class='matched-text {config.whatsapp['class_match_search']}']\"):\n\t\t\t\t\t\t\t\tif element.text == a:\n\t\t\t\t\t\t\t\t\ta = element\n\t\t\t\t\t\t\ta.click()\n\t\t\t\t\t\t\t_try_again = False\n\t\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\t\t_try += 1\n\t\t\t\t\t\t\tsleep(5)\n\n\t\t\tnew_name = driver.find_element_by_class_name(config.whatsapp[\"class_name\"]) \\\n\t\t\t\t.find_element_by_tag_name(\"span\") \\\n\t\t\t\t.text\n\t\t\tif name == new_name:\n\t\t\t\tlogging.info(f\"Enviando mensagem para {name}\")\n\t\t\t\tfor message in messages:\n\t\t\t\t\tif is_file:\n\t\t\t\t\t\tdriver.find_element_by_css_selector(\n\t\t\t\t\t\t\t'span[data-icon=\"clip\"]').click()\n\t\t\t\t\t\tattach = driver.finIO_Wrapperd_element_by_css_selector(\n\t\t\t\t\t\t\t'input[type=\"file\"]')\n\t\t\t\t\t\tattach.send_keys(message)\n\t\t\t\t\t\tWebDriverWait(driver, 200).until(EC.presence_of_element_located(\n\t\t\t\t\t\t\t(By.XPATH, f\"//div[contains(@class, '{config.whatsapp['class_file_send']}')]\")))\n\t\t\t\t\t\tdriver.find_element_by_xpath(\n\t\t\t\t\t\t\tf\"//div[contains(@class, '{config.whatsapp['class_file_send']}')]\").click()\n\t\t\t\t\telse:\n\t\t\t\t\t\t# Find the message box\n\t\t\t\t\t\tmsg_box = driver.find_elements_by_class_name(config.whatsapp[\"class_message_box\"])[1]\n\n\t\t\t\t\t\t# Javascript to be injected\n\t\t\t\t\t\tjs = f'event = document.createEvent(\"UIEvents\");doc = document.getElementsByClassName(\"{config.whatsapp[\"class_message_box\"]} copyable-text selectable-text\")[1];doc.innerHTML = arguments[0];event.initUIEvent(\"input\", true, true, window, 1);doc.dispatchEvent(event);'\n\n\t\t\t\t\t\t# Execute the JS code\n\t\t\t\t\t\tdriver.execute_script(js, message)\n\n\t\t\t\t\t\t# Send the message\n\t\t\t\t\t\tmsg_box.send_keys(Keys.ENTER)\n\t\t\telse:\n\t\t\t\tlogging.critical(f\"O ponteiro foi direcionado para {name} por\u00e9m encontrou {new_name}\")\n\t\t\t\t# Sleep to prevent any possible errors\n\t\t\tsleep(0.3)\n\n\t\t\t# Reset the search bar\n\t\t\tsearch.send_keys(Keys.ESCAPE)\n\t\texcept:\n\t\t\tfallback(driver)\n\t\telse:\n\t\t\tcallback(driver)"
            ]
        ]
    },
    {
        "blob_id": "014442c52df6cfc9302ce48ac5b1ba27eebb94e3",
        "matched_blocks": [
            [
                59,
                67,
                "                        try:\n                            turned_on_graphs[g_two].vertex(n)\n                        except ValueError:\n                            continue\n                        else:\n                            graph.vp.nd[graph.vertex(v)] = g_two\n                            graph.vp.cd[graph.vertex(v)] = g\n                            vertex_bound = True\n                            break"
            ]
        ]
    },
    {
        "blob_id": "b0899d16fe1a2cf357e99b1a96871e994a3beac0",
        "matched_blocks": [
            [
                236,
                262,
                "        try:\n            stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                   re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                   re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', stmt, flags=re.S|re.I), \\\n                   flags=re.S|re.I), \\\n                   flags=re.S|re.I)\n            #stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', stmt, flags=re.S|re.I), flags=re.S|re.I)\n            lexer = TSqlLexer(InputStream(stmt))\n            lexer.removeErrorListeners()\n            lexer.addErrorListener(TSqlErrorListener())            \n            stream = CommonTokenStream(lexer)\n            parser = TSqlParser(stream)\n            parser.removeErrorListeners()\n            parser.addErrorListener(TSqlErrorListener())\n            tree = parser.tsql_file()\n            lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n            walker = ParseTreeWalker()\n            walker.walk(lsnr, tree)\n        except Exception as e:\n            cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n            stmt = stmt.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform') + ';'\n            cnv_ds.cntx.logger.add_log_details(stmt)\n            cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n            cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed statement. Result may be iscosistant.')                \n        else:    \n            stmt = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform') + ';'     \n            cnv_ds.cntx.logger.add_log('INFO', 'Statement parse completed.')"
            ],
            [
                515,
                541,
                "        try:\n            stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                   re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                   re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', stmt, flags=re.S|re.I), \\\n                   flags=re.S|re.I), \\\n                   flags=re.S|re.I)            \n            #stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', stmt, flags=re.S|re.I), flags=re.S|re.I)\n            lexer = TSqlLexer(InputStream(stmt))\n            lexer.removeErrorListeners()\n            lexer.addErrorListener(TSqlErrorListener())            \n            stream = CommonTokenStream(lexer)\n            parser = TSqlParser(stream)\n            parser.removeErrorListeners()\n            parser.addErrorListener(TSqlErrorListener())\n            tree = parser.tsql_file()\n            lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n            walker = ParseTreeWalker()\n            walker.walk(lsnr, tree)\n        except Exception as e:\n            cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n            stmt = stmt.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform') + ';'\n            cnv_ds.cntx.logger.add_log_details(stmt)\n            cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n            cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed statement. Result may be iscosistant.')                \n        else:    \n            stmt = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform') + ';'    \n            cnv_ds.cntx.logger.add_log('INFO', 'Statement parse completed.')        "
            ],
            [
                171,
                197,
                "            try:\n                stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                       re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                       re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', stmt, flags=re.S|re.I), \\\n                       flags=re.S|re.I), \\\n                       flags=re.S|re.I)            \n                #stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', stmt, flags=re.S|re.I), flags=re.S|re.I)\n                lexer = TSqlLexer(InputStream(stmt))\n                lexer.removeErrorListeners()\n                lexer.addErrorListener(TSqlErrorListener())            \n                stream = CommonTokenStream(lexer)\n                parser = TSqlParser(stream)\n                parser.removeErrorListeners()\n                parser.addErrorListener(TSqlErrorListener())\n                tree = parser.tsql_file()\n                lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n                walker = ParseTreeWalker()\n                walker.walk(lsnr, tree)\n            except Exception as e:\n                cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n                stmt = stmt.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')\n                cnv_ds.cntx.logger.add_log_details(stmt)\n                cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n                cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed statement. Result may be iscosistant.')                \n            else:    \n                stmt = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')      \n                cnv_ds.cntx.logger.add_log('INFO', 'Statement parse completed.')"
            ],
            [
                406,
                432,
                "            try:\n                stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                       re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                       re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', stmt, flags=re.S|re.I), \\\n                       flags=re.S|re.I), \\\n                       flags=re.S|re.I)              \n                #stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', stmt, flags=re.S|re.I), flags=re.S|re.I)\n                lexer = TSqlLexer(InputStream(stmt))\n                lexer.removeErrorListeners()\n                lexer.addErrorListener(TSqlErrorListener())            \n                stream = CommonTokenStream(lexer)\n                parser = TSqlParser(stream)\n                parser.removeErrorListeners()\n                parser.addErrorListener(TSqlErrorListener())\n                tree = parser.tsql_file()\n                lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n                walker = ParseTreeWalker()\n                walker.walk(lsnr, tree)\n            except Exception as e:\n                cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n                stmt = stmt.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')\n                cnv_ds.cntx.logger.add_log_details(stmt)\n                cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n                cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed statement. Result may be iscosistant.')                \n            else:    \n                stmt = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')\n                cnv_ds.cntx.logger.add_log('INFO', 'Statement parse completed.')            "
            ],
            [
                943,
                969,
                "            try:\n                stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                       re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                       re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', self.text, flags=re.S|re.I), \\\n                       flags=re.S|re.I), \\\n                       flags=re.S|re.I)                  \n                #stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', self.text, flags=re.S|re.I), flags=re.S|re.I)\n                lexer = TSqlLexer(InputStream(stmt))\n                lexer.removeErrorListeners()\n                lexer.addErrorListener(TSqlErrorListener())            \n                stream = CommonTokenStream(lexer)\n                parser = TSqlParser(stream)\n                parser.removeErrorListeners()\n                parser.addErrorListener(TSqlErrorListener())\n                tree = parser.tsql_file()\n                lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n                walker = ParseTreeWalker()\n                walker.walk(lsnr, tree)\n            except Exception as e:\n                cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n                stmt = stmt.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform') + ';'\n                cnv_ds.cntx.logger.add_log_details(stmt)\n                cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n                cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed statement. Result may be iscosistant.')                \n            else:    \n                stmt = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform') + ';'     \n                cnv_ds.cntx.logger.add_log('INFO', 'Statement parse completed.')"
            ],
            [
                1505,
                1531,
                "                try:\n                    var_asgn_sql = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                                   re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                                   re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', var_asgn_sql, flags=re.S|re.I), \\\n                                   flags=re.S|re.I), \\\n                                   flags=re.S|re.I)                    \n                    #var_asgn_sql = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', var_asgn_sql, flags=re.S|re.I), flags=re.S|re.I)\n                    lexer = TSqlLexer(InputStream(var_asgn_sql))\n                    lexer.removeErrorListeners()\n                    lexer.addErrorListener(TSqlErrorListener())\n                    stream = CommonTokenStream(lexer)\n                    parser = TSqlParser(stream)\n                    parser.removeErrorListeners()\n                    parser.addErrorListener(TSqlErrorListener())\n                    tree = parser.tsql_file()\n                    lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n                    walker = ParseTreeWalker()\n                    walker.walk(lsnr, tree)\n                except Exception as e:\n                    cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n                    var_asgn_sql = var_asgn_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')\n                    cnv_ds.cntx.logger.add_log_details(var_asgn_sql)\n                    cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n                    cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed staement. Result may be iscosistant.')\n                else:\n                    cnv_ds.cntx.logger.add_log('INFO', 'Statement parse completed.')\n                    var_asgn_sql = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')"
            ],
            [
                767,
                818,
                "                    try:\n                        upd_table_df = cnv_ds.table_df_map[upd_table]\n                        upd_table_df_tmp_1 = upd_table_df + '_1'\n                        upd_table_df_tmp_2 = upd_table_df + '_2'\n                    except:\n                        cnv_ds.cntx.logger.add_log(\"ERROR\",\"Table to be updated not present in table_df_map\")\n                        cnv_ds.cntx.logger.add_log_details(f\"table_df_map : {cnv_ds.table_df_map} \\n update table : {upd_table}\")\n                    else:\n                        # create python dictionary with key as column to be updated and value as update value \n                        upd_col_dict = {}\n            \n                        # split set section of update statement to get each column assignment\n                        set_fields = util.newSplit(upd_set_str, ',')\n                        cnv_ds.cntx.logger.add_log(\"INFO\",\"Columns Splitting begins \")\n                        # for each column assignment get update column and updating value\n                        if set_fields:\n                            # for each column assignment get update column and updating value\n                            for field in set_fields:\n                                side = field.split('=')\n                                side[0] = side[0].strip()\n                                side[1] = self.replaceVariables(cnv_ds, side[1].strip(), False)\n                                if re.match(r'\\w+\\.\\w+', side[0], re.S|re.I):\n                                    upd_col_dict[side[0]] = f'{side[1]} as {side[0]}'\n                                else:\n                                    upd_col_dict[f'{upd_table_alias}.{side[0]}'.strip('.')]= f'{side[1]} as {side[0]}'\n                        else:\n                            side = upd_set_str.split('=')\n                            side[0] = side[0].strip()\n                            side[1] = self.replaceVariables(cnv_ds, side[1].strip(), False)\n                            if re.match(r'\\w+\\.\\w+', side[0], re.S|re.I):\n                                upd_col_dict[side[0]] = f'{side[1]} as {side[0]}'\n                            else:\n                                upd_col_dict[f'{upd_table_alias}.{side[0]}'.strip('.')]= f'{side[1]} as {side[0]}'\n                        cnv_ds.cntx.logger.add_log(\"INFO\",\"Splitting Completed \")\n            \n                        # pyspark code for update value select statement\n                        cnv_code += f\"df_col_list = mod_df['{upd_table_df}'].columns\\n\"\n                        if upd_table_alias:\n                            cnv_code += f\"df_col_list_str = ('{upd_table_alias}.') + (',{upd_table_alias}.').join(df_col_list)\\n\"\n                        else:                   \n                            cnv_code += f\"df_col_list_str = ','.join(df_col_list)\\n\"\n                        cnv_code += f\"upd_col_dict = {upd_col_dict}\\n\\n\"        \n                        cnv_code += \"for col in upd_col_dict.keys():\\n\"\n                        cnv_code += ' '*4 + \"df_col_list_str = df_col_list_str.replace(col,upd_col_dict[col])\\n\\n\"\n                        \n                        # final update value select statement\n                        upd_from = f' from {upd_from_str} \\n' + (f'where {upd_where_str}' if upd_where_str else '')\n                        upd_from = util.replaceTableWithDF(cnv_ds, upd_from)\n                        upd_from = self.replaceVariables(cnv_ds, upd_from) \n                        update_sql = '\"select \" + df_col_list_str + ' + upd_from                  \n                        cnv_ds.cntx.logger.add_log(\"INFO\",\"Update SQL Statement :\")\n                        cnv_ds.cntx.logger.add_log_details(update_sql)"
            ],
            [
                828,
                907,
                "                    try :\n                        upd_table_df = cnv_ds.table_df_map[upd_table]\n                        upd_table_df_tmp_1 = upd_table_df + '_1'\n                        upd_table_df_tmp_2 = upd_table_df + '_2'\n                    except:\n                        cnv_ds.cntx.logger.add_log(\"ERROR\",\"Table to be updated not present in table_df_map\")\n                        cnv_ds.cntx.logger.add_log_details(f\"table_df_map : {cnv_ds.table_df_map} \\n update table : {upd_table}\")\n                    else:\n                        # check if update statement has where condition\n                        if re.search(r'\\bWHERE\\b', stmt, re.S|re.I):\n                            # get the set section of update\n                            upd_set_str = re.search(r'(?<=SET)\\s+(.*?)\\s+(?=WHERE)', stmt, re.S|re.I).group(1).strip()\n                            # get the where section of update statement\n                            upd_where_str = re.search(r'\\bSET\\b.*?\\bWHERE\\b(.*)', stmt, re.S|re.I).group(1).strip()\n                        else:\n                            # get the set section of update\n                            upd_set_str = re.search(r'(?<=SET)\\s+(.*?);', stmt, re.S|re.I).group(1).strip()\n                            upd_where_str = ''\n                        cnv_ds.cntx.logger.add_log(\"INFO\",\"SET section of update :\\n\")\n                        cnv_ds.cntx.logger.add_log_details(upd_set_str)\n                        cnv_ds.cntx.logger.add_log(\"INFO\",\"Statements preset after 'WHERE' Clause:\")\n                        cnv_ds.cntx.logger.add_log_details(upd_where_str)\n            \n                        # make sql to select records that will be updated\n                        if upd_where_str == '':\n                            subtract_sql = f\"select * \\n from {upd_table_df}\"\n                        else:\n                            subtract_sql = f\"select * \\n from {upd_table_df} \" + (f\"\\n where {upd_where_str}\" if {upd_where_str} else '')\n                        cnv_ds.cntx.logger.add_log(\"INFO\", f\"Subtract SQL Statement :\")\n                        cnv_ds.cntx.logger.add_log_details(subtract_sql)\n            \n                        # remove semi-colon at the end\n                        if subtract_sql.strip()[-1] == ';':\n                            subtract_sql = subtract_sql.strip()[:-1]\n            \n                        #>-o-< replace db table names with corresponding dataframe name\n                        subtract_sql = util.replaceTableWithDF(cnv_ds, subtract_sql)\n                        subtract_sql = self.replaceVariables(cnv_ds, subtract_sql)                     \n            \n                        # create python dictionary with key as column to be updated and value as update value\n                        upd_col_dict = {}        \n                        # split set section of update statement to get each column assignment\n                        set_fields = util.newSplit(upd_set_str, ',')\n                        cnv_ds.cntx.logger.add_log(\"INFO\",\"Columns Splitting begins\")\n                        # for each column assignment get update column and updating value\n                        if set_fields:\n                            # for each column assignment get update column and updating value\n                            for field in set_fields:\n                                side = field.split('=')\n                                side[0] = side[0].strip()\n                                side[1] = self.replaceVariables(cnv_ds, side[1].strip(), False)\n                                if re.match(r'\\w+\\.\\w+', side[0], re.S|re.I):\n                                    upd_col_dict[side[0]] = f'{side[1]} as {side[0]}'\n                                else:\n                                    upd_col_dict[f'{upd_table_alias}.{side[0]}'.strip('.')]= f'{side[1]} as {side[0]}'\n                        else:\n                            side = upd_set_str.split('=')\n                            side[0] = side[0].strip()\n                            side[1] = self.replaceVariables(cnv_ds, side[1].strip(), False)\n                            if re.match(r'\\w+\\.\\w+', side[0], re.S|re.I):\n                                upd_col_dict[side[0]] = f'{side[1]} as {side[0]}'\n                            else:\n                                upd_col_dict[f'{upd_table_alias}.{side[0]}'.strip('.')]= f'{side[1]} as {side[0]}'\n                        cnv_ds.cntx.logger.add_log(\"INFO\",\"Splitting Completed \")\n            \n                        # pyspark code for update value select statement\n                        cnv_code += f\"df_col_list = mod_df['{upd_table_df}'].columns\\n\"\n                        cnv_code += f\"df_col_list_str = ','.join({df_col_list})\\n\"\n                        cnv_ds.cntx.logger.add_log(\"INFO\",f\"df_col_list_str = {','.join(df_col_list)}\")\n                        cnv_code += f\"upd_col_dict = {upd_col_dict}\\n\\n\"\n                        cnv_code += \"for col in upd_col_dict.keys():\\n\"\n                        cnv_code += ' '*4 + \"df_col_list_str = df_col_list_str.replace(col,upd_col_dict[col])\\n\\n\"\n            \n                        # final update value select statement\n                        upd_from = f' from {upd_table_df} \\n' + (f'where {upd_where_str}' if upd_where_str else '')\n                        upd_from = util.replaceTableWithDF(cnv_ds, upd_from)\n                        upd_from = self.replaceVariables(cnv_ds, upd_from) \n                        update_sql = '\"select \" + df_col_list_str + ' + upd_from\n                        cnv_ds.cntx.logger.add_log(\"INFO\",f\"Update SQL Statement :\")\n                        cnv_ds.cntx.logger.add_log_details(update_sql)"
            ],
            [
                1227,
                1253,
                "                    try:\n                        cur_sel_stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                                       re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                                       re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', cur_sel_stmt, flags=re.S|re.I), \\\n                                       flags=re.S|re.I), \\\n                                       flags=re.S|re.I)                         \n                        #cur_sel_stmt = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', cur_sel_stmt, flags=re.S|re.I), flags=re.S|re.I)\n                        lexer = TSqlLexer(InputStream(cur_sel_stmt))\n                        lexer.removeErrorListeners()\n                        lexer.addErrorListener(TSqlErrorListener())\n                        stream = CommonTokenStream(lexer)\n                        parser = TSqlParser(stream)\n                        parser.removeErrorListeners()\n                        parser.addErrorListener(TSqlErrorListener())\n                        tree = parser.tsql_file()\n                        lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n                        walker = ParseTreeWalker()\n                        walker.walk(lsnr, tree)\n                    except Exception as e:\n                        cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n                        cur_sel_stmt = cur_sel_stmt.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')\n                        cnv_ds.cntx.logger.add_log_details(cur_sel_stmt)\n                        cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n                        cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed script content. Result may be iscosistant.')\n                    else:\n                        cnv_ds.cntx.logger.add_log('INFO', 'Script contect parse completed.')\n                        cur_sel_stmt = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')"
            ],
            [
                1434,
                1460,
                "                        try:\n                            var_asgn_sql = re.sub(r'\\bLOAD\\b', r'__LOAD__', \\\n                                           re.sub(r'\\bBLOCK\\b', r'__BLOCK__', \\\n                                           re.sub(r'\\bPLATFORM\\b', r'__PLATFORM__', var_asgn_sql, flags=re.S|re.I), \\\n                                           flags=re.S|re.I), \\\n                                           flags=re.S|re.I)                              \n                            #var_asgn_sql = re.sub(r'\\bLOAD\\b', r'__LOAD__', re.sub(r'\\bBLOCK\\b', r'__BLOCK__', var_asgn_sql, flags=re.S|re.I), flags=re.S|re.I)\n                            lexer = TSqlLexer(InputStream(var_asgn_sql))\n                            lexer.removeErrorListeners()\n                            lexer.addErrorListener(TSqlErrorListener())\n                            stream = CommonTokenStream(lexer)\n                            parser = TSqlParser(stream)\n                            parser.removeErrorListeners()\n                            parser.addErrorListener(TSqlErrorListener())\n                            tree = parser.tsql_file()\n                            lsnr = XxTsqlListener(stream, cnv_ds.cntx.logger)\n                            walker = ParseTreeWalker()\n                            walker.walk(lsnr, tree)\n                        except Exception as e:\n                            cnv_ds.cntx.logger.add_log('ERROR', 'Failed to parse below statement')\n                            var_asgn_sql = var_asgn_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')\n                            cnv_ds.cntx.logger.add_log_details(var_asgn_sql)\n                            cnv_ds.cntx.logger.add_log_details('Syntax error: ' + str(e))\n                            cnv_ds.cntx.logger.add_log('WARN', 'Using unparsed statement. Result may be iscosistant.')\n                        else:\n                            cnv_ds.cntx.logger.add_log('INFO', 'Statement parse completed.')\n                            var_asgn_sql = lsnr.out_sql.replace('__LOAD__', 'load').replace('__BLOCK__', 'block').replace('__PLATFORM__', 'platform')"
            ]
        ]
    },
    {
        "blob_id": "3f9b93cdc55810f2510840c677c58fcc3a808d26",
        "matched_blocks": [
            [
                182,
                189,
                "                try:\n                    items.remove(item)\n                except KeyError:\n                    subscribers.discard(peer)\n                    if not subscribers:\n                        remove.append(item)\n                else:\n                    subscribers.add(peer)"
            ],
            [
                467,
                472,
                "                        try:\n                            callbacks.remove(callback)\n                        except KeyError:\n                            pass\n                        else:\n                            topics.append(topic)"
            ]
        ]
    },
    {
        "blob_id": "80c52904e709c500ffafd4ec6a179515becbb032",
        "matched_blocks": [
            [
                34,
                40,
                "                try:\n                    code = open(join(dr, sub_fn), 'r').read()\n                except UnicodeDecodeError as e:\n                    # some code has invalid characters for tests, just ignore them\n                    pass\n                else:\n                    code_set.add(code)"
            ]
        ]
    },
    {
        "blob_id": "a67f20bd13b3a8195ac6cb023a7c043a24db7dd0",
        "matched_blocks": [
            [
                19,
                28,
                "try: \n    text = input (\"Enter something --> \")\n    if len(text) < 3:\n        raise ShortInputException(len(text), 3)\nexcept EOFError:\n    print(\"EOFError\")\nexcept ShortInputException as ex:\n    print(('ShortInputException: The input was ' + '{0} long, expected at least {1}').format(ex.length, ex.atleast))\nelse:\n    print('No exception raised')"
            ]
        ]
    },
    {
        "blob_id": "3701dcb0526d0abec2a1850baf3176ed362ec0d1",
        "matched_blocks": [
            [
                5,
                11,
                "try:\n    # The 'demandimport' breaks pyflakes and flake8.plugins.pyflakes\n    from mercurial import demandimport\nexcept ImportError:\n    pass\nelse:\n    demandimport.disable()"
            ]
        ]
    },
    {
        "blob_id": "7fb011a29c6115ef674244c90559770ca5e968c4",
        "matched_blocks": [
            [
                814,
                824,
                "            try:\n                ray.get_actor(name, namespace=namespace)\n            except ValueError:  # Name is not taken.\n                pass\n            else:\n                raise ValueError(\n                    f\"The name {name} (namespace={namespace}) is already \"\n                    \"taken. Please use \"\n                    \"a different name or get the existing actor using \"\n                    f\"ray.get_actor('{name}', namespace='{namespace}')\"\n                )"
            ]
        ]
    },
    {
        "blob_id": "48d7d88a0832ff84684f7bf088965503ede311d0",
        "matched_blocks": [
            [
                143,
                150,
                "        try:\n            torchvision_upgraded\n        except NameError:\n          run_shell_command('pip uninstall -y torchvision')\n          run_shell_command('pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl')\n          torchvision_upgraded = True\n        else:\n          print(\"torchvision already upgraded\")"
            ]
        ]
    },
    {
        "blob_id": "3cb0647035b2f6a5cfed330277424565ed81fa27",
        "matched_blocks": [
            [
                1801,
                1808,
                "            try:\n                names, _, _, defaults = getargspec(layer.get_output_for)\n            except TypeError:\n                # If introspection is not possible, skip it\n                pass\n            else:\n                if defaults is not None:\n                    accepted_kwargs |= set(names[-len(defaults):])"
            ]
        ]
    },
    {
        "blob_id": "8a4871b4d661ef4a0a122394b00d6b5f55566f2e",
        "matched_blocks": [
            [
                21,
                35,
                "        try:\n            from rosidl_generator_py import import_type_support\n            module = import_type_support('std_msgs')\n        except ImportError:\n            logger = logging.getLogger('rosidl_generator_py.MultiArrayLayout')\n            logger.debug(\n                'Failed to import needed modules for type support:\\n' + traceback.format_exc())\n        else:\n            cls._CONVERT_FROM_PY = module.convert_from_py_msg_multi_array_layout\n            cls._CONVERT_TO_PY = module.convert_to_py_msg_multi_array_layout\n            cls._TYPE_SUPPORT = module.type_support_msg_multi_array_layout\n            cls._DESTROY_ROS_MESSAGE = module.destroy_ros_message_msg_multi_array_layout\n            from std_msgs.msg import MultiArrayDimension\n            if MultiArrayDimension.__class__._TYPE_SUPPORT is None:\n                MultiArrayDimension.__class__.__import_type_support__()"
            ]
        ]
    },
    {
        "blob_id": "839a457979fb1ed47d3989de5b9b4bf6af87eb91",
        "matched_blocks": [
            [
                293,
                312,
                "    try:\n        r = requests.get(matching_article['sb_url'])\n        soup = BeautifulSoup(r.text, 'html.parser')\n    except:\n        pass\n    else:\n        # TODO: Check status code maybe, abort on 404, 500, etc?\n        desc = soup.findAll('p', {'class': 'description'})\n        if desc:\n            description = desc[0].next\n        img = soup.find(id='product-image-carousel')\n        if img:\n            try:\n                img_path = img.find('img')['src']\n            except KeyError:\n                img_path = img.find('img')['data-ng-src']  # Apparently, some articles make use of AngularJS-directives\n            if 'http' in img_path:\n                image_url = img_path\n            else:\n                image_url = 'http:%s' % img_path"
            ]
        ]
    },
    {
        "blob_id": "e2c5a124b1d605b156114ec0a8636fb103cbd5d3",
        "matched_blocks": [
            [
                148,
                161,
                "    try:\n        import grpc_tools  # pylint: disable=unused-import\n    except ImportError as e:\n        # NOTE: It's possible that we're encountering a transitive ImportError, so\n        # we check for that and re-raise if so.\n        if \"grpc_tools\" not in e.args[0]:\n            raise\n        protos = _uninstalled_protos\n        services = _uninstalled_services\n        protos_and_services = _uninstalled_protos_and_services\n    else:\n        from grpc_tools.protoc import _protos as protos  # pylint: disable=unused-import\n        from grpc_tools.protoc import _services as services  # pylint: disable=unused-import\n        from grpc_tools.protoc import _protos_and_services as protos_and_services  # pylint: disable=unused-import"
            ]
        ]
    },
    {
        "blob_id": "ddb617b3840deff9580b1979fa5f9a1accfb1906",
        "matched_blocks": [
            [
                757,
                770,
                "            try:\n                from .processor.ffmpeg import has_ffmpeg_installed\n                if has_ffmpeg_installed():\n                    from .processor.ffmpeg import ffmpeg_concat_flv_to_mp4\n                    ffmpeg_concat_flv_to_mp4(parts, output_filepath)\n                else:\n                    from .processor.join_flv import concat_flv\n                    concat_flv(parts, output_filepath)\n                print('Merged into %s' % output_filename)\n            except:\n                raise\n            else:\n                for part in parts:\n                    os.remove(part)"
            ],
            [
                773,
                786,
                "            try:\n                from .processor.ffmpeg import has_ffmpeg_installed\n                if has_ffmpeg_installed():\n                    from .processor.ffmpeg import ffmpeg_concat_mp4_to_mp4\n                    ffmpeg_concat_mp4_to_mp4(parts, output_filepath)\n                else:\n                    from .processor.join_mp4 import concat_mp4\n                    concat_mp4(parts, output_filepath)\n                print('Merged into %s' % output_filename)\n            except:\n                raise\n            else:\n                for part in parts:\n                    os.remove(part)"
            ],
            [
                789,
                802,
                "            try:\n                from .processor.ffmpeg import has_ffmpeg_installed\n                if has_ffmpeg_installed():\n                    from .processor.ffmpeg import ffmpeg_concat_ts_to_mkv\n                    ffmpeg_concat_ts_to_mkv(parts, output_filepath)\n                else:\n                    from .processor.join_ts import concat_ts\n                    concat_ts(parts, output_filepath)\n                print('Merged into %s' % output_filename)\n            except:\n                raise\n            else:\n                for part in parts:\n                    os.remove(part)"
            ]
        ]
    },
    {
        "blob_id": "4e716e88211d1235e4eb2d17c6c4c7d49c93d68d",
        "matched_blocks": [
            [
                20,
                31,
                "    try:\n        p.user(username)\n        p.pass_(passwd)\n    except poplib.error_proto as e:\n        print(\"Login failed:\", e)\n    else:\n        response, listings, octet_count = p.list()\n        if not listings:\n            print('No messages')\n        for listing in listings:\n            number, size = listing.decode('ascii').split()\n            print('Message %s hav %s bytes ' % (number, size))"
            ]
        ]
    },
    {
        "blob_id": "aba8fcd3ea58d7fe66b3bbe8099f8f60d5f4097d",
        "matched_blocks": [
            [
                45,
                54,
                "        try:\n            response = delegator(self.ethereum_tester, params)\n        except NotImplementedError:\n            return {\n                \"error\": \"RPC Endpoint has not been implemented: {0}\".format(method),\n            }\n        else:\n            return {\n                'result': response,\n            }"
            ]
        ]
    },
    {
        "blob_id": "a9ce27dab2091e921cd004331e4fd2bda5e1d9f0",
        "matched_blocks": [
            [
                24,
                29,
                "    try:\n        s.decode('ascii')\n    except UnicodeDecodeError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "520f9b2c12841c1dc754883a7bd3372228c509ce",
        "matched_blocks": [
            [
                71,
                83,
                "        try:\n            self._session_query(table, filters).one()\n        except NoResultFound:\n            raise InvalidItem\n        else:\n            # try to delete item\n            try:\n                # we cannot call .delete() on _session_query because order_by\n                self.session.query(table).filter_by(id=id).delete()\n            except Exception as e:\n                logger.info(\"_delete_item: Exception: %s\" % str(e))\n            else:\n                self.session.commit()"
            ],
            [
                86,
                93,
                "        try:\n            self._session_query(table, filters).one()\n        except NoResultFound:\n            # delete worked\n            return id\n        else:\n            # idea is still in the database, so delete failed\n            raise DeleteItem"
            ],
            [
                98,
                108,
                "        try:\n            item = self._session_query(table, filters=filters).one()\n        except (NoResultFound, MultipleResultsFound):\n            raise\n        else:\n            for (key, value) in kwargs.items():\n                if hasattr(item, key):\n                    try:\n                        setattr(item, key, value)\n                    except:\n                        raise EditItem"
            ],
            [
                162,
                169,
                "        try:\n            self._edit_item(Author, id, **kwargs)\n        except (NoResultFound, MultipleResultsFound):\n            raise\n        except EditItem:\n            raise EditAuthor\n        else:\n            return id"
            ],
            [
                234,
                241,
                "        try:\n            self._edit_item(Idea, id, **kwargs)\n        except (NoResultFound, MultipleResultsFound):\n            raise\n        except EditItem:\n            raise EditIdea\n        else:\n            return id"
            ],
            [
                246,
                253,
                "        try:\n            self._delete_item(Idea, id)\n        except InvalidItem:\n            raise InvalidIdea\n        except DeleteItem:\n            raise DeleteIdea\n        else:\n            return id"
            ],
            [
                77,
                83,
                "            try:\n                # we cannot call .delete() on _session_query because order_by\n                self.session.query(table).filter_by(id=id).delete()\n            except Exception as e:\n                logger.info(\"_delete_item: Exception: %s\" % str(e))\n            else:\n                self.session.commit()"
            ]
        ]
    },
    {
        "blob_id": "0ada88f3910da72c94b9570c150091d0054b2826",
        "matched_blocks": [
            [
                814,
                821,
                "\t\ttry:\n\t\t\tret = self.ctx.hash_cache[id(self)]\n\t\texcept KeyError:\n\t\t\tpass\n\t\texcept AttributeError:\n\t\t\tself.ctx.hash_cache = {}\n\t\telse:\n\t\t\treturn ret"
            ]
        ]
    },
    {
        "blob_id": "8d3a4b9527fea6024f6e9a906f6403928591cd3a",
        "matched_blocks": [
            [
                101,
                106,
                "\t\ttry:\n\t\t\ttarget =stacks.index(maxstack)\n\t\texcept :\n\t\t\ttarget = stacks.index(max(stacks))\n\t\telse:\n\t\t\tpass"
            ]
        ]
    },
    {
        "blob_id": "112463482bf8fab973b1e9c8adabb702be030432",
        "matched_blocks": [
            [
                315,
                320,
                "        try:\n            self.lookup_by_type(typ)\n        except KeyError:\n            return False\n        else:\n            return True"
            ],
            [
                299,
                304,
                "            try:\n                printer = self.lookup(obj)\n            except KeyError:\n                pass\n            else:\n                return printer(obj)"
            ],
            [
                869,
                875,
                "            try:\n                printer = self.lookup(obj)\n            except KeyError:\n                pass\n            else:\n                printer(obj)\n                return True"
            ]
        ]
    },
    {
        "blob_id": "b294fdcf2ade2b00c45ea2b90e81c1a00a85a489",
        "matched_blocks": [
            [
                216,
                221,
                "        try:\n            investigator.get(timeout=5)\n        except investigator.TimeoutError as e:\n            messages.error(request, 'Worker timeout: %s' % e)\n        else:\n            messages.success(request, 'Celery is OK')"
            ]
        ]
    },
    {
        "blob_id": "94dc0dfabc4bdc458a90b979dc28da65b91a1a81",
        "matched_blocks": [
            [
                58,
                64,
                "                try:\n                    data, server = self.sock.recvfrom(16)\n                except socket.timeout:\n                    logging.debug('timed out, no more responses')\n                    break\n                else:\n                    logging.debug(\"received {} from {}\".format(data, server))"
            ]
        ]
    },
    {
        "blob_id": "1d443fcd8a68dc9c0124dcbff16c16d020b695ab",
        "matched_blocks": [
            [
                70,
                88,
                "        try:\n            from pip._vendor.lockfile import LockFile\n            from pip._vendor.lockfile.mkdirlockfile import MkdirLockFile\n        except ImportError:\n            notice = dedent(\n                \"\"\"\n            NOTE: In order to use the FileCache you must have\n            lockfile installed. You can install it via pip:\n              pip install lockfile\n            \"\"\"\n            )\n            raise ImportError(notice)\n\n        else:\n            if use_dir_lock:\n                lock_class = MkdirLockFile\n\n            elif lock_class is None:\n                lock_class = LockFile"
            ]
        ]
    },
    {
        "blob_id": "dfa8ed8ef57d85008cd1f76dfb8b973a559a0601",
        "matched_blocks": [
            [
                1492,
                1498,
                "                try:\n                    key, value = _LSB_REGEX.match(line.rstrip('\\n')).groups()[:2]\n                except AttributeError:\n                    pass\n                else:\n                    # Adds lsb_distrib_{id,release,codename,description}\n                    ret['lsb_{0}'.format(key.lower())] = value.rstrip()"
            ],
            [
                717,
                726,
                "                try:\n                    ret = __salt__['cmd.run_all']('{0} -a'.format(virtinfo))\n                except salt.exceptions.CommandExecutionError:\n                    if salt.log.is_logging_configured():\n                        failed_commands.add(virtinfo)\n                else:\n                    if ret['stdout'].endswith('not supported'):\n                        command = 'prtdiag'\n                    else:\n                        command = 'virtinfo'"
            ],
            [
                2768,
                2774,
                "                    try:\n                        via, gw_ip = line.split()[1:3]\n                    except ValueError:\n                        pass\n                    else:\n                        if via == 'via':\n                            grains['ip{0}_gw'.format(ip_version)] = gw_ip"
            ],
            [
                1618,
                1676,
                "            try:\n                with salt.utils.files.fopen('/proc/1/cmdline') as fhr:\n                    init_cmdline = fhr.read().replace('\\x00', ' ').split()\n            except (IOError, OSError):\n                pass\n            else:\n                try:\n                    init_bin = salt.utils.path.which(init_cmdline[0])\n                except IndexError:\n                    # Emtpy init_cmdline\n                    init_bin = None\n                    log.warning('Unable to fetch data from /proc/1/cmdline')\n                if init_bin is not None and init_bin.endswith('bin/init'):\n                    supported_inits = (b'upstart', b'sysvinit', b'systemd')\n                    edge_len = max(len(x) for x in supported_inits) - 1\n                    try:\n                        buf_size = __opts__['file_buffer_size']\n                    except KeyError:\n                        # Default to the value of file_buffer_size for the minion\n                        buf_size = 262144\n                    try:\n                        with salt.utils.files.fopen(init_bin, 'rb') as fp_:\n                            edge = b''\n                            buf = fp_.read(buf_size).lower()\n                            while buf:\n                                buf = edge + buf\n                                for item in supported_inits:\n                                    if item in buf:\n                                        if six.PY3:\n                                            item = item.decode('utf-8')\n                                        grains['init'] = item\n                                        buf = b''\n                                        break\n                                edge = buf[-edge_len:]\n                                buf = fp_.read(buf_size).lower()\n                    except (IOError, OSError) as exc:\n                        log.error(\n                            'Unable to read from init_bin (%s): %s',\n                            init_bin, exc\n                        )\n                elif salt.utils.path.which('supervisord') in init_cmdline:\n                    grains['init'] = 'supervisord'\n                elif salt.utils.path.which('dumb-init') in init_cmdline:\n                    # https://github.com/Yelp/dumb-init\n                    grains['init'] = 'dumb-init'\n                elif salt.utils.path.which('tini') in init_cmdline:\n                    # https://github.com/krallin/tini\n                    grains['init'] = 'tini'\n                elif init_cmdline == ['runit']:\n                    grains['init'] = 'runit'\n                elif '/sbin/my_init' in init_cmdline:\n                    # Phusion Base docker container use runit for srv mgmt, but\n                    # my_init as pid1\n                    grains['init'] = 'runit'\n                else:\n                    log.debug(\n                        'Could not determine init system from command line: (%s)',\n                        ' '.join(init_cmdline)\n                    )"
            ],
            [
                1885,
                1922,
                "                try:\n                    release_re = re.compile(\n                        r'((?:Open|Oracle )?Solaris|OpenIndiana|OmniOS) (Development)?'\n                        r'\\s*(\\d+\\.?\\d*|v\\d+)\\s?[A-Z]*\\s?(r\\d+|\\d+\\/\\d+|oi_\\S+|snv_\\S+)?'\n                    )\n                    osname, development, osmajorrelease, osminorrelease = \\\n                        release_re.search(rel_data).groups()\n                except AttributeError:\n                    # Set a blank osrelease grain and fallback to 'Solaris'\n                    # as the 'os' grain.\n                    grains['os'] = grains['osfullname'] = 'Solaris'\n                    grains['osrelease'] = ''\n                else:\n                    if development is not None:\n                        osname = ' '.join((osname, development))\n                    if HAS_UNAME:\n                        uname_v = os.uname()[3]\n                    else:\n                        uname_v = os.name\n                    grains['os'] = grains['osfullname'] = osname\n                    if osname in ['Oracle Solaris'] and uname_v.startswith(osmajorrelease):\n                        # Oracla Solars 11 and up have minor version in uname\n                        grains['osrelease'] = uname_v\n                    elif osname in ['OmniOS']:\n                        # OmniOS\n                        osrelease = []\n                        osrelease.append(osmajorrelease[1:])\n                        osrelease.append(osminorrelease[1:])\n                        grains['osrelease'] = \".\".join(osrelease)\n                        grains['osrelease_stamp'] = uname_v\n                    else:\n                        # Sun Solaris 10 and earlier/comparable\n                        osrelease = []\n                        osrelease.append(osmajorrelease)\n                        if osminorrelease:\n                            osrelease.append(osminorrelease)\n                        grains['osrelease'] = \".\".join(osrelease)\n                        grains['osrelease_stamp'] = uname_v"
            ]
        ]
    },
    {
        "blob_id": "11eef008880481bfe84471d427df3e9704280dc6",
        "matched_blocks": [
            [
                114,
                144,
                "    try:\n        with redirect_stdout(stdout):\n            ret = await func()\n    except Exception as e:\n        value = stdout.getvalue()\n        err = await ctx.send(f'```py\\n{value}{traceback.format_exc()}\\n```')\n    else:\n        value = stdout.getvalue()\n        if ret is None:\n            if value:\n                try:\n\n                    out = await ctx.send(f'```py\\n{value}\\n```')\n                except:\n                    paginated_text = paginate(value)\n                    for page in paginated_text:\n                        if page == paginated_text[-1]:\n                            out = await ctx.send(f'```py\\n{page}\\n```')\n                            break\n                        await ctx.send(f'```py\\n{page}\\n```')\n        else:\n            bot._last_result = ret\n            try:\n                out = await ctx.send(f'```py\\n{value}{ret}\\n```')\n            except:\n                paginated_text = paginate(f\"{value}{ret}\")\n                for page in paginated_text:\n                    if page == paginated_text[-1]:\n                        out = await ctx.send(f'```py\\n{page}\\n```')\n                        break\n                    await ctx.send(f'```py\\n{page}\\n```')"
            ]
        ]
    },
    {
        "blob_id": "d317a0275ab087d829c5671886f0d36c21322360",
        "matched_blocks": [
            [
                41,
                58,
                "try:\n    with open(_CONF_FILE, \"r\") as f:\n        _CONFIG = json.load(f)\nexcept FileNotFoundError:\n    IN_TOKEN = input(\"Bot token: \")\n    print(\"Use | to delimeter multiple prefixes\")\n    IN_PREFIXES = input(\"Bot prefixes: \").split(\"|\")\n\n    with open(_CONF_FILE, mode=\"w\") as f:\n        json.dump({\"TOKEN\": IN_TOKEN, \"PREFIXES\": IN_PREFIXES}, f)\n    _TOKEN = IN_TOKEN\n    _PREFIXES = IN_PREFIXES\nexcept Exception as e:\n    console.print_exception(show_locals=True)\n    # print(e)\nelse:\n    _TOKEN = _CONFIG[\"TOKEN\"]\n    _PREFIXES = _CONFIG[\"PREFIXES\"]"
            ],
            [
                179,
                184,
                "    try:\n        await bot.load_plugin(f\"plugins.{plugin}\")\n    except errors.PluginError as e:\n        await ctx.channel.send(f\"Error: {e}\")\n    else:\n        await ctx.channel.send(f\"Loaded {plugin}.\")"
            ],
            [
                190,
                195,
                "    try:\n        await bot.unload_plugin(plugin)\n    except errors.PluginError as e:\n        await ctx.channel.send(f\"Error: {e}\")\n    else:\n        await ctx.channel.send(f\"Unloaded {plugin}.\")"
            ],
            [
                201,
                207,
                "    try:\n        await bot.unload_plugin(plugin)\n        await bot.load_plugin(f\"plugins.{plugin}\")\n    except errors.PluginError as e:\n        await ctx.channel.send(f\"Error: {e}\")\n    else:\n        await ctx.channel.send(f\"Reloaded {plugin}.\")"
            ]
        ]
    },
    {
        "blob_id": "1f03b32254f1d0ce03b2a51b6b6eb983daeac7b5",
        "matched_blocks": [
            [
                338,
                345,
                "    try:\n        fun(*args, **kwds)\n    except exc:\n        pass\n    except Exception as e:\n        raise AssertionError(\"Unexpected exception raised: \"+type(e).__name__)\n    else:\n        raise AssertionError(\"No exception raised\")"
            ]
        ]
    },
    {
        "blob_id": "ff97a521596c59392b60440d22ae0e97386c3ff3",
        "matched_blocks": [
            [
                372,
                383,
                "            try:\n                result = ec2.describe_snapshots(SnapshotIds=snap_ids)\n            except ClientError as e:\n                if e.response['Error']['Code'] == 'InvalidSnapshot.NotFound':\n                    msg = e.response['Error']['Message']\n                    e_snap_id = msg[msg.find(\"'\")+1:msg.rfind(\"'\")]\n                    self.log.warning(\"Snapshot not found %s\" % e_snap_id)\n                    snap_ids.remove(e_snap_id)\n                    continue\n                raise\n            else:\n                return result.get('Snapshots', ())"
            ]
        ]
    },
    {
        "blob_id": "aa0c4ed9935283356909351e267db22a24e3bf0b",
        "matched_blocks": [
            [
                339,
                344,
                "                try:\n                    iter(data[0])\n                except TypeError:\n                    pass\n                else:\n                    data = np.concatenate(data)"
            ]
        ]
    },
    {
        "blob_id": "1a8efffcae7adc01c05fdc5993f02a1f63fcc224",
        "matched_blocks": [
            [
                82,
                94,
                "        try:\n            max_size = self.options['max_size']\n            self.switch_to_transparent(src_file, dest_file, self.options['tolerance'], max_size=max_size)\n            assert os.path.isfile(dest_file)\n        except Exception:\n            if not prod.image_proc_error:\n                prod.image_proc_error = True\n                prod.save()\n            return \"failed to convert file %s for product (id:%s)\\n%s\\n\\n\" % (src_file, prod.id, traceback.format_exc())\n        else:\n            if prod.image_proc_error:\n                prod.image_proc_error = False\n                prod.save()"
            ]
        ]
    },
    {
        "blob_id": "0552be6bb809fe22f88984b556d11ae35e1c7f67",
        "matched_blocks": [
            [
                27,
                33,
                "    try:\n        data = requests.get(\"http://api.urbandictionary.com/v0/random\").json()\n    except Exception:\n        logger.exception(\"Failed to fetch UD api data\")\n        render_error(\"Failed to fetch data over API, server down probably\")\n    else:\n        show_ud(bot, data)"
            ]
        ]
    },
    {
        "blob_id": "1ed6aabee6d7190722b11ed638964b2b03eee14d",
        "matched_blocks": [
            [
                258,
                267,
                "    try:\n        with os.fdopen(fh, \"w\") as replacement:\n            with open(original_path) as original:\n                yield original, replacement\n    except Exception:\n        raise\n    else:\n        shutil.copymode(original_path, replacement_path)\n        os.remove(original_path)\n        shutil.move(replacement_path, original_path)"
            ]
        ]
    },
    {
        "blob_id": "4da42d86fc055e4c083c4767d6b52276c3ed6602",
        "matched_blocks": [
            [
                69,
                99,
                "        try:\n            with runner(filename=backup_id, user=user, password=password)\\\n                    as bkup:\n                LOG.info(\"Starting Backup %s\", backup_id)\n                success, note, checksum, location = swiftStorage.save(\n                    BACKUP_CONTAINER,\n                    bkup)\n\n            LOG.info(\"Backup %s completed status: %s\", backup_id, success)\n            LOG.info(\"Backup %s file size: %s\", backup_id, bkup.content_length)\n            LOG.info('Backup %s swift checksum: %s', backup_id, checksum)\n            LOG.info('Backup %s location: %s', backup_id, location)\n\n            if not success:\n                raise BackupError(backup.note)\n\n        except Exception as e:\n            LOG.error(e)\n            LOG.error(\"Error saving %s Backup\", backup_id)\n            backup.state = BackupState.FAILED\n            backup.save()\n            raise\n\n        else:\n            LOG.info(\"Saving %s Backup Info to model\", backup_id)\n            backup.state = BackupState.COMPLETED\n            backup.checksum = checksum\n            backup.location = location\n            backup.note = note\n            backup.backup_type = bkup.backup_type\n            backup.save()"
            ],
            [
                103,
                144,
                "        try:\n            LOG.debug(\"Cleaning out restore location: %s\", restore_location)\n            utils.execute_with_timeout(\"sudo\", \"chmod\", \"-R\",\n                                       \"0777\", restore_location)\n            utils.clean_out(restore_location)\n\n            LOG.debug(\"Finding backup %s to restore\", backup_id)\n            backup = DBBackup.find_by(id=backup_id)\n\n            LOG.debug(\"Getting Restore Runner of type %s\", backup.backup_type)\n            restore_runner = self._get_restore_runner(backup.backup_type)\n\n            LOG.debug(\"Getting Storage Strategy\")\n            storage_strategy = get_storage_strategy(\n                CONF.storage_strategy,\n                CONF.storage_namespace)(context)\n\n            LOG.debug(\"Preparing storage to download stream.\")\n            download_stream = storage_strategy.load(context,\n                                                    backup.location,\n                                                    restore_runner.is_zipped,\n                                                    backup.checksum)\n\n            with restore_runner(restore_stream=download_stream,\n                                restore_location=restore_location) as runner:\n                LOG.debug(\"Restoring instance from backup %s to %s\",\n                          backup_id, restore_location)\n                content_size = runner.restore()\n                LOG.info(\"Restore from backup %s completed successfully to %s\",\n                         backup_id, restore_location)\n                LOG.info(\"Restore size: %s\", content_size)\n\n                utils.execute_with_timeout(\"sudo\", \"chown\", \"-R\",\n                                           \"mysql\", restore_location)\n\n        except Exception as e:\n            LOG.error(e)\n            LOG.error(\"Error restoring backup %s\", backup_id)\n            raise\n\n        else:\n            LOG.info(\"Restored Backup %s\", backup_id)"
            ]
        ]
    },
    {
        "blob_id": "6f125041dcf4a7fbb0435d9bc3b5e691f3a73a44",
        "matched_blocks": [
            [
                116,
                126,
                "        try:\n            _model = META_TYPE_MAP[type(v)]\n        except KeyError:\n            raise NotImplementedError(_('Query on %(key)s is of %(value)s '\n                                        'type and is not supported') %\n                                      {\"key\": k, \"value\": type(v)})\n        else:\n            meta_q = session.query(_model).\\\n                filter(and_(_model.meta_key == key,\n                            _model.value == v)).subquery()\n            query = query.filter_by(id=meta_q.c.id)"
            ],
            [
                283,
                291,
                "                        try:\n                            _model = META_TYPE_MAP[type(v)]\n                        except KeyError:\n                            LOG.warn(_(\"Unknown metadata type. Key (%s) will \"\n                                       \"not be queryable.\"), key)\n                        else:\n                            session.add(_model(id=meter.id,\n                                               meta_key=key,\n                                               value=v))"
            ]
        ]
    },
    {
        "blob_id": "7c2d17ddb06d955c905ab695d8215828781f9cfd",
        "matched_blocks": [
            [
                95,
                106,
                "        try:\n            with open(path, 'w') as csvfile:\n                writer = csv.DictWriter(csvfile, fieldnames=headers)\n                writer.writeheader()\n\n                for item in data_list:\n                    row = dict(zip(headers, item_to_list_converter(item)))\n                    writer.writerow(row)\n        except PermissionError:\n            return Errors.FILE_CURRENTLY_OPEN\n        else:\n            return Errors.SUCCESS"
            ]
        ]
    },
    {
        "blob_id": "2164d42c3bd1009d1f13a0035f79365a0d3e7f15",
        "matched_blocks": [
            [
                35,
                48,
                "        try:\n            pool = await aioredis.create_pool(\n                *self._connection_info[0], **self._connection_info[1]\n            )\n        except ConnectionError:\n            LOG.exception(\"Redis connection error\")\n            await asyncio.sleep(self._reconnection_timeoff)\n            self._task = self._loop.create_task(self._connect())\n        except Exception as e:\n            LOG.exception(\"Redis connection error\")\n            self._result.set_exception(e)\n        else:\n            LOG.info(\"Redis connection pool created\")\n            self._result.set_result(pool)"
            ],
            [
                68,
                79,
                "        try:\n            async with self.connection(timeout=timeout) as con:\n                await con.execute(\"SET\", \"xxx_STATUS\", 1)\n                await con.execute(\"DEL\", \"xxx_STATUS\", 1)\n        except asyncio.TimeoutError:\n            return False\n        except Exception:\n            LOG.exception(\"Redis failed status\")\n            return False\n        else:\n            LOG.log(4, \"Redis status OK\")\n            return True"
            ],
            [
                99,
                104,
                "        try:\n            pool = await self._result\n        except asyncio.CancelledError:\n            pass\n        else:\n            await asyncio.wait_for(pool.wait_closed(), timeout=self._shutdown_timeout)"
            ]
        ]
    },
    {
        "blob_id": "25bd19ebec3d335bb1ab4630ad5ef6a7c9856ce5",
        "matched_blocks": [
            [
                56,
                61,
                "try:\n    import mmap\nexcept ImportError:\n    has_mmap = False\nelse:\n    has_mmap = True"
            ],
            [
                289,
                295,
                "            try:\n                contents = mmap.mmap(fd, size, access=mmap.ACCESS_READ)\n            except mmap.error:\n                # Perhaps a socket?\n                pass\n            else:\n                return contents, size"
            ],
            [
                1581,
                1588,
                "            try:\n                base_offset, base_crc32 = entries[delta_base]\n            except KeyError:\n                type_num = REF_DELTA\n                raw = (delta_base, raw)\n            else:\n                type_num = OFS_DELTA\n                raw = (offset - base_offset, raw)"
            ]
        ]
    },
    {
        "blob_id": "d6bc7164d5e3d4930bcdbb6d3a9ddfdd071805e2",
        "matched_blocks": [
            [
                5,
                18,
                "try:\n    a = 0 / int(input('\u8bf7\u8f93\u5165\u4e00\u4e2a\u6570\u5b57'))\n# \u53ef\u540c\u65f6\u6355\u83b7\u591a\u79cd\u7c7b\u578b\u7684\u5f02\u5e38\nexcept ZeroDivisionError as ze:\n    print('\u53d1\u751f\u9664\u96f6\u5f02\u5e38', ze)\n    logging.exception(ze, '\u53d1\u751f\u9664\u96f6\u5f02\u5e38')\n# \u53ef\u540c\u65f6\u6355\u83b7\u591a\u79cd\u7c7b\u578b\u7684\u5f02\u5e38\nexcept ValueError as ve:\n    print('\u53d1\u751f\u6574\u578b\u8f6c\u6362\u5f02\u5e38', ve)\n    logging.exception(ve, '\u53d1\u751f\u6574\u578b\u8f6c\u6362\u5f02\u5e38')\n# \u6ca1\u6709\u53d1\u751f\u5f02\u5e38\nelse:\n    print('\u6ca1\u6709\u53d1\u751f\u5f02\u5e38,good job')\n    logging.info('\u6ca1\u6709\u53d1\u751f\u5f02\u5e38,good job')"
            ]
        ]
    },
    {
        "blob_id": "ec2e2f1225cf3c27c122d9403076f857e991253f",
        "matched_blocks": [
            [
                167,
                174,
                "try:\n    import anyjson\nexcept ImportError:\n    pass\nelse:\n    anyjson._modules.append((__name__, 'dumps', TypeError,\n                                       'loads', ValueError, 'load'))\n    anyjson.force_implementation(__name__)"
            ]
        ]
    },
    {
        "blob_id": "78f830f6a4e511a9f2c0d2035dc92486062ffd25",
        "matched_blocks": [
            [
                534,
                542,
                "    try:\n        fun(*args, **kwds)\n    except exc as e:\n        if message is not None and message not in e.error['message']:\n            raise AssertionError(\"Expected substring not found:\"+e.error['message'])\n    except Exception as e:\n        raise AssertionError(\"Unexpected exception raised: \"+type(e).__name__)\n    else:\n        raise AssertionError(\"No exception raised\")"
            ],
            [
                560,
                571,
                "    try:\n        fun(*args, **kwds)\n    except JSONRPCException as e:\n        # JSONRPCException was thrown as expected. Check the code and message values are correct.\n        if (code is not None) and (code != e.error[\"code\"]):\n            raise AssertionError(\"Unexpected JSONRPC error code %i\" % e.error[\"code\"])\n        if (message is not None) and (message not in e.error['message']):\n            raise AssertionError(\"Expected substring not found:\"+e.error['message'])\n    except Exception as e:\n        raise AssertionError(\"Unexpected exception raised: \"+type(e).__name__)\n    else:\n        raise AssertionError(\"No exception raised\")"
            ]
        ]
    },
    {
        "blob_id": "d9928d82395d5c0f5f21546f330a57c49586eccf",
        "matched_blocks": [
            [
                15,
                20,
                "try:\n    import yaml\nexcept ImportError:  # pragma: no cover\n    _have_yaml = False\nelse:\n    _have_yaml = True"
            ]
        ]
    },
    {
        "blob_id": "4be89123e49ddac69d783cd58a65464869343d44",
        "matched_blocks": [
            [
                47,
                56,
                "        try:\n            get_credential = keyring.get_credential\n        except AttributeError:\n            pass\n        else:\n            logger.debug(\"Getting credentials from keyring for %s\", url)\n            cred = get_credential(url, username)\n            if cred is not None:\n                return cred.username, cred.password\n            return None"
            ]
        ]
    },
    {
        "blob_id": "fad28a7559308bee0c5acdfc8681f51b8076f9be",
        "matched_blocks": [
            [
                863,
                885,
                "                try:\n                    del table[record_id]\n                except:\n                    # Row is not deletable\n                    self.error = INTEGRITY_ERROR\n                    continue\n                else:\n                    # Successfully deleted\n                    numrows += 1\n                    # Clear session\n                    if s3_get_last_record_id(tablename) == record_id:\n                        s3_remove_last_record_id(tablename)\n                    # Audit\n                    audit(\"delete\", prefix, name,\n                          record=row[pkey], representation=format)\n                    # On-delete hook\n                    ondelete = get_config(\"ondelete\")\n                    if ondelete:\n                        callback(ondelete, row)\n                    # Commit after each row to not have it rolled back by\n                    # subsequent cascade errors\n                    if not cascade:\n                        db.commit()"
            ],
            [
                1074,
                1091,
                "                try:\n                    del table[row[pkey]]\n                except:\n                    # Row is not deletable\n                    self.error = INTEGRITY_ERROR\n                    db.rollback()\n                    raise\n                else:\n                    # Clear session\n                    if s3_get_last_record_id(tablename) == row[pkey]:\n                        s3_remove_last_record_id(tablename)\n\n                    # Delete super-entity\n                    delete_super(table, row)\n\n                    # On-delete\n                    if ondelete:\n                        callback(ondelete, row, tablename=tablename)"
            ],
            [
                3714,
                3721,
                "                try:\n                    rfield = rfields[iSortCol]\n                except KeyError:\n                    # iSortCol specifies a non-existent column, i.e. \n                    # iSortCol_x>=numcols => ignore\n                    columns.append(Storage(field=None))\n                else:\n                    columns.append(rfield)"
            ],
            [
                4439,
                4446,
                "                            try:\n                                rfield = resource.resolve_selector(\"(location)$lat\")\n                            except (SyntaxError, AttributeError):\n                                rfield = None\n                            else:\n                                if not rfield.field or rfield.tname != \"gis_location\":\n                                    # Invalid location context\n                                    rfield = None"
            ]
        ]
    },
    {
        "blob_id": "4b12cb9e5dcf0c50d61ba29d1ec577502c471c7c",
        "matched_blocks": [
            [
                27,
                38,
                "    try:\n        #Check for BerryIMUv1 (LSM9DS0)\n        #If no LSM9DS0 is connected, there will be an I2C bus error and the program will exit.\n        #This section of code stops this from happening.\n        LSM9DS0_WHO_G_response = (bus.read_byte_data(LSM9DS0_GYR_ADDRESS, LSM9DS0_WHO_AM_I_G))\n        LSM9DS0_WHO_XM_response = (bus.read_byte_data(LSM9DS0_ACC_ADDRESS, LSM9DS0_WHO_AM_I_XM))\n    except IOError as e:\n        print('')        #need to do something here, so we just print a space\n    else:\n        if (LSM9DS0_WHO_G_response == 0xd4) and (LSM9DS0_WHO_XM_response == 0x49):\n            print(\"Found BerryIMUv1 (LSM9DS0)\")\n            BerryIMUversion = 1"
            ],
            [
                41,
                53,
                "    try:\n        #Check for BerryIMUv2 (LSM9DS1)\n        #If no LSM9DS1 is connnected, there will be an I2C bus error and the program will exit.\n        #This section of code stops this from happening.\n        LSM9DS1_WHO_XG_response = (bus.read_byte_data(LSM9DS1_GYR_ADDRESS, LSM9DS1_WHO_AM_I_XG))\n        LSM9DS1_WHO_M_response = (bus.read_byte_data(LSM9DS1_MAG_ADDRESS, LSM9DS1_WHO_AM_I_M))\n\n    except IOError as f:\n        print('')        #need to do something here, so we just print a space\n    else:\n        if (LSM9DS1_WHO_XG_response == 0x68) and (LSM9DS1_WHO_M_response == 0x3d):\n            print(\"Found BerryIMUv2 (LSM9DS1)\")\n            BerryIMUversion = 2"
            ],
            [
                55,
                67,
                "    try:\n        #Check for BerryIMUv3 (LSM6DSL and LIS3MDL)\n        #If no LSM6DSL or LIS3MDL is connected, there will be an I2C bus error and the program will exit.\n        #This section of code stops this from happening.\n        LSM6DSL_WHO_AM_I_response = (bus.read_byte_data(LSM6DSL_ADDRESS, LSM6DSL_WHO_AM_I))\n        LIS3MDL_WHO_AM_I_response = (bus.read_byte_data(LIS3MDL_ADDRESS, LIS3MDL_WHO_AM_I))\n\n    except IOError as f:\n        print('')        #need to do something here, so we just print a space\n    else:\n        if (LSM6DSL_WHO_AM_I_response == 0x6A) and (LIS3MDL_WHO_AM_I_response == 0x3D):\n            print(\"Found BerryIMUv3 (LSM6DSL and LIS3MDL)\")\n            BerryIMUversion = 3"
            ]
        ]
    },
    {
        "blob_id": "a64d02a24daf5ab8ca5a5f191ae05d6461c66b22",
        "matched_blocks": [
            [
                362,
                368,
                "try:\n    f = tempfile.NamedTemporaryFile(prefix=u\"tmp\u20ac\")\nexcept UnicodeEncodeError:\n    unicode_paths = False\nelse:\n    unicode_paths = True\n    f.close()"
            ]
        ]
    },
    {
        "blob_id": "e074302c25447ad18fcf0611616ce9b72342db7e",
        "matched_blocks": [
            [
                20,
                29,
                "        try:\n            client.lsp.send_request(\n                INITIALIZE,\n                InitializeParams(\n                    process_id=1234, root_uri=root.as_uri(),\n                    capabilities=None)).result(timeout=CALL_TIMEOUT)\n        except futures.TimeoutError:\n            retry -= 1\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "99f477ff8ee5eee19b30adddfcaa704802c97c42",
        "matched_blocks": [
            [
                406,
                412,
                "                try:\n                    floo = json.loads(open(os.path.join(floo_path, '.floo'), 'rb').read().decode('utf-8'))\n                    floo = utils.parse_url(floo['url'])\n                except Exception:\n                    pass\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "a634d6ced49aa47a61f022b4f53aaa91c4288ef5",
        "matched_blocks": [
            [
                6090,
                6100,
                "    try:\n        shutil.copyfile(backup['Location'], path)\n    except IOError as exc:\n        ret['comment'] = \\\n            'Unable to restore {0} to {1}: ' \\\n            '{2}'.format(backup['Location'], path, exc)\n        return ret\n    else:\n        ret['result'] = True\n        ret['comment'] = 'Successfully restored {0} to ' \\\n                         '{1}'.format(backup['Location'], path)"
            ],
            [
                6149,
                6156,
                "    try:\n        os.remove(backup['Location'])\n    except IOError as exc:\n        ret['comment'] = 'Unable to remove {0}: {1}'.format(backup['Location'],\n                                                            exc)\n    else:\n        ret['result'] = True\n        ret['comment'] = 'Successfully removed {0}'.format(backup['Location'])"
            ],
            [
                2995,
                3006,
                "        try:\n            ofile.seek(-len(linesep), os.SEEK_END)\n        except IOError as exc:\n            if exc.errno in (errno.EINVAL, errno.ESPIPE):\n                # Empty file, simply append lines at the beginning of the file\n                pass\n            else:\n                raise\n        else:\n            if ofile.read(len(linesep)) != linesep:\n                ofile.seek(0, os.SEEK_END)\n                ofile.write(linesep)"
            ],
            [
                6104,
                6109,
                "        try:\n            fstat = os.stat(path)\n        except (OSError, IOError):\n            ret['comment'] += ', but was unable to set ownership'\n        else:\n            os.chown(path, fstat.st_uid, fstat.st_gid)"
            ]
        ]
    },
    {
        "blob_id": "dafb204afe5ff1b605e8aec2f89f580f90634585",
        "matched_blocks": [
            [
                7,
                25,
                "    try:\n        dbParam = read_db_config()\n        db = pymysql.connect(**dbParam)\n        cursor = db.cursor()\n\n        sql = \"SELECT * FROM Addresses WHERE id={0}\".format(id)\n        cursor.execute(sql)\n\n        db.close()\n        return cursor.fetchone()\n    except ValueError:\n        # print(\"One of your inputs is invalid. Please try again.\")\n        return (\"error\", \"error\", \"error\", \"error\", \"error\")\n    except Exception as err:\n        # print(\"Something went wrong: {0}\".format(err))\n        return (\"error\", \"error\", \"error\", \"error\", \"error\")\n    else:\n        if db != None:\n            db.close()"
            ],
            [
                30,
                47,
                "    try:\n        dbParam = read_db_config()\n        db = pymysql.connect(**dbParam)\n        cursor = db.cursor()\n\n        sql = \"SELECT * FROM Addresses ORDER BY id DESC LIMIT 1\"\n        cursor.execute(sql)\n\n        idNum, targetName, targetStreet, targetCity, targetState, targetZip = cursor.fetchone()\n        db.close()\n        return idNum\n    except ValueError:\n        return 0\n    except Exception as err:\n        return 0\n    else:\n        if db != None:\n            db.close()"
            ]
        ]
    },
    {
        "blob_id": "edb73aa974b2ff670bff17c70b81de6e39a18a3a",
        "matched_blocks": [
            [
                303,
                310,
                "            try:\n                filtered = filter_chain.apply(value)\n            except Exception as e:\n                return self._invalid_value(value, e, exc_info=True)\n            else:\n                # noinspection PyProtectedMember\n                self._has_errors = self._has_errors or filter_chain._has_errors\n                return filtered"
            ]
        ]
    },
    {
        "blob_id": "35b8a0e073fe1e4ace98a7f1bbf543673ee3905f",
        "matched_blocks": [
            [
                37,
                44,
                "try:\n\tfile = open(fileLocation,\"a\")\nexcept IOError:\n        print('Cannot open file. Check the that you have the correct file location', arg)\nelse:\n\tfile.write(datavarehusTekst +\"\\r\\n\")\n\tfile.write(businessIntelligenceTekst+\"\\r\\n\")\n\tfile.close()"
            ]
        ]
    },
    {
        "blob_id": "2e2e661679365383af13075eca866455d5be9a63",
        "matched_blocks": [
            [
                31,
                38,
                "try:\n    import absl.logging\nexcept ImportError:\n    pass\nelse:\n    absl.logging.set_verbosity(\"info\")\n    absl.logging.set_stderrthreshold(\"info\")\n    absl.logging._warn_preinit_stderr = False"
            ]
        ]
    },
    {
        "blob_id": "e18bf50cd5e5c0cee6e3670840430470da5195de",
        "matched_blocks": [
            [
                26,
                48,
                "  try:\n    populate_score_definition('_email.click', 50)\n    populate_score_definition('_email.open', 10)\n    populate_score_definition('_email.delivered', 2)\n    populate_score_definition('_email.hardbounce', -1000)\n    populate_score_definition('_email.complaint', -1000)\n    populate_score_definition('_email.unsubscribe', -500)\n    populate_score_definition('_SMS.SUCCESS', 2)\n    populate_score_definition('_SMS.OPTOUT', -500)\n    populate_score_definition('_campaign.send', 2)\n    populate_score_definition('_campaign.opened_notification', 50)\n    populate_score_definition('_campaign.received_foreground', 2)\n    populate_score_definition('_campaign.received_background', 2)\n    populate_score_definition('_session.start', 2)\n    populate_score_definition('_userauth.sign_up', 50)\n    populate_score_definition('_monetization.purchase', 100)\n\n  except Exception as e:\n    logging.error('Received Error while populating default values: %s', e)\n    send(event, context, 'FAILED', {})\n\n  else:\n    send(event, context, 'SUCCESS', {})"
            ]
        ]
    },
    {
        "blob_id": "ee8325140ee199eb4ec33895c95ca606a33b2d84",
        "matched_blocks": [
            [
                18,
                30,
                "        try:\n            session.commit()\n        except IntegrityError as e:\n            app.logger.error(\n                \"Failed commit: id={0.id}, error={e}\".format(transaction, e)\n            )\n            return session.rollback()\n        else:\n            app.logger.info(\n                \"Match transaction; transaction={0.id}, \"\n                \"accountmatch={1.id}\".format(transaction, accountmatch)\n            )\n            return transaction"
            ],
            [
                40,
                57,
                "                try:\n                    app.logger.debug(\"Compiling regex; regex={0}\".format(amr.regex))\n                    regex = re.compile(amr.regex)\n                except TypeError:\n                    app.logger.error(\n                        \"Failed to parse regex; \" \"id={amr.id}\".format(amr)\n                    )\n                    continue\n                else:\n                    for transaction in session.query(Transaction).filter_by(\n                        user=self.user, account=None, bankaccount=am.bankaccount\n                    ):\n                        app.logger.debug(\n                            \"Searching transaction memo for a match; \"\n                            \"memo=({0}), regex={0}\".format(transaction.memo, amr.regex)\n                        )\n                        if regex.search(transaction.memo):\n                            self._match_transaction(am, transaction)"
            ]
        ]
    },
    {
        "blob_id": "fe3f8bc0182f16e1abb5aa2672774f9a9ca0a79a",
        "matched_blocks": [
            [
                244,
                260,
                "        try:\n            vrs_obj = self.tlr._from_gnomad(vcf_coords, assembly_name=assembly)\n        except (ValidationError, TranslatorValidationError) as e:\n            vrs_obj = None\n            _logger.error(\"ValidationError when translating %s from gnomad: %s\", vcf_coords, str(e))\n        except KeyError as e:\n            vrs_obj = None\n            _logger.error(\"KeyError when translating %s from gnomad: %s\", vcf_coords, str(e))\n        except AssertionError as e:\n            vrs_obj = None\n            _logger.error(\"AssertionError when translating %s from gnomad: %s\", vcf_coords, str(e))\n        except Exception as e:  # pylint: disable=broad-except\n            vrs_obj = None\n            _logger.error(\"Unhandled Exception when translating %s from gnomad: %s\", vcf_coords, str(e))\n        else:\n            if not vrs_obj:\n                _logger.debug(\"None was returned when translating %s from gnomad\", vcf_coords)"
            ]
        ]
    },
    {
        "blob_id": "f55e1a9380f0f5df962aaf54ae7bd0c5312a045a",
        "matched_blocks": [
            [
                1235,
                1241,
                "        try:\n            params_to_set = args[0]\n        except IndexError:\n            raise InstrumentParameterException('Set command requires a parameter dict.')\n        else:\n            if not isinstance(params_to_set, dict):\n                raise InstrumentParameterException('Set parameters not a dict.')"
            ],
            [
                1473,
                1487,
                "            try:\n                prompt, result = self._get_response(timeout=4,\n                                                      expected_prompt=[InstrumentPrompts.MAIN_MENU,\n                                                                       InstrumentPrompts.SLEEPING])\n            except InstrumentTimeoutException:\n                log.debug('_go_to_root_menu: TIMED_OUT WAITING FOR ROOT MENU FROM ONE CONTROL-C !')\n                pass\n            else:\n                if prompt == InstrumentPrompts.MAIN_MENU:\n                    log.debug(\"_go_to_root_menu: got root menu prompt\")\n                    return\n                if prompt == InstrumentPrompts.SLEEPING:\n                    # instrument says it is sleeping, so try to wake it up\n                    log.debug(\"_go_to_root_menu: GOT SLEEPING PROMPT !\")\n                    break"
            ]
        ]
    },
    {
        "blob_id": "7d7eda7f64d6fa1cbf1abbb9778f87c8ffc2ddc1",
        "matched_blocks": [
            [
                33,
                38,
                "    try:\n        database_array.append(message_parsed[1:len(message_parsed)])\n    except Warning:\n        print(\"Something not right!\")\n    else:\n        return database_array"
            ],
            [
                43,
                50,
                "    try:\n        database_array.insert(database_array[int(message[0])], message[1:len(message)])\n    except TypeError:\n        print(\"Wrong type!\")\n    except IndexError:\n        print(\"Wrong index!\")\n    else:\n        return database_array"
            ],
            [
                55,
                62,
                "    try:\n        database_array[int(message[0])].clear()\n    except TypeError:\n        print(\"Wrong type!\")\n    except IndexError:\n        print(\"Wrong index!\")\n    else:\n        return database_array"
            ],
            [
                94,
                110,
                "        try:\n            file = open(message[1])\n        except IOError:\n            print(\"Input error!\")\n        else:\n            database_array.clear()\n            i, j = 0, 0\n            try:\n                for line in file:\n                    if line == \"\\n\":\n                        i += 1\n                    else:\n                        database_array[i] = simple_parse(line)\n            except EOFError:\n                print(\"Read successful!\")\n            file.close()\n            return database_array"
            ]
        ]
    },
    {
        "blob_id": "a1779179c2054f6e836a42d2ce8325c8f5b7106b",
        "matched_blocks": [
            [
                27,
                33,
                "\t\ttry :\n\t\t\tcategory_obj = Category.objects.get( name = category )\n\t\texcept ObjectDoesNotExist :\n\t\t\tmessages.error( request, f' No such Category exists. ' )\n\t\t\treturn None\n\t\telse :\n\t\t\treturn category_obj"
            ],
            [
                120,
                144,
                "\t\t\ttry :\n\t\t\t\tcategory_obj = Category.objects.get( code = category_wise[0][0], name = category_wise[0][1] )\n\t\t\texcept ObjectDoesNotExist :\n\t\t\t\tprint( f\"Error : No category exist by name '{ category_wise[0] }' so can't update sub-categories { subcategories }. \" )\n\t\t\telse :\n\t\t\t\tfor subcategory in subcategories :\n\t\t\t\t\tsubcategory = subcategory.split( ',' )\n\t\t\t\t\t# checks if SubCategory already exists in DB\n\t\t\t\t\ttry :\n\t\t\t\t\t\tsubcategory_obj = SubCategory.objects.get( name = subcategory[ 1 ], category = category_obj )\n\t\t\t\t\t\tprint( f\" SubCategory '{ subcategory_obj.name }' already exist in DB. \" )\n\t\t\t\t\t\tcontinue\n\t\t\t\t\texcept ObjectDoesNotExist :\n\t\t\t\t\t\t#checks if code is not taken by other SubCategory in a category_wise manner\n\t\t\t\t\t\ttry :\n\t\t\t\t\t\t\tsubcategory_obj = SubCategory.objects .get( code = subcategory[0], category =  category_obj )\n\t\t\t\t\t\t\tprint( f\" Another SubCategory '{ subcategory_obj.name }' exist with code '{ subcategory_obj.code }'. \" )\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\texcept ObjectDoesNotExist :\n\t\t\t\t\t\t\t# saves subcategory if not present\n\t\t\t\t\t\t\tsubcategory_obj = SubCategory( code = subcategory[0] )\n\t\t\t\t\t\t\tsubcategory_obj.name = subcategory[1] \n\t\t\t\t\t\t\tsubcategory_obj.category = category_obj\n\t\t\t\t\t\t\tsubcategory_obj.save()\n\t\t\t\t\t\t\tprint( f\" Added new SubCategory with  code '{ subcategory_obj.code }' and name { subcategory_obj.name } \" )"
            ],
            [
                290,
                296,
                "\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\tgenerated_id = count_data[cat_index][sub_index]\n\t\t\t\t\t\texcept IndexError:\n\t\t\t\t\t\t\tcount_data[cat_index][sub_index] = '1'\n\t\t\t\t\t\t\tgenerated_id = '0'\n\t\t\t\t\t\telse:\n\t\t\t\t\t\t\tcount_data[cat_index][sub_index] = str( int(generated_id) + 1 )"
            ]
        ]
    },
    {
        "blob_id": "2ed9f83a79a48cfd95f2eb595c5dee45aee3f6df",
        "matched_blocks": [
            [
                40,
                58,
                "            try:\n                # This doesn't actually kill the process, just sends a signal of 0 to test it.\n                os.kill(cron_db_entry.pid, 0)\n            except ProcessLookupError:\n                # Process does not exist, good to go.\n                pass\n            else:\n                # Process still exists, stop execution!\n                error = f\"Process #{cron_db_entry.pid} ({cron_db_entry.name}) is still running!\"\n\n                if SENTRY_DSN:\n                    capture_message(\n                        f\"Process #{cron_db_entry.pid} ({cron_db_entry.name}) is still running!\",\n                        level=\"error\",\n                    )\n                else:\n                    logger.error(error)\n\n                exit(1)"
            ]
        ]
    },
    {
        "blob_id": "62b8bb2665eb52fab6f6ae27be08fd45103fc21e",
        "matched_blocks": [
            [
                455,
                463,
                "        try:\n            match = self.rex_search(regexp, flags=flags, byte=byte)\n        except DataNotFound:\n            if default is NULL:\n                raise DataNotFound('Regexp not found')\n            else:\n                return default\n        else:\n            return normalize_space(decode_entities(match.group(1))) # pylint: disable=no-member"
            ],
            [
                240,
                247,
                "            try:\n                codecs.lookup(charset)\n            except LookupError:\n                logger.error('Unknown charset found: %s.'\n                             ' Using utf-8 istead.', charset)\n                self.charset = 'utf-8'\n            else:\n                self.charset = charset"
            ]
        ]
    },
    {
        "blob_id": "6d14d26ba8d381f9ed5cef9a5cfdb6f18817b2ca",
        "matched_blocks": [
            [
                211,
                216,
                "            try:\n                evaluator_id = self._evaluator_deletion_queue.pop()\n            except IndexError:\n                break\n            else:\n                self._send(evaluator_id, None)"
            ]
        ]
    },
    {
        "blob_id": "e359ea1b320c4d6a9f269e337631799285f3b7bf",
        "matched_blocks": [
            [
                249,
                300,
                "        try:\n            table_schema = cursor.execute(\n                \"SELECT sql FROM sqlite_master WHERE type='table' and name=%s\" % (\n                    self.connection.ops.quote_name(table_name),\n                )\n            ).fetchone()[0]\n        except TypeError:\n            # table_name is a view.\n            pass\n        else:\n            # Check constraint parsing is based of SQLite syntax diagram.\n            # https://www.sqlite.org/syntaxdiagrams.html#table-constraint\n            def next_ttype(ttype):\n                for token in tokens:\n                    if token.ttype == ttype:\n                        return token\n\n            statement = sqlparse.parse(table_schema)[0]\n            tokens = statement.flatten()\n            for token in tokens:\n                name = None\n                if token.match(sqlparse.tokens.Keyword, 'CONSTRAINT'):\n                    # Table constraint\n                    name_token = next_ttype(sqlparse.tokens.Literal.String.Symbol)\n                    name = name_token.value[1:-1]\n                    token = next_ttype(sqlparse.tokens.Keyword)\n                if token.match(sqlparse.tokens.Keyword, 'UNIQUE'):\n                    constraints[name] = {\n                        'unique': True,\n                        'columns': [],\n                        'primary_key': False,\n                        'foreign_key': False,\n                        'check': False,\n                        'index': False,\n                    }\n                if token.match(sqlparse.tokens.Keyword, 'CHECK'):\n                    # Column check constraint\n                    if name is None:\n                        column_token = next_ttype(sqlparse.tokens.Literal.String.Symbol)\n                        column = column_token.value[1:-1]\n                        name = '__check__%s' % column\n                        columns = [column]\n                    else:\n                        columns = []\n                    constraints[name] = {\n                        'check': True,\n                        'columns': columns,\n                        'primary_key': False,\n                        'unique': False,\n                        'foreign_key': False,\n                        'index': False,\n                    }"
            ]
        ]
    },
    {
        "blob_id": "286164908e84c5092d847553da2a904fea968b9a",
        "matched_blocks": [
            [
                52,
                81,
                "        try:\n            for n in instrument_namelist:\n                orderbook, updatedtime = self.change_orderbook(self.deribit.getorderbook(n))\n                summary = self.deribit.getsummary(self.deribit.getorderbook(n)['instrument'])\n                # timestamp = ''.join(list(filter(lambda ch: ch in '0123456789', updatedtime)))\n                # \u5199\u5165\u6570\u636e\u5e93\n                cur.execute(\"\"\"INSERT INTO deribit\n                    (contract_type, data_type, exchange, order_meta_data, symbol, updated_time, summary_meta_data)\n                    VALUES(%s, %s, %s, %s, %s, %s, %s);\"\"\",\n                            (orderbook['contract_type'], orderbook['data_type'], orderbook['exchange'], str(orderbook),\n                             orderbook['symbol'], updatedtime, str(summary)))\n\n                conn.commit()\n\n            del summary\n            del orderbook\n            del updatedtime\n            del instrument\n            del instrument_namelist\n            del cur\n        except:\n            print('\u5199\u5165\u6570\u636e\u51fa\u9519\u3002')\n            self.insert_orderbook(300)\n        else:\n            conn.close()\n            timenow = time.ctime(time.time())\n            print(\"loop at\", timenow)\n            global t\n            t = Timer(tim, self.insert_orderbook, (tim,))\n            t.start()"
            ]
        ]
    },
    {
        "blob_id": "2a105f6bc2331fb8e233a4c673ef407ce743c551",
        "matched_blocks": [
            [
                21,
                28,
                "\ttry:\n\t\tresponse = await protocol.request(request).response\n\texcept Exception as e:\n\t\tprint('Failed to fetch resource:')\n\t\tprint(e)\n\telse:\n\t\tprint (\"Result code:\", response.code,\"\\n\",\n\t\t\"Payload:\", response.payload)"
            ]
        ]
    },
    {
        "blob_id": "f05d24eb8f4d5d54d3df572de195af889ba875b5",
        "matched_blocks": [
            [
                45,
                51,
                "    try:\n        data = api.issues.list(args, conf)\n    except:\n        error('fatal: API error while gettings issues list')\n        raise\n    else:\n        renderer.issues.as_table(data)"
            ]
        ]
    },
    {
        "blob_id": "5b09a6e9ef86e34d2568dace59e39c5c04cb4294",
        "matched_blocks": [
            [
                12,
                25,
                "    try:\n        dbox.users_get_current_account()\n    except dropbox.exceptions.DropboxException:\n        print(\"Can't connect to DropBox '\"+file_name+\"'.\")\n    else:\n\n        read_file_handler = open(local_path+file_name, 'rb')\n\n        try:\n            dbox.files_upload(read_file_handler.read(), CLOUDPATH+file_name, mode=dropbox.files.WriteMode('overwrite'))\n        except dropbox.exceptions.DropboxException:\n            print(\"Can't upload '\"+file_name+\"'.\")\n        finally:\n            read_file_handler.close()"
            ],
            [
                31,
                39,
                "    try:\n        dbox.users_get_current_account()\n    except dropbox.exceptions.DropboxException:\n        print(\"Can't connect to DropBox '\"+file_name+\"'.\")\n    else:\n        try:\n            dbox.files_download_to_file(local_path+file_name, CLOUDPATH+file_name)\n        except dropbox.exceptions.ApiError:\n            print(\"Can't download '\"+file_name+\"'.\")"
            ]
        ]
    },
    {
        "blob_id": "00c4b0a22845e040c070e2fe81c9351d6a81b81b",
        "matched_blocks": [
            [
                74,
                79,
                "        try:\n            await ctx.channel.purge(limit=messages + 1)\n        except Exception as e:\n            await ctx.send(\"I cannot delete the messages. Make sure I have the manage messages permission.\")\n        else:\n            await ctx.send(f'{messages} messages deleted. \ud83d\udc4c', delete_after=3)"
            ]
        ]
    },
    {
        "blob_id": "bc1a07b3eb747663ff4e50e38909ef3ba7caa0ed",
        "matched_blocks": [
            [
                115,
                120,
                "        try:\n            subprocess.check_output((\"lsof\", \"-v\"))\n        except (OSError, subprocess.CalledProcessError):\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "711f489fe4421ccd263e1e4f760ac6188ad61a7a",
        "matched_blocks": [
            [
                290,
                295,
                "            try:\n                yield from self._send_req(request)\n            except Errors.KafkaError as err:\n                log.error(\"LeaveGroup request failed: %s\", err)\n            else:\n                log.info(\"LeaveGroup request succeeded\")"
            ],
            [
                821,
                841,
                "            try:\n                with (yield from self._commit_lock):\n                    yield from asyncio.shield(\n                        self._do_commit_offsets(assignment, offsets),\n                        loop=self._loop)\n            except (Errors.UnknownMemberIdError,\n                    Errors.IllegalGenerationError,\n                    Errors.RebalanceInProgressError) as err:\n                raise Errors.CommitFailedError(\n                    \"Commit cannot be completed since the group has already \"\n                    \"rebalanced and may have assigned the partitions \"\n                    \"to another member\")\n            except Errors.KafkaError as err:\n                if not err.retriable:\n                    raise err\n                else:\n                    # wait backoff and try again\n                    yield from asyncio.sleep(\n                        self._retry_backoff_ms / 1000, loop=self._loop)\n            else:\n                break"
            ],
            [
                989,
                999,
                "            try:\n                offsets = yield from self._do_fetch_commit_offsets(partitions)\n            except Errors.KafkaError as err:\n                if not err.retriable:\n                    raise err\n                else:\n                    # wait backoff and try again\n                    yield from asyncio.sleep(\n                        self._retry_backoff_ms / 1000, loop=self._loop)\n            else:\n                return offsets"
            ]
        ]
    },
    {
        "blob_id": "4feb08a787d4150afc715d7edaf517188ec7e248",
        "matched_blocks": [
            [
                20,
                28,
                "   try:\n      print(\"Connecting on GPSD...\")\n      gpsd.connect()      \n   except:\n      print(\"Could not connect to GPSD.\\nThis script is persistent and will try to reconnect to GPSD in 10 sec.\",sys.exc_info()[0])\n      time.sleep(10)\n   else:\n      print(\"GPSD connected!\")\n      break"
            ],
            [
                76,
                83,
                "      try:\n         print(\"Closing file.\")\n         f.close()\n      except:\n         raise   \n      else:\n         print(\"File closed.\")\n         break"
            ]
        ]
    },
    {
        "blob_id": "b5c3aaeb67b72aa382b640e6dbb778933d5488b5",
        "matched_blocks": [
            [
                24,
                39,
                "try:\n    from distutils import version\n    import scipy.io\n    import scipy.version\nexcept ImportError as err:\n    HAVE_SCIPY = False\n    SCIPY_ERR = err\nelse:\n    if version.LooseVersion(scipy.version.version) < '0.8':\n        HAVE_SCIPY = False\n        SCIPY_ERR = ImportError(\"your scipy version is too old to support \" +\n                                \"MatlabIO, you need at least 0.8. \" +\n                                \"You have %s\" % scipy.version.version)\n    else:\n        HAVE_SCIPY = True\n        SCIPY_ERR = None"
            ]
        ]
    },
    {
        "blob_id": "7226bb2dcef47693a30e496007e67ac5cab23a55",
        "matched_blocks": [
            [
                1,
                35,
                "try:\n    from random import randint\n\n    nu = randint(1, 100)\nexcept:\n    print('Desculpa, mas aconteceu um erro na solicita\u00e7\u00e3o')\nelse:\n    Aviso1 = print('Chute do 1 adiante ;)')\n    aviso = print('escreva \"[Sair]\" para finalizar')\n    ch = str\n    ch1 = 0\n    while ch != 'sair'.strip():\n            from time import sleep\n            ch1 = int(input('Chute um numero: \\n '.strip()))\n            sleep(1.0)\n\n            ch = str(input('Deseja sair? Caso n\u00e3o... Aperte ENTER: '.strip() ))\n            sleep(1.0)\n\n            if ch1 <= nu:\n\n                print('Quase hein!!!')\n                sleep(1.0)\n            elif ch1 >= nu:\n                print('Quase l\u00e1!!!')\n                sleep(1.0)\n\n            elif ch1 == nu:\n                print('Acertouuuu!!')\n\n                sleep(1.0)\n    else:\n        if ch == 'sair'.strip():\n            print('At\u00e9 breve!!')\n            sleep(1.0)"
            ]
        ]
    },
    {
        "blob_id": "f0c8ff7f6b332b17b9b6c8c7766378478af6c6b5",
        "matched_blocks": [
            [
                465,
                472,
                "            try:\n                email.send()\n            except Exception as e:\n                msg = 'Could not send password reset e-mail, please try again later.'\n                logger.exception(msg)\n                flash(msg, 'danger')\n            else:\n                flash('Password reset link was sent to your e-mail address.', 'success')"
            ]
        ]
    },
    {
        "blob_id": "434ab6de074e51792190b98a4d2fe7111f78c589",
        "matched_blocks": [
            [
                36,
                50,
                "    try:\n        selected_choice = p.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the poll voting form.\n        return render(request, 'polls/detail.html', {\n            'poll': p,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(p.id,)))"
            ]
        ]
    },
    {
        "blob_id": "807c1bda878f4fd044b408e7ea19357e343ca3ec",
        "matched_blocks": [
            [
                57,
                64,
                "    try:\n        with open('/root/city_code.txt', \"w+\") as f:\n            for city in city_code_list:\n                f.write(city[0] + \":\" + city[1] + \"\\n\")\n    except OSError as reason:\n        print(str(reason))\n    else:\n        print(\"\u6587\u4ef6\u5199\u5165\u5b8c\u6bd5\uff01\")"
            ]
        ]
    },
    {
        "blob_id": "ecacb54265cd97d2192d5166ef0b87a3f1f27cb8",
        "matched_blocks": [
            [
                40,
                56,
                "    try:\n\n        fp = open(f, \"rb\")\n\n        try:\n            p = PcfFontFile.PcfFontFile(fp)\n        except SyntaxError:\n            fp.seek(0)\n            p = BdfFontFile.BdfFontFile(fp)\n\n        p.save(f)\n\n    except (SyntaxError, IOError):\n        print(\"failed\")\n\n    else:\n        print(\"OK\")"
            ]
        ]
    },
    {
        "blob_id": "a8dd63d37641bf5d2dbd04c750a68c9fc500b906",
        "matched_blocks": [
            [
                103,
                122,
                "\t\ttry:\n\t\t\tfp = open(path, 'r')\n\n\t\texcept FileNotFoundError:\n\t\t\traise FileNotFoundError(\"Unable to open the file path provided\")\n\n\t\telse:\n\t\t\twith fp:\n\t\t\t\tif header:\n\t\t\t\t\theader_info = next(fp)\n\t\t\t\t\tif len(header_info.split(sep)) != fields:\n\t\t\t\t\t\traise ValueError(f\"File path has {len(header_info.split(sep))} invalid number of fields instead of {fields}\")\n\n\t\t\t\tfor line in fp:\n\t\t\t\t\tif len(line.split(sep)) != fields:\n\t\t\t\t\t\traise ValueError(f\" file has {len(next(fp.split(sep)))} fields instead of {fields} \")\n\n\t\t\t\t\telse:\n\t\t\t\t\t\tline = line.strip().split(sep)\n\t\t\t\t\t\tyield tuple(line)"
            ]
        ]
    },
    {
        "blob_id": "fb5e14362c54bc9ed160c239f7c153c7f418275d",
        "matched_blocks": [
            [
                514,
                523,
                "            try:\n                file = open( joinpath( path, '%s.po' % lang ), 'rt' )\n            except IOError:\n                pass\n            else:\n                msg.manage_import( lang, file )\n                file.close()\n\n                # fix empty string (just in case...)\n                msg.manage_editLS( '', (lang, '') )"
            ]
        ]
    },
    {
        "blob_id": "8cfd3c66b9a03394e87c6cbbac0e72ae02d96b6b",
        "matched_blocks": [
            [
                14,
                21,
                "        try:\n            idade = int(input('Idade: '))\n        except:\n            print('\\033[31mERRO: por favor, digite um n\u00famero inteiro v\u00e1lido.\\033[m')\n        else:\n            print(f'Novo registro de {nome} adicionado')\n            arq.write(f'\\n{nome:<30}{idade} anos')\n            v\u00e1lido = True"
            ]
        ]
    },
    {
        "blob_id": "214e442be29616883451dca6b73800ab366555e6",
        "matched_blocks": [
            [
                27,
                32,
                "    try:\n        shared_link = get_client().sharing_create_shared_link(filepath)\n    except dropbox.exceptions.ApiError as e:\n        raise click.ClickException('There was a problem with the path.')\n    else:\n        return shared_link.url"
            ]
        ]
    },
    {
        "blob_id": "5a850bb6a63234b950eedb091013eaf3870c052c",
        "matched_blocks": [
            [
                1994,
                2001,
                "        try:\n            fut.wait()\n        except ValueError as e:\n            msg = str(e)\n            # Ensure newlines are unescaped to provide a better repr of error.\n            self.assertEqual(msg, msg.encode(\"utf-8\").decode(\"unicode_escape\"))\n        else:\n            self.assertTrue(False, \"expected raise_func_escape to raise ValueError.\")"
            ]
        ]
    },
    {
        "blob_id": "e050beb4b72499f095479534ef15503012f24674",
        "matched_blocks": [
            [
                90,
                114,
                "    try:\n        stats = activator.activate_sequentially(object_enumerable, count)\n    except sap.cli.wb.StopObjectActivation as ex:\n        printout('Activation has stopped')\n\n        printout_activation_stats(ex.stats)\n\n        if ex.stats.active_objects:\n            printout('Active objects:')\n            for obj in ex.stats.active_objects:\n                printout_adt_object('  ', obj)\n\n        return 1\n    else:\n        printout('Activation has finished')\n        printout_activation_stats(stats)\n\n        if stats.inactive_objects:\n            printout('Inactive objects:')\n            for obj in stats.inactive_objects:\n                printout_adt_object('  ', obj)\n\n            return 1\n\n        return 1 if stats.errors > 0 else 0"
            ]
        ]
    },
    {
        "blob_id": "667eb6fed857ae58ec25443185865bad8ea25cc9",
        "matched_blocks": [
            [
                539,
                551,
                "    try:\n        ctype = con['type'].lower()\n    except KeyError as e:\n        raise KeyError('Constraint %d has no type defined.' % ic) from e\n    except TypeError as e:\n        raise TypeError(\n            'Constraints must be a sequence of dictionaries.'\n        ) from e\n    except AttributeError as e:\n        raise TypeError(\"Constraint's type must be a string.\") from e\n    else:\n        if ctype not in ['eq', 'ineq']:\n            raise ValueError(\"Unknown constraint type '%s'.\" % con['type'])"
            ]
        ]
    },
    {
        "blob_id": "d2e84a80214b0bb95c3fcd82c32d59441a577327",
        "matched_blocks": [
            [
                261,
                267,
                "                try:\n                    putter = self.putters.pop()\n                    self._put(putter.item)\n                except:\n                    putter.throw(*sys.exc_info())\n                else:\n                    putter.switch(putter)"
            ]
        ]
    },
    {
        "blob_id": "05da5fd12fbafb2386db3b2f9980d4c9d9063e02",
        "matched_blocks": [
            [
                138,
                156,
                "        try:\n            qName = query.id\n        except AttributeError:\n            qName = \"query\"\n            qual = \"*\"\n        else:\n            try:\n                hard_clip_left = query.annotations[\"hard_clip_left\"]\n            except (AttributeError, KeyError):\n                pass\n            try:\n                hard_clip_right = query.annotations[\"hard_clip_right\"]\n            except (AttributeError, KeyError):\n                pass\n            try:\n                qual = query.letter_annotations[\"phred_quality\"]\n            except (AttributeError, KeyError):\n                qual = \"*\"\n            query = query.seq"
            ],
            [
                158,
                163,
                "        try:\n            rName = target.id\n        except AttributeError:\n            rName = \"target\"\n        else:\n            target = target.seq"
            ],
            [
                173,
                180,
                "        try:\n            query = bytes(query)\n        except TypeError:  # string\n            pass\n        except UndefinedSequenceError:\n            query = \"*\"\n        else:\n            query = str(query, \"ASCII\")"
            ],
            [
                188,
                229,
                "        try:\n            operations = alignment.operations\n        except AttributeError:\n            operations = None\n            for tEnd, qEnd in coordinates[1:, :]:\n                tCount = tEnd - tStart\n                qCount = qEnd - qStart\n                if tCount == 0:\n                    cigar += \"%dI\" % qCount  # insertion to the reference\n                    qStart = qEnd\n                elif qCount == 0:\n                    cigar += \"%dD\" % tCount  # deletion from the reference\n                    tStart = tEnd\n                else:\n                    if tCount != qCount:\n                        raise ValueError(\"Unequal step sizes in alignment\")\n                    cigar += \"%dM\" % tCount\n                    tStart = tEnd\n                    qStart = qEnd\n        else:\n            for operation, (tEnd, qEnd) in zip(operations, coordinates[1:, :]):\n                tCount = tEnd - tStart\n                qCount = qEnd - qStart\n                if tCount == 0:\n                    assert operation == ord(\"I\")\n                    cigar += \"%dI\" % qCount  # insertion to the reference\n                    qStart = qEnd\n                elif qCount == 0:\n                    if operation == ord(\"N\"):\n                        cigar += \"%dN\" % tCount  # skipped region from the reference\n                    elif operation == ord(\"D\"):\n                        cigar += \"%dD\" % tCount  # deletion from the reference\n                    else:\n                        raise ValueError(f\"Unexpected operation {operation}\")\n                    tStart = tEnd\n                else:\n                    if tCount != qCount:\n                        raise ValueError(\"Unequal step sizes in alignment\")\n                    assert operation == ord(\"M\")\n                    cigar += \"%dM\" % tCount\n                    tStart = tEnd\n                    qStart = qEnd"
            ],
            [
                325,
                331,
                "        try:\n            score = alignment.score\n        except AttributeError:\n            pass\n        else:\n            field = \"AS:i:%d\" % int(round(score))\n            fields.append(field)"
            ],
            [
                332,
                364,
                "        try:\n            annotations = alignment.annotations\n        except AttributeError:\n            pass\n        else:\n            for key, value in annotations.items():\n                if isinstance(value, int):\n                    datatype = \"i\"\n                    value = str(value)\n                elif isinstance(value, float):\n                    datatype = \"f\"\n                    value = str(value)\n                elif isinstance(value, str):\n                    if len(value) == 1:\n                        datatype = \"A\"\n                    else:\n                        datatype = \"Z\"\n                elif isinstance(value, bytes):\n                    datatype = \"H\"\n                    value = \"\".join(map(str, value))\n                elif isinstance(value, numpy.array):\n                    datatype = \"B\"\n                    if numpy.issubdtype(value.dtype, numpy.integer):\n                        letter = \"i\"\n                    elif numpy.issubdtype(value.dtype, float):\n                        letter = \"f\"\n                    else:\n                        raise ValueError(\n                            f\"Array of incompatible data type {value.dtype} in annotation '{key}'\"\n                        )\n                    value = \",\".join(map(str, value))\n                field = f\"{key}:{datatype}:{value}\"\n                fields.append(field)"
            ],
            [
                462,
                468,
                "        try:\n            line = self._line\n        except AttributeError:\n            lines = stream\n        else:\n            lines = chain([line], stream)\n            del self._line"
            ],
            [
                111,
                117,
                "            try:\n                description = record.description\n            except AttributeError:\n                pass\n            else:\n                if description != \"<unknown description>\":\n                    fields.append(\"DS:%s\" % description)"
            ]
        ]
    },
    {
        "blob_id": "69296a87df603a878a884e2d1f80f56eaf03c9f8",
        "matched_blocks": [
            [
                68,
                75,
                "        try:\n            dict_comp.flatten({'a': [0, 1], 'a.1': 2, })\n        except dict_comp.DuplicateIndexException:\n            pass\n        except Exception as e:\n            raise\n        else:\n            assert \"did not raise exception\""
            ]
        ]
    },
    {
        "blob_id": "e7df89bb363a64317c365f5f45a13d4c5a2e4096",
        "matched_blocks": [
            [
                198,
                206,
                "        try:\n            st = os.stat(fn)\n        except OSError:\n            # File most likely does not exist\n            pass\n        else:\n            # XXX What about other special files? (sockets, devices...)\n            if shutil.stat.S_ISFIFO(st.st_mode):\n                raise shutil.SpecialFileError(\"`%s` is a named pipe\" % fn)"
            ]
        ]
    },
    {
        "blob_id": "0fdfd0a2fe0d2384fb8bf820f0da8991e1d1fce7",
        "matched_blocks": [
            [
                55,
                60,
                "    try:\n        model = joblib.load(_path)\n    except:\n        raise Exception('\u6a21\u578b\u52a0\u8f7d\u9519\u8bef\uff01')\n    else:\n        return model"
            ],
            [
                67,
                72,
                "    try:\n        joblib.dump(_model,_path)\n    except:\n        raise Exception('\u6a21\u578b\u4fdd\u5b58\u9519\u8bef\uff01')\n    else:\n        return"
            ]
        ]
    },
    {
        "blob_id": "d5ea4520f6777f61e947e3360ca60515640e7d72",
        "matched_blocks": [
            [
                453,
                458,
                "    try:\n        x.write(b'')\n    except TypeError:\n        return True\n    else:\n        return False"
            ],
            [
                286,
                296,
                "            try:\n                del callbackd[cid]\n            except KeyError:\n                continue\n            else:\n                for signal, functions in list(\n                        six.iteritems(self._func_cid_map)):\n                    for function, value in list(six.iteritems(functions)):\n                        if value == cid:\n                            del functions[function]\n                return"
            ]
        ]
    },
    {
        "blob_id": "7d3241eb1799353ed75353e467681373a61ac336",
        "matched_blocks": [
            [
                119,
                130,
                "        try:\n            result = nx.ping(dest_ip)\n        except Exception as e:\n            self.failed(f'Ping from {nx.name}->{dest_ip} failed: {e}')\n        else:\n            m = re.search(r\"(?P<rate>\\d+)\\.\\d+% packet loss\", result)\n            loss_rate = m.group('rate')\n\n            if int(loss_rate) < 20:\n                self.passed(f'Ping loss rate {loss_rate}%')\n            else:\n                self.failed(f'Ping loss rate {loss_rate}%')"
            ]
        ]
    },
    {
        "blob_id": "221cf3f8b981c2f28598a2e9958dcaebe825e227",
        "matched_blocks": [
            [
                44,
                51,
                "                try:\n                    os.makedirs(prj_cfg.FILE_LOG_PATH, exist_ok=True)\n                    Logger.__log_file = open(file=file_path_name, mode='w')\n                except OSError as err:\n                    self.error('Cannot open file: {file}, error: {err}'\n                        .format(file=file_path_name, err=err))\n                else:\n                    utils_exit.register_on_exit(Logger.close_log_file)"
            ]
        ]
    },
    {
        "blob_id": "63dcaf6fca6681641b302ca7d9485d92ad238958",
        "matched_blocks": [
            [
                528,
                578,
                "                try:\n                    kwargs = self.feature_kwargs(feat)\n                except LayerMapError as msg:\n                    # Something borked the validation\n                    if strict:\n                        raise\n                    elif not silent:\n                        stream.write('Ignoring Feature ID %s because: %s\\n' % (feat.fid, msg))\n                else:\n                    # Constructing the model using the keyword args\n                    is_update = False\n                    if self.unique:\n                        # If we want unique models on a particular field, handle the\n                        # geometry appropriately.\n                        try:\n                            # Getting the keyword arguments and retrieving\n                            # the unique model.\n                            u_kwargs = self.unique_kwargs(kwargs)\n                            m = self.model.objects.using(self.using).get(**u_kwargs)\n                            is_update = True\n\n                            # Getting the geometry (in OGR form), creating\n                            # one from the kwargs WKT, adding in additional\n                            # geometries, and update the attribute with the\n                            # just-updated geometry WKT.\n                            geom = getattr(m, self.geom_field).ogr\n                            new = OGRGeometry(kwargs[self.geom_field])\n                            for g in new:\n                                geom.add(g)\n                            setattr(m, self.geom_field, geom.wkt)\n                        except ObjectDoesNotExist:\n                            # No unique model exists yet, create.\n                            m = self.model(**kwargs)\n                    else:\n                        m = self.model(**kwargs)\n\n                    try:\n                        # Attempting to save.\n                        m.save(using=self.using)\n                        num_saved += 1\n                        if verbose:\n                            stream.write('%s: %s\\n' % ('Updated' if is_update else 'Saved', m))\n                    except Exception as msg:\n                        if strict:\n                            # Bailing out if the `strict` keyword is set.\n                            if not silent:\n                                stream.write('Failed to save the feature (id: %s) into the model with the keyword arguments:\\n' % feat.fid)\n                                stream.write('%s\\n' % kwargs)\n                            raise\n                        elif not silent:\n                            stream.write('Failed to save %s:\\n %s\\nContinuing\\n' % (kwargs, msg))"
            ]
        ]
    },
    {
        "blob_id": "a81bb46994fc6461d42cfe0ba8c6e447be9c71b4",
        "matched_blocks": [
            [
                243,
                248,
                "            try:\n                time.sleep(sleep_duration)\n            except KeyboardInterrupt as e:\n                printc(\"<red>You interrupted the process of sending this message, skipping to next one (or stopping now)...<reset><white>\")\n            else:\n                printc(\"\\nDone sleeping for <red>{}<reset><white> seconds, it's time to query the API !\".format(sleep_duration))"
            ],
            [
                304,
                309,
                "            try:\n                sleep_duration = int(argv[index + 1])\n            except:\n                printc(\"<red>Unable to get a sleep duration value from the command line argument ('{}' does not convert to an integer).\".format(argv[index + 1]))  # DEBUG\n            else:\n                argv.pop(index)  # remove sleep_duration"
            ]
        ]
    },
    {
        "blob_id": "b31f396350cbbd37359e1a9e342d4727d49e9c68",
        "matched_blocks": [
            [
                134,
                160,
                "    try:\n        cubes = list(robot.world.visible_objects)\n    except asyncio.TimeoutError:\n        print(\"find_and_update_cubes: timeout error\")\n        return False, seen_cubes\n    else:\n        changed = False\n        for cube in cubes:\n            is_cube_1 = cube.object_id == robot.world.light_cubes[cozmo.objects.LightCube1Id].object_id\n            is_cube_2 = cube.object_id == robot.world.light_cubes[cozmo.objects.LightCube2Id].object_id\n            is_cube_3 = cube.object_id == robot.world.light_cubes[cozmo.objects.LightCube3Id].object_id\n            if 1 not in seen_cubes and is_cube_1:\n                print(\"I found cube 1 at \" + str(poseToGridRaw(cube.pose)))\n                seen_cubes[1] = cube\n                changed = True\n                gP = add_goal_obstacle_to_grid(grid, poseToGridRaw(cube.pose), seen_cubes[1])\n            elif 2 not in seen_cubes and is_cube_2:\n                print(\"I found cube 2 at \" + str(poseToGridRaw(cube.pose)))\n                seen_cubes[2] = cube\n                changed = True\n                add_obstacle_to_grid(grid, poseToGridRaw(cube.pose))\n            elif 3 not in seen_cubes and is_cube_3:\n                print(\"I found cube 3 at \" + str(poseToGridRaw(cube.pose)))\n                seen_cubes[3] = cube\n                changed = True\n                add_obstacle_to_grid(grid, poseToGridRaw(cube.pose))\n        return changed, seen_cubes, gP"
            ]
        ]
    },
    {
        "blob_id": "0a89a58dcfb26dada77c7dc1f606138749173f1f",
        "matched_blocks": [
            [
                364,
                370,
                "            try:\n                store = self.externalStoreCache[self]\n            except KeyError:\n                logger.info('Creating new external store for %s', self)\n                store = self.externalStoreCache[self] = self._createExternalStore()\n            else:\n                logger.info('Reusing external store for %s', self)"
            ]
        ]
    },
    {
        "blob_id": "483c301f953c3c537727a973289e3a0073e0e2cc",
        "matched_blocks": [
            [
                67,
                81,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "6179cc482ce3eda55fca3ef42564012d3b315c90",
        "matched_blocks": [
            [
                113,
                137,
                "            try:\n                response = self._session.post(*args, **kwargs)\n            except (requests.exceptions.ConnectionError,\n                    requests.exceptions.Timeout):\n                # No response from server at all\n                if max_delay < delay:\n                    # Give up\n                    raise\n                time.sleep(delay)\n                delay *= 2\n            else:\n                if response.status_code == 503:\n                    # Service unavailable\n                    if max_delay < delay:\n                        # Give up\n                        return response\n                    time.sleep(delay)\n                    delay *= 2\n                elif response.status_code == 429:\n                    # Too many requests\n                    time.sleep(int(response.headers.get('Retry-After', 1)))\n                    delay = 1\n                else:\n                    # Success. Or at least, not a response that we want to retry\n                    return response"
            ]
        ]
    },
    {
        "blob_id": "bd6a9831ec6c286db6ed408f8d0f498356771f0c",
        "matched_blocks": [
            [
                121,
                129,
                "        try:\n            fields = self.object.searchindex.fields\n        except:\n            fields = {}\n        else:\n            for key, field in fields.items():\n                has_model_attr = getattr(field, 'model_attr', None)\n                if has_model_attr is not None:\n                    outfields[key] = force_text(has_model_attr)"
            ]
        ]
    },
    {
        "blob_id": "824534efc2fec88f9dc03d4f37045b4d0e53624d",
        "matched_blocks": [
            [
                2213,
                2242,
                "    try:\n        beta = float(window)\n    except (TypeError, ValueError) as e:\n        args = ()\n        if isinstance(window, tuple):\n            winstr = window[0]\n            if len(window) > 1:\n                args = window[1:]\n        elif isinstance(window, str):\n            if window in _needs_param:\n                raise ValueError(\"The '\" + window + \"' window needs one or \"\n                                 \"more parameters -- pass a tuple.\") from e\n            else:\n                winstr = window\n        else:\n            raise ValueError(\"%s as window type is not supported.\" %\n                             str(type(window))) from e\n\n        try:\n            winfunc = _win_equiv[winstr]\n        except KeyError as e:\n            raise ValueError(\"Unknown window type.\") from e\n\n        if winfunc is dpss:\n            params = (Nx,) + args + (None,)\n        else:\n            params = (Nx,) + args\n    else:\n        winfunc = kaiser\n        params = (Nx, beta)"
            ]
        ]
    },
    {
        "blob_id": "37291519aaae3a4c2821aa4a82b255206baef928",
        "matched_blocks": [
            [
                5,
                10,
                "    try:\n        f(*args)\n    except ex:\n        pass\n    else:\n        assert False"
            ],
            [
                26,
                31,
                "    try:\n        tmp.weights_size\n    except NotImplementedError:\n        pass\n    else:\n        assert False"
            ]
        ]
    },
    {
        "blob_id": "8852a16d08a5a003bc41bff9adedcf3cc48f8f8d",
        "matched_blocks": [
            [
                10,
                15,
                "    try:\n        __import__(module_name)\n    except ImportError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "f578af94f827e03d57627805204eccd982cf649c",
        "matched_blocks": [
            [
                454,
                461,
                "                try:\n                    order = Order.objects.get(\n                        number=data['order_number'], user=self.request.user)\n                except Order.DoesNotExist:\n                    pass\n                else:\n                    return redirect(\n                        'customer:order', order_number=order.number)"
            ]
        ]
    },
    {
        "blob_id": "c646d5714413964656c20a34b700806958456ef0",
        "matched_blocks": [
            [
                388,
                396,
                "            try:\n                ProductAlert.objects.get(\n                    product=self.product, email__iexact=email,\n                    status=ProductAlert.ACTIVE)\n            except ProductAlert.DoesNotExist:\n                pass\n            else:\n                raise forms.ValidationError(_(\n                    \"There is already an active stock alert for %s\") % email)"
            ],
            [
                408,
                416,
                "            try:\n                ProductAlert.objects.get(product=self.product,\n                                         user=self.user,\n                                         status=ProductAlert.ACTIVE)\n            except ProductAlert.DoesNotExist:\n                pass\n            else:\n                raise forms.ValidationError(_(\n                    \"You already have an active alert for this product\"))"
            ]
        ]
    },
    {
        "blob_id": "05922d249f748d4419bb3cfaef132df5ead2bb63",
        "matched_blocks": [
            [
                55,
                68,
                "    try:\n        device.execute(\"write erase\", reply=wr_dialog)\n    except Exception as e:\n        raise Exception(\n            \"Error while executing 'write erase' on device '{}' : {}\".format(\n                device.name, e\n            )\n        ) from e\n    else:\n        log.info(\n            \"Successfully executed 'write erase' command on device '{}'\".format(\n                device.name\n            )\n        )"
            ],
            [
                121,
                142,
                "    try:\n        device.connect()\n    except (ConnectionError, TimeoutError) as e:\n        # Connection or Timeout Error but 'no' has been sent\n        # simply destroy handle at this point\n        device.disconnect()\n        log.info(\n            \"Reconnected to device '{}' after 'write erase' and reload'\".format(\n                hostname\n            )\n        )\n    except Exception as e:\n        raise Exception(\n            \"Error reconnecting to device '{}' after 'write erase'\"\n            \" and reload\".format(hostname)\n        ) from e\n    else:\n        device.disconnect()\n        log.info(\n            \"Successully reconnected to device '{}' after 'write erase' \"\n            \"and reload'\".format(hostname)\n        )"
            ]
        ]
    },
    {
        "blob_id": "c517166cc1f3487953498d678a31ad7fb19e3f58",
        "matched_blocks": [
            [
                27,
                41,
                "    try:\n        selected_song = album.song_set.get(pk=request.POST['song'])\n    except (KeyError,Song.DoesNotExist):\n        return render(request,\"music/detail.html\",{\n             'album': album,\n              'error_message':\"you did't selected any Songs\"\n\n        })\n    else:\n        if selected_song.is_favourite is False:\n            selected_song.is_favourite = True\n        else:\n            selected_song.is_favourite = False\n        selected_song.save()\n        return render(request,\"music/detail.html\",{\"album\": album})"
            ]
        ]
    },
    {
        "blob_id": "788d74a0541595cac3c54e408e4d3d2a423cdc26",
        "matched_blocks": [
            [
                37,
                42,
                "                try:\n                    instance.full_clean()\n                except ValidationError as e:\n                    log.debug('Invalid data(%s): %s', e, dict(item))\n                else:\n                    yield instance"
            ]
        ]
    },
    {
        "blob_id": "fc931823e2e0c5dadbbef45f1c7f9f23c9c60607",
        "matched_blocks": [
            [
                1455,
                1461,
                "        try:\n            dct = self.to_dict()\n        except Exception:\n            utils.display_traceback(in_ipython=True)\n            return {}\n        else:\n            return renderers.get()(dct)"
            ]
        ]
    },
    {
        "blob_id": "0764fd9cfe586798c0d72ae40679aabd7fe72a9e",
        "matched_blocks": [
            [
                194,
                199,
                "    try:\n        cached_db = flask.request.cookies['DB']\n    except:\n        return list_db[0]\n    else:\n        return cached_db"
            ]
        ]
    },
    {
        "blob_id": "a12a2f37cb428903860417ef23a04a630d2274bd",
        "matched_blocks": [
            [
                41,
                46,
                "    try:\n        os.mkdir(save_path)\n    except OSError:\n        print(\"Creation of the directory %s failed\" % save_path)\n    else:\n        print(\"Successfully created the directory %s \" % save_path)"
            ]
        ]
    },
    {
        "blob_id": "77af20813e4b021b3ccc6c4ed6a0217b42fee8fe",
        "matched_blocks": [
            [
                158,
                183,
                "        try:\n            LOG.debug(\"Getting Restore Runner %(type)s.\", backup_info)\n            restore_runner = self._get_restore_runner(backup_info['type'])\n\n            LOG.debug(\"Getting Storage Strategy.\")\n            storage = get_storage_strategy(\n                CONF.storage_strategy,\n                CONF.storage_namespace)(context)\n\n            runner = restore_runner(storage, location=backup_info['location'],\n                                    checksum=backup_info['checksum'],\n                                    restore_location=restore_location)\n            backup_info['restore_location'] = restore_location\n            LOG.debug(\"Restoring instance from backup %(id)s to \"\n                      \"%(restore_location)s.\", backup_info)\n            content_size = runner.restore()\n            LOG.debug(\"Restore from backup %(id)s completed successfully \"\n                      \"to %(restore_location)s.\", backup_info)\n            LOG.debug(\"Restore size: %s.\", content_size)\n\n        except Exception:\n            LOG.exception(\"Error restoring backup %(id)s.\", backup_info)\n            raise\n\n        else:\n            LOG.debug(\"Restored backup %(id)s.\", backup_info)"
            ]
        ]
    },
    {
        "blob_id": "39857f0c0b9b5a6994f5441765d1379c4d670600",
        "matched_blocks": [
            [
                99,
                110,
                "        try:\n            match = resolve(match_url)\n        except Resolver404:\n            pass\n        else:\n            current_url = '%s:%s' % (match.app_name, match.url_name)\n            namespace = 'common'\n            if context.get('site_namespace'):\n                namespace = context.get('site_namespace')\n            changelist_url = '%s:%s_%s_changelist' % (namespace, opts.app_label, opts.model_name)\n            if changelist_url == current_url and '_changelist_filters' in preserved_filters:\n                preserved_filters = dict(parse_qsl(preserved_filters['_changelist_filters']))"
            ],
            [
                147,
                172,
                "        try:\n            f, attr, value = lookup_field(field_name, result, cl.model_admin)\n        except ObjectDoesNotExist:\n            result_repr = empty_value_display\n        else:\n            empty_value_display = getattr(attr, 'empty_value_display', empty_value_display)\n            if f is None or f.auto_created:\n                if field_name == 'action_checkbox':\n                    row_classes.append('action-checkbox')\n                if field_name == 'details_button':\n                    row_classes.append('details-button')\n                boolean = getattr(attr, 'boolean', False)\n                result_repr = display_for_value(value, empty_value_display, boolean)\n                if isinstance(value, (datetime.date, datetime.time)):\n                    row_classes.append('nowrap')\n            else:\n                if isinstance(f.remote_field, models.ManyToOneRel):\n                    field_val = getattr(result, f.name)\n                    if field_val is None:\n                        result_repr = empty_value_display\n                    else:\n                        result_repr = field_val\n                else:\n                    result_repr = display_for_field(value, f, empty_value_display)\n                if isinstance(f, (models.DateField, models.TimeField, models.ForeignKey)):\n                    row_classes.append('nowrap')"
            ],
            [
                183,
                206,
                "            try:\n                url = cl.url_for_result(result)\n            except NoReverseMatch:\n                link_or_text = result_repr\n            else:\n                url = common_add_preserved_filters(\n                    {\n                        'preserved_filters': cl.preserved_filters,\n                        'opts': cl.opts},\n                    url)\n                # Convert the pk to something that can be used in Javascript.\n                # Problem cases are long ints (23L) and non-ASCII strings.\n                if cl.to_field:\n                    attr = str(cl.to_field)\n                else:\n                    attr = pk\n                value = result.serializable_value(attr)\n                link_or_text = format_html(\n                    '<a href=\"{}\"{}>{}</a>',\n                    url,\n                    format_html(\n                        ' data-popup-opener=\"{}\"', value\n                    ) if cl.is_popup else '',\n                    result_repr)"
            ]
        ]
    },
    {
        "blob_id": "953537f3f43158e3304220842227e163622193db",
        "matched_blocks": [
            [
                1549,
                1557,
                "        try:\n            trans = self.inaxes.transData.inverted()\n            xdata, ydata = trans.transform_point((x, y))\n        except ValueError:\n            self.xdata = None\n            self.ydata = None\n        else:\n            self.xdata = xdata\n            self.ydata = ydata"
            ],
            [
                2594,
                2604,
                "        try:\n            x_state, y_state = (\n                cycle[(cycle.index((x_state, y_state)) + 1) % len(cycle)])\n        except ValueError:\n            # Exclude major grids not in a uniform state.\n            pass\n        else:\n            # If turning major grids off, also turn minor grids off.\n            ax.grid(x_state, which=\"major\" if x_state else \"both\", axis=\"x\")\n            ax.grid(y_state, which=\"major\" if y_state else \"both\", axis=\"y\")\n            canvas.draw_idle()"
            ],
            [
                2613,
                2622,
                "        try:\n            x_state, y_state = (\n                cycle[(cycle.index((x_state, y_state)) + 1) % len(cycle)])\n        except ValueError:\n            # Exclude minor grids not in a uniform state.\n            pass\n        else:\n            ax.grid(x_state, which=\"both\", axis=\"x\")\n            ax.grid(y_state, which=\"both\", axis=\"y\")\n            canvas.draw_idle()"
            ],
            [
                2924,
                2942,
                "            try:\n                s = event.inaxes.format_coord(event.xdata, event.ydata)\n            except (ValueError, OverflowError):\n                pass\n            else:\n                artists = [a for a in event.inaxes.mouseover_set\n                           if a.contains(event) and a.get_visible()]\n\n                if artists:\n                    a = max(artists, key=lambda x: x.zorder)\n                    if a is not event.inaxes.patch:\n                        data = a.get_cursor_data(event)\n                        if data is not None:\n                            s += ' [%s]' % a.format_cursor_data(data)\n\n                if len(self.mode):\n                    self.set_message('%s, %s' % (self.mode, s))\n                else:\n                    self.set_message(s)"
            ]
        ]
    },
    {
        "blob_id": "38fa1bdcf32d9a41324dc89afe6c727eb8ccee83",
        "matched_blocks": [
            [
                700,
                707,
                "    try:\n        await bot.wait_for('message', check=verifycheck, timeout=5)\n        if TypeError:\n            await ctx.send('failed')\n    except asyncio.TimeoutError:\n        await ctx.send(\"**The verification token has expired!  Please send $verify to start a new one.**\")\n    else:\n        await ctx.author.add_roles(role)"
            ]
        ]
    },
    {
        "blob_id": "1f6f0c2490ff3734c1773283e4029d90c7b09ae1",
        "matched_blocks": [
            [
                215,
                223,
                "        try:\n            sci_cat = await self.bot.wait_for('message', timeout=30.0, check=check)\n                        \n        except asyncio.TimeoutError:\n            await ctx.send('```Too slow choosing jabroni, try !books again when'\n                           ' you\\'ve made up your mind!```')\n        else:\n            chosen_cat = sci_cat.content\n            print(chosen_cat)"
            ],
            [
                235,
                242,
                "        try:\n            sci_inc = await self.bot.wait_for('message', timeout=30.0, check=check)\n                        \n        except asyncio.TimeoutError:\n            await ctx.send('```too slow```')\n            \n        else:\n            chosen_inc = sci_inc.content"
            ]
        ]
    },
    {
        "blob_id": "2670a564756e2418d01354846cf57d5defcc1c20",
        "matched_blocks": [
            [
                942,
                955,
                "    try:\n        from cftime import datetime as cftime_datetime\n    except ImportError:\n        return False\n    else:\n        if var.dtype == np.dtype('O') and var.data.size > 0:\n            sample = var.data.ravel()[0]\n            if isinstance(sample, dask_array_type):\n                sample = sample.compute()\n                if isinstance(sample, np.ndarray):\n                    sample = sample.item()\n            return isinstance(sample, cftime_datetime)\n        else:\n            return False"
            ]
        ]
    },
    {
        "blob_id": "58228ea9f2d640725e31bb16f5c48b23318a43d7",
        "matched_blocks": [
            [
                169,
                181,
                "    try:\n        resident = Resident.objects.get(id=int(resident_id))\n    except Resident.DoesNotExist:\n        return JsonResponse({'error': True, 'error_msg': 'No resident with id '.format(resident_id)})\n    else:\n        response = []\n        if resident.family:\n            members = resident.family.members.all()\n            for member in members:\n                item = {'id': member.id, 'name': resident.name}\n                response.append(item)\n\n        return JsonResponse({'error': False, 'length': len(response), 'members': response})"
            ],
            [
                34,
                44,
                "        try:\n            app_user = AppUser.objects.get(mobile=mobile, password=password)\n        except AppUser.DoesNotExist:\n            response['error'] = True\n            response['error_msg'] = 'Wrong mobile or password'\n        else:\n            response = model_to_dict(app_user, fields=['name', 'identity', 'mobile', 'password'])\n            response['resident_id'] = app_user.resident.id\n            response['created_at'] = app_user.created_at\n            response['updated_at'] = app_user.updated_at\n            response['error'] = False"
            ],
            [
                61,
                81,
                "        try:\n            #  here should consider the mobile or identity has been registered\n            AppUser.objects.get(mobile=mobile)\n        except AppUser.DoesNotExist:\n            try:\n                resident = Resident.objects.get(identity=identity)\n            except Resident.DoesNotExist:\n                response['error'] = True\n                response['error_msg'] = 'There is no information about the resident in the system.'\n            else:\n                app_user = AppUser(name=name, password=password, mobile=mobile, identity=identity)\n                app_user.resident = resident\n                app_user.save()\n                response = model_to_dict(app_user, fields=['name', 'identity', 'mobile', 'password'])\n                response['resident_id'] = resident.id\n                response['created_at'] = app_user.created_at\n                response['updated_at'] = app_user.updated_at\n                response['error'] = False\n        else:\n            response['error'] = True\n            response['error_msg'] = 'The mobile has registered'"
            ],
            [
                65,
                78,
                "            try:\n                resident = Resident.objects.get(identity=identity)\n            except Resident.DoesNotExist:\n                response['error'] = True\n                response['error_msg'] = 'There is no information about the resident in the system.'\n            else:\n                app_user = AppUser(name=name, password=password, mobile=mobile, identity=identity)\n                app_user.resident = resident\n                app_user.save()\n                response = model_to_dict(app_user, fields=['name', 'identity', 'mobile', 'password'])\n                response['resident_id'] = resident.id\n                response['created_at'] = app_user.created_at\n                response['updated_at'] = app_user.updated_at\n                response['error'] = False"
            ]
        ]
    },
    {
        "blob_id": "9aa1920c963f4e1c59d8f11e9efff552b6d5d9ac",
        "matched_blocks": [
            [
                233,
                252,
                "            try:\n                res = self.client.resources.get(\n                    stack_identifier, resource_name)\n            except heat_exceptions.HTTPNotFound:\n                if success_on_not_found:\n                    return\n                # ignore this, as the resource may not have\n                # been created yet\n            else:\n                if res.resource_status == status:\n                    return\n                wait_for_action = status.split('_')[0]\n                resource_action = res.resource_status.split('_')[0]\n                if (resource_action == wait_for_action and\n                        fail_regexp.search(res.resource_status)):\n                    raise exceptions.StackResourceBuildErrorException(\n                        resource_name=res.resource_name,\n                        stack_identifier=stack_identifier,\n                        resource_status=res.resource_status,\n                        resource_status_reason=res.resource_status_reason)"
            ],
            [
                312,
                323,
                "            try:\n                stack = self.client.stacks.get(stack_identifier,\n                                               resolve_outputs=False)\n            except heat_exceptions.HTTPNotFound:\n                if success_on_not_found:\n                    return\n                # ignore this, as the resource may not have\n                # been created yet\n            else:\n                if self._verify_status(stack, stack_identifier, status,\n                                       fail_regexp):\n                    return"
            ],
            [
                348,
                358,
                "            try:\n                fn(*args, **kwargs)\n            except heat_exceptions.HTTPConflict as ex:\n                # FIXME(sirushtim): Wait a little for the stack lock to be\n                # released and hopefully, the stack should be usable again.\n                if ex.error['error']['type'] != 'ActionInProgress':\n                    raise ex\n\n                time.sleep(build_interval)\n            else:\n                break"
            ],
            [
                423,
                433,
                "            try:\n                nested_identifier = self._get_nested_identifier(\n                    stack_identifier, res_name)\n            except Exception:\n                # We may have to wait, if the create is in-progress\n                if wait:\n                    time.sleep(build_interval)\n                else:\n                    raise\n            else:\n                return nested_identifier"
            ],
            [
                575,
                584,
                "            try:\n                rsrc_events = self.client.events.list(stack_identifier,\n                                                      resource_name=rsrc_name)\n            except heat_exceptions.HTTPNotFound:\n                LOG.debug(\"No events yet found for %s\" % rsrc_name)\n            else:\n                matched = [e for e in rsrc_events\n                           if e.resource_status_reason == reason]\n                if len(matched) == num_expected:\n                    return matched"
            ]
        ]
    },
    {
        "blob_id": "6c55a910a82f7506bb0163f4c1d2657d10e9d633",
        "matched_blocks": [
            [
                393,
                399,
                "\t\t\ttry:\n\t\t\t\ts, a = c.accept()\n\t\t\t\t#s.settimeout(30)\n\t\t\texcept socket.timeout:\n\t\t\t\tprint('Waiting for clinet to connect...')\n\t\t\telse:\n\t\t\t\tbreak"
            ],
            [
                356,
                362,
                "\t\t\t\ttry:\n\t\t\t\t\tself.downloader(key)\n\t\t\t\texcept:\n\t\t\t\t\tprint('Error!!')\n\t\t\t\t\tprint((traceback.format_exc()))\n\t\t\t\telse:\n\t\t\t\t\tprint('Done!!')"
            ]
        ]
    },
    {
        "blob_id": "2fd547723d832790323016a9974bfa1bfc32a049",
        "matched_blocks": [
            [
                54,
                60,
                "                try:\n                    (username, password) = credentials.split(':', 1)\n                except ValueError:\n                    raise zc.buildout.UserError('Every pair credentials must '\n                                                'be separated be a colon.')\n                else:\n                    self.credentials.append((username, password))"
            ]
        ]
    },
    {
        "blob_id": "2fbbd183b02fc3f961d32a9f9a9bf87a801392d7",
        "matched_blocks": [
            [
                154,
                159,
                "        try:\n            cur = self.room\n        except AttributeError:\n            pass\n        else:\n            cur.remove(self)"
            ]
        ]
    },
    {
        "blob_id": "d807160b884fc48664baecba5091c81617606ca4",
        "matched_blocks": [
            [
                1133,
                1152,
                "        try:\n            if within_columns_clause:\n                col = only_froms[element.element]\n            else:\n                col = with_cols[element.element]\n        except KeyError as err:\n            coercions._no_text_coercion(\n                element.element,\n                extra=(\n                    \"Can't resolve label reference for ORDER BY / \"\n                    \"GROUP BY / DISTINCT etc.\"\n                ),\n                exc_cls=exc.CompileError,\n                err=err,\n            )\n        else:\n            kwargs[\"render_label_as_label\"] = col\n            return self.process(\n                col, within_columns_clause=within_columns_clause, **kwargs\n            )"
            ],
            [
                1759,
                1769,
                "            try:\n                opstring = OPERATORS[operator_]\n            except KeyError as err:\n                util.raise_(\n                    exc.UnsupportedCompilationError(self, operator_),\n                    replace_context=err,\n                )\n            else:\n                return self._generate_generic_binary(\n                    binary, opstring, from_linter=from_linter, **kw\n                )"
            ]
        ]
    },
    {
        "blob_id": "3196775b33a54481b53b726ec99dbc4e1e604f81",
        "matched_blocks": [
            [
                208,
                219,
                "        try:\n          valid_options_under_scope = set(options.for_scope(scope))\n        # Only catch ConfigValidationError. Other exceptions will be raised directly.\n        except Config.ConfigValidationError:\n          error_log.append(\"Invalid scope [{}] in {}\".format(section, config.configpath))\n        else:\n          # All the options specified under [`section`] in `config` excluding bootstrap defaults.\n          all_options_under_scope = (set(config.configparser.options(section)) -\n                                     set(config.configparser.defaults()))\n          for option in all_options_under_scope:\n            if option not in valid_options_under_scope:\n              error_log.append(\"Invalid option '{}' under [{}] in {}\".format(option, section, config.configpath))"
            ]
        ]
    },
    {
        "blob_id": "ab14c4d4a9d8c432ae24647c18b9e98e4968ece0",
        "matched_blocks": [
            [
                33,
                147,
                "    try:\n        cv_image = CvBridge().imgmsg_to_cv2(msg, \"bgr8\")\n        # crop out the excess image\n        cv_image = cv_image[100:300, 100:300, :]\n    except CvBridgeError as e:\n        print(\"[INFO]: Error in obtaining image from CvBridge! Skipping frame!\")\n    else:\n        # convert to gray\n        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\n        # convert to edges\n        edges = cv2.Canny(gray, 50, 150)\n        cv2.imshow(\"edges\", edges)\n        cv2.waitKey(1)\n        # convert to thresholded image\n        ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n        # extract hough lines\n        lines = cv2.HoughLinesP(edges, 1, m.pi/180, 2, None, 20, 1)\n\n        # list of [count, angle] pairs\n        cnt_ang_pair = []\n\n        # draw lines\n        for i in range(lines.shape[0]):\n            for line in lines[i]:\n                pt1 = (line[0], line[1])\n                pt2 = (line[2], line[3])\n                cv2.line(cv_image, pt1, pt2, (255, 0, 0), 3)\n                # calculate angle\n                ang = m.atan2(pt2[1]-pt1[1], pt2[0]-pt1[0])\n                cnt_ang_pair.append([1, m.degrees(ang)])\n\n        ###################### show the detected lines ########################\n        cv2.imshow(\"frame\", cv_image)\n        cv2.waitKey(1)\n        #######################################################################\n\n        if len(cnt_ang_pair) != 0:\n            # sort the cnt_ang_pair\n            cnt_ang_pair.sort(key=lambda x: x[1])\n\n            # bunch up the pairs based on predetermined threshold\n            ang_thresh_deg = 1\n            bunch = [cnt_ang_pair[0]]\n            for i in range(1, len(cnt_ang_pair)):\n                pairs = cnt_ang_pair[i]\n                if abs(pairs[1] - bunch[-1][1]) < ang_thresh_deg:\n                    # update the value and the count\n                    new_count = bunch[-1][0] + 1\n                    new_value = (\n                        (bunch[-1][1] * (new_count - 1) * 1.0) / new_count) + (pairs[1]*1.0) / new_count\n                    bunch[-1] = [new_count, new_value]\n                else:\n                    # time to append\n                    bunch.append(pairs)\n\n            # sort bunch based on first value i.e. count\n            bunch.sort(key=lambda x: x[0], reverse=True)\n\n            if DEBUG:\n                print(\"The cnt_ang_pair list is: \\n {} \\n\".format(cnt_ang_pair))\n                print(\"The bunched up list is: \\n {} \\n\".format(bunch))\n\n            # use the first value of bunch\n            f_ori = m.radians(bunch[0][1])  # in degrees\n            f_ori1 = wrap2Pi(f_ori + m.radians(90) - ini_angle_offset)\n            f_ori2 = wrap2Pi(f_ori + m.radians(-90) - ini_angle_offset)\n            f_ori3 = wrap2Pi(f_ori + m.radians(180) - ini_angle_offset)\n\n            # we need to find which has the smallest difference\n            # f_ori, f_ori1 or f_ori2\n            if(abs(wrap2Pi(best_ori_estimate - f_ori)) < abs(wrap2Pi(best_ori_estimate - f_ori1)) and abs(wrap2Pi(best_ori_estimate - f_ori)) < abs(wrap2Pi(best_ori_estimate - f_ori2)) and abs(wrap2Pi(best_ori_estimate - f_ori)) < abs(wrap2Pi(best_ori_estimate - f_ori3))):\n                best_ori_estimate_temp = f_ori\n            elif(abs(wrap2Pi(best_ori_estimate - f_ori1)) < abs(wrap2Pi(best_ori_estimate - f_ori)) and abs(wrap2Pi(best_ori_estimate - f_ori1)) < abs(wrap2Pi(best_ori_estimate - f_ori2)) and abs(wrap2Pi(best_ori_estimate - f_ori1)) < abs(wrap2Pi(best_ori_estimate - f_ori3))):\n                best_ori_estimate_temp = f_ori1\n            elif(abs(wrap2Pi(best_ori_estimate - f_ori2)) < abs(wrap2Pi(best_ori_estimate - f_ori)) and abs(wrap2Pi(best_ori_estimate - f_ori2)) < abs(wrap2Pi(best_ori_estimate - f_ori1)) and abs(wrap2Pi(best_ori_estimate - f_ori2)) < abs(wrap2Pi(best_ori_estimate - f_ori3))):\n                best_ori_estimate_temp = f_ori2\n            else:\n                best_ori_estimate_temp = f_ori3\n\n            # will get the best_ori_estimate in degrees , the choice is made so that any difference will be amplified more than radians\n            best_ori_estimate = best_ori_estimate_temp\n            if DEBUG:\n                print(\"best ori estimate: {} deg\".format(\n                    m.degrees(best_ori_estimate)))\n            # to debug lets plot the best_ori_estimate in the image\n            pt1 = [200, 200]\n            pt2 = [200, 200]\n            line_angle = best_ori_estimate\n            pt2[0] = int(pt2[0] + 200*m.cos(line_angle))\n            pt2[1] = int(pt2[1] + 200*m.sin(line_angle))\n\n            cv2.line(cv_image, (pt1[0], pt1[1]),\n                     (pt2[0], pt2[1]), (0, 0, 255), 3)\n\n            # publish abs odometry for yaw\n            # create euler angles\n            roll = 0\n            pitch = 0\n            yaw = -best_ori_estimate\n\n            # convert to quaternion\n            q = quaternion_from_euler(roll, pitch, yaw)\n\n            # create a odom message\n            odom_msg = Odometry()\n            odom_msg.pose.pose.orientation.x = q[0]\n            odom_msg.pose.pose.orientation.y = q[1]\n            odom_msg.pose.pose.orientation.z = q[2]\n            odom_msg.pose.pose.orientation.w = q[3]\n            odom_msg.header.frame_id = \"odom\"\n            odom_msg.header.stamp = rospy.Time().now()\n            odom_pub.publish(odom_msg)\n\n        rosimg = CvBridge().cv2_to_imgmsg(cv_image, \"bgr8\")\n        image_pub.publish(rosimg)"
            ]
        ]
    },
    {
        "blob_id": "00213373c71f2901f04b9c3f250dfd0d591ee90b",
        "matched_blocks": [
            [
                402,
                411,
                "        try:\n            living = sys.modules[self.name]\n        except KeyError:\n            pass\n        else:\n            try:\n                return living.__all__\n            except AttributeError:\n                return [name for name in living.__dict__.keys()\n                        if not name.startswith('_')]"
            ],
            [
                1146,
                1151,
                "                    try:\n                        infered._proxied.getattr('__get__', context)\n                    except NotFoundError:\n                        yield infered\n                    else:\n                        yield YES"
            ]
        ]
    },
    {
        "blob_id": "be482f68c77ac6d63b899a6a260d3ae75f83a5d2",
        "matched_blocks": [
            [
                74,
                83,
                "        try:\n            _process_plot_format(args[1])\n        except ValueError:\n            pass\n        else:\n            warnings.warn(\n                \"Second argument {!r} is ambiguous: could be a color spec but \"\n                \"is in data; using as data.  Either rename the entry in data \"\n                \"or use three arguments to plot.\".format(args[1]),\n                RuntimeWarning, stacklevel=3)"
            ],
            [
                2104,
                2111,
                "            try:\n                dp, x, height, width, y, kwargs = matcher(*args, **kwargs)\n            except TypeError as e:\n                # This can only come from a no-match as there is\n                # no other logic in the matchers.\n                exps.append(e)\n            else:\n                break"
            ],
            [
                2417,
                2424,
                "            try:\n                dp, y, width, height, left, kwargs = matcher(*args, **kwargs)\n            except TypeError as e:\n                # This can only come from a no-match as there is\n                # no other logic in the matchers.\n                excs.append(e)\n            else:\n                break"
            ],
            [
                2638,
                2647,
                "            try:\n                # fallback to positional argument\n                linefmt = args[0]\n            except IndexError:\n                linecolor = 'C0'\n                linemarker = 'None'\n                linestyle = '-'\n            else:\n                linestyle, linemarker, linecolor = \\\n                    _process_plot_format(linefmt)"
            ],
            [
                2652,
                2661,
                "            try:\n                # fallback to positional argument\n                markerfmt = args[1]\n            except IndexError:\n                markercolor = 'C0'\n                markermarker = 'o'\n                markerstyle = 'None'\n            else:\n                markerstyle, markermarker, markercolor = \\\n                    _process_plot_format(markerfmt)"
            ],
            [
                2667,
                2679,
                "            try:\n                # fallback to positional argument\n                basefmt = args[2]\n            except IndexError:\n                if rcParams['_internal.classic_mode']:\n                    basecolor = 'C2'\n                else:\n                    basecolor = 'C3'\n                basemarker = 'None'\n                basestyle = '-'\n            else:\n                basestyle, basemarker, basecolor = \\\n                    _process_plot_format(basefmt)"
            ],
            [
                3187,
                3198,
                "            try:\n                a, b = err\n            except (TypeError, ValueError):\n                pass\n            else:\n                if iterable(a) and iterable(b):\n                    # using list comps rather than arrays to preserve units\n                    low = [thisx - thiserr for (thisx, thiserr)\n                           in cbook.safezip(data, a)]\n                    high = [thisx + thiserr for (thisx, thiserr)\n                            in cbook.safezip(data, b)]\n                    return low, high"
            ]
        ]
    },
    {
        "blob_id": "569f63067b99e401112c47ab863db8f43cd3d205",
        "matched_blocks": [
            [
                33,
                39,
                "try:\n    from IPython.core.display import display as _display\n    from IPython.core.display import Image as _Image\nexcept ImportError:\n    _global_IPLoad = False\nelse:\n    _global_IPLoad = True"
            ],
            [
                42,
                50,
                "try: # get_ipython() method is not available in IPython versions prior to 2.0\n    from IPython import get_ipython as _get_ipython\nexcept:\n    _global_in_IPython_env = False\nelse:\n    if _get_ipython(): # if global interactive shell instance is available\n        _global_in_IPython_env = True\n    else:\n        _global_in_IPython_env = False"
            ],
            [
                52,
                57,
                "try:\n    import matplotlib.image as _matimg\nexcept ImportError:\n    _global_mpl_img_load = False\nelse:\n    _global_mpl_img_load = True"
            ],
            [
                485,
                505,
                "        try:\n            self._conversation.ConnectTo(self._appName,\" \")\n        except Exception as err2:\n            _debugPrint(2, \"Exception occured at attempt to call ConnecTo.\"\n                        \" Error = {err}\".format(err=str(err2)))\n            if self.__liveCh >= _MAX_PARALLEL_CONV:\n                _sys.stderr.write(\"ERROR: {err}. \\nMore than {liveConv} \"\n                \"simultaneous conversations not allowed!\\n\"\n                .format(err=str(err2), liveConv =_MAX_PARALLEL_CONV))\n            else:\n                _sys.stderr.write(\"ERROR: {err}.\\nZEMAX may not be running!\\n\"\n                                 .format(err=str(err2)))\n            # should close the DDE server if it exist\n            self.zDDEClose()\n            _debugPrint(2,\"PyZDDE server: \" + str(PyZDDE.__server))\n            return -1\n        else:\n            _debugPrint(1,\"Zemax instance successfully connected\")\n            PyZDDE.__liveCh += 1 # increment the number of live channels\n            self._connection = True\n            return 0"
            ],
            [
                7090,
                7100,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyPOPSettings(dst, start_surf, end_surf, field, wave, auto,\n                                    beamType, paramN, pIrr, tPow, sampx, sampy,\n                                    srcFile, widex, widey, fibComp, fibFile,\n                                    fibType, fparamN, ignPol, pos, tiltx, tilty)\n            return dst"
            ],
            [
                7403,
                7411,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyFFTPSFCrossSecSettings(dst, dtype, row, sample, wave,\n                                               field, pol, norm, scale)\n            return dst"
            ],
            [
                7541,
                7549,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyFFTPSFSettings(dst, dtype, sample, wave, field, surf, pol,\n                                       norm, imgDelta)\n            return dst"
            ],
            [
                7672,
                7680,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyHuygensPSFCrossSecSettings(dst, pupilSample, imgSample,\n                                                   wave, field, imgDelta, dtype)\n            return dst"
            ],
            [
                7800,
                7808,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyHuygensPSFSettings(dst, pupilSample, imgSample, wave,\n                                           field, imgDelta, dtype)\n            return dst"
            ],
            [
                8036,
                8044,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyFFTMTFSettings(dst, sample, wave, field, dtype, surf,\n                                       maxFreq, showDiff, pol, useDash)\n            return dst"
            ],
            [
                8181,
                8190,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyHuygensMTFSettings(dst, pupilSample, imgSample, imgDelta,\n                                           config, wave, field, dtype, maxFreq,\n                                           pol, useDash)\n            return dst"
            ],
            [
                8488,
                8500,
                "        try:\n            _shutil.copy(src, dst)\n        except IOError:\n            print(\"ERROR: Invalid settingsFile {}\".format(dst))\n            return\n        else:\n            self.zModifyImageSimulationSettings(dst, image, height, over, guard,\n                                                flip, rotate, wave, field, pupilSample,\n                                                imgSample, psfx, psfy, aberr, pol,\n                                                fixedAper, illum, showAs, reference,\n                                                suppress, pixelSize, xpix, ypix,\n                                                flipSimImg, outFile)\n            return dst"
            ],
            [
                10217,
                10228,
                "        try:\n            f = open(filename, mode)\n        except IOError:\n            timeDelta = _datetime.datetime.now() - ti\n            if timeDelta.total_seconds() > timeout:\n                status = False\n                break\n            else:\n                _time.sleep(0.25)\n        else:\n            f.close()\n            break"
            ],
            [
                10258,
                10264,
                "        try:\n            _os.remove(fileName)\n        except OSError:\n            count += 1\n            _time.sleep(0.2)\n        else:\n            status = True"
            ]
        ]
    },
    {
        "blob_id": "633f67db56b3fc27c70671b9cff7a90c51faa754",
        "matched_blocks": [
            [
                34,
                41,
                "            try:\n                self._redis = redis.Redis(host = ip, port = port, db = db, password = user_pass, decode_responses=True) # redis\u9ed8\u8ba4\u7aef\u53e3\u662f6379\n                self._pipe = self._redis.pipeline(transaction=True) # redis-py\u9ed8\u8ba4\u5728\u6267\u884c\u6bcf\u6b21\u8bf7\u6c42\u90fd\u4f1a\u521b\u5efa\uff08\u8fde\u63a5\u6c60\u7533\u8bf7\u8fde\u63a5\uff09\u548c\u65ad\u5f00\uff08\u5f52\u8fd8\u8fde\u63a5\u6c60\uff09\u4e00\u6b21\u8fde\u63a5\u64cd\u4f5c\uff0c\u5982\u679c\u60f3\u8981\u5728\u4e00\u6b21\u8bf7\u6c42\u4e2d\u6307\u5b9a\u591a\u4e2a\u547d\u4ee4\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528pipline\u5b9e\u73b0\u4e00\u6b21\u8bf7\u6c42\u6307\u5b9a\u591a\u4e2a\u547d\u4ee4\uff0c\u5e76\u4e14\u9ed8\u8ba4\u60c5\u51b5\u4e0b\u4e00\u6b21pipline \u662f\u539f\u5b50\u6027\u64cd\u4f5c\u3002\n\n            except Exception as e:\n                raise\n            else:\n                log.debug('\u8fde\u63a5\u5230redis\u6570\u636e\u5e93 ip:%s  port:%s'%(ip, port))"
            ]
        ]
    },
    {
        "blob_id": "977bc6a3732170a6fb220cdaace2fb742271b850",
        "matched_blocks": [
            [
                45,
                62,
                "try:\n    import scipy\nexcept ImportError:  # pragma: no cover\n    pass\nelse:\n\n    def test_lm_sym_to_coeffs_sparse():\n        m = Matrix([[1.2, x], [3.4*y, 1.2 + 3*x - 4.5*y + z]])\n        coeffs = lm_sym_to_coeffs(m, [x, y, z], sparse=True)\n        assert len(coeffs) == 2\n        assert len(coeffs[0]) == 3\n        assert (coeffs[0][0].toarray() ==\n                np.matrix([[0.0, 1.0], [0.0, 3.0]])).all()\n        assert (coeffs[0][1].toarray() ==\n                np.matrix([[0.0, 0.0], [3.4, -4.5]])).all()\n        assert (coeffs[0][2].toarray() ==\n                np.matrix([[0.0, 0.0], [0.0, 1.0]])).all()\n        assert (coeffs[1].toarray() == np.matrix([[1.2, 0.0], [0.0, 1.2]])).all()"
            ]
        ]
    },
    {
        "blob_id": "d37c55351fcc58f0a0f56e067c8a897e7fc01e76",
        "matched_blocks": [
            [
                41,
                57,
                "    try:\n\n        fp = open(f, \"rb\")\n\n        try:\n            p = PcfFontFile.PcfFontFile(fp)\n        except SyntaxError:\n            fp.seek(0)\n            p = BdfFontFile.BdfFontFile(fp)\n\n        p.save(f)\n\n    except (SyntaxError, IOError):\n        print(\"failed\")\n\n    else:\n        print(\"OK\")"
            ]
        ]
    },
    {
        "blob_id": "e28dda0fea03c07d8d1c770ef4a665cbbac09b72",
        "matched_blocks": [
            [
                394,
                406,
                "            try:\n                self.connection_create(broker)\n                self.connection.open()\n            except qpid_exceptions.ConnectionError as e:\n                msg_dict = dict(e=e, delay=delay)\n                msg = _(\"Unable to connect to AMQP server: %(e)s. \"\n                        \"Sleeping %(delay)s seconds\") % msg_dict\n                LOG.error(msg)\n                time.sleep(delay)\n                delay = min(2 * delay, 60)\n            else:\n                LOG.info(_('Connected to AMQP server on %s'), broker)\n                break"
            ]
        ]
    },
    {
        "blob_id": "952e5fe17fa49a0c33d312d1f3589025e168647d",
        "matched_blocks": [
            [
                1274,
                1279,
                "            try:\n                policy.run()\n            except RuntimeError:\n                pass\n            else:\n                self.fail(\"should have raised error\")"
            ]
        ]
    },
    {
        "blob_id": "bcb2bac7460fd22247f6850cfb190c7713966a7e",
        "matched_blocks": [
            [
                886,
                897,
                "        try:\n            traits = self.driver.get_traits(nodename)\n        except NotImplementedError:\n            pass\n        else:\n            # NOTE(mgoddard): set_traits_for_provider does not refresh the\n            # provider tree in the report client, so we rely on the above call\n            # to set_inventory_for_provider or update_compute_node to ensure\n            # that the resource provider exists in the tree and has had its\n            # cached traits refreshed.\n            self.reportclient.set_traits_for_provider(\n                context, compute_node.uuid, traits)"
            ]
        ]
    },
    {
        "blob_id": "35e7366e76f6e50c77b6fa3fcf1065b6905128ef",
        "matched_blocks": [
            [
                21,
                26,
                "try:\n   import decays\nexcept ImportError:\n   pass\nelse:\n   all_decays = decays.all_decays"
            ],
            [
                28,
                33,
                "try:\n   import form_factors\nexcept ImportError:\n   pass\nelse:\n   all_form_factors = form_factors.all_form_factors"
            ],
            [
                35,
                40,
                "try:\n   import CT_vertices\nexcept ImportError:\n   pass\nelse:\n   all_CTvertices = CT_vertices.all_CTvertices"
            ]
        ]
    },
    {
        "blob_id": "07b6821130e2375c1024ba22e1c8cf416bd8f8e7",
        "matched_blocks": [
            [
                344,
                360,
                "        try:\n            # Try activating rlcompleter, because it's handy.\n            import readline\n        except ImportError:\n            pass\n        else:\n            # We don't have to wrap the following import in a 'try', because\n            # we already know 'readline' was imported successfully.\n            import rlcompleter\n            readline.set_completer(rlcompleter.Completer(imported_objects).complete)\n            # Enable tab completion on systems using libedit (e.g. macOS).\n            # These lines are copied from Lib/site.py on Python 3.4.\n            readline_doc = getattr(readline, '__doc__', '')\n            if readline_doc is not None and 'libedit' in readline_doc:\n                readline.parse_and_bind(\"bind ^I rl_complete\")\n            else:\n                readline.parse_and_bind(\"tab:complete\")"
            ]
        ]
    },
    {
        "blob_id": "667d3af8118c7cbfd7575b8ce28ac5bec9d9c774",
        "matched_blocks": [
            [
                203,
                212,
                "        try:\n            catalog = gettext_module.translation(domain, path, ['en'])\n            t.update(catalog._catalog)\n        except IOError:\n            pass\n        else:\n            # 'en' is the selected language and at least one of the packages\n            # listed in `packages` has an 'en' catalog\n            if en_selected:\n                en_catalog_missing = False"
            ]
        ]
    },
    {
        "blob_id": "19172244f167fb5ed0a40749ee2b2ec36237c41a",
        "matched_blocks": [
            [
                426,
                434,
                "        try:\n            conn, addr = serv.accept()\n        except socket.timeout:\n            pass\n        else:\n            conn.send(\"1 Hola mundo\\n\")\n            # (2) Signal the caller that it is safe to close the socket.\n            evt.set()\n            conn.close()"
            ],
            [
                497,
                502,
                "        try:\n            DummyFTPServer((HOST, 0), af=socket.AF_INET6)\n        except socket.error:\n            pass\n        else:\n            tests.append(TestIPv6Environment)"
            ]
        ]
    },
    {
        "blob_id": "c71cb016fd30053e434a2b42e23a96a22cca55b8",
        "matched_blocks": [
            [
                50,
                69,
                "                try:\n                    gamertag = link.split('/')[-1] # last item in link is gamertag\n                    platform = link.split('/')[-2] # item before gamertag is platform\n                except IndexError:\n                    logger.error(\"Gamertag:%(name)s Link:%(link)s is not formatted properly\" % locals())\n                else:\n                    playerdict[i][gamertag] = {} # define dict for each gamertag and values for that gamertag\n                    a = 0\n                    for item in row:  # handle kwargs\n                        if len(row) - a > 2:\n                            playerdict[i][gamertag][a] = item\n                            a += 1\n                    if \"ps4\" == platform or \"ps\" == platform:\n                        platform = \"psn\"\n                    if \"xbox\" == platform:\n                        platform = \"xbl\"\n                    playerdict[i][gamertag]['platform'] = platform\n                    playerdict[i][gamertag]['name'] = name\n                    playerdict[i][gamertag]['link'] = link\n                    i += 1"
            ]
        ]
    },
    {
        "blob_id": "d5beca5ed8e459e345d112583d4a63556cbbeb03",
        "matched_blocks": [
            [
                62,
                67,
                "        try:\n            key = next(self.iterator)\n        except StopIteration:\n            raise StopIteration\n        else:\n            return (key[0], key[1], self.nest[key])"
            ],
            [
                168,
                173,
                "            try:\n                nest = all_nests.find_word_nest(word)\n            except Exception as e:\n                print(e)\n            else:\n                print(nest)"
            ],
            [
                177,
                182,
                "            try:\n                nest = all_nests.find_root_nest(root)\n            except Exception as e:\n                print(e)\n            else:\n                print(nest)"
            ],
            [
                186,
                192,
                "            try:\n                nest = all_nests.find_word_nest(word)\n            except Exception as e:\n                print(e)\n            else:\n                subtree = nest.restore_subtree(word, nest)\n                print(subtree)"
            ],
            [
                196,
                202,
                "            try:\n                nest = all_nests.find_word_nest(word)\n            except Exception as e:\n                print(e)\n            else:\n                word = nest.find_word(word.lower())\n                nest.restore_chain(word, {}, nest)"
            ]
        ]
    },
    {
        "blob_id": "56380b22c1a19bc1360e4db687e97a20ed9ed327",
        "matched_blocks": [
            [
                40,
                47,
                "            try:\n                await bot.send_file(userid , file = filename, reply_to = message)\n            except Exception as e:\n                await bot.delete_messages(None, msg)\n                await bot.send_message(userid, unsuccessful_upload, reply_to = message)\n                print(line_number(), e)\n            else:\n                await bot.delete_messages(None, msg)"
            ]
        ]
    },
    {
        "blob_id": "6fb95dced758154aad6d1a944de9536f17a0b428",
        "matched_blocks": [
            [
                61,
                72,
                "        try:\n            data = urllib.urlopen(url).read()\n        except Exception:\n            # Could be a socket error or an HTTP error--either way, we\n            # don't care--it's a failure to us.\n            result.append(-1)\n        else:\n            if not CheckTitle(data):\n                result.append(-1)\n            else:\n                elapsed = int((time.time() - startTime) * 1000)\n                result.append(elapsed)"
            ],
            [
                86,
                95,
                "        try:\n            title = titleRegex.search(html).group(1)\n        except Exception:\n            # If there is no match, then we consider it a failure.\n            result.append(-1)\n        else:\n            if title == HTTP_TITLE:\n                return True\n            else:\n                return False"
            ]
        ]
    },
    {
        "blob_id": "c797fec39e87cec2724d05c13ea1be0f98111384",
        "matched_blocks": [
            [
                15,
                22,
                "        try:\n            sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n            sock.connect(ipc_path)\n            sock.settimeout(timeout)\n        except (FileNotFoundError, socket.error):\n            time.sleep(0.01)\n        else:\n            break"
            ],
            [
                28,
                33,
                "        try:\n            requests.get(endpoint_uri)\n        except requests.ConnectionError:\n            time.sleep(0.01)\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "635bd4085a4fdd6fef954d62dc513a0220d56cfd",
        "matched_blocks": [
            [
                3,
                13,
                "        try:\n            number = int(input(msg))\n        except (ValueError, TypeError):\n            print('[ERRO] Digite um n\u00famero inteiro v\u00e1lido.')\n            print()\n        except KeyboardInterrupt:\n            print('[ERRO] Entrada de dados interrompida.')\n            print('Considerando valor 0')\n            return 0\n        else:\n            return number"
            ],
            [
                18,
                31,
                "        try:\n            number = float(input(msg).replace(',', '.'))\n        except (ValueError, TypeError):\n            print('[ERRO] Digite um n\u00famero real v\u00e1lido.')\n            print()\n        except KeyboardInterrupt:\n            print('[ERRO] Entrada de dados interrompida.')\n            print('Considerando valor 0')\n            return 0\n        else:\n            if number.is_integer():\n                return int(number)\n\n            return number"
            ]
        ]
    },
    {
        "blob_id": "974b5a912e8ade9a6b5fb67c9e6a53632a967fc2",
        "matched_blocks": [
            [
                26,
                32,
                "    try:\n        import aiohttp  # noqa\n    except ImportError:\n        pass\n    else:\n        from ._async import AIOCloudStack  # noqa\n        __all__.append('AIOCloudStack')"
            ]
        ]
    },
    {
        "blob_id": "cd7b1c735c48d2803238e6ba0ddab6a70ce5d66f",
        "matched_blocks": [
            [
                64,
                69,
                "    try:\n        result = future.result()\n    except:\n        return False\n    else:\n        return result"
            ],
            [
                88,
                99,
                "    try:\n        image_request = wit_download_image(image_url, saveimages)\n        similarities, embeddings = clipper.return_similarities(image_request, captions, image_url)\n        similarities = {caption_dict[j]: round(similarities[i], 4) for i, j in enumerate(available_ids) }\n    except Exception as e:\n        print('Exception while trying to download {}'.format(image_url))\n        print(e)\n        return False, False, False\n    else:\n        if not saveembeddings:\n            embeddings = None\n        return row[0], similarities, embeddings"
            ]
        ]
    },
    {
        "blob_id": "d845e7db8174b7dc130dbeb3c29996425aadaf14",
        "matched_blocks": [
            [
                162,
                170,
                "        try:                            \n            pinfo = proc.as_dict(attrs=['name'])\n        except util.NoSuchProcess:\n            pass\n        else:\n            if 'omxplayer' == pinfo['name']:\n                proc.kill()\n            if 'python3' == pinfo['name']:\n                proc.kill()"
            ],
            [
                209,
                230,
                "                    try:\n                        p.status()\n                    except util.NoSuchProcess:\n                        # Process is dead, check if another one is active\n                        p = None\n                        running = False\n                        for proc in util.process_iter():\n                            try:\n                                pinfo = proc.as_dict(attrs=['name'])\n                            except util.NoSuchProcess:\n                                pass\n                            else:\n                                if 'omxplayer' == pinfo['name']:\n                                    running = True\n                                    p = proc\n                                    break\n                        if p is not None:\n                            logging.info('Video Ended')\n                    else:\n                        running = True\n                        # Slight delay to match rfid timeout scenerio\n                        time.sleep(EQL_DELAY)"
            ],
            [
                234,
                242,
                "                        try:\n                            pinfo = proc.as_dict(attrs=['name'])\n                        except util.NoSuchProcess:\n                            pass\n                        else:\n                            if 'omxplayer' == pinfo['name']:\n                                running = True\n                                p = proc\n                                break"
            ],
            [
                216,
                224,
                "                            try:\n                                pinfo = proc.as_dict(attrs=['name'])\n                            except util.NoSuchProcess:\n                                pass\n                            else:\n                                if 'omxplayer' == pinfo['name']:\n                                    running = True\n                                    p = proc\n                                    break"
            ]
        ]
    },
    {
        "blob_id": "c0b8870b43e999588ed4befc1e107dd7815911b0",
        "matched_blocks": [
            [
                326,
                333,
                "        try:\n            rv = next(self._items)\n        except StopIteration:\n            self.__exit__(None, None, None)\n            raise\n        else:\n            self.update()\n            return rv"
            ]
        ]
    },
    {
        "blob_id": "2500703afbfbf68c508d1c88738f2728e58cc730",
        "matched_blocks": [
            [
                34,
                52,
                "    try:\n        mcr = MCRcon(ip, pas, int(port))\n        mcr.connect()\n    # \u0415\u0441\u043b\u0438, \u043d\u0435\u0432\u0435\u0440\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u043d\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0439 \u0441\u0435\u0440\u0432\u0435\u0440, \u0432\u044b\u043a\u043b\u044e\u0447\u0435\u043d RCON, \u0432\u044b\u0432\u043e\u0434\u0438\u043c \u043e\u0448\u0438\u0431\u043a\u0443\n    except OSError:\n        print('\u041f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043e\u0448\u0438\u0431\u043a\u0430. '\n              '\u0423\u0434\u043e\u0441\u0442\u043e\u0432\u0435\u0440\u044c\u0442\u0435\u0441\u044c \u0432 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0441\u0442\u0438\u043c \u0432\u0432\u0435\u0434\u0451\u043d\u044b\u0445 \u0412\u0430\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u0438 \u043f\u043e\u0432\u0442\u043e\u0440\u0438\u0442\u0435 \u043f\u043e\u043f\u044b\u0442\u043a\u0443. '\n              '\u0415\u0441\u043b\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432\u0435\u0440\u043d\u044b, \u0442\u043e \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430 \u0432 \u0432\u044b\u043a\u043b\u044e\u0447\u0435\u043d\u043d\u043e\u043c RCON.')\n    # \u0415\u0441\u043b\u0438, \u0432 \u043f\u043e\u0440\u0442\u0443 \u043f\u0440\u0438\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u0431\u0443\u043a\u0432\u044b, \u0432\u044b\u0432\u043e\u0434\u0438\u043c \u043e\u0448\u0438\u0431\u043a\u0443\n    except ValueError:\n        print('\u041f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043e\u0448\u0438\u0431\u043a\u0430. RCON-\u043f\u043e\u0440\u0442 \u043d\u0435 \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0442\u044c \u0431\u0443\u043a\u0432\u0435\u043d\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f.')\n    # \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0430\u0435\u043c\u0441\u044f\n    else:\n        print('[LOG] \u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u043e.')\n        print('[LOG] \u0412\u0432\u043e\u0434 \u043a\u043e\u043c\u0430\u043d\u0434 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0441\u044f \u0431\u0435\u0437 \u0437\u043d\u0430\u043a\u0430 \"/\".')\n        while True:\n            command = input()\n            resp = mcr.command(command)\n            print('[\u0421\u0435\u0440\u0432\u0435\u0440] ' + resp)"
            ]
        ]
    },
    {
        "blob_id": "a41dac01512c4cbd46fd752aea66a51c1515261d",
        "matched_blocks": [
            [
                316,
                331,
                "        try:\n            i = os.copy_file_range(in_fd, out_fd, 5)\n        except OSError as e:\n            # Handle the case in which Python was compiled\n            # in a system with the syscall but without support\n            # in the kernel.\n            if e.errno != errno.ENOSYS:\n                raise\n            self.skipTest(e)\n        else:\n            # The number of copied bytes can be less than\n            # the number of bytes originally requested.\n            self.assertIn(i, range(0, 6));\n\n            with open(TESTFN2, 'rb') as in_file:\n                self.assertEqual(in_file.read(), data[:i])"
            ],
            [
                353,
                376,
                "        try:\n            i = os.copy_file_range(in_fd, out_fd, bytes_to_copy,\n                                   offset_src=in_skip,\n                                   offset_dst=out_seek)\n        except OSError as e:\n            # Handle the case in which Python was compiled\n            # in a system with the syscall but without support\n            # in the kernel.\n            if e.errno != errno.ENOSYS:\n                raise\n            self.skipTest(e)\n        else:\n            # The number of copied bytes can be less than\n            # the number of bytes originally requested.\n            self.assertIn(i, range(0, bytes_to_copy+1));\n\n            with open(TESTFN4, 'rb') as in_file:\n                read = in_file.read()\n            # seeked bytes (5) are zero'ed\n            self.assertEqual(read[:out_seek], b'\\x00'*out_seek)\n            # 012 are skipped (in_skip)\n            # 345678 are copied in the file (in_skip + bytes_to_copy)\n            self.assertEqual(read[out_seek:],\n                             data[in_skip:in_skip+i])"
            ],
            [
                1086,
                1094,
                "        try:\n            os.listdir(sub21_path)\n        except PermissionError:\n            self.addCleanup(os.chmod, sub21_path, stat.S_IRWXU)\n        else:\n            os.chmod(sub21_path, stat.S_IRWXU)\n            os.unlink(tmp5_path)\n            os.rmdir(sub21_path)\n            del self.sub2_tree[1][:1]"
            ],
            [
                1814,
                1819,
                "        try:\n            os.execve('', ['arg'], {})\n        except OSError as e:\n            self.assertTrue(e.winerror is None or e.winerror != 0)\n        else:\n            self.fail('No OSError raised')"
            ],
            [
                1825,
                1834,
                "        try:\n            os.stat(support.TESTFN)\n        except FileNotFoundError:\n            exists = False\n        except OSError as exc:\n            exists = True\n            self.fail(\"file %s must not exist; os.stat failed with %s\"\n                      % (support.TESTFN, exc))\n        else:\n            self.fail(\"file %s must not exist\" % support.TESTFN)"
            ],
            [
                1878,
                1884,
                "        try:\n            f(support.make_bad_fd(), *args)\n        except OSError as e:\n            self.assertEqual(e.errno, errno.EBADF)\n        else:\n            self.fail(\"%r didn't raise an OSError with a bad file descriptor\"\n                      % f)"
            ],
            [
                2879,
                2884,
                "        try:\n            exitcode = spawn(os.P_WAIT, args[0], args, newenv)\n        except ValueError:\n            pass\n        else:\n            self.assertEqual(exitcode, 127)"
            ],
            [
                2889,
                2894,
                "        try:\n            exitcode = spawn(os.P_WAIT, args[0], args, newenv)\n        except ValueError:\n            pass\n        else:\n            self.assertEqual(exitcode, 127)"
            ],
            [
                2899,
                2904,
                "        try:\n            exitcode = spawn(os.P_WAIT, args[0], args, newenv)\n        except ValueError:\n            pass\n        else:\n            self.assertEqual(exitcode, 127)"
            ],
            [
                3155,
                3162,
                "        try:\n            sent = os.sendfile(self.sockno, self.fileno, offset, 4096)\n        except OSError as e:\n            # Solaris can raise EINVAL if offset >= file length, ignore.\n            if e.errno != errno.EINVAL:\n                raise\n        else:\n            self.assertEqual(sent, 0)"
            ],
            [
                1896,
                1900,
                "            try: os.fstat(fd+i)\n            except OSError:\n                pass\n            else:\n                break"
            ],
            [
                2512,
                2520,
                "            try:\n                os.symlink(src, dest)\n            except FileNotFoundError:\n                pass\n            else:\n                try:\n                    os.remove(dest)\n                except OSError:\n                    pass"
            ],
            [
                2522,
                2530,
                "            try:\n                os.symlink(os.fsencode(src), os.fsencode(dest))\n            except FileNotFoundError:\n                pass\n            else:\n                try:\n                    os.remove(dest)\n                except OSError:\n                    pass"
            ],
            [
                3500,
                3511,
                "                try:\n                    if isinstance(name, (str, bytes)):\n                        func(name, *func_args)\n                    else:\n                        with self.assertWarnsRegex(DeprecationWarning, 'should be'):\n                            func(name, *func_args)\n                except OSError as err:\n                    self.assertIs(err.filename, name, str(func))\n                except UnicodeDecodeError:\n                    pass\n                else:\n                    self.fail(\"No exception thrown by {}\".format(func))"
            ]
        ]
    },
    {
        "blob_id": "64b1ff60158655b97b826b8467eb04fc9536b67f",
        "matched_blocks": [
            [
                3,
                10,
                "try:\n    response = request.urlopen('http://cuiqingcai.com/index.htm')\nexcept error.HTTPError as e:\n    print(e.reason, e.code, e.headers, sep='\\n')\nexcept error.URLError as e:\n    print(e.reason)\nelse:\n    print('Request Successfully')"
            ]
        ]
    },
    {
        "blob_id": "4a5537829c493633c4f10247ebb6978fcf02f5a0",
        "matched_blocks": [
            [
                4,
                9,
                "        try:\n            comment_index = line.index(';')\n        except ValueError:\n            result.append(line)\n        else:\n            result.append(line[:comment_index])"
            ]
        ]
    },
    {
        "blob_id": "e31ee367fc6802635bca02f0078aae7a1c53faf9",
        "matched_blocks": [
            [
                229,
                237,
                "    try:\n        date, collector = date_coll.split(\" \u041a\u041e\u041b\u041b.: \", maxsplit=1)\n    except ValueError:\n        print(date_coll)\n    else:\n        if date != \"?\":\n            data[\"date\"] = date.rstrip(\".\")\n        if collector != \"?\":\n            data[\"collector\"] = collector"
            ]
        ]
    },
    {
        "blob_id": "8eff51fa665518a50f44a8c513d5f865fc70e37a",
        "matched_blocks": [
            [
                66,
                77,
                "        try:\n            response = requests.get(self.url, timeout = 30)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            print('Conneted failed')\n            return\n        except:\n            print('Socket failed!')\n            return\n        else:\n            print(response)\n            return response"
            ]
        ]
    },
    {
        "blob_id": "18bc5d05c4ffea418c8ea9744307ba2f5f990eb4",
        "matched_blocks": [
            [
                1407,
                1412,
                "                try:\n                    del self._constraints[constraint.name]\n                except KeyError:\n                    raise LookupError(\"Constraint %s not in solver\" % constraint)\n                else:\n                    constraint.problem = None"
            ]
        ]
    },
    {
        "blob_id": "e4bcdf2e5a6ee879997a68875791a84f8e83bf15",
        "matched_blocks": [
            [
                42,
                63,
                "        try:\n            subst1.try_add_variable('i3.1.2.2.2.1.0_1', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 20348\n            if len(subjects) >= 1:\n                tmp2 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i3.1.2.2.2.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 20349\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*f\n                        yield 0, subst2\n                subjects.appendleft(tmp2)"
            ],
            [
                52,
                62,
                "                try:\n                    subst2.try_add_variable('i3.1.2.2.2.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 20349\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*f\n                        yield 0, subst2"
            ]
        ]
    },
    {
        "blob_id": "ad220607cdea2e76f125df22d300fd8ae01b3438",
        "matched_blocks": [
            [
                537,
                551,
                "try:\n    # Get the version of the pyperclip module as a float\n    pyperclip_ver = float('.'.join(pyperclip.__version__.split('.')[:2]))\n\n    # The extraneous output bug in pyperclip on Linux using xclip was fixed in more recent versions of pyperclip\n    if sys.platform.startswith('linux') and pyperclip_ver < 1.6:\n        # Avoid extraneous output to stderr from xclip when clipboard is empty at cost of overwriting clipboard contents\n        pyperclip.copy('')\n    else:\n        # Try getting the contents of the clipboard\n        _ = pyperclip.paste()\nexcept PyperclipException:\n    can_clip = False\nelse:\n    can_clip = True"
            ],
            [
                1195,
                1200,
                "                        try:\n                            self.pipe_proc.wait()\n                        except KeyboardInterrupt:\n                            pass\n                        else:\n                            break"
            ]
        ]
    },
    {
        "blob_id": "c43c7bcbbad1cac818d700eaac5a23d93dc3d3f6",
        "matched_blocks": [
            [
                1881,
                1899,
                "    try:\n        if not package:\n            module = import_module(name)\n        else:\n            module = import_module('.' + name, package=package)\n    except ImportError:\n        if warn:\n            warnings.warn(\"failed to import module %s\" % name)\n    else:\n        for attr in dir(module):\n            if ignore and attr.startswith(ignore):\n                continue\n            if prefix:\n                if attr in globals():\n                    globals()[prefix + attr] = globals()[attr]\n                elif warn:\n                    warnings.warn(\"no Python implementation of \" + attr)\n            globals()[attr] = getattr(module, attr)\n        return True"
            ]
        ]
    },
    {
        "blob_id": "4c72cb0146c753049d6f053bd18d47b06596e152",
        "matched_blocks": [
            [
                148,
                153,
                "        try:\n            user = User.objects.get(mobile=mobile)\n        except User.DoesNotExist:\n            pass\n        else:\n            attrs['user'] = user"
            ]
        ]
    },
    {
        "blob_id": "cf4b67c14d7a1b9856437ecb6e313e98a2c15a74",
        "matched_blocks": [
            [
                42,
                47,
                "        try:\n            authn = cherrypy.request.headers['Authorization']\n        except KeyError:\n            pr_args = {}\n        else:\n            pr_args = {'auth': authn}"
            ]
        ]
    },
    {
        "blob_id": "3c5c13bc7708b7f1f902b92f1224968214201cf3",
        "matched_blocks": [
            [
                37,
                47,
                "try:\n    driver.find_element_by_css_selector(ingreso_usuario).send_keys(user)\n    driver.find_element_by_css_selector(ingreso_contrasenia).send_keys(psw)\n    driver.find_element_by_css_selector(boton_login).click()\n    driver.find_element_by_xpath(xpath_error_psw)\n         \nexcept Exception as ex:                     \n    print(ex)\n    print(\"Ingreso correcto a la p\u00e1gina\")\nelse:\n    print(\"La contrasenia ingresada es incorrecta\")     "
            ]
        ]
    },
    {
        "blob_id": "ddb9e86f2af78422c26df983d968c40f0bf75e76",
        "matched_blocks": [
            [
                100,
                106,
                "    try:\n        if estudiantes:\n            return render_to_response('resources/buscar-resultados.html', {'estudiante': estudiantes})\n    except:\n        return HttpResponse(\"Hubo una excepcion\")\n    else:\n        return HttpResponse(\"No hay estudiantes con ese nombre\")"
            ]
        ]
    },
    {
        "blob_id": "7d4400ac49d0ef48666e684ef308d532017899c9",
        "matched_blocks": [
            [
                143,
                148,
                "        try:\n            d = func.__dict__\n        except AttributeError:\n            pass\n        else:\n            newfunc.__dict__.update(d)"
            ]
        ]
    },
    {
        "blob_id": "d34e42ad9c1bf18173a1e92c7869c8a1c4acb417",
        "matched_blocks": [
            [
                1318,
                1337,
                "        try:\n            hex_hash = await self.session_mgr.broadcast_transaction(raw_tx)\n        except DaemonError as e:\n            error, = e.args\n            message = error['message']\n            self.logger.info(f'error sending transaction: {message}')\n            raise RPCError(BAD_REQUEST, 'the transaction was rejected by '\n                           f'network rules.\\n\\n{message}\\n[{raw_tx}]')\n        else:\n            self.txs_sent += 1\n            client_ver = util.protocol_tuple(self.client)\n            if client_ver != (0, ):\n                msg = self.coin.warn_old_client_on_tx_broadcast(client_ver)\n                if msg:\n                    self.logger.info(f'sent tx: {hex_hash}. and warned user to upgrade their '\n                                     f'client from {self.client}')\n                    return msg\n\n            self.logger.info(f'sent tx: {hex_hash}')\n            return hex_hash"
            ],
            [
                179,
                185,
                "            try:\n                self.servers[service] = await serve(session_factory, host,\n                                                    service.port, ssl=sslc)\n            except OSError as e:    # don't suppress CancelledError\n                self.logger.error(f'{kind} server failed to listen on {service.address}: {e}')\n            else:\n                self.logger.info(f'{kind} server listening on {service.address}')"
            ],
            [
                1226,
                1232,
                "            try:\n                with codecs.open(banner_file, 'r', 'utf-8') as f:\n                    banner = f.read()\n            except (OSError, UnicodeDecodeError) as e:\n                self.logger.error(f'reading banner file {banner_file}: {e!r}')\n            else:\n                banner = await self.replaced_banner(banner)"
            ]
        ]
    },
    {
        "blob_id": "efeee94769b83f842bac96bd9d32030c907b7472",
        "matched_blocks": [
            [
                794,
                801,
                "    try:\n      graph.as_graph_element(obj + \":1\")\n    except (KeyError, ValueError):\n      pass\n    else:\n      raise ValueError(\"Name %s is ambiguous, \"\n                       \"as this `Operation` has multiple outputs \"\n                       \"(at least 2).\" % obj)"
            ]
        ]
    },
    {
        "blob_id": "175006eb5905eb05d3eff2e0c2859795a73c2c91",
        "matched_blocks": [
            [
                1256,
                1276,
                "            try:\n                unioned_return = self.union_overload_result(plausible_targets, args,\n                                                            arg_types, arg_kinds, arg_names,\n                                                            callable_name, object_type,\n                                                            context,\n                                                            arg_messages=unioned_errors)\n            except TooManyUnions:\n                union_interrupted = True\n            else:\n                # Record if we succeeded. Next we need to see if maybe normal procedure\n                # gives a narrower type.\n                if unioned_return:\n                    returns, inferred_types = zip(*unioned_return)\n                    # Note that we use `combine_function_signatures` instead of just returning\n                    # a union of inferred callables because for example a call\n                    # Union[int -> int, str -> str](Union[int, str]) is invalid and\n                    # we don't want to introduce internal inconsistencies.\n                    unioned_result = (UnionType.make_simplified_union(list(returns),\n                                                                      context.line,\n                                                                      context.column),\n                                      self.combine_function_signatures(inferred_types))"
            ]
        ]
    },
    {
        "blob_id": "026357fa9d59a1d7f4235da8c7fd087eb3e3e65f",
        "matched_blocks": [
            [
                309,
                321,
                "            try:\n                self.resource_version = self._run(kube_client, self.resource_version,\n                                                  self.worker_uuid, self.kube_config)\n            except ReadTimeoutError:\n                self.log.warning(\"There was a timeout error accessing the Kube API. \"\n                                 \"Retrying request.\", exc_info=True)\n                time.sleep(1)\n            except Exception:\n                self.log.exception('Unknown error in KubernetesJobWatcher. Failing')\n                raise\n            else:\n                self.log.warning('Watch died gracefully, starting back up with: '\n                                 'last resource_version: %s', self.resource_version)"
            ]
        ]
    },
    {
        "blob_id": "6093d2129fcc9b86264e32f2199313f4ee2360fc",
        "matched_blocks": [
            [
                457,
                465,
                "        try:\n            self.priority.insert_stream(event.stream_id)\n        except priority.DuplicateStreamError:\n            # Stream already in the tree. This can happen if we received a\n            # PRIORITY frame before a HEADERS frame. Just move on: we set the\n            # stream up properly in _handlePriorityUpdate.\n            pass\n        else:\n            self.priority.block(event.stream_id)"
            ],
            [
                559,
                567,
                "        try:\n            self.conn.send_headers(streamID, headers)\n        except h2.exceptions.StreamClosedError:\n            # Stream was closed by the client at some point. We need to not\n            # explode here: just swallow the error. That's what write() does\n            # when a connection is lost, so that's what we do too.\n            return\n        else:\n            self.transport.write(self.conn.data_to_send())"
            ]
        ]
    },
    {
        "blob_id": "62a6d539be9bbfbbbbed23228177058ae2f177d0",
        "matched_blocks": [
            [
                165,
                190,
                "            try:\n                await borg.send_file(\n                    event.chat_id,\n                    downloaded_file_name,\n                    thumb=thumb,\n                    caption=\"reuploaded by [IndianBot](https://github.com/blackshadow98/BlackShadowBot\",\n                    force_document=False,\n                    allow_cache=False,\n                    reply_to=event.message.id,\n                    attributes=[\n                        DocumentAttributeVideo(\n                            duration=duration,\n                            w=width,\n                            h=height,\n                            round_message=False,\n                            supports_streaming=True\n                        )\n                    ]\n                    )\n            except Exception as e:\n                await event.edit(str(e))\n            else:\n                end = datetime.now()\n                os.remove(downloaded_file_name)\n                ms_two = (end - end_one).seconds\n                await event.edit(\"Downloaded in {} seconds. Uploaded in {} seconds.\".format(ms_one, ms_two))"
            ]
        ]
    },
    {
        "blob_id": "22fb3233db2132607fab1c822ba5a8ffa1c379b2",
        "matched_blocks": [
            [
                792,
                804,
                "        try:\n            self.logger.debug('connecting to %s', self.hostname)\n            device.open()\n        except napalm.base.exceptions.ConnectionException as e:\n            self.logger.error(\n                'error while trying to connect to %s reason \"%s\"',\n                self.hostname, e)\n        except Exception:\n            self.logger.error(\n                'error while trying to connect to %s', self.hostname)\n        else:\n            self.logger.debug('successfully connected to %s', self.hostname)\n            success = True"
            ],
            [
                866,
                899,
                "            try:\n                # Load the config\n                self.logger.debug('merging configuration on %s', self.hostname)\n                device.load_merge_candidate(config=config)\n\n                # Get the config diff\n                self.logger.debug(\n                    'checking for configuration changes on %s', self.hostname)\n                changes = device.compare_config()\n                self.logger.debug('raw napalm output %s', changes)\n\n                # Commit the config if required\n                if commit:\n                    self.logger.debug(\n                        'commiting configuration on %s', self.hostname)\n                    device.commit_config()\n\n                else:\n                    self.logger.debug(\n                        'discarding configuration on %s', self.hostname)\n                    device.discard_config()\n            except napalm.base.exceptions.MergeConfigException as e:\n                changes = None\n                self.logger.debug(\n                    'unable to merge configuration on %s reason \"%s\"',\n                    self.hostname, e)\n            except Exception as e:\n                changes = None\n                self.logger.debug(\n                    'unable to merge configuration on %s error \"%s\"',\n                    self.hostname, e)\n            else:\n                self.logger.debug(\n                    'successfully merged configuration on %s', self.hostname)"
            ]
        ]
    },
    {
        "blob_id": "14539757dac6949ee5971550e5ce037dd82f2b1f",
        "matched_blocks": [
            [
                3,
                15,
                "    try:\n        key,value=map(str,input().split(\",\"))        \n    except:\n        print(\"Please Enter proper way\")\n        \n    else:\n        if key==\"STOP\":\n            break\n        else:\n            try:\n                dicts.update({key:int(value)}) \n            except:\n                print(\"please Enter proper type!\")"
            ]
        ]
    },
    {
        "blob_id": "baf4d87749ea095190114050aad3fa7b44c2eca0",
        "matched_blocks": [
            [
                600,
                618,
                "        try:\n            result = reverse_geocode(self.lat, self.lng)\n        except GeoLookupException:\n            if self.geo_country:\n                # If self.geo_country is already set, just give up.\n                pass\n            else:\n                # No country set, we need to at least set the placeholder one.\n                self.geo_country = Country.objects.get(mapbox_id='geo_error')\n                self.geo_region = None\n                self.geo_city = None\n        else:\n            if result:\n                country, region, city = result\n                self.geo_country = country\n                self.geo_region = region\n                self.geo_city = city\n            else:\n                logger.error('Got back NONE from reverse_geocode on %s, %s' % (self.lng, self.lat))"
            ]
        ]
    },
    {
        "blob_id": "6a2ed3c32e208f9299ed262c00312288f929adf8",
        "matched_blocks": [
            [
                52,
                63,
                "                try:\n                    with open(filepath, 'wb') as file:\n                        response = urllib2.urlopen(image_url)\n                        file.write(response.read())\n                except Exception as reason:\n                    log.msg(\"Save image error: {0}\".format(reason), level=log.ERROR, spider=spider)\n                else:\n                    log.msg(\"Download image to MongoDB database!\", level=log.DEBUG, spider=spider)\n                    if filepath:\n                        item['image_local_path'] = filepath\n                        self.collection.insert(dict(item))\n                        log.msg(\"Article added to MongoDB database!\", level=log.DEBUG, spider=spider)"
            ]
        ]
    },
    {
        "blob_id": "0d145842d396563c5b8a1447cf8b1f1ed34271b5",
        "matched_blocks": [
            [
                172,
                177,
                "            try:\n                feature_name = TRANSLATIONS[language].get('feature', self.feature_keyword)\n            except KeyError:\n                feature_name = self.feature_keyword\n            else:\n                feature_name = feature_name.replace('|', ' or ')"
            ]
        ]
    },
    {
        "blob_id": "6bde1babbb4cbffd465b40e13eabce1b1a9c4819",
        "matched_blocks": [
            [
                236,
                253,
                "                try:\n                    newstat[path] = curstat = path.stat()\n                except py.error.ENOENT:\n                    if oldstat:\n                        changed = True\n                else:\n                    if oldstat:\n                        if oldstat.mtime != curstat.mtime or \\\n                           oldstat.size != curstat.size:\n                            changed = True\n                            py.builtin.print_(\"# MODIFIED\", path)\n                            if removepycfiles and path.ext == \".py\":\n                                pycfile = path + \"c\"\n                                if pycfile.check():\n                                    pycfile.remove()\n\n                    else:\n                        changed = True"
            ]
        ]
    },
    {
        "blob_id": "44e7dea39aac459fdf95bbe331d4cec4b032daae",
        "matched_blocks": [
            [
                783,
                794,
                "        try:\n            comparator_factory = self.type.comparator_factory\n        except AttributeError as err:\n            util.raise_(\n                TypeError(\n                    \"Object %r associated with '.type' attribute \"\n                    \"is not a TypeEngine class or object\" % self.type\n                ),\n                replace_context=err,\n            )\n        else:\n            return comparator_factory(self)"
            ],
            [
                1868,
                1882,
                "            try:\n                # the regex used for text() currently will not match\n                # a unique/anonymous key in any case, so use the _orig_key\n                # so that a text() construct can support unique parameters\n                existing = new_params[bind._orig_key]\n            except KeyError as err:\n                util.raise_(\n                    exc.ArgumentError(\n                        \"This text() construct doesn't define a \"\n                        \"bound parameter named %r\" % bind._orig_key\n                    ),\n                    replace_context=err,\n                )\n            else:\n                new_params[existing._orig_key] = bind"
            ],
            [
                1885,
                1896,
                "            try:\n                existing = new_params[key]\n            except KeyError as err:\n                util.raise_(\n                    exc.ArgumentError(\n                        \"This text() construct doesn't define a \"\n                        \"bound parameter named %r\" % key\n                    ),\n                    replace_context=err,\n                )\n            else:\n                new_params[key] = existing._with_value(value, required=False)"
            ],
            [
                3986,
                3997,
                "            try:\n                lower = int(range_[0])\n            except ValueError as err:\n                util.raise_(\n                    exc.ArgumentError(\n                        \"Integer or None expected for range value\"\n                    ),\n                    replace_context=err,\n                )\n            else:\n                if lower == 0:\n                    lower = RANGE_CURRENT"
            ],
            [
                4002,
                4013,
                "            try:\n                upper = int(range_[1])\n            except ValueError as err:\n                util.raise_(\n                    exc.ArgumentError(\n                        \"Integer or None expected for range value\"\n                    ),\n                    replace_context=err,\n                )\n            else:\n                if upper == 0:\n                    upper = RANGE_CURRENT"
            ]
        ]
    },
    {
        "blob_id": "2a47e879d137e708d030f6ac083e3e1fd82f3bed",
        "matched_blocks": [
            [
                74,
                85,
                "            try:\n                result = 10/task\n                sleep(1)\n            except (KeyboardInterrupt, SystemExit) as exc:\n                print(\"Worker #{}: Caught Interruption {}: {}\".format(worker_id, type(exc).__name__, exc))\n                raise\n            except Exception as exc:\n                print(\"Worker #{}: Caught exception {}: {}\".format(worker_id, type(exc).__name__, exc))\n                error_queue.put_nowait(exc)\n            else:\n                print(\"Worker #{}: found {}\".format(worker_id, result))\n                result_queue.put_nowait(result)"
            ]
        ]
    },
    {
        "blob_id": "d78dae8aa293992ac876084340178bc18620f645",
        "matched_blocks": [
            [
                25,
                37,
                "        try:\n            connection = sqlite3.connect(\"data.db\")\n            cursor = connection.cursor()\n        except sqlite3.Error as er:\n            raise ValueError(er)\n        else:\n            query = \"INSERT INTO users VALUES (NULL, ?, ?)\"\n            try:\n                cursor.execute(query, (data['username'], data['password']))\n            except sqlite3.Error as er:\n                raise ValueError(er)\n            else:\n                connection.commit()"
            ],
            [
                32,
                37,
                "            try:\n                cursor.execute(query, (data['username'], data['password']))\n            except sqlite3.Error as er:\n                raise ValueError(er)\n            else:\n                connection.commit()"
            ]
        ]
    },
    {
        "blob_id": "592d52bc3c0bcd666d32e7ea0e23f7ec16206150",
        "matched_blocks": [
            [
                48,
                53,
                "    try:\n        NVVM()\n    except NvvmSupportError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "f1c418b99da433012c0e6e30e94ffc182c271916",
        "matched_blocks": [
            [
                65,
                71,
                "        try:\n            result = self.trello.boards.get(board_id=board_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get Trello board.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                79,
                85,
                "        try:\n            result = self.trello.boards.get_list(board_id=board_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get lists.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                93,
                99,
                "        try:\n            result = self.trello.boards.get_label(board_id=board_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get board labels.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                107,
                113,
                "        try:\n            result = self.trello.boards.get_member(board_id=board_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get board members.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                121,
                127,
                "        try:\n            result = self.trello.cards.get_member(card_id=card_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get card members.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                135,
                141,
                "        try:\n            result = self.trello.cards.get_list(card_id_or_shortlink=card_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get card list.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                182,
                188,
                "        try:\n            cards = self.trello.lists.get_card(idList=list_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get cards from list.')\n            raise TrelloBoardException\n        else:\n            return cards"
            ],
            [
                196,
                202,
                "        try:\n            result = self.trello.cards.get(card_id_or_shortlink=card_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get card.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                220,
                226,
                "        try:\n            result = self.trello.cards.get_attachment(card_id_or_shortlink=card_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get attachments.')\n            raise TrelloBoardException\n        else:\n            return result"
            ],
            [
                234,
                240,
                "        try:\n            result = self.trello.cards.get_checklist(card_id_or_shortlink=card_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get checklists.')\n            raise TrelloBoardException\n        else:\n            return result   # if len(result) is not 0 else None"
            ],
            [
                248,
                254,
                "        try:\n            checklist_items = self.trello.checklists.get_checkItem(idChecklist=checklist_id, fields='name')\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get checklist items.')\n            raise TrelloBoardException\n        else:\n            return [li['name'] for li in checklist_items]"
            ],
            [
                262,
                268,
                "        try:\n            board_cards = self.trello.boards.get_card(board_id=board_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to get board cards.')\n            raise TrelloBoardException\n        else:\n            return list(filter(lambda card: card['idList'] != self.completeListId, board_cards))"
            ],
            [
                283,
                289,
                "        try:\n            new_card = self.trello.cards.new(name=card_name, idList=card_list_id, pos=pos, desc=card_desc)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to add card.')\n            raise TrelloBoardException\n        else:\n            return new_card"
            ],
            [
                299,
                304,
                "        try:\n            new_label = self.trello.cards.new_label(card_id_or_shortlink=card_id, name=name, color=color)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Card label {name} already exists.')\n        else:\n            return new_label"
            ],
            [
                313,
                319,
                "        try:\n            new_member = self.trello.cards.new_idMember(card_id_or_shortlink=card_id, value=member_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to add card member.')\n            raise TrelloBoardException\n        else:\n            return new_member"
            ],
            [
                331,
                337,
                "        try:\n            attachment = self.trello.cards.new_attachment(card_id_or_shortlink=card_id, url=url, file=file, name=name, mimeType=mimeType)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to add attachment.')\n            raise TrelloBoardException\n        else:\n            return attachment"
            ],
            [
                346,
                352,
                "        try:\n            checklist = self.trello.cards.new_checklist(card_id_or_shortlink=card_id, name=name)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to add checklist.')\n            raise TrelloBoardException\n        else:\n            return checklist"
            ],
            [
                378,
                384,
                "        try:\n            new_list = self.trello.lists.new(name=listName, idBoard=board_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to add list.')\n            raise TrelloBoardException\n        else:\n            return new_list"
            ],
            [
                405,
                411,
                "        try:\n            self.extension.copy_card(card_id, destination_list_id)\n        except HTTPError as httpe:\n            print(f'[!] {httpe.response.status_code}: Unable to copy card.')\n            raise TrelloBoardException\n        else:\n            self.delete_card(card_id)"
            ],
            [
                363,
                369,
                "            try:\n                item = self.trello.checklists.new_checkItem(idChecklist=checklist_id, name=name)\n            except HTTPError as httpe:\n                print(f'[!] {httpe.response.status_code}: Unable to add checklist item.')\n                raise TrelloBoardException\n            else:\n                return item"
            ]
        ]
    },
    {
        "blob_id": "8353cc7bb8452e9ef9ae1467ef3f8ec6c9d9f34e",
        "matched_blocks": [
            [
                11,
                28,
                "try:\n    # Try importing\n    from PySide import QtGui, QtCore, QtOpenGL  # noqa\nexcept Exception as exp:\n    # Fail: this backend cannot be used\n    available, testable, why_not, which = False, False, str(exp), None\nelse:\n    # Success\n    available, testable, why_not = True, True, None\n    has_uic = False\n    import PySide\n    which = ('PySide', PySide.__version__, QtCore.__version__)\n    # Remove _qt module to force an import even if it was already imported\n    sys.modules.pop(__name__.replace('_pyside', '_qt'), None)\n    # Import _qt. Keep a ref to the module object!\n    backends.qt_lib = 'pyside'  # Signal to _qt what it should import\n    from . import _qt  # noqa\n    from ._qt import *  # noqa"
            ]
        ]
    },
    {
        "blob_id": "4c92209826937397eb23395c4c36cb223ce539d5",
        "matched_blocks": [
            [
                97,
                104,
                "        try:\n            if config.get(\"development\") and config.get(\"json_authentication_override\"):\n                return config.get(\"json_authentication_override\")\n            tkn_header = self.request.headers[\"authorization\"]\n        except KeyError:\n            raise WebAuthNError(reason=\"Missing Authorization Header\")\n        else:\n            tkn_str = tkn_header.split(\" \")[-1]"
            ],
            [
                105,
                110,
                "        try:\n            tkn = self.jwt_validator(tkn_str)\n        except AuthenticationError as e:\n            raise WebAuthNError(reason=e.message)\n        else:\n            return tkn"
            ]
        ]
    },
    {
        "blob_id": "fef5147e970920c7d7ac5ef2afcfd0b117d14024",
        "matched_blocks": [
            [
                54,
                64,
                "    try:\n        fun(*args, **kwds)\n    except JSONRPCException:\n        raise AssertionError(\"Use assert_raises_rpc_error() to test RPC failures\")\n    except exc as e:\n        if message is not None and message not in e.error['message']:\n            raise AssertionError(\"Expected substring not found:\" + e.error['message'])\n    except Exception as e:\n        raise AssertionError(\"Unexpected exception raised: \" + type(e).__name__)\n    else:\n        raise AssertionError(\"No exception raised\")"
            ],
            [
                80,
                88,
                "    try:\n        fun(*args, **kwds)\n    except CalledProcessError as e:\n        if returncode != e.returncode:\n            raise AssertionError(\"Unexpected returncode %i\" % e.returncode)\n        if output not in e.output:\n            raise AssertionError(\"Expected substring not found:\" + e.output)\n    else:\n        raise AssertionError(\"No exception raised\")"
            ],
            [
                113,
                125,
                "    try:\n        fun(*args, **kwds)\n    except JSONRPCException as e:\n        # JSONRPCException was thrown as expected. Check the code and message values are correct.\n        if (code is not None) and (code != e.error[\"code\"]):\n            raise AssertionError(\"Unexpected JSONRPC error code %i\" % e.error[\"code\"])\n        if (message is not None) and (message not in e.error['message']):\n            raise AssertionError(\"Expected substring not found:\" + e.error['message'])\n        return True\n    except Exception as e:\n        raise AssertionError(\"Unexpected exception raised: \" + type(e).__name__)\n    else:\n        return False"
            ]
        ]
    },
    {
        "blob_id": "cf3ff688eca559e72b7a03c95a74663b58dfad04",
        "matched_blocks": [
            [
                108,
                115,
                "        try:\n            jobFunc(*orderArgs)\n        except Exception as err:\n            traceback.print_exc()\n            self.log('[ERROR][doOrderJobs_doing]\u6267\u884c[%s]\u5931\u8d25' % (order), level='error')\n            return False, err\n        else:\n            return True, ''"
            ]
        ]
    },
    {
        "blob_id": "ccc08696bb1af782a16f12ab9b1ff3d1aa5fa18e",
        "matched_blocks": [
            [
                302,
                315,
                "            try:\n                related_name = attrs.pop('TenantMeta').related_name\n            except (KeyError, AttributeError):\n                pass\n            else:\n                # Attach a descriptor to the tenant model to access the\n                # underlying model based on the tenant instance.\n                def attach_descriptor(tenant_model):\n                    descriptor = TenantModelDescriptor(model)\n                    setattr(tenant_model, related_name, descriptor)\n                # Avoid circular imports on Django < 1.7\n                from .settings import TENANT_MODEL\n                app_label, model_name = TENANT_MODEL.split('.')\n                lazy_class_prepared(app_label, model_name, attach_descriptor)"
            ]
        ]
    },
    {
        "blob_id": "7e8ffd682bae9bbaff7485ca16af4ec980de96df",
        "matched_blocks": [
            [
                18,
                25,
                "    try:\n        print('get')\n        data = dataQueue.get(block=False)\n    except queue.Empty:\n        pass\n    else:\n        root.insert('end', 'consumer got => %s\\n' % str(data))\n        root.see('end')"
            ]
        ]
    },
    {
        "blob_id": "5fdbaa95b28a30a142d9895a2f09731edc34cc8a",
        "matched_blocks": [
            [
                22,
                27,
                "    try:\n        cmd = ctl.undo.pop()\n    except IndexError:\n        raise CmdError(\"nothing to undo\")\n    else:\n        cmd()"
            ]
        ]
    },
    {
        "blob_id": "09177b0fd6319c31fa7e32f81c9473d115073427",
        "matched_blocks": [
            [
                42,
                47,
                "            try:\n                record = self._log_queue.get(block=False)\n            except queue.Empty:\n                break\n            else:\n                self._display(record)"
            ]
        ]
    },
    {
        "blob_id": "7b0ed7ee1034799bdfb9d1341cd9f0c69f68aab1",
        "matched_blocks": [
            [
                11,
                18,
                "    try:\n        print(float(i))\n# except \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc608\uc678\uac00 \ubc1c\uc0dd\ud588\uc744 \ub54c \uc218\ud589\ud560 \ucf54\ub4dc\ub97c \uc9c0\uc815\ud55c\ub2e4.    \n    except:\n        print(0)\n# else \ucf54\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec \uc608\uc678\uac00 \ubc1c\uc0dd\ud558\uc9c0 \uc54a\uc558\uc744 \ub54c \uc218\ud589\ud560 \ucf54\ub4dc\ub97c \uc9c0\uc815\ud55c\ub2e4.\n    else:\n        print(\"clean data\")"
            ]
        ]
    },
    {
        "blob_id": "6da44852f8000825e8a6e17ae73f9d01f8a06a24",
        "matched_blocks": [
            [
                19,
                25,
                "        try:\n            if nro1<0:   # si el numero 1 menor a cero levantame una excepcion\n                raise Exception('no puedo hacer la operacion suma porq nro1 es menor a cero')\n        except:\n            return 'se\u00f1or no puede poner un numero menor a cero en el primer digito'\n        else:\n            return nro1+nro2"
            ],
            [
                33,
                39,
                "        try:\n            if not type(nro1) is int:       # si nro1 no es un integer entonces\n                raise TypeError('multiplicar solo acepta enteros') # levantame una excepcion del tipo TypeError\n        except TypeError:\n            return 'no puedo multiplicar'\n        else:\n            return nro1 * nro2"
            ],
            [
                45,
                54,
                "        try:\n            n3 = n1/n2        \n        except ZeroDivisionError:\n            return 'no se puede dividir por cero'\n        except NameError:\n            return'no se puede dividir por una variable no definida'\n        except TypeError:\n            return 'hay un error en el  tipo de datos ingresados'\n        else:\n            return ('el resultado de la division es ' + n3)"
            ]
        ]
    },
    {
        "blob_id": "1abbb932f8ca7cf400a8f4e275b0355ce59e534a",
        "matched_blocks": [
            [
                45,
                56,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        return HttpResponseRedirect(\n            reverse('polls:results', args=(question_id, )))"
            ]
        ]
    },
    {
        "blob_id": "e8519a97fb7a10b34702f8bc053774cc1ae0a89f",
        "matched_blocks": [
            [
                139,
                154,
                "        try:\n            super(Bot, self).__init__(\n                    client_id = client_id,\n                    client_secret = client_secret,\n                    user_agent = user_agent,\n                    username = username,\n                    password = password\n                    )\n        except:\n            print('Failed to authenticate')\n            print('/*************\\\\ \\n')\n\n        else:\n            print('Signed in as:',self.user.me())\n            print('read_only:',self.read_only)\n            print('/*************\\\\ \\n')"
            ]
        ]
    },
    {
        "blob_id": "ddf47d224f7d5fdde321387abe4c3738cc0dd469",
        "matched_blocks": [
            [
                396,
                412,
                "    try:\n        for chunk in iterator:\n            rv = dec.decompress(chunk)\n            if rv:\n                yield rv\n    except zlib.error:\n        # If there was an error decompressing, just return the raw chunk\n        yield chunk\n        # Continue to return the rest of the raw data\n        for chunk in iterator:\n            yield chunk\n    else:\n        # Make sure everything has been returned from the decompression object\n        buf = dec.decompress(bytes())\n        rv = buf + dec.flush()\n        if rv:\n            yield rv"
            ]
        ]
    },
    {
        "blob_id": "68c3596f7b0719e22f39a5bb9add3cf40d285973",
        "matched_blocks": [
            [
                431,
                450,
                "            try:\n                filename = '\"%s\"' % filename\n                if line and self.editor_line:\n                    command = self.editor_line.format(filename=filename,\n                                                      line=line)\n                else:\n                    try:\n                        command = self.editor.format()\n                    except KeyError:\n                        command = self.editor.format(filename=filename)\n                    else:\n                        command += ' ' + filename\n            except KeyError:\n                self._append_plain_text('Invalid editor command.\\n')\n            else:\n                try:\n                    Popen(command, shell=True)\n                except OSError:\n                    msg = 'Opening editor with command \"%s\" failed.\\n'\n                    self._append_plain_text(msg % command)"
            ],
            [
                437,
                442,
                "                    try:\n                        command = self.editor.format()\n                    except KeyError:\n                        command = self.editor.format(filename=filename)\n                    else:\n                        command += ' ' + filename"
            ]
        ]
    },
    {
        "blob_id": "579153317b369ad77af1c66c5cb43036e863cc19",
        "matched_blocks": [
            [
                84,
                95,
                "        try:\n            obj = open(html_name)\n        except Exception:\n            response = \"HTTP/1.1 404 not found\\r\\n\"\n            response += \"Content_Type:text/html\\r\\n\"\n            response += \"\\r\\n\"\n            response += \"<h1>sorry.....<h1>\"\n        else:\n            response = \"HTTP/1.1 200 OK\\r\\n\"\n            response += \"Content_Type:text/html\\r\\n\"\n            response += \"\\r\\n\"\n            response += obj.read()"
            ]
        ]
    },
    {
        "blob_id": "92929d241384233660875a5731e7b8bdb4618600",
        "matched_blocks": [
            [
                18,
                23,
                "            try:\n                index = self.FORWARD.index(char)\n            except ValueError:\n                output.append(char)\n            else:\n                output.append(self.FORWARD[index+self.offset])"
            ],
            [
                30,
                35,
                "            try:\n                index = self.BACKWARD.index(char)\n            except ValueError:\n                output.append(char)\n            else:\n                output.append(self.BACKWARD[index-self.offset])"
            ]
        ]
    },
    {
        "blob_id": "94d62292972786336dbaf6ee93f5948c03eca8fc",
        "matched_blocks": [
            [
                128,
                135,
                "        try:\n            self.opt['fasttext_md5']\n        except KeyError:\n            self.opt['fasttext_md5'] = current_fasttext_md5\n        else:\n            if self.opt['fasttext_md5'] != current_fasttext_md5:\n                raise ConfigError(\n                    \"Given fasttext model does NOT match fasttext model used previously to train loaded model\")"
            ]
        ]
    },
    {
        "blob_id": "9872129ddae8300dd001e9f43937ff90f02662ec",
        "matched_blocks": [
            [
                207,
                217,
                "        try:\n            args = self.storages[storage_name]\n        except KeyError:\n            pair_pref = 'Pair {}: '.format(pair_name) if pair_name else ''\n            raise exceptions.UserError(\n                '{}Storage {!r} not found. '\n                'These are the configured storages: {}'\n                .format(pair_pref, storage_name, list(self.storages))\n            )\n        else:\n            return expand_fetch_params(args)"
            ]
        ]
    },
    {
        "blob_id": "b0da7bdba534730f35505b2301bd30a30bf8b8a2",
        "matched_blocks": [
            [
                8,
                18,
                "    try:\n        frase = input()\n    except EOFError:\n        break\n    else:\n        for c in frase:\n            if c == ' ':\n                s += c\n            else:\n                s += linha[linha.find(c)-1]\n        print(s)"
            ]
        ]
    },
    {
        "blob_id": "fa330cd7420513def946754db264b6638a17e5ef",
        "matched_blocks": [
            [
                92,
                100,
                "        try:\n            changed_value = self._track_diff[key]\n        except DiffMissingError as missing:\n            if missing.is_deleted:\n                raise KeyError(key)\n            else:\n                return self._original_read_db[key]\n        else:\n            return changed_value"
            ],
            [
                113,
                121,
                "        try:\n            self._track_diff[key]\n        except DiffMissingError as missing:\n            if missing.is_deleted:\n                return False\n            else:\n                return key in self._original_read_db\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "8a2fa77e9a860b3b2ac21b16b7d0e7fe45df1e7a",
        "matched_blocks": [
            [
                78,
                107,
                "            try:\n                await self._async_try_connect(host, location, tls, verify_tls)\n            except HoleError as ex:\n                _LOGGER.debug(\"Connection failed: %s\", ex)\n                if is_import:\n                    _LOGGER.error(\"Failed to import: %s\", ex)\n                    return self.async_abort(reason=\"cannot_connect\")\n                errors[\"base\"] = \"cannot_connect\"\n            else:\n                self._config = {\n                    CONF_HOST: host,\n                    CONF_NAME: name,\n                    CONF_LOCATION: location,\n                    CONF_SSL: tls,\n                    CONF_VERIFY_SSL: verify_tls,\n                }\n                if is_import:\n                    api_key = user_input.get(CONF_API_KEY)\n                    return self.async_create_entry(\n                        title=name,\n                        data={\n                            **self._config,\n                            CONF_STATISTICS_ONLY: api_key is None,\n                            CONF_API_KEY: api_key,\n                        },\n                    )\n                self._config[CONF_STATISTICS_ONLY] = user_input[CONF_STATISTICS_ONLY]\n                if self._config[CONF_STATISTICS_ONLY]:\n                    return self.async_create_entry(title=name, data=self._config)\n                return await self.async_step_api_key()"
            ]
        ]
    },
    {
        "blob_id": "71441fa1fa9ec1e4bcfd5d9d66fe1050ae9fe9b6",
        "matched_blocks": [
            [
                100,
                122,
                "                try:\n                    from rucio.client.replicaclient import ReplicaClient\n                    client = ReplicaClient(account=account)\n                    not_declared = []\n                    # chunk the list to avoid \"request too large\" errors\n                    for chunk in chunked(missing_list):\n                        result = client.declare_bad_file_replicas(chunk, \"detected missing by CE\", force=True)\n                        not_declared += result.pop(rse, [])      # there shuld be no other RSE in there\n                        assert not result, \"Other RSEs in the not_declared dictionary: \"  + \",\".join(result.keys())\n                except Exception as e:\n                    status = \"failed\"\n                    error = f\"Rucio declaration error: {e}\"\n                else:\n                    not_declared_count = len(not_declared)\n                    if not_declared_count:\n                        print(\"Replicas failed to declare:\", not_declared_count)\n                    declaration_errors = {}\n                    for item in not_declared:\n                        words = item.split(None, 1)\n                        if len(words) == 2:\n                            declaration_errors[error] = declaration_errors.get(words[1], 0) + 1\n                    my_stats[\"declaration_errors\"] = declaration_errors\n                    my_stats[\"declared_missing_files\"] = len(missing_list) - not_declared_count"
            ]
        ]
    },
    {
        "blob_id": "4c6c5d18a00823a83ef35c263e076351815ec55a",
        "matched_blocks": [
            [
                10,
                15,
                "    try:\n        __import__(module_name)\n    except ImportError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "25c724ee779ec1d3fdd96581b62e411fcba9cf2a",
        "matched_blocks": [
            [
                70,
                91,
                "            try:\n                last_day_count = yield self.get_pay_count(cur, self.last_create_at_start, self.last_create_at_end)\n                total_count = yield self.get_pay_count(cursor=cur, create_at_start=None,\n                                                       create_at_end=self.last_create_at_end)\n                total_query_start = datetime.strptime(self.create_at_start_search, '%Y-%m-%d %H:%M:%S') + timedelta(\n                    1) if int(self.query_date) == 2 else self.create_at_start_search\n                total_count_search = yield self.get_pay_count(cur, total_query_start,\n                                                              self.create_at_end_search)\n                search_count_details = yield self.get_pay_count_detail(cur, self.create_at_start_search,\n                                                                       self.create_at_end_search,\n                                                                       (self.pageindex - 1) *\n                                                                       10, self.query_date,\n                                                                       page=True)\n                chart_show_details = yield self.get_pay_count_detail(cur, self.create_at_start_search,\n                                                                     self.create_at_end_search, 0, self.query_date,\n                                                                     page=False)\n\n            except Exception as err:\n                cur.connection.rollback()\n                log.exception.exception(err)\n            else:\n                cur.connection.commit()"
            ]
        ]
    },
    {
        "blob_id": "2a8a2fea5ef6b27e5ad95edd93fb19dddb4b601a",
        "matched_blocks": [
            [
                45,
                66,
                "        try:\n            subst1.try_add_variable('i2.2.1.2.2.1.0_1', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 68382\n            if len(subjects) >= 1:\n                tmp2 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i2.2.1.2.2.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 68383\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*d\n                        yield 0, subst2\n                subjects.appendleft(tmp2)"
            ],
            [
                68,
                89,
                "        try:\n            subst1.try_add_variable('i2.4.1.0_1', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 68600\n            if len(subjects) >= 1:\n                tmp5 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i2.4.1.0', tmp5)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 68601\n                    if len(subjects) == 0:\n                        pass\n                        # 1: x*f\n                        yield 1, subst2\n                subjects.appendleft(tmp5)"
            ],
            [
                55,
                65,
                "                try:\n                    subst2.try_add_variable('i2.2.1.2.2.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 68383\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*d\n                        yield 0, subst2"
            ],
            [
                78,
                88,
                "                try:\n                    subst2.try_add_variable('i2.4.1.0', tmp5)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 68601\n                    if len(subjects) == 0:\n                        pass\n                        # 1: x*f\n                        yield 1, subst2"
            ]
        ]
    },
    {
        "blob_id": "39f7af7280a9edaad084a39bfc6d0a4a25ec4583",
        "matched_blocks": [
            [
                12,
                26,
                "    try:\n      aluno = Aluno.objects.get(email=email)\n    except Aluno.DoesNotExist:\n      #Usuario n\u00e3o existe\n      form = AlunoForm(req.POST)\n      if form.is_valid():\n          aluno = form.save()\n          req.session['aluno_id'] = aluno.id\n          return redirect('/perguntas/1')\n      else:\n          contexto = {'form': form}\n          return render(req, 'base/home.html', contexto)\n    else:\n        req.session['aluno_id'] = aluno.id\n        return redirect('/perguntas/1')"
            ]
        ]
    },
    {
        "blob_id": "4592366353bb1a72dfd875e0dfdbd622612baa2b",
        "matched_blocks": [
            [
                39,
                47,
                "        try:\n            request.session['client_slug'] = ClientUser.objects.get(\n                user=user).client.slug\n        except ClientUser.DoesNotExist:\n            request.session['client_slug'] = None\n            request.session.save()\n        else:\n            request.session.save()\n            return Response({'success': 'Thank you for signing-in!'})"
            ]
        ]
    },
    {
        "blob_id": "ec0778ffeb0bd6ff240b5121ae131486c2c5ce1b",
        "matched_blocks": [
            [
                5,
                12,
                "    try:\n        arquivo = open(f'{arq}', 'rt')\n        arquivo.close()\n\n    except FileNotFoundError:\n        return False\n    else:\n        return True"
            ],
            [
                16,
                22,
                "    try:\n        arquivo = open(f'{arq}', 'wt+', encoding='utf-8')\n        arquivo.close()\n    except:\n        print('\\033[31mN\u00e3o foi poss\u00edvel criar o arquivo!\\033[m')\n    else:\n        print(f'\\033[32mArquivo {arq} criado com sucesso!\\033[m')"
            ],
            [
                27,
                35,
                "    try:\n        arquivo = open(f'{arq}', 'rt', encoding='utf-8')\n    except:\n        print('\\033[31mN\u00e3o foi poss\u00edvel abrir o arquivo para leitura\\033[m')\n    else:\n        for linha in arquivo:\n            dado = linha.split(';')\n            dado[1] = dado[1].replace('\\n', '')\n            print(f'{dado[0]:<30}{dado[1]:>3} Anos')"
            ],
            [
                41,
                51,
                "    try:\n        arquivo = open(f'{arq}', 'at', encoding='utf-8')\n    except:\n        print('\\033[31mHouve um erro ao tentar abrir o arquivo\\033[m')\n    else:\n        try:\n            arquivo.write(f'{nome};{idade}\\n')\n        except:\n            print('\\033[31mHouve um erro ao tentar escrever no arquivo\\033[m')\n        else:\n            print('\\033[32mNovo regristro adicionado com sucesso\\033[m')"
            ],
            [
                46,
                51,
                "        try:\n            arquivo.write(f'{nome};{idade}\\n')\n        except:\n            print('\\033[31mHouve um erro ao tentar escrever no arquivo\\033[m')\n        else:\n            print('\\033[32mNovo regristro adicionado com sucesso\\033[m')"
            ]
        ]
    },
    {
        "blob_id": "3d28100d3c9863e403e81490f9fc06870275da9c",
        "matched_blocks": [
            [
                342,
                352,
                "        try:\n            with open(\"local/init\", \"rb\") as f:\n                s = f.read()\n                s = security.protege_data(s, False)\n                modules = json.loads(s)[\"modules\"]\n        except (KeyError, FileNotFoundError) as e:\n            raise StructureError(\n                \"Impossible des lire les derniers modules utilis\u00e9s !\")\n        else:\n            self.modules = {k: 0 for k in modules}  # low permission\n            self.mode_online = False"
            ]
        ]
    },
    {
        "blob_id": "3675d76144a4cb90dfa45bd20ea6edef9095baa9",
        "matched_blocks": [
            [
                14,
                19,
                "try:\n    import ipywidgets\nexcept ImportError:\n    _HAS_IPYWIDGETS = False\nelse:\n    _HAS_IPYWIDGETS = True"
            ],
            [
                21,
                26,
                "try:\n    from IPython.display import display\nexcept ImportError:\n    _HAS_IPYTHON = False\nelse:\n    _HAS_IPYTHON = True"
            ]
        ]
    },
    {
        "blob_id": "a422c21afb63d1c974617ac9b5a9cd52a441fc53",
        "matched_blocks": [
            [
                436,
                455,
                "            try:\n                dag.validate()\n                self.bag_dag(dag=dag, root_dag=dag)\n            except AirflowTimetableInvalid as exception:\n                self.log.exception(\"Failed to bag_dag: %s\", dag.fileloc)\n                self.import_errors[dag.fileloc] = f\"Invalid timetable expression: {exception}\"\n                self.file_last_changed[dag.fileloc] = file_last_changed_on_disk\n            except (\n                AirflowClusterPolicyViolation,\n                AirflowDagCycleException,\n                AirflowDagDuplicatedIdException,\n                AirflowDagInconsistent,\n                ParamValidationError,\n            ) as exception:\n                self.log.exception(\"Failed to bag_dag: %s\", dag.fileloc)\n                self.import_errors[dag.fileloc] = str(exception)\n                self.file_last_changed[dag.fileloc] = file_last_changed_on_disk\n            else:\n                found_dags.append(dag)\n                found_dags += dag.subdags"
            ]
        ]
    },
    {
        "blob_id": "20e5e3d3efd7b71f0d1245e11bc770db1c7e042d",
        "matched_blocks": [
            [
                102,
                117,
                "        try:\n            udev = pyudev.Device.from_device_file(context, name)\n        # pyudev started raising another error in 0.18\n        except (ValueError, EnvironmentError, pyudev.DeviceNotFoundError) as e:\n            LOG.warning(\"Device %(dev)s is inaccessible, skipping... \"\n                        \"Error: %(error)s\", {'dev': name, 'error': e})\n            extra = {}\n        else:\n            # TODO(lucasagomes): Since lsblk only supports\n            # returning the short serial we are using\n            # ID_SERIAL_SHORT here to keep compatibility with the\n            # bash deploy ramdisk\n            extra = {key: udev.get('ID_%s' % udev_key) for key, udev_key in\n                     [('wwn', 'WWN'), ('serial', 'SERIAL_SHORT'),\n                      ('wwn_with_extension', 'WWN_WITH_EXTENSION'),\n                      ('wwn_vendor_extension', 'WWN_VENDOR_EXTENSION')]}"
            ],
            [
                285,
                297,
                "        try:\n            out, _ = utils.execute(cmd, shell=True)\n        except (processutils.ProcessExecutionError, OSError) as e:\n            LOG.warning(\"Cannot get system vendor information: %s\", e)\n        else:\n            for line in out.split('\\n'):\n                line_arr = line.split(':', 1)\n                if len(line_arr) != 2:\n                    continue\n                if line_arr[0].strip() == 'product':\n                    product_name = line_arr[1].strip()\n                elif line_arr[0].strip() == 'serial':\n                    serial_number = line_arr[1].strip()"
            ]
        ]
    },
    {
        "blob_id": "9fbba12d321ad7bcae325cc7b8e8bc3d77faa827",
        "matched_blocks": [
            [
                126,
                139,
                "            try:\n                with transaction.atomic():\n                    MoMoTransaction.objects.using('wallets').filter(object_id=object_id) \\\n                        .update(processor_tx_id=paymentref, message='OK', is_running=False,\n                                status=MoMoTransaction.SUCCESS)\n            except:\n                logger.error(\"YUP: Could not mark transaction as Successful. User: %s, Amt: %d\" % (tx.username, tx.amount), exc_info=True)\n            else:\n                try:\n                    momo_after_checkout(request, transaction=tx)\n                except:\n                    MoMoTransaction.objects.using('wallets').filter(object_id=object_id) \\\n                        .update(message=traceback.format_exc())\n                    logger.error(\"YUP: Error while running callback. User: %s, Amt: %d\" % (tx.username, tx.amount), exc_info=True)"
            ]
        ]
    },
    {
        "blob_id": "fcdcbb3dc629b15123b24d968288cd160f889ebb",
        "matched_blocks": [
            [
                38,
                43,
                "        try:\n            f = open(get_file)\n        except IOError:\n            response = ('404','===Sorry not found the page===')\n        else:\n            response = ('200',f.read())"
            ]
        ]
    },
    {
        "blob_id": "17c60f274d555ceefc3a340a5ea260e332aa47df",
        "matched_blocks": [
            [
                839,
                844,
                "            try:\n                position = int(self.arg(1)[2:])\n            except ValueError:\n                pass\n            else:\n                self.shift()"
            ],
            [
                990,
                996,
                "            try:\n                result = eval(code)  # pylint: disable=eval-used\n            except SyntaxError:\n                exec(code)  # pylint: disable=exec-used\n            else:\n                if result and not quiet:\n                    p(result)"
            ]
        ]
    },
    {
        "blob_id": "6d2b8a6b52fcfa85775cb6e350914e11786547cf",
        "matched_blocks": [
            [
                40,
                52,
                "    try:\n        #Check for LSM6DSL on the BerryIMUv3\n        #If no LSM6DSL, there will be an I2C bus error and the program will exit.\n        #This section of code stops this from happening.\n        LSM6DSL_WHO_AM_I_response = readReg(LSM6DSL_WHO_AM_I)\n\n\n    except IOError as f:\n        print('')        #need to do something here, so we just print a space\n    else:\n        if (LSM6DSL_WHO_AM_I_response == 0x6A) :\n            print(\"Found BerryIMUv3 (LSM6DSL)\")\n            BerryIMUversion = 3"
            ]
        ]
    },
    {
        "blob_id": "c04e1153268660de34728d5915c479b521c2ca22",
        "matched_blocks": [
            [
                418,
                434,
                "    try:\n        app.start()\n\n    except:\n        log_buff.flush()\n        val = log_buff.getvalue()\n        result = {\"success\": False}\n        result[\"error\"] = traceback.format_exc()\n        if val:\n            result[\"log\"] = val\n\n    else:\n        log_buff.flush()\n        val = log_buff.getvalue()\n        result = {\"success\": True}\n        if val:\n            result[\"log\"] = val"
            ]
        ]
    },
    {
        "blob_id": "044933ceef9d864c4c6bbdae99fddac39245cf68",
        "matched_blocks": [
            [
                33,
                43,
                "\ttry:\n\t\tselected_choice = question.choice_set.get(pk=request.POST['choice'])\n\texcept (KeyError, Choice.DoesNotExist):\n\t\treturn render(request, 'polls/detail.html', {\n\t\t\t'question': question,\n\t\t\t'error_message': \"You didn't select a choice.\",\n\t\t\t})\n\telse:\n\t\tselected_choice.votes += 1\n\t\tselected_choice.save()\n\t\treturn HttpResponseRedirect(reverse('polls:results', args=(question_id,)))"
            ]
        ]
    },
    {
        "blob_id": "7e5b96550afe812018fe239ac8ed2783e7cc8f84",
        "matched_blocks": [
            [
                106,
                112,
                "    try:\n        requests.get(url,proxies)\n    except:\n        pass\n    else:\n        if i not in _useful:\n           _useful.append(i)"
            ]
        ]
    },
    {
        "blob_id": "47691724cd46a16d1b211ae062bb5ffb915997d6",
        "matched_blocks": [
            [
                47,
                53,
                "    try:\n        lb= bovy_coords.radec_to_lb(ra/180.*numpy.pi,dec/180.*numpy.pi,\n                                    degree=False,epoch=1975.)   \n    except IOError:\n        pass\n    else:\n        raise AssertionError('radec functions with epoch not equal to 1950 or 2000 did not raise IOError')"
            ]
        ]
    },
    {
        "blob_id": "2374e0ff5975297383338decbc186c82df6b502f",
        "matched_blocks": [
            [
                303,
                308,
                "        try:\n            value = self.db[key]\n        except KeyError:\n            sock.sendall(FAIL_BYTE)\n        else:\n            sock.sendall(SUCCESS_BYTE + len(value).to_bytes(LEN_BYTES, 'little') + value)"
            ],
            [
                323,
                328,
                "        try:\n            del self.db[key]\n        except KeyError:\n            sock.sendall(FAIL_BYTE)\n        else:\n            sock.sendall(SUCCESS_BYTE)"
            ],
            [
                487,
                495,
                "        try:\n            value = self._track_diff[key]\n        except DiffMissingError as missing:\n            if missing.is_deleted:\n                raise KeyError(key)\n            else:\n                return self._db[key]\n        else:\n            return value"
            ],
            [
                509,
                514,
                "        try:\n            self[key]\n        except KeyError:\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "5970ff0445b098caa0b2d0fd4c0dcf275fa5f854",
        "matched_blocks": [
            [
                1849,
                1854,
                "    try:\n        ptnp= potential.toPlanarPotential('something else')\n    except potential.PotentialError:\n        pass\n    else:\n        raise AssertionError('Using toPlanarPotential with a string rather than an Potential or a planarPotential did not raise PotentialError')"
            ],
            [
                1924,
                1929,
                "    try:\n        ptnp= potential.toVerticalPotential('something else',1.2,phi=0.8)\n    except potential.PotentialError:\n        pass\n    else:\n        raise AssertionError('Using toVerticalPotential with a string rather than an Potential or a linearPotential did not raise PotentialError')"
            ],
            [
                2075,
                2080,
                "    try:\n        potential.plotRotcurve([dp])\n    except (AttributeError,potential.PotentialError): #should be raised\n        pass\n    else:\n        raise AssertionError(\"plotRotcurve for non-axisymmetric potential should have raised AttributeError, but didn't\")"
            ],
            [
                2081,
                2086,
                "    try:\n        potential.plotEscapecurve([dp])\n    except AttributeError: #should be raised\n        pass\n    else:\n        raise AssertionError(\"plotEscapecurve for non-axisymmetric potential should have raised AttributeError, but didn't\")"
            ],
            [
                2106,
                2111,
                "    try:\n        lp.lindbladR(0.5,'wrong resonance')\n    except IOError:\n        pass\n    else:\n        raise AssertionError(\"lindbladR w/ wrong m input should have raised IOError, but didn't\")"
            ],
            [
                2186,
                2191,
                "    try:\n        potential.evaluateplanarPotentials(dp,1.)\n    except potential.PotentialError:\n        pass\n    else:\n        raise AssertionError('evaluateplanarPotentials for non-axisymmetric potential w/o specifying phi did not raise PotentialError')"
            ],
            [
                2192,
                2197,
                "    try:\n        potential.evaluateplanarRforces(dp,1.)\n    except potential.PotentialError:\n        pass\n    else:\n        raise AssertionError('evaluateplanarRforces for non-axisymmetric potential w/o specifying phi did not raise PotentialError')"
            ],
            [
                2198,
                2203,
                "    try:\n        potential.evaluateplanarphiforces(dp,1.)\n    except potential.PotentialError:\n        pass\n    else:\n        raise AssertionError('evaluateplanarphiforces for non-axisymmetric potential w/o specifying phi did not raise PotentialError')"
            ],
            [
                2204,
                2209,
                "    try:\n        potential.evaluateplanarR2derivs(dp,1.)\n    except potential.PotentialError:\n        pass\n    else:\n        raise AssertionError('evaluateplanarR2derivs for non-axisymmetric potential w/o specifying phi did not raise PotentialError')"
            ],
            [
                2245,
                2247,
                "    try: rp.R2deriv(1.,0.1)\n    except potential.PotentialError: pass\n    else: raise AssertionError(\"RazorThinExponentialDiskPotential's R2deriv did not raise AttributeError for z=/= 0 input\")"
            ],
            [
                2742,
                2744,
                "    try: pp.conc(220.,8.)\n    except AttributeError: pass\n    else: raise AssertionError('conc function for potential w/o scale did not raise AttributeError')"
            ],
            [
                2750,
                2752,
                "    try: mp.mvir(220.,8.)\n    except AttributeError: pass\n    else: raise AssertionError('mvir function for potential w/o rvir did not raise AttributeError')"
            ],
            [
                2818,
                2821,
                "    try:\n        LinShuReductionFactor(lp,R,sr)\n    except IOError: pass\n    else: raise AssertionError(\"LinShuReductionFactor w/o nonaxiPot set or k=,m=,OmegaP= set did not raise IOError\")"
            ],
            [
                2854,
                2857,
                "    try: bp.nemo_accname()\n    except AttributeError: pass\n    else:\n        raise AssertionError('nemo_accname for potential w/o accname does not raise AttributeError')"
            ],
            [
                2858,
                2861,
                "    try: bp.nemo_accpars(220.,8.)\n    except AttributeError: pass\n    else:\n        raise AssertionError('nemo_accpars for potential w/o accname does not raise AttributeError')"
            ],
            [
                2978,
                2982,
                "    try:\n        mn= potential.MN3ExponentialDiskPotential(amp=1.,hz=50.)\n    except IOError: pass\n    else:\n        raise AssertionError(\"MN3ExponentialDiskPotential with ridiculous hz should have given IOError, but didn't\")"
            ],
            [
                4236,
                4242,
                "    try:\n        kp.plot(effective=True,Lz=None)\n    except RuntimeError:\n        print(\"Here\")\n        pass\n    else:\n        raise AssertionError(\"Potential.plot with effective=True, but Lz=None did not return a RuntimeError\")"
            ],
            [
                4244,
                4249,
                "    try:\n        potential.plotPotentials([kp],effective=True,Lz=None)\n    except RuntimeError:\n        pass\n    else:\n        raise AssertionError(\"Potential.plot with effective=True, but Lz=None did not return a RuntimeError\")"
            ],
            [
                954,
                956,
                "        try: tp(1.2,0.1,dR=4,dphi=10)\n        except NotImplementedError: pass\n        else: raise AssertionError('Higher-order derivative request in potential __call__ does not raise NotImplementedError for %s' % p)"
            ]
        ]
    },
    {
        "blob_id": "024c2f21cc0211e8419ecff745b30e15d26c451a",
        "matched_blocks": [
            [
                1844,
                1849,
                "    try:\n        _client_wrapper('inspect_container', name, catch_api_errors=False)\n    except docker.errors.APIError:\n        __context__[contextkey] = False\n    else:\n        __context__[contextkey] = True"
            ],
            [
                1019,
                1027,
                "        try:\n            image_id = re.match(\n                r'Pushing tags? for rev \\[([0-9a-f]+)',\n                status\n            ).group(1)\n        except AttributeError:\n            return\n        else:\n            data['Id'] = image_id"
            ],
            [
                1416,
                1423,
                "            try:\n                link_name, link_alias = item.split(':')\n            except ValueError:\n                raise SaltInvocationError(err)\n            else:\n                if not link_name.startswith('/'):\n                    # Normalize container name to make comparisons simpler\n                    link_name = '/' + link_name"
            ],
            [
                1285,
                1302,
                "                try:\n                    key, val = env_var.split('=')\n                except AttributeError:\n                    raise SaltInvocationError(\n                        'Invalid environment variable definition \\'{0}\\''\n                        .format(env_var)\n                    )\n                else:\n                    if key in repacked_env:\n                        raise SaltInvocationError(\n                            'Duplicate environment variable \\'{0}\\''\n                            .format(key)\n                        )\n                    if not isinstance(val, six.string_types):\n                        raise SaltInvocationError(\n                            'Environment values must be strings {key}=\\'{val}\\''\n                            .format(key=key, val=val))\n                    repacked_env[key] = val"
            ]
        ]
    },
    {
        "blob_id": "b3400b68e39d10df48d558b5f4a0f0aa7b3787f3",
        "matched_blocks": [
            [
                58,
                68,
                "        try:\n            fmtint = str(int(fmt))\n        except ValueError:\n            return linestyle, marker, color  # Yes\n        else:\n            if fmt != fmtint:\n                # user definitely doesn't want tri_down marker\n                return linestyle, marker, color  # Yes\n            else:\n                # ignore converted color\n                color = None"
            ],
            [
                179,
                196,
                "                try:\n                    _process_plot_format(args[1])\n                except ValueError:  # case 1)\n                    label_namer_idx = 1\n                else:\n                    if replaced[1] is not args[1]:  # case 2a)\n                        cbook._warn_external(\n                            f\"Second argument {args[1]!r} is ambiguous: could \"\n                            f\"be a format string but is in 'data'; using as \"\n                            f\"data.  If it was intended as data, set the \"\n                            f\"format string to an empty string to suppress \"\n                            f\"this warning.  If it was intended as a format \"\n                            f\"string, explicitly pass the x-values as well.  \"\n                            f\"Alternatively, rename the entry in 'data'.\",\n                            RuntimeWarning)\n                        label_namer_idx = 1\n                    else:  # case 2b)\n                        label_namer_idx = 0"
            ]
        ]
    },
    {
        "blob_id": "42983223ec1ec685ad95399c0bf213151fcc9c28",
        "matched_blocks": [
            [
                166,
                174,
                "                try:\n                    series_data.fred_response(params)\n                except json.JSONDecodeError:\n                    delay = 5\n                    print('\\t --CONNECTION ERROR--',\n                          '\\n\\t Sleeping for {} seconds.'.format(delay))\n                    time.sleep(delay) \n                else:\n                    success = True"
            ],
            [
                192,
                200,
                "                try:\n                    series_data.yahoo_response(series_id)\n                except req.HTTPError:\n                    delay = 5\n                    print('\\t --CONNECTION ERROR--',\n                          '\\n\\t Sleeping for {} seconds.'.format(delay))\n                    time.sleep(delay)\n                else:\n                    success = True"
            ]
        ]
    },
    {
        "blob_id": "35f6822467bc9491df6aecb05a27905bfc3f14e3",
        "matched_blocks": [
            [
                28,
                41,
                "            try:\n                sock = self._connect_to_graylog_input()\n            except OSError as e:  # For issue: OSError: [Errno 99] Cannot assign requested address #6\n                if retries:\n                    logging.error(\"Error connecting to graylog: {}. Retrying {} more times\".format(e, retries))\n                    retries -= 1\n                    time.sleep(30)\n                else:\n                    logging.error(\"Error connecting to graylog: {}. Giving up for this message: {}\".format(\n                        e, msg_string))\n                    self.unsuccessfully_sent += 1\n                    return\n            else:\n                break"
            ]
        ]
    },
    {
        "blob_id": "b7d9a62a9063131475db350a5126b1db69686109",
        "matched_blocks": [
            [
                29,
                39,
                "        try:\n            downloaded_file_name = await borg.download_media(\n                reply_message, Config.TMP_DOWNLOAD_DIRECTORY\n            )\n        except Exception as e:\n            await event.edit(str(e))\n            return\n        else:\n            await event.edit(\"sending to ReMove.BG\")\n            output_file_name = ReTrieveFile(downloaded_file_name)\n            os.remove(downloaded_file_name)"
            ]
        ]
    },
    {
        "blob_id": "a8e4ef9b084180f0b52f64f6f6095abcc3c4c3d1",
        "matched_blocks": [
            [
                20,
                25,
                "      try:\n        num = int(reply)\n      except:\n        print('Bad!' * 8)\n      else:\n        print(int(reply) ** 2)"
            ]
        ]
    },
    {
        "blob_id": "4ea7ca6c5ee15075612d8d24d97f7d8d407e1ee1",
        "matched_blocks": [
            [
                11,
                17,
                "    try:\n        now = parse(baddate['date'] + ' ' + baddate['time'])\n        sess = Session(start=now)\n    except ValueError:\n        assert True\n    else:\n        assert False"
            ],
            [
                21,
                27,
                "    try:\n        now = parse(badtime['date'] + ' ' + badtime['time'])\n        sess = Session(start=now)\n    except ValueError:\n        assert True\n    else:\n        assert False"
            ]
        ]
    },
    {
        "blob_id": "6fd5ae7f371e20f8828cbb898d54eb07bf1451cc",
        "matched_blocks": [
            [
                5,
                10,
                "    try:\n        lint_changelog(\"\\n# Changelog\")\n    except InputError as err:\n        assert err.args[0] == 2\n    else:\n        assert False"
            ],
            [
                12,
                17,
                "    try:\n        lint_changelog(\"# Changeog\")\n    except InputError as err:\n        assert err.args[0] == 1\n    else:\n        assert False"
            ],
            [
                21,
                35,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n## [Unreleased\n\n### Added\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 3\n    else:\n        assert False"
            ],
            [
                39,
                53,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n## [v0.1.1] - 2019-10-50\n\n### Added\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 3\n    else:\n        assert False"
            ],
            [
                57,
                75,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n## [Unreleased]\n\n### Fixed\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\n### Added\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 9\n    else:\n        assert False"
            ],
            [
                79,
                91,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n### Added\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 3\n    else:\n        assert False"
            ],
            [
                93,
                107,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n## [Unreleased]\n\n### Aded\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 5\n    else:\n        assert False"
            ],
            [
                109,
                121,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n##[Unreleased]\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 3\n    else:\n        assert False"
            ],
            [
                125,
                136,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n## [Unreleased]\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 3\n    else:\n        assert False"
            ],
            [
                138,
                149,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n## [Unreleased]\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 2\n    else:\n        assert False"
            ],
            [
                151,
                164,
                "    try:\n        lint_changelog(\n            \"\"\"# Changelog\n\n## [Unreleased]\n\n\n- Support for reStructuredText footnotes (DOCSP-6620).\n\"\"\"\n        )\n    except InputError as err:\n        assert err.args[0] == 5\n    else:\n        assert False"
            ]
        ]
    },
    {
        "blob_id": "3e5b12e35731eec884414abf42d2848f5c206574",
        "matched_blocks": [
            [
                14,
                24,
                "try:\n    namedModule(\"sphinxcontrib\")\n    namedModule(\"sphinx\")\n    namedModule(\"docutils\")\nexcept ImportError:\n    skip = \"Sphinx not installed.\"\nelse:\n    from sphinx.errors import SphinxError\n\n    from ..publicapi import (\n        Example, KleinRoute, getRoutes, _loadExamples, _formatExample, makeRst)"
            ]
        ]
    },
    {
        "blob_id": "d214632235dec77165de3d3a2b1e58512288f656",
        "matched_blocks": [
            [
                16,
                24,
                "        try:\n            await client.login(token)\n\n        except (discord.HTTPException, aiohttp.ClientError):\n            logging.exception(\"Discord.py trying to login...\")\n            await asyncio.sleep(retry.delay())\n\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "a3f2e4bb0795509a1989e00ee7a39cc5427dd76e",
        "matched_blocks": [
            [
                78,
                85,
                "                try:\n                    fullname = os.path.splitext(filename)[0] + ext\n                    image = Image.open(fullname)\n                except Exception:\n                    pass\n                else:\n                    if image and image.mode in (\"1\", \"L\"):\n                        break"
            ]
        ]
    },
    {
        "blob_id": "e8a66deaca4a86cd89f40a33e293daf79a905ad0",
        "matched_blocks": [
            [
                28,
                34,
                "    try:\n        data4, addr4 = sock4.recvfrom(100)\n    except BlockingIOError:\n        print(\"No data from ipv4\")\n    else:\n        print(data4.decode())\n        break"
            ],
            [
                36,
                42,
                "    try:\n        data6, addr6 = sock6.recvfrom(100)\n    except BlockingIOError:\n        print(\"No data from ipv6\")\n    else:\n        print(data6.decode())\n        break"
            ]
        ]
    },
    {
        "blob_id": "81ffdc08a595c22ea937ba79d969b3acb46d13d1",
        "matched_blocks": [
            [
                960,
                967,
                "            try:\n                yield pathset\n            except Exception:\n                if pathset is not None:\n                    pathset.rollback()\n            else:\n                if pathset is not None:\n                    pathset.commit()"
            ]
        ]
    },
    {
        "blob_id": "b55a7cde61f3fd3fbf8bac635ace888b98e55d6e",
        "matched_blocks": [
            [
                24,
                32,
                "        try:\n            inform_view_on_change = self.__inform_view_on_changes\n        except AttributeError:\n            # It's possible that the attribute was already collected when the itemChange happened\n            # (if it was triggered during the gc of the object).\n            pass\n        else:\n            if inform_view_on_change and change in [self.ItemPositionHasChanged, self.ItemTransformHasChanged]:\n                self.informViewBoundsChanged()"
            ]
        ]
    },
    {
        "blob_id": "a451e7f6d55784dc1c2e5f0f53537cc861388029",
        "matched_blocks": [
            [
                11,
                20,
                "    try:\n        # Create databases\n        r.db_create('platform').run()\n        # Create tables\n        r.db('platform').table_create('videos',\n                                      primary_key='video_id').run()\n    except Exception as e:\n        print('Database is already setup')\n    else:\n        print('Database setup successful')"
            ]
        ]
    },
    {
        "blob_id": "5d60feb8769d1485490b5ef335ee7b4911efa151",
        "matched_blocks": [
            [
                9,
                17,
                "        try:\n            list_vals , num_non_vals = moduleTasks.loadDataFrom(signalName, folderName)\n        except (OSError,ValueError):\n            d[signalName] = None\n        else:\n            if num_non_vals <= maxCount:\n                d[signalName] = list_vals\n            else:\n                d[signalName] = []"
            ],
            [
                25,
                42,
                "        try:\n            bound = moduleTasks.isBounded(v, bounds, threshold)\n        except ValueError:\n            pass\n        else:\n            if bound:\n                new_filename = k + \".txt\"\n                path_string = targetFolder + \"/\" + new_filename\n                with open(path_string,\"w\") as myFile:\n\n                    for val in v[:-1]:\n                        final_str = \"{:.3f}\\n\".format(val)\n                        myFile.write(final_str)\n\n                    final_str = \"{:.3f}\".format(v[-1])\n                    myFile.write(final_str)\n            else:\n                pass"
            ]
        ]
    },
    {
        "blob_id": "52105ccb751bec1915213401decb69f2b90eb15c",
        "matched_blocks": [
            [
                119,
                124,
                "    try:\n        hook._prepare_collections()\n    except InvalidCollectionConfiguration:\n        pass\n    else:\n        assert False, \"Invalid Collection Name did not raise error\""
            ]
        ]
    },
    {
        "blob_id": "b7935778e4af05b4794433f47991deced92fb943",
        "matched_blocks": [
            [
                8,
                17,
                "        try:\n            json_res = json.loads(response.content)\n        except ValueError:\n            if not response.content:\n                self.message = status_code\n            else:\n                self.message = 'Invalid JSON error message from Binance Chain: {}'.format(response.text)\n        else:\n            self.code = json_res.get('code', None)\n            self.message = json_res['message']"
            ],
            [
                41,
                47,
                "        try:\n            json_res = json.loads(response.content)\n        except ValueError:\n            self.message = 'Invalid JSON error message from Binance Chain: {}'.format(response.text)\n        else:\n            self.code = json_res['error']['code']\n            self.message = json_res['error']['message']"
            ]
        ]
    },
    {
        "blob_id": "442fad6be8023fcbb53d570c9b25f989f82ecd75",
        "matched_blocks": [
            [
                486,
                497,
                "            try:\n                resp = await client.fetch(self.hub_api_url)\n            except Exception:\n                self.log.exception(\n                    \"Failed to connect to my Hub at %s (attempt %i/%i). Is it running?\",\n                    self.hub_api_url,\n                    i,\n                    RETRIES,\n                )\n                await asyncio.sleep(min(2 ** i, 16))\n            else:\n                break"
            ],
            [
                575,
                581,
                "            try:\n                await client.fetch(req)\n            except Exception:\n                self.log.exception(\"Error notifying Hub of activity\")\n                return False\n            else:\n                return True"
            ]
        ]
    },
    {
        "blob_id": "d1597ffd8c87152ec49b9949a7de3ec827c5d1d4",
        "matched_blocks": [
            [
                33,
                43,
                "    try:\n        if not PY3min and sys.platform == 'win32':\n            path = os.path.expanduser(b\"~\").decode(sys.getfilesystemencoding())\n        else:\n            path = os.path.expanduser(\"~\")\n    except ImportError:\n        # This happens on Google App Engine (pwd module is not present).\n        pass\n    else:\n        if os.path.isdir(path):\n            return path"
            ],
            [
                1916,
                1923,
                "    try:\n        from PySide import __version__\n        from PySide import QtCore\n    except ImportError:\n        raise CheckFailed(\"PySide not found\")\n    else:\n        return (\"Qt: %s, PySide: %s\" %\n                (QtCore.__version__, __version__))"
            ],
            [
                1932,
                1938,
                "    try:\n        qt_version = QtCore.QT_VERSION\n        pyqt_version_str = QtCore.PYQT_VERSION_STR\n    except AttributeError:\n        raise CheckFailed('PyQt4 not correctly imported')\n    else:\n        return (\"Qt: %s, PyQt: %s\" % (self.convert_qt_version(qt_version), pyqt_version_str))"
            ],
            [
                1967,
                1974,
                "    try:\n        from PySide2 import __version__\n        from PySide2 import QtCore\n    except ImportError:\n        raise CheckFailed(\"PySide2 not found\")\n    else:\n        return (\"Qt: %s, PySide2: %s\" %\n                (QtCore.__version__, __version__))"
            ],
            [
                1982,
                1988,
                "    try:\n        qt_version = QtCore.QT_VERSION\n        pyqt_version_str = QtCore.PYQT_VERSION_STR\n    except AttributeError:\n        raise CheckFailed('PyQt5 not correctly imported')\n    else:\n        return (\"Qt: %s, PyQt: %s\" % (self.convert_qt_version(qt_version), pyqt_version_str))"
            ],
            [
                1529,
                1540,
                "        try:\n            import gtk\n        except ImportError:\n            raise CheckFailed(\"Requires pygtk\")\n        except RuntimeError:\n            raise CheckFailed('pygtk present, but import failed.')\n        else:\n            version = (2, 2, 0)\n            if gtk.pygtk_version < version:\n                raise CheckFailed(\n                    \"Requires pygtk %d.%d.%d or later. \"\n                    \"Found %d.%d.%d\" % (version + gtk.pygtk_version))"
            ],
            [
                1685,
                1700,
                "        try:\n            res = p.map_async(backend_gtk3agg_internal_check, [0])\n            success, msg = res.get(timeout=10)[0]\n        except multiprocessing.TimeoutError:\n            p.terminate()\n            # No result returned. Probaly hanging, terminate the process.\n            success = False\n            raise CheckFailed(\"Check timed out\")\n        except:\n            p.close()\n            # Some other error.\n            success = False\n            msg = \"Could not determine\"\n            raise\n        else:\n            p.close()"
            ],
            [
                1759,
                1772,
                "        try:\n            res = p.map_async(backend_gtk3cairo_internal_check, [0])\n            success, msg = res.get(timeout=10)[0]\n        except multiprocessing.TimeoutError:\n            p.terminate()\n            # No result returned. Probaly hanging, terminate the process.\n            success = False\n            raise CheckFailed(\"Check timed out\")\n        except:\n            p.close()\n            success = False\n            raise\n        else:\n            p.close()"
            ],
            [
                1879,
                1910,
                "        try:\n            p = multiprocessing.Pool()\n\n        except:\n            # Can't do multiprocessing, fall back to normal approach\n            # (this will fail if importing both PyQt4 and PyQt5).\n            try:\n                # Try in-process\n                msg = self.callback(self)\n            except RuntimeError:\n                raise CheckFailed(\n                    \"Could not import: are PyQt4 & PyQt5 both installed?\")\n\n        else:\n            # Multiprocessing OK\n            try:\n                res = p.map_async(self.callback, [self])\n                msg = res.get(timeout=10)[0]\n            except multiprocessing.TimeoutError:\n                p.terminate()\n                # No result returned. Probaly hanging, terminate the process.\n                raise CheckFailed(\"Check timed out\")\n            except:\n                # Some other error.\n                p.close()\n                raise\n            else:\n                # Clean exit\n                p.close()\n            finally:\n                # Tidy up multiprocessing\n                p.join()"
            ],
            [
                2019,
                2029,
                "        try:\n            import cairocffi\n        except ImportError:\n            try:\n                import cairo\n            except ImportError:\n                raise CheckFailed(\"cairocffi or pycairo not found\")\n            else:\n                return \"pycairo version %s\" % cairo.version\n        else:\n            return \"cairocffi version %s\" % cairocffi.version"
            ],
            [
                378,
                389,
                "            try:\n                output = check_output(command, shell=True,\n                                      stderr=subprocess.STDOUT)\n            except subprocess.CalledProcessError:\n                pass\n            else:\n                output = output.decode(sys.getfilesystemencoding())\n                use_defaults = False\n                for token in output.split():\n                    attr = flag_map.get(token[:2])\n                    if attr is not None:\n                        getattr(ext, attr).insert(0, token[2:])"
            ],
            [
                1894,
                1907,
                "            try:\n                res = p.map_async(self.callback, [self])\n                msg = res.get(timeout=10)[0]\n            except multiprocessing.TimeoutError:\n                p.terminate()\n                # No result returned. Probaly hanging, terminate the process.\n                raise CheckFailed(\"Check timed out\")\n            except:\n                # Some other error.\n                p.close()\n                raise\n            else:\n                # Clean exit\n                p.close()"
            ],
            [
                2022,
                2027,
                "            try:\n                import cairo\n            except ImportError:\n                raise CheckFailed(\"cairocffi or pycairo not found\")\n            else:\n                return \"pycairo version %s\" % cairo.version"
            ],
            [
                1203,
                1211,
                "                    try:\n                        urlretrieve(tarball_url, tarball_path)\n                    except IOError:  # URLError (a subclass) on Py3.\n                        print(\"Failed to download {0}\".format(tarball_url))\n                    else:\n                        if get_file_hash(tarball_path) != LOCAL_FREETYPE_HASH:\n                            print(\"Invalid hash.\")\n                        else:\n                            break"
            ]
        ]
    },
    {
        "blob_id": "effb3ee7b4162231d120df597dc22d67af06d86a",
        "matched_blocks": [
            [
                42,
                59,
                "    try:\n        os.getcwd()\n       #\u521b\u5efa\u4e00\u4e2acss\u7684\u540c\u540d\u6587\u4ef6\u5939\n        os.mkdir('css')\n      #\u5207\u6362\u5230css\u6587\u4ef6\u5939\uff0c\u4e5f\u5c31\u662f\u6539\u53d8\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u5c06\u8981\u4e0b\u8f7d\u7684\u6587\u4ef6\u4e0b\u8f7d\u5230\u8fd9\u4e2a\u6587\u4ef6\u5939\n        os.chdir('css')\n       #\u904d\u5386\u521a\u624d\u8fd4\u56de\u7684\u6587\u4ef6\u540d\u5217\u8868\n        for FILE in downloadlist:\n            f.retrbinary('RETR %s' % FILE,open(FILE,'wb').write)\n            \n            print('\u6587\u4ef6\"%s\"\u4e0b\u8f7d\u6210\u529f' % FILE)\n    except ftplib.error_perm:\n        print('\u65e0\u6cd5\u8bfb\u53d6\"%s\"' % FILE)\n        os.unlink(FILE)\n    else:\n        print('\u6587\u4ef6\u5168\u90e8\u4e0b\u8f7d\u5b8c\u6bd5\uff01')\n        f.quit()\n        return"
            ]
        ]
    },
    {
        "blob_id": "e818bc7a318cc3ddf9fc9ed347ef379a052b40dd",
        "matched_blocks": [
            [
                270,
                336,
                "    try:\n        logger.debug(f\"{handler} is invoked.\")\n\n        if handler.timeout is not None and state.runtime.total_seconds() >= handler.timeout:\n            raise HandlerTimeoutError(f\"{handler} has timed out after {state.runtime}.\")\n\n        if handler.retries is not None and state.retries >= handler.retries:\n            raise HandlerRetriesError(f\"{handler} has exceeded {state.retries} retries.\")\n\n        result = await invoke_handler(\n            handler=handler,\n            cause=cause,\n            retry=state.retries,\n            started=state.started or datetime.datetime.utcnow(),  # \"or\" is for type-checking.\n            runtime=state.runtime,\n            settings=settings,\n            lifecycle=lifecycle,  # just a default for the sub-handlers, not used directly.\n            extra_context=extra_context,\n            subrefs=subrefs,\n        )\n\n    # The cancellations are an excepted way of stopping the handler. Especially for daemons.\n    except asyncio.CancelledError:\n        logger.warning(f\"{handler} is cancelled. Will escalate.\")\n        raise\n\n    # Unfinished children cause the regular retry, but with less logging and event reporting.\n    except HandlerChildrenRetry as e:\n        logger.debug(f\"{handler} has unfinished sub-handlers. Will retry soon.\")\n        return Outcome(final=False, exception=e, delay=e.delay, subrefs=subrefs)\n\n    # Definitely a temporary error, regardless of the error strictness.\n    except TemporaryError as e:\n        logger.error(f\"{handler} failed temporarily: {str(e) or repr(e)}\")\n        return Outcome(final=False, exception=e, delay=e.delay, subrefs=subrefs)\n\n    # Same as permanent errors below, but with better logging for our internal cases.\n    except HandlerTimeoutError as e:\n        logger.error(f\"{str(e) or repr(e)}\")  # already formatted\n        return Outcome(final=True, exception=e, subrefs=subrefs)\n        # TODO: report the handling failure somehow (beside logs/events). persistent status?\n\n    # Definitely a permanent error, regardless of the error strictness.\n    except PermanentError as e:\n        logger.error(f\"{handler} failed permanently: {str(e) or repr(e)}\")\n        return Outcome(final=True, exception=e, subrefs=subrefs)\n        # TODO: report the handling failure somehow (beside logs/events). persistent status?\n\n    # Regular errors behave as either temporary or permanent depending on the error strictness.\n    except Exception as e:\n        if errors_mode == ErrorsMode.IGNORED:\n            logger.exception(f\"{handler} failed with an exception. Will ignore.\")\n            return Outcome(final=True, subrefs=subrefs)\n        elif errors_mode == ErrorsMode.TEMPORARY:\n            logger.exception(f\"{handler} failed with an exception. Will retry.\")\n            return Outcome(final=False, exception=e, delay=backoff, subrefs=subrefs)\n        elif errors_mode == ErrorsMode.PERMANENT:\n            logger.exception(f\"{handler} failed with an exception. Will stop.\")\n            return Outcome(final=True, exception=e, subrefs=subrefs)\n            # TODO: report the handling failure somehow (beside logs/events). persistent status?\n        else:\n            raise RuntimeError(f\"Unknown mode for errors: {errors_mode!r}\")\n\n    # No errors means the handler should be excluded from future runs in this reaction cycle.\n    else:\n        logger.info(f\"{handler} succeeded.\")\n        return Outcome(final=True, result=result, subrefs=subrefs)"
            ]
        ]
    },
    {
        "blob_id": "6482e4a85461ebb87d38041a954fc23f5bc83bf5",
        "matched_blocks": [
            [
                2508,
                2513,
                "        try:\n            _distr3_gen(name='dummy')\n        except TypeError:\n            pass\n        else:\n            raise AssertionError('TypeError not raised.')"
            ]
        ]
    },
    {
        "blob_id": "8196a6d153f61f9ad7d3d169b3850fb382e2b167",
        "matched_blocks": [
            [
                147,
                153,
                "        try:  # faker isn't a prod requirement\n            from faker import Factory\n        except ImportError:\n            pass\n        else:\n            fake = Factory.create()\n            ret['fake'] = fake"
            ]
        ]
    },
    {
        "blob_id": "419b6c02dcf9186aa633d2437aefac974a53e4c2",
        "matched_blocks": [
            [
                512,
                521,
                "                try:\n                    crt_local, = glob(join(\"deploy\", \"*.crt\"))\n                    key_local, = glob(join(\"deploy\", \"*.key\"))\n                except ValueError:\n                    parts = (crt_file, key_file, env.domains[0])\n                    sudo(\"openssl req -new -x509 -nodes -out %s -keyout %s \"\n                         \"-subj '/CN=%s' -days 3650\" % parts)\n                else:\n                    upload_template(crt_local, crt_file, use_sudo=True)\n                    upload_template(key_local, key_file, use_sudo=True)"
            ]
        ]
    },
    {
        "blob_id": "b9ad69bdbf385d46340fc239c009c33b974daad4",
        "matched_blocks": [
            [
                732,
                739,
                "        try:\n            output = side.output_field\n        except FieldError:\n            pass\n        else:\n            if output.get_internal_type() == \"DurationField\":\n                sql, params = compiler.compile(side)\n                return connection.ops.format_for_duration_arithmetic(sql), params"
            ],
            [
                762,
                777,
                "            try:\n                lhs_type = self.lhs.output_field.get_internal_type()\n                rhs_type = self.rhs.output_field.get_internal_type()\n            except (AttributeError, FieldError):\n                pass\n            else:\n                allowed_fields = {\n                    \"DecimalField\",\n                    \"DurationField\",\n                    \"FloatField\",\n                    \"IntegerField\",\n                }\n                if lhs_type not in allowed_fields or rhs_type not in allowed_fields:\n                    raise DatabaseError(\n                        f\"Invalid arguments for operator {self.connector}.\"\n                    )"
            ]
        ]
    },
    {
        "blob_id": "e5ff8e07720becd3b30394b879b0f3f773c9351f",
        "matched_blocks": [
            [
                105,
                110,
                "        try:\n            prop = getattr(type(self), name)\n        except AttributeError:\n            log.exception(f\"'{type(self).__name__}' has no property '{name}'\")\n        else:\n            prop.load(self, value)"
            ]
        ]
    },
    {
        "blob_id": "323ec850c34bcc51687b6833ac475f05d6a343e0",
        "matched_blocks": [
            [
                28,
                38,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except(KeyError, Choice.DoesNotExist):\n        return render(request, 'polls/detail.html', {\n            'question':question,\n            'error_message':\"You didn't select a choice\",\n        })\n    else:\n        selected_choice.votes+=1\n        selected_choice.save()\n        return HttpResponseRedirect(reverse('polls:results',args=(question.id, )))"
            ]
        ]
    },
    {
        "blob_id": "e545e4f7cc77d47ff77977212d086de1004b5695",
        "matched_blocks": [
            [
                510,
                657,
                "        try:\n            p2pkhTransaction = True\n            derivations = self.get_tx_derivations(tx)\n            inputhasharray = []\n            hasharray = []\n            pubkeyarray = []\n\n            # Build hasharray from inputs\n            for i, txin in enumerate(tx.inputs()):\n                if txin['type'] == 'coinbase':\n                    self.give_error(\"Coinbase not supported\") # should never happen\n\n                if txin['type'] != 'p2pkh':\n                    p2pkhTransaction = False\n\n                for x_pubkey in txin['x_pubkeys']:\n                    if x_pubkey in derivations:\n                        index = derivations.get(x_pubkey)\n                        inputPath = \"%s/%d/%d\" % (self.get_derivation(), index[0], index[1])\n                        inputHash = sha256d(binascii.unhexlify(tx.serialize_preimage(i)))\n                        hasharray_i = {'hash': to_hexstr(inputHash), 'keypath': inputPath}\n                        hasharray.append(hasharray_i)\n                        inputhasharray.append(inputHash)\n                        break\n                else:\n                    self.give_error(\"No matching x_key for sign_transaction\") # should never happen\n\n            # Build pubkeyarray from outputs\n            for o in tx.outputs():\n                assert o.type == TYPE_ADDRESS\n                info = tx.output_info.get(o.address)\n                if info is not None:\n                    index = info.address_index\n                    changePath = self.get_derivation() + \"/%d/%d\" % index\n                    changePubkey = self.derive_pubkey(index[0], index[1])\n                    pubkeyarray_i = {'pubkey': changePubkey, 'keypath': changePath}\n                    pubkeyarray.append(pubkeyarray_i)\n\n            # Special serialization of the unsigned transaction for\n            # the mobile verification app.\n            # At the moment, verification only works for p2pkh transactions.\n            if p2pkhTransaction:\n                class CustomTXSerialization(Transaction):\n                    @classmethod\n                    def input_script(self, txin, estimate_size=False):\n                        if txin['type'] == 'p2pkh':\n                            return Transaction.get_preimage_script(txin)\n                        if txin['type'] == 'p2sh':\n                            # Multisig verification has partial support, but is disabled. This is the\n                            # expected serialization though, so we leave it here until we activate it.\n                            return '00' + push_script(Transaction.get_preimage_script(txin))\n                        raise Exception(\"unsupported type %s\" % txin['type'])\n                tx_dbb_serialized = CustomTXSerialization(tx.serialize()).serialize_to_network()\n            else:\n                # We only need this for the signing echo / verification.\n                tx_dbb_serialized = None\n\n            # Build sign command\n            dbb_signatures = []\n            steps = math.ceil(1.0 * len(hasharray) / self.maxInputs)\n            for step in range(int(steps)):\n                hashes = hasharray[step * self.maxInputs : (step + 1) * self.maxInputs]\n\n                msg = {\n                    \"sign\": {\n                        \"data\": hashes,\n                        \"checkpub\": pubkeyarray,\n                    },\n                }\n                if tx_dbb_serialized is not None:\n                    msg[\"sign\"][\"meta\"] = to_hexstr(sha256d(tx_dbb_serialized))\n                msg = json.dumps(msg).encode('ascii')\n                dbb_client = self.plugin.get_client(self)\n\n                if not dbb_client.is_paired():\n                    raise Exception(\"Could not sign transaction.\")\n\n                reply = dbb_client.hid_send_encrypt(msg)\n                if 'error' in reply:\n                    raise Exception(reply['error']['message'])\n\n                if 'echo' not in reply:\n                    raise Exception(\"Could not sign transaction.\")\n\n                if self.plugin.is_mobile_paired() and tx_dbb_serialized is not None:\n                    reply['tx'] = tx_dbb_serialized\n                    self.plugin.comserver_post_notification(reply)\n\n                if steps > 1:\n                    self.handler.show_message(_(\"Signing large transaction. Please be patient ...\") + \"\\n\\n\" +\n                                              _(\"To continue, touch the Digital Bitbox's blinking light for 3 seconds.\") + \" \" +\n                                              _(\"(Touch {} of {})\").format((step + 1), steps) + \"\\n\\n\" +\n                                              _(\"To cancel, briefly touch the blinking light or wait for the timeout.\") + \"\\n\\n\")\n                else:\n                    self.handler.show_message(_(\"Signing transaction...\") + \"\\n\\n\" +\n                                              _(\"To continue, touch the Digital Bitbox's blinking light for 3 seconds.\") + \"\\n\\n\" +\n                                              _(\"To cancel, briefly touch the blinking light or wait for the timeout.\"))\n\n                # Send twice, first returns an echo for smart verification\n                reply = dbb_client.hid_send_encrypt(msg)\n                self.handler.finished()\n\n                if 'error' in reply:\n                    if reply[\"error\"].get('code') in (600, 601):\n                        # aborted via LED short touch or timeout\n                        raise UserCancelled()\n                    raise Exception(reply['error']['message'])\n\n                if 'sign' not in reply:\n                    raise Exception(\"Could not sign transaction.\")\n\n                dbb_signatures.extend(reply['sign'])\n\n            # Fill signatures\n            if len(dbb_signatures) != len(tx.inputs()):\n                raise Exception(\"Incorrect number of transactions signed.\") # Should never occur\n            for i, txin in enumerate(tx.inputs()):\n                num = txin['num_sig']\n                for pubkey in txin['pubkeys']:\n                    signatures = list(filter(None, txin['signatures']))\n                    if len(signatures) == num:\n                        break # txin is complete\n                    ii = txin['pubkeys'].index(pubkey)\n                    signed = dbb_signatures[i]\n                    if 'recid' in signed:\n                        # firmware > v2.1.1\n                        recid = int(signed['recid'], 16)\n                        s = binascii.unhexlify(signed['sig'])\n                        h = inputhasharray[i]\n                        pk = ecc.ECPubkey.from_sig_string(s, recid, h)\n                        pk = pk.get_public_key_hex(compressed=True)\n                    elif 'pubkey' in signed:\n                        # firmware <= v2.1.1\n                        pk = signed['pubkey']\n                    if pk != pubkey:\n                        continue\n                    sig_r = int(signed['sig'][:64], 16)\n                    sig_s = int(signed['sig'][64:], 16)\n                    sig = ecc.der_sig_from_r_and_s(sig_r, sig_s)\n                    sig = to_hexstr(sig) + '01'\n                    tx.add_signature_to_txin(i, ii, sig)\n        except UserCancelled:\n            raise\n        except BaseException as e:\n            self.give_error(e, True)\n        else:\n            print_error(\"Transaction is_complete\", tx.is_complete())\n            tx.raw = tx.serialize()"
            ]
        ]
    },
    {
        "blob_id": "58c7af9907e90657db990a4e460eb35ea902d102",
        "matched_blocks": [
            [
                135,
                149,
                "            try:\n                client, response = check(\n                    request,\n                    quiet=True, returnResponse=True\n                )\n            except (HTTPBadRequest, HTTPForbidden) as e:        # 400, 403 error\n                get_error_message(e) | expect.any(\n                    should.start_with('may not be empty'),\n                    should.start_with('Invalid page parameter specified'),\n                    should.contain('Invalid Authorization Token')\n                )\n            else:\n                raise Exception(\n                    \"Expected error message, got {} status code instead.\".format(\n                        response.status_code))"
            ]
        ]
    },
    {
        "blob_id": "877343d781a764411b317db919dd9c0f701410dc",
        "matched_blocks": [
            [
                2091,
                2118,
                "    try:\n        beta = float(window)\n    except (TypeError, ValueError):\n        args = ()\n        if isinstance(window, tuple):\n            winstr = window[0]\n            if len(window) > 1:\n                args = window[1:]\n        elif isinstance(window, str):\n            if window in _needs_param:\n                raise ValueError(\n                    \"The '\" + window + \"' window needs one or \"\n                    \"more parameters -- pass a tuple.\"\n                )\n            else:\n                winstr = window\n        else:\n            raise ValueError(\"%s as window type is not supported.\" % str(type(window)))\n\n        try:\n            winfunc = _win_equiv[winstr]\n        except KeyError:\n            raise ValueError(\"Unknown window type.\")\n\n        params = (Nx,) + args + (sym,)\n    else:\n        winfunc = kaiser\n        params = (Nx, beta, sym)"
            ]
        ]
    },
    {
        "blob_id": "25dbb752fd770ca7129476e4ebc8d3a1657c5c7c",
        "matched_blocks": [
            [
                77,
                86,
                "        try:\n            cursor = self.con.cursor()\n            cursor.execute(\"INSERT INTO {0} ({1}) VALUES (?)\".format(table, column), (value,))\n        except sqlite3.Error as e:\n            self.logger.error('Failed to insert \"%s\" into accounting database %s table. Error: %s',\n                              value, table, str(e))\n            return None\n        else:\n            self.con.commit()\n            return cursor.lastrowid"
            ],
            [
                118,
                133,
                "        try:\n            cur = self.con.cursor()\n            cur.execute(\"INSERT OR IGNORE INTO UsageRecords VALUES (?,?,?,?,?,?,?,?,?,?,?)\",\n                        (ur['RecordId'], ur['RecordType'], ur['StartTime'], ur['EndTime'],\n                         ur['WallTime'], ur['CpuTime'], ur['Processors'],\n                         ur['JobName'], ur['JobID'], ur['Owner'], ur['OwnerVO']))\n        except sqlite3.Error as e:\n            self.logger.error('Failed to insert \"%s\" record into accounting database. Error: %s',\n                              ur['RecordId'], str(e))\n            return False\n        else:\n            self.con.commit()\n            if not cur.rowcount:\n                self.logger.warning('Record \"%s\" is already exists in accounting database (insert ignored).',\n                                    ur['RecordId'])\n            return True"
            ]
        ]
    },
    {
        "blob_id": "3baa5490caeaee6f4b3444ff8bdbe2023f78f045",
        "matched_blocks": [
            [
                3165,
                3192,
                "    try:\n        nn = n[mask]\n    except TypeError:\n        # TypeError: only integer scalar arrays can be converted to a scalar index\n        pass\n    else:\n        # make sure that we have a nullable type\n        # if we have nulls\n        if not _isna_compat(v, nn[0]):\n            pass\n        elif not (is_float_dtype(nn.dtype) or is_integer_dtype(nn.dtype)):\n            # only compare integers/floats\n            pass\n        elif not (is_float_dtype(v.dtype) or is_integer_dtype(v.dtype)):\n            # only compare integers/floats\n            pass\n        else:\n\n            # we ignore ComplexWarning here\n            with warnings.catch_warnings(record=True):\n                warnings.simplefilter(\"ignore\", np.ComplexWarning)\n                nn_at = nn.astype(v.dtype)\n\n            comp = nn == nn_at\n            if is_list_like(comp) and comp.all():\n                nv = v.copy()\n                nv[mask] = nn_at\n                return nv"
            ]
        ]
    },
    {
        "blob_id": "e6ee58c3908afd7b80ba87d31854d697a226f745",
        "matched_blocks": [
            [
                91,
                100,
                "        try:\n            _, status_code, _ = client.delete_repository_with_http_info(project_name, repo_name)\n        except Exception as e:\n            base._assert_status_code(expect_status_code, e.status)\n            if expect_response_body is not None:\n                base._assert_status_body(expect_response_body, e.body)\n            return\n        else:\n            base._assert_status_code(expect_status_code, status_code)\n            base._assert_status_code(200, status_code)"
            ]
        ]
    },
    {
        "blob_id": "784e7a40abe66b769c8b6ffca8fcf4ff447532c1",
        "matched_blocks": [
            [
                233,
                244,
                "        try:\n            device_info = _get_virtual_machine_info(\n                ssh,\n                vmid,\n                master_ip_address,\n                storages,\n                hypervisor_ip_address,\n            )\n        except NoLanError as e:\n            logger.warning(unicode(e))\n        else:\n            detected_machines.append(device_info)"
            ],
            [
                300,
                309,
                "        try:\n            device_info = _ssh_proxmox(ip_address, user, password)\n        except (ConnectionError, NoMatchError) as e:\n            result['status'] = 'error'\n            messages.append(unicode(e))\n        else:\n            result.update({\n                'status': 'success',\n                'device': device_info,\n            })"
            ]
        ]
    },
    {
        "blob_id": "37772295d6806cbdf230e844be853091aca78884",
        "matched_blocks": [
            [
                114,
                130,
                "    try:\n        client_version = client.web3.version.node\n    except (requests.exceptions.ConnectionError, EthNodeCommunicationError):\n        print(\n            '\\n'\n            'Could not contact the ethereum node through JSON-RPC.\\n'\n            'Please make sure that JSON-RPC is enabled for these interfaces:\\n'\n            '\\n'\n            '    eth_*, net_*, web3_*\\n'\n            '\\n'\n            'geth: https://github.com/ethereum/go-ethereum/wiki/Management-APIs\\n'\n        )\n        sys.exit(1)\n    else:\n        if not is_supported_client(client_version):\n            print('You need a Byzantium enabled ethereum node. Parity >= 1.7.6 or Geth >= 1.7.2')\n            sys.exit(1)"
            ],
            [
                183,
                188,
                "        try:\n            etherscan_block = quantity_decoder(requests.get(url).json()['result'])\n        except (RequestException, ValueError, KeyError):\n            gevent.sleep(sleep)\n        else:\n            return etherscan_block"
            ]
        ]
    },
    {
        "blob_id": "4f7ae60a8596d2b441a4ff0da86b405f6c80aba6",
        "matched_blocks": [
            [
                355,
                361,
                "    try:\n      parsed_value = parser(value) if parser else value\n    except ArgumentTypeError:\n      pass\n    else:\n      if fn(parsed_value):\n        return parsed_value"
            ]
        ]
    },
    {
        "blob_id": "6f5739437c1132e3e559ac5dced0ee9060cff126",
        "matched_blocks": [
            [
                170,
                176,
                "            try:\n                future.result()\n                obj = self.kvstore.get(alert_type)\n            except Exception as exc:\n                self.log.error(f'''Alert Type: {alert_type} thread generated an exception: {exc}''', exc_info=True)\n            else:\n                self.log.info(f'''Alert Type: {alert_type} thread completed {obj}''')"
            ]
        ]
    },
    {
        "blob_id": "d319a777775a0ffe11718c976c9346769e3aa48d",
        "matched_blocks": [
            [
                321,
                327,
                "            try:\n                for attr in path[1:-1]:\n                    obj = getattr(obj, attr)\n            except AttributeError:\n                ns = []\n            else:\n                ns = dir(obj)"
            ]
        ]
    },
    {
        "blob_id": "ca7121f0cb13794ff8f00a7bfaefb4c28de1c5ef",
        "matched_blocks": [
            [
                1885,
                1892,
                "        try:\n            output = subprocess.check_output(['svnversion'], cwd=path)\n        except (subprocess.CalledProcessError, OSError):\n            pass\n        else:\n            m = re.match(rb'(?P<revision>\\d+)', output)\n            if m:\n                return int(m.group('revision'))"
            ],
            [
                1914,
                1922,
                "        try:\n            output = subprocess.check_output(\n                ['hg', 'identify', '--num'], cwd=path)\n        except (subprocess.CalledProcessError, OSError):\n            pass\n        else:\n            m = re.match(rb'(?P<revision>\\d+)', output)\n            if m:\n                return int(m.group('revision'))"
            ]
        ]
    },
    {
        "blob_id": "35735a0f868b7b08da72f3eb034598d7ec4f2e66",
        "matched_blocks": [
            [
                13,
                30,
                "    try:\n        conn = psycopg2.connect(\"dbname='uo_db2' user='alex_korentsvit' host='localhost' password='qwerty'\")\n    except:\n        print (\"I am unable to connect to the database\")\n    else:\n        print('successfully connected to the database')\n        cur = conn.cursor()\n        cur.execute(\"SELECT id, EDRPOU_code, Name, State FROM UO_TABLE\")\n        counter = 0\n        for record in cur:\n            data.append(record)\n            counter += 1\n            if counter == 500:\n                break\n                            \n        return render_template('Table_LE.html',\n                               title = 'Table',\n                               data = data)"
            ]
        ]
    },
    {
        "blob_id": "912c36ec729b749cdf5a01caf4cd29055cf3f717",
        "matched_blocks": [
            [
                27,
                39,
                "    try:\n        file = open(user_input_txt_path, \"r\")\n    except FileNotFoundError:\n        logging.error(f\"\\nCan't find the file': '{user_input}'\\nFull Path: '{user_input_txt_path}'\\nExiting.\")\n        sys.exit(FileNotFoundError)\n    except IOError:\n        logging.error(f\"\\nDoesn't look like you can open the file: '{user_input}'\\nFull Path: '{user_input_txt_path}'\\nExiting.\")\n        sys.exit(IOError)\n    else:\n        line = file.readline()\n        scale, weights = re.findall(r'\"(.*?)\"', line)\n        file.close()\n        return scale, weights"
            ],
            [
                74,
                82,
                "        try:\n            to_int = int(value)\n            if to_int < 0: raise ValueError\n        except ValueError:\n            logging.error(\n                f\"Unable to convert {type} value {value} to non-negative integer.\\nFull {type} values were {list_of_strings}\")\n            sys.exit(ValueError)\n        else:\n            result.append(int(value))"
            ]
        ]
    },
    {
        "blob_id": "e0c8c4c0b7a047572396c6c0991544d737272059",
        "matched_blocks": [
            [
                311,
                323,
                "            try:\n                sent = self._socket.send(next_msg)\n            except socket.error as err:\n                if (err.args[0] in NONBLOCKING):\n                    with self._deque_lock:\n                        self.deque.appendleft(next_msg)\n                else:\n                    self.defunct(err)\n                return\n            else:\n                if sent < len(next_msg):\n                    with self._deque_lock:\n                        self.deque.appendleft(next_msg[sent:])"
            ]
        ]
    },
    {
        "blob_id": "722ef07c55d107ae6b86b0b0ec8322d13ff12b06",
        "matched_blocks": [
            [
                5905,
                5928,
                "            try:\n                name = self._parse_nested_name(memberPointer=True)\n                self.skip_ws()\n                if not self.skip_string('*'):\n                    self.fail(\"Expected '*' in pointer to member declarator.\")\n                self.skip_ws()\n            except DefinitionError as e:\n                self.pos = pos\n                prevErrors.append((e, \"If pointer to member declarator\"))\n            else:\n                volatile = False\n                const = False\n                while 1:\n                    if not volatile:\n                        volatile = self.skip_word_and_ws('volatile')\n                        if volatile:\n                            continue\n                    if not const:\n                        const = self.skip_word_and_ws('const')\n                        if const:\n                            continue\n                    break\n                next = self._parse_declarator(named, paramMode, typed)\n                return ASTDeclaratorMemPtr(name, const, volatile, next=next)"
            ]
        ]
    },
    {
        "blob_id": "31672d8e2de23f5693ee5779bd4d8596a757726c",
        "matched_blocks": [
            [
                1132,
                1142,
                "        try:\n            call_subprocess(\n                args,\n                show_stdout=show_stdout,\n                extra_ok_returncodes=extra_ok_returncodes,\n                spinner=spinner,\n            )\n        except Exception as exc:\n            exc_type = type(exc)\n        else:\n            exc_type = None"
            ]
        ]
    },
    {
        "blob_id": "9ec1e3c261193a232d7e2a9c5348f74283e9ee2d",
        "matched_blocks": [
            [
                9,
                14,
                "    try:\n        r = requests.get(url)\n    except:\n        return ''\n    else:\n        return r.text"
            ]
        ]
    },
    {
        "blob_id": "69de345e3e9229d4e043d6f0a1f030e386f82eae",
        "matched_blocks": [
            [
                103,
                109,
                "    try:\n        cmd.run()\n    except CompileError:\n        return False\n    else:\n        fullPath = os.path.join(cmd.build_lib, cmd.get_ext_filename(\"bitmsghash\"))\n        return os.path.isfile(fullPath)"
            ]
        ]
    },
    {
        "blob_id": "cd9815be7c9cc8ccdc4c8d46f182389f7124895a",
        "matched_blocks": [
            [
                11,
                16,
                "        try:\n            WebDriverWait(self.driver, 10).until(EC.visibility_of_element_located(GoodsLibLocations.exit_link))\n        except:\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "e366dc33075d4ee9d91f47385c5bf027c89992fb",
        "matched_blocks": [
            [
                258,
                269,
                "    try:\n        url = config.dumpstr_base_url\n    except AttributeError:\n        d = Dumpstr(\"\")\n        def error(*args, **kwargs):\n            raise Exception(\n                \"You did not set your dumpstr_base_url \"\n                \"in localconfig.py, so you can't upload reports.\")\n        d.upload_report = error\n        return d\n    else:\n        return Dumpstr(url)"
            ]
        ]
    },
    {
        "blob_id": "b27ed7531c256460e07f7316d031b380db5cb555",
        "matched_blocks": [
            [
                100,
                127,
                "        try:\n            logger.debug(\"Lock cache file.\")\n            fcntl.flock(fp, fcntl.LOCK_EX | fcntl.LOCK_NB)\n        except IOError as error:\n            if error.errno != 11:\n                raise\n            logger.debug(\"Cache file is locked.\")\n            retry = True\n        else:\n            if file_exists:\n                logger.debug(\"Read cache from existing file.\")\n                cache.load_json(fp)\n                if cache.expired(expire_time):\n                    logger.debug(\"Cache expired, do check.\")\n                    cache.master = master_check()\n                    cache.set_now()\n                    logger.debug(\"Write cache to existing file.\")\n                    fp.seek(0)\n                    cache.safe_json(fp)\n                    fp.truncate()\n                else:\n                    logger.debug(\"Cache not expired.\")\n            else:\n                logger.debug(\"Do check.\")\n                cache.master = master_check()\n                cache.set_now()\n                logger.debug(\"Write cache to new file.\")\n                cache.safe_json(fp)"
            ]
        ]
    },
    {
        "blob_id": "7a078ba6c584589e621dc961a42158f02278319b",
        "matched_blocks": [
            [
                28,
                33,
                "try:\n    PATH.find(\"assistant/android/\")\nexcept:\n    RESOURCE_PATH = \"../resource/\"\nelse:\n    RESOURCE_PATH = \"assistant/resource/\""
            ]
        ]
    },
    {
        "blob_id": "aa7bb21486b531494255928b0bfdcbb6bea15b79",
        "matched_blocks": [
            [
                57,
                62,
                "            try:\n                _ = self.__getattribute__(c)\n            except ObjectDoesNotExist:\n                pass\n            else:\n                return c.capitalize()"
            ],
            [
                112,
                117,
                "            try:\n                _ = self.__getattribute__(c)\n            except ObjectDoesNotExist:\n                pass\n            else:\n                return c.capitalize()"
            ]
        ]
    },
    {
        "blob_id": "c7d459ad4d1f4fb67a30e1e253fbb2b2895f54b7",
        "matched_blocks": [
            [
                125,
                133,
                "    try:\n        yield\n    except exc_class as exc:\n        if isinstance(msg, basestring):\n            eq_(str(exc), msg)\n        elif msg is not None:\n            msg.search(str(exc))\n    else:\n        raise AssertionError('%s not raised' % exc_class.__name__)"
            ]
        ]
    },
    {
        "blob_id": "f35fa005b2b679e759f83c8c1abaa1ee213bf401",
        "matched_blocks": [
            [
                28,
                44,
                "        try:\n            resultado = a / b\n        # except ZeroDivisionError as e --> Esta manera solo atrapara Division / 0 y la de Typo NO\n        except ZeroDivisionError as e:\n            print(\"Ocurrio un error atrapado por ZeroDivisionError\", e)\n            print(type(e))\n        except TypeError as e:\n            print(\"Ocurrio un error atrapado por Type Error\", e)\n            print(type(e))\n        except ValueError as e:\n            print(\"Ocurrio un error atrapado por Value Error\", e)\n            print(type(e))\n        except Exception as e:\n            print(\"Ocurrio un error atrapado por Exception Gral\", e)\n            print(type(e))\n        else:\n            print(\"No se presento ninguna exception\")"
            ]
        ]
    },
    {
        "blob_id": "1073d9a157fb985c0ec1d8bf290c3d49288e07e5",
        "matched_blocks": [
            [
                137,
                159,
                "        try:\n            self.question = next(self.questions_i)\n        except StopIteration:\n            bad_answers = ''\n            for q,a in self.bad_answers.items():\n                # ', '.join(...) because key:value - tuples\n                bad_answers += '{} - {} >> {}\\n'.format(\n                    ', '.join(q), \n                    a, \n                    ', '.join(self.qa_dict[q])\n                )\n            result_text = '\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b:\\n{} \u0438\u0437 {}\\n\\n{}'.format(\n                self.length - len(self.bad_answers),\n                self.length,\n                bad_answers\n            )\n            self._on_exit(result_text)\n        else:\n            self.display = self.pattern.format(\n                self.info,\n                # if there are more than one questions\n                random.choice(self.question)\n            )"
            ],
            [
                173,
                182,
                "        try:\n            self.question = next(self.questions_i)\n        except StopIteration:\n            self._on_exit('\u041d\u0435\u0442 \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u044b\u0445 \u0432\u043e\u043f\u0440\u043e\u0441\u043e\u0432!')\n        else:\n            self.display = self.pattern.format(\n                self.info,\n                # if there are several question options\n                random.choice(self.question)\n            )"
            ],
            [
                249,
                266,
                "        try:\n            if len(answer_text) == 0:\n                raise ValueError()\n            for index in re.split('\\s+', answer_text):\n                index = int(index.strip())\n                if index < 1 or index > len(self._cur_answer_list):\n                    raise ValueError()\n                cur_answers.append(self._cur_answer_list[index - 1])\n        except ValueError:\n            error = True\n        else:\n            self._answers.append(cur_answers)\n            self._counter += 1\n            if self._counter == len(self._data):\n                self._display_result()\n                return\n  \n            self._cur_answer_list = self._prepare_question()"
            ]
        ]
    },
    {
        "blob_id": "057960e15bf592de3eaac0311f6e861f90dda900",
        "matched_blocks": [
            [
                82,
                94,
                "    try:\n        frame = get_frame(ser)\n    except Exception as e:\n        print('get frame got exception: {}'.format(e.message))\n    else:\n        if not valid_frame_checksum(frame):\n            print('frame checksum mismatch')\n            return\n        data = {'data': decode_frame(frame)}\n        version, error_code = get_version_and_error_code(frame)\n        data['version'] = version\n        data['errcode'] = error_code\n        return data"
            ]
        ]
    },
    {
        "blob_id": "dc3aa683a0dd94aec2e0cf105b15bd1d27f596fa",
        "matched_blocks": [
            [
                1570,
                1576,
                "        try:\n            result = self._buffer.popleft()\n        except IndexError:\n            self._eof()\n        else:\n            self._counter += 1\n            return result"
            ]
        ]
    },
    {
        "blob_id": "bf67822d3bde7b6f73418549a4686a1a0b14a6cb",
        "matched_blocks": [
            [
                57,
                64,
                "        try:\n            user = User.objects.get(mobile=mobile)\n        except User.DoesNotExist:\n            user = None\n        else:\n            password = attrs['password']\n            if not user.check_password(password):\n                raise serializers.ValidationError('\u7528\u6237\u540d\u5bc6\u7801\u9519\u8bef')"
            ]
        ]
    },
    {
        "blob_id": "72f6b97608fa084e9debf3f0cc1533439c08731d",
        "matched_blocks": [
            [
                276,
                282,
                "                try:\n                    fp, _, _ = imp.find_module(name, [path])\n                except ImportError:\n                    raise UserError(\"Missing plugin: %s.\" % name)\n                else:\n                    legacy_plugins.append(name)\n                    logger.debug(\"%s is a legacy plugin.\", name)"
            ]
        ]
    },
    {
        "blob_id": "3b5aa865ddc96e630cfced764ef31e8373a02922",
        "matched_blocks": [
            [
                3424,
                3435,
                "            try:\n                path_out, path_in = split_bezier_intersecting_with_closedpath(\n                    arrow_path, in_f, tolerance=0.01)\n            except NonIntersectingPathException:\n                # if this happens, make a straight line of the head_length\n                # long.\n                x0, y0 = _point_along_a_line(x2, y2, x1, y1, head_length)\n                x1n, y1n = 0.5 * (x0 + x2), 0.5 * (y0 + y2)\n                arrow_path = [(x0, y0), (x1n, y1n), (x2, y2)]\n                path_head = arrow_path\n            else:\n                path_head = path_in"
            ]
        ]
    },
    {
        "blob_id": "afce243a4d7ee76553735dace72d9cef5b52557d",
        "matched_blocks": [
            [
                104,
                116,
                "        try:\n            self.model._meta.get_field(self.fk_field)\n        except FieldDoesNotExist:\n            return [\n                checks.Error(\n                    \"The GenericForeignKey object ID references the non-existent field '%s'.\" % self.fk_field,\n                    hint=None,\n                    obj=self,\n                    id='contenttypes.E001',\n                )\n            ]\n        else:\n            return []"
            ],
            [
                123,
                166,
                "        try:\n            field = self.model._meta.get_field(self.ct_field)\n        except FieldDoesNotExist:\n            return [\n                checks.Error(\n                    \"The GenericForeignKey content type references the non-existent field '%s.%s'.\" % (\n                        self.model._meta.object_name, self.ct_field\n                    ),\n                    hint=None,\n                    obj=self,\n                    id='contenttypes.E002',\n                )\n            ]\n        else:\n            if not isinstance(field, models.ForeignKey):\n                return [\n                    checks.Error(\n                        \"'%s.%s' is not a ForeignKey.\" % (\n                            self.model._meta.object_name, self.ct_field\n                        ),\n                        hint=(\n                            \"GenericForeignKeys must use a ForeignKey to \"\n                            \"'contenttypes.ContentType' as the 'content_type' field.\"\n                        ),\n                        obj=self,\n                        id='contenttypes.E003',\n                    )\n                ]\n            elif field.remote_field.model != ContentType:\n                return [\n                    checks.Error(\n                        \"'%s.%s' is not a ForeignKey to 'contenttypes.ContentType'.\" % (\n                            self.model._meta.object_name, self.ct_field\n                        ),\n                        hint=(\n                            \"GenericForeignKeys must use a ForeignKey to \"\n                            \"'contenttypes.ContentType' as the 'content_type' field.\"\n                        ),\n                        obj=self,\n                        id='contenttypes.E004',\n                    )\n                ]\n            else:\n                return []"
            ]
        ]
    },
    {
        "blob_id": "94525c4e1278e1b638d45df4e32589b8ea6e5133",
        "matched_blocks": [
            [
                22,
                29,
                "        try:\n            decoder.decode(\n                ints2octs((36, 128, 4, 15, 81, 117, 105, 99, 107, 32, 98, 114, 111, 119, 110, 32, 102, 111, 120, 0, 0))\n            )\n        except PyAsn1Error:\n            pass\n        else:\n            assert 0, 'indefinite length encoding tolerated'"
            ]
        ]
    },
    {
        "blob_id": "b2e9aef98ce8e65f58c90611607ae2f1481b8d51",
        "matched_blocks": [
            [
                25,
                39,
                "try:\n    response = table.delete_item(\n        Key={\n            'year': year,\n            'title': title\n        },\n    )\nexcept ClientError as e:\n    if e.response['Error']['Code'] == \"ConditionalCheckFailedException\":\n        print(e.response['Error']['Message'])\n    else:\n        raise\nelse:\n    print(\"Item deletado com sucesso:\")\n    print(json.dumps(response, indent=4, cls=DecimalEncoder))"
            ]
        ]
    },
    {
        "blob_id": "7a51e91eab24da21143727ffd1b8305c04b2dc13",
        "matched_blocks": [
            [
                407,
                414,
                "try:\n    from zope.testing.cleanup import addCleanUp\nexcept ImportError:  # pragma: no cover\n    # don't have that part of Zope\n    pass\nelse:  # pragma: no cover\n    addCleanUp(_clear)\n    del addCleanUp"
            ]
        ]
    },
    {
        "blob_id": "88ed4535cc1d89f37f97af16d48dceabab6add6f",
        "matched_blocks": [
            [
                62,
                72,
                "            try:\n                selection = int(input(options))\n            except ValueError as e:\n                wrong = True\n                continue\n            else:\n                if selection in [1, 2, 3, 4, 5]:\n                    break\n                else:\n                    wrong = True\n                    continue"
            ]
        ]
    },
    {
        "blob_id": "2a4a81a565fab19cc75a574eb4d85c9994bb0767",
        "matched_blocks": [
            [
                165,
                176,
                "        try:\n            f = self.open(TESTFN, bad_mode)\n        except ValueError as msg:\n            if msg.args[0] != 0:\n                s = str(msg)\n                if TESTFN in s or bad_mode not in s:\n                    self.fail(\"bad error message for invalid mode: %s\" % s)\n            # if msg.args[0] == 0, we're probably on Windows where there may be\n            # no obvious way to discover why open() failed.\n        else:\n            f.close()\n            self.fail(\"no error for invalid mode: %s\" % bad_mode)"
            ],
            [
                144,
                150,
                "            try:\n                f = self.open(TESTFN, mode)\n            except ValueError:\n                pass\n            else:\n                f.close()\n                self.fail('%r is an invalid file mode' % mode)"
            ]
        ]
    },
    {
        "blob_id": "e3f53a3a413ada1afe4a2375cc0ac058751e6347",
        "matched_blocks": [
            [
                348,
                353,
                "        try:\n            inspect.getcallargs(method, *args, **kwargs)\n        except TypeError:\n            raise JSONRPCInvalidParamsError()\n        else:\n            return method(*args, **kwargs)"
            ]
        ]
    },
    {
        "blob_id": "0dbbfc44ad918fd60ea9a824d8dd7fbbd1ae0b89",
        "matched_blocks": [
            [
                397,
                414,
                "            try:\n                result = Trainable.train(self)\n            except RayError as e:\n                if self.config[\"ignore_worker_failures\"]:\n                    logger.exception(\n                        \"Error in train call, attempting to recover\")\n                    self._try_recover()\n                else:\n                    logger.info(\n                        \"Worker crashed during call to train(). To attempt to \"\n                        \"continue training without the failed worker, set \"\n                        \"`'ignore_worker_failures': True`.\")\n                    raise e\n            except Exception as e:\n                time.sleep(0.5)  # allow logs messages to propagate\n                raise e\n            else:\n                break"
            ]
        ]
    },
    {
        "blob_id": "c3d0c6798414ea088eb7b3efc5bd017d1d44eda3",
        "matched_blocks": [
            [
                43,
                49,
                "        try:\n            dev = resources.device.from_ansible_facts(facts['ansible_facts'])\n        except KeyError as err:\n            LOG.warning('failed loading device from %s: missing %s',\n                        factfile, err)\n        else:\n            devices.append(dev)"
            ]
        ]
    },
    {
        "blob_id": "57ef03fac4bc95824230305e2183185b4966fc18",
        "matched_blocks": [
            [
                63,
                76,
                "    try:\n        selected_choix = p.choix_set.get(pk=request.POST['choix'])\n    except (KeyError, Choix.DoesNotExist):\n        # R\u00e9affiche le formulaire de vote de la question\n        return render(request, 'sondages/detail.html', {\n            'question': p.slug,\n            'error_message': \"Vous n'avez pas s\u00e9l\u00e9ctionn\u00e9 votre choix.\",\n            })\n    else:\n        selected_choix.votes += 1\n        selected_choix.save()\n        p.votants.add(request.user)\n        p.save()\n        return HttpResponseRedirect(reverse('sondages:resultats', args=(p.slug,)))"
            ]
        ]
    },
    {
        "blob_id": "54ab1a3e48473fb3ff1a996b624f3840d35b63ee",
        "matched_blocks": [
            [
                232,
                239,
                "        try:\n            with s.get(\"/fail\", catch_response=True) as r:\n                r.success()\n                raise OtherException(\"wtf\")\n        except OtherException as e:\n            pass\n        else:\n            self.fail(\"OtherException should have been raised\")"
            ]
        ]
    },
    {
        "blob_id": "5c24262b5869bb78d600241b7e07ecfb429f2b32",
        "matched_blocks": [
            [
                22,
                38,
                "        try:\n            print(\"Instance Generate Command Detected. Instance Generating...\\n \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131 \uba85\ub839\uc774 \uac10\uc9c0\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131 \uc911...\")\n            print(\"\\n\\nData received. Data reading. Might take time...\\n\ub370\uc774\ud130 \uc785\uc218. \ub370\uc774\ud130 \uc77d\ub294 \uc911\uc785\ub2c8\ub2e4. \ub370\uc774\ud130 \ud06c\uae30\uc5d0 \ub530\ub77c \uc2dc\uac04\uc774 \ub2e4\uc18c \uc18c\uc694\ub420 \uc218 \uc788\uc2b5\ub2c8\ub2e4...\")\n\n            self.data = pd.read_csv(fileName)\n            self.original = self.data\n        except:\n\n            print(\"\\n\\nInitiated Failed. Recommendation: Check whether you forget to enter 'csv' file name as parameter. \\n \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131 \uc2e4\ud328. \uc81c\uc548: 'csv' \ud30c\uc77c \uc774\ub984\uc744 \uc81c\ub300\"\n                  \"\ud30c\ub77c\ubbf8\ud130\ub85c \ub123\uc5c8\ub294\uc9c0 \ud655\uc778\ud558\uc2ed\uc2dc\uc624.\")\n\n        else:\n\n            print(self.data)\n            print(\n                \"\\n\\nData reading Complete. Data type in pandas DataFrame object. Displaying data...\\n \ub370\uc774\ud130 \uc77d\uae30\uac00 \uc644\ub8cc\ub418\uc5c8\uc2b5\ub2c8\ub2e4. \ub370\uc774\ud130 \ud0c0\uc785\uc740 \ud310\ub2e4\uc2a4 \ub370\uc774\ud130\ud504\ub808\uc784 \uac1d\uccb4\uc785\ub2c8\ub2e4. \ub370\uc774\ud130 \uac1c\uc694\ub97c \ud45c\uc2dc\ud558\uc600\uc2b5\ub2c8\ub2e4.\")\n            print(\"\\n\\nInstance Successfully Generated. \\n \uc778\uc2a4\ud134\uc2a4 \uc0dd\uc131 \uc131\uacf5. \uc0dd\uc131 \ud504\ub85c\uc138\uc2a4 \uc885\ub8cc.\")"
            ]
        ]
    },
    {
        "blob_id": "1bf5009a1190a9c57239a41e7bf9e3f4a691325d",
        "matched_blocks": [
            [
                77,
                85,
                "    try:\n        f = open(fname, \"rb\", )\n    except Exception as e:\n        logging.error(f\"{e}\")\n        auth_data = \"\"\n    else:\n        auth_data = pickle.load(f)\n       # logging.info(f'Otwarto plik {fname}')\n        f.close()"
            ]
        ]
    },
    {
        "blob_id": "7af9b207267783e0942797fe0352a8a2e29d2aed",
        "matched_blocks": [
            [
                103,
                108,
                "        try:\n            _shell(config[\"upload-if\"], version=config[\"python\"], echo=True)\n        except CalledProcessError:\n            pass\n        else:\n            _shell(config[\"upload\"], version=config[\"python\"], echo=True)"
            ],
            [
                66,
                71,
                "                try:\n                    _shell(config[\"test-if\"], version=version, echo=True)\n                except CalledProcessError:\n                    pass\n                else:\n                    _shell(config[\"test\"], version=version, echo=True)"
            ]
        ]
    },
    {
        "blob_id": "c5d6b42f2836cb90508dfb929e9c065b433edca9",
        "matched_blocks": [
            [
                19,
                72,
                "  try:\n    # se lee el archivo\n    File = open(nombre,\"r\")\n    datos = File.readlines()\n    File.close()\n\n  except IOError as ioe:\n    print(\"Error al abrir el archivo\")\n    print(ioe)\n    return \n  except Exception as e:\n    print(\"Ocurri\u00f3 otro error\")\n    raise e\n  else:\n    # se quitan los saltos de l\u00ednea\n    for i in range(len(datos)):\n      datos[i]=datos[i].replace(\"\\n\",\"\")\n\n    # se rescatan los caracteres\n    caracteres = datos.pop(0).split(\",\")[1:]\n    \n    # se inicializa la tabla de transiciones\n    tablaTransicion={}\n\n    # para cada l\u00ednea en la lista de datos\n    for l\u00ednea in datos:\n      # se separan los datos por medio de las comas\n      informaci\u00f3n = l\u00ednea.split(\",\")\n\n      # se saca el primer elemento separado que representa el estado\n      estado = informaci\u00f3n.pop(0)\n\n      # se genera la lista de transiciones con la informaci\u00f3n restante y\n      # la lista de caracteres\n      listaTransicion=dict(zip(caracteres,informaci\u00f3n))\n\n      # se revisa si el estado tiene un * para representar en la tabla que \n      # se trata de un estado de aceptaci\u00f3n\n      if \"*\" in estado:\n        listaTransicion[\"aceptaci\u00f3n\"]=True\n        estado = estado.replace(\"*\",\"\")\n      else:\n        listaTransicion[\"aceptaci\u00f3n\"]=False\n\n\n      if \"->\" in estado:\n        listaTransicion[\"inicio\"]=True\n        estado = estado.replace(\"->\",\"\")\n      else:\n        listaTransicion[\"inicio\"]=False\n      # se agrega esta informaci\u00f3n a la tabla de transiciones\n      tablaTransicion[estado]=listaTransicion\n\n    return tablaTransicion"
            ]
        ]
    },
    {
        "blob_id": "4f27b2f80d0c42c3f4b9d365e081ee521395bbfc",
        "matched_blocks": [
            [
                67,
                101,
                "    try:\n        fo = open(file_name, 'r')\n\n\n    except FileNotFoundError:\n        print('That file is not found.')\n    else:\n        n = int(fo.readline())\n        e = int(fo.readline())\n        fo.close()\n\n        encrypted_blocks = []\n        ciphertext = -1\n\n        if (len(message) > 0):\n            ciphertext = ord(message[0])\n\n        for i in range(1, len(message)):\n\n            if (i % block_size == 0):\n                encrypted_blocks.append(ciphertext)\n                ciphertext = 0\n\n\n            ciphertext = ciphertext * 1000 + ord(message[i])\n\n        encrypted_blocks.append(ciphertext)\n\n\n        for i in range(len(encrypted_blocks)):\n            encrypted_blocks[i] = str((encrypted_blocks[i]**e) % n)\n\n        encrypted_message = \" \".join(encrypted_blocks)\n\n        return encrypted_message"
            ]
        ]
    },
    {
        "blob_id": "54cf93179518b8b172fbb7bd732db4e3b0d2fd34",
        "matched_blocks": [
            [
                4,
                11,
                "try:\n    ...\nexcept ZeroDivisionError as e:\n    logging.exception(e)\nexcept ValueError as e:\n    logging.exception(e)\nelse:\n    ..."
            ]
        ]
    },
    {
        "blob_id": "11df87788c2b33af28f923719187d1b66c1174d2",
        "matched_blocks": [
            [
                490,
                497,
                "        try:\n            password = self.cleaned_data['password']\n            password_2 = self.cleaned_data['password_2']\n        except KeyError:\n            pass\n        else:\n            if password != password_2:\n                raise forms.ValidationError(\"Passwords do not match\")"
            ]
        ]
    },
    {
        "blob_id": "6b77414cdcd00e64ad48aa484216b1d5616ad607",
        "matched_blocks": [
            [
                259,
                271,
                "        try:\n            xmlTree = ElementTree.parse(filename)\n            xmlRoot = xmlTree.getroot()\n        except ElementTree.ParseError as ex:\n            raise Exception(\n                \"DriverPackagerLite: Invalid XML (%s): %s\" % (filename, ex))\n        else:\n            script = xmlRoot.findall('./config/script')\n            for s in script:\n                if self.doSquish:\n                    c4zStartFile = self.GetSquishyOutputFile(self.srcdir)\n                else:\n                    c4zStartFile = s.attrib.get('file')"
            ],
            [
                444,
                459,
                "        try:\n            xmlTree = ElementTree.parse(manifestPath)\n            xmlRoot = xmlTree.getroot()\n        except IOError as ex:\n            self.Log(ex)\n            retcode = ex.errno\n        except ElementTree.ParseError as ex:\n            self.Log(\"DriverPackagerLite: Invalid XML (%s): %s\" %\n                     (manifestPath, ex))\n            retcode = ex.code\n        else:\n            try:\n                self.ParseXml(xmlRoot, self.srcdir, 0, 0)\n            except Exception as ex:\n                self.Log(ex)\n                retcode = 255"
            ]
        ]
    },
    {
        "blob_id": "c7ef812fb6b1c0a1bcbf2e8e463e19da84748944",
        "matched_blocks": [
            [
                65,
                71,
                "    try:\n        check_tree(tree)\n    except BaseError as error:\n        sys.stderr.write('### error: {0}\\n'.format(str(error)))\n        return 1\n    else:\n        return 0"
            ]
        ]
    },
    {
        "blob_id": "5e226e8a4f61607c503a7fbb214526a9b7b85f9c",
        "matched_blocks": [
            [
                695,
                716,
                "        try:\n            self.do_create_action('pre_shared_key', psk_info,\n                                  conn_id, 'Pre-Shared Key')\n            self.do_create_action('ike_policy', ike_policy_info,\n                                  ike_policy_id, 'IKE Policy')\n            self.do_create_action('ipsec_policy', ipsec_policy_info,\n                                  ipsec_policy_id, 'IPSec Policy')\n            self.do_create_action('ipsec_connection', connection_info,\n                                  site_conn_id, 'IPSec Connection')\n\n            # TODO(pcm): FUTURE - Do DPD for v1 and handle if >1 connection\n            # and different DPD settings\n            for route_id, route_info in routes_info:\n                self.do_create_action('static_route', route_info,\n                                      route_id, 'Static Route')\n        except CsrResourceCreateFailure:\n            self.do_rollback()\n            LOG.info(\"FAILED: Create of IPSec site-to-site connection %s\",\n                     conn_id)\n        else:\n            LOG.info(\"SUCCESS: Created IPSec site-to-site connection %s\",\n                     conn_id)"
            ]
        ]
    },
    {
        "blob_id": "dfc53f5b42b2bfadb6e5728e9481d2c7e2f9c217",
        "matched_blocks": [
            [
                73,
                107,
                "    try:\n        assert len(qreq_.daids) > 0, 'there are no database chips'\n        assert len(qreq_.qaids) > 0, 'there are no query chips'\n    except AssertionError as ex:\n        ut.printex(ex, 'Impossible query request', iswarning=True,\n                   keys=['qreq_.qaids', 'qreq_.daids'])\n        if ut.SUPER_STRICT:\n            raise\n        cm_list = [None for qaid in qreq_.qaids]\n    else:\n        # --- BIG CACHE ---\n        # Do not use bigcache single queries\n        is_big = len(qreq_.qaids) > MIN_BIGCACHE_BUNDLE\n        use_bigcache_ = (use_bigcache and use_cache and is_big)\n        if (use_bigcache_ or save_qcache):\n            cacher = qreq_.get_big_cacher()\n            if use_bigcache_:\n                try:\n                    qaid2_cm = cacher.load()\n                    cm_list = [qaid2_cm[qaid] for qaid in qreq_.qaids]\n                except (IOError, AttributeError):\n                    pass\n                else:\n                    return cm_list\n        # ------------\n        # Execute query request\n        qaid2_cm = execute_query_and_save_L1(qreq_, use_cache, save_qcache,\n                                             verbose=verbose,\n                                             use_supercache=use_supercache,\n                                             invalidate_supercache=invalidate_supercache)\n        # ------------\n        if save_qcache and is_big:\n            cacher.save(qaid2_cm)\n\n        cm_list = [qaid2_cm[qaid] for qaid in qreq_.qaids]"
            ],
            [
                90,
                96,
                "                try:\n                    qaid2_cm = cacher.load()\n                    cm_list = [qaid2_cm[qaid] for qaid in qreq_.qaids]\n                except (IOError, AttributeError):\n                    pass\n                else:\n                    return cm_list"
            ],
            [
                248,
                253,
                "                try:\n                    cm = chip_match.ChipMatch.load_from_fpath(fpath, verbose=False)\n                except chip_match.NeedRecomputeError:\n                    pass\n                else:\n                    qaid2_cm_hit[cm.qaid] = cm"
            ]
        ]
    },
    {
        "blob_id": "fef7011c55ec568149d5c60459a8d905cf1322bd",
        "matched_blocks": [
            [
                566,
                582,
                "            try:\n                assert camera.focuser.is_connected\n            except AttributeError:\n                self.logger.debug(\n                    'Camera {} has no focuser, skipping autofocus'.format(cam_name))\n            except AssertionError:\n                self.logger.debug(\n                    'Camera {} focuser not connected, skipping autofocus'.format(cam_name))\n            else:\n                try:\n                    # Start the autofocus\n                    autofocus_event = camera.autofocus(**kwargs)\n                except Exception as e:\n                    self.logger.error(\n                        \"Problem running autofocus: {}\".format(e))\n                else:\n                    autofocus_events[cam_name] = autofocus_event"
            ],
            [
                575,
                582,
                "                try:\n                    # Start the autofocus\n                    autofocus_event = camera.autofocus(**kwargs)\n                except Exception as e:\n                    self.logger.error(\n                        \"Problem running autofocus: {}\".format(e))\n                else:\n                    autofocus_events[cam_name] = autofocus_event"
            ]
        ]
    },
    {
        "blob_id": "0c9fc4de478378d991d5e1a44f5a7232bb8291de",
        "matched_blocks": [
            [
                479,
                484,
                "            try:\n                dtime = datetime.datetime.fromtimestamp(int(data[\"modified\"]))\n            except Exception:\n                time_str = \"\"\n            else:\n                time_str = dtime.isoformat().replace(\"T\", \" \")"
            ]
        ]
    },
    {
        "blob_id": "941b70169ea0201bf4913ade211f0567886e5ca5",
        "matched_blocks": [
            [
                5,
                10,
                "    try:\n        t = Takuzu(board=b, debug=True)\n    except AssertionError as e:\n        pass\n    else:\n        raise Exception('board={} should throw AssertionError'.format(b))"
            ]
        ]
    },
    {
        "blob_id": "0e029895d75465efd99006fba963cce56d4204ed",
        "matched_blocks": [
            [
                265,
                271,
                "            try:\n                targfunc(self.arr_date)\n            except TypeError:\n                pass\n            else:\n                self.check_fun(testfunc, targfunc, 'arr_date', **kwargs)\n                objs += [self.arr_date.astype('O')]"
            ],
            [
                274,
                280,
                "            try:\n                targfunc(self.arr_tdelta)\n            except TypeError:\n                pass\n            else:\n                self.check_fun(testfunc, targfunc, 'arr_tdelta', **kwargs)\n                objs += [self.arr_tdelta.astype('O')]"
            ]
        ]
    },
    {
        "blob_id": "f455540522194eb3be6d7bae8d61d33128be232a",
        "matched_blocks": [
            [
                172,
                177,
                "    try:\n        get_id_from_title(data_insert['title'], cursor)\n    except InvalidEventTitleError:\n        pass\n    else:\n        raise ExistingEventError"
            ],
            [
                312,
                318,
                "    try:\n        event_id = get_id_from_title(event_title,cursor)\n    except InvalidEventTitleError:\n        return \"Invalid Event Title\"\n    else:\n        cursor.execute('select * from event where event_id = %s', (event_id,))\n        return cursor.fetchall()"
            ],
            [
                34,
                70,
                "        try:\n            game_id = get_game_id(game_name, self.cursor)\n            check_date_format(event_date)\n            data_insert = {  # prepare data insert\n                'event_id': -1,\n                'date': date.fromtimestamp(int(time.mktime(time.strptime(event_date, '%m/%d/%Y')))),  # create date\n                'game_id': game_id,  # get game's ID number\n                'title': event_title,  # event's title\n                'team_size': team_size, # individual team size\n            }\n\n            sql_create_event(data_insert, self.cursor, self.cnx)\n\n            team_size = int(data_insert['team_size'])\n            teams = create_blank_teams(team_size)\n\n            embed = create_embed_message(data_insert['title'], data_insert['date'],\n                                         get_game_name(data_insert['game_id'], self.cursor),\n                                         teams, ctx)  # Created embeded message\n        except DateFormatError:\n            await ctx.send(\"Error: your date is invalid.  Please use MM/DD/YYYY format\")\n        except GameNotFoundError:\n            await ctx.send(\"Error: trying to create an event for a game that does not exist\")\n        except ExistingEventError:\n            await ctx.send(\"Error: event with this title already exists\")\n        except IntegrityError:\n            await ctx.send(\"Error: this event already exists\")\n        except TeamSizeError:\n            await ctx.send(\"Error: team size must be above 0\")\n        else:\n            event_channel = self.bot.get_channel(self.event_channel_id)\n            msg = await event_channel.send(embed=embed)\n            sql_update_event_id(msg.id, event_title, self.cursor, self.cnx) # Set event_id in database\n            await msg.add_reaction('\u2611')   # Add accept emoji to message\n            await msg.add_reaction('\ud83c\uddfd')    # Add decline emoji to message\n\n            await ctx.send(\"Successfully created event \" + event_title + \"!\")"
            ],
            [
                80,
                93,
                "        try:\n            event_id = get_id_from_title(event_title, self.cursor)\n            sql_delete_event(ctx.author.id, event_id, self.cursor, self.cnx)\n        except AdminPermissionError:\n            await ctx.send(\"Permission error: only admins may delete events\")\n        except InvalidEventTitleError:\n            await ctx.send(\"Error: trying to delete an event that does not exist\")\n        else:\n            sql_delete_all_registrations(event_id, self.cursor, self.cnx)   # Remove all registrations for event\n            event_channel = self.bot.get_channel(self.event_channel_id)     # Get event channel\n            msg = await event_channel.fetch_message(event_id)       # Get event message\n            await msg.delete()\n\n            await ctx.send(\"Successfully deleted event \" + event_title + \"!\")"
            ]
        ]
    },
    {
        "blob_id": "c0ca452c8ce617c7325b3edfc9dbf2b3044ab390",
        "matched_blocks": [
            [
                951,
                956,
                "                try:\n                    fn(slf, *args, **kwargs)\n                except Exception:\n                    return\n                else:\n                    slf.fail('expected test to fail, but it passed')"
            ]
        ]
    },
    {
        "blob_id": "5371def4c9a318093a1628fa6841d168af224c7e",
        "matched_blocks": [
            [
                190,
                195,
                "            try:\n                handler = self.client._state_handlers[state]\n            except KeyError:\n                pass\n            else:\n                handler(key=key)"
            ],
            [
                1646,
                1652,
                "            try:\n                w = get_worker()\n            except Exception:\n                direct = False\n            else:\n                if w.scheduler.address == self.scheduler.address:\n                    direct = True"
            ],
            [
                1878,
                1884,
                "            try:\n                w = get_worker()\n            except Exception:\n                direct = False\n            else:\n                if w.scheduler.address == self.scheduler.address:\n                    direct = True"
            ],
            [
                1678,
                1685,
                "                        try:\n                            st = self.futures[key]\n                            exception = st.exception\n                            traceback = st.traceback\n                        except (KeyError, AttributeError):\n                            exc = CancelledError(key)\n                        else:\n                            raise exception.with_traceback(traceback)"
            ]
        ]
    },
    {
        "blob_id": "0887008584eeea663532c44e77a845c93fb8e5b4",
        "matched_blocks": [
            [
                393,
                403,
                "    try:\n        host, port = address.split(':', maxsplit=1)\n    except ValueError:\n        pass\n    else:\n        try:\n            address = (host, int(port))\n        except ValueError:\n            raise ConfigError(\n                f'syslog address port not an integer: {port!r}'\n            ) from None"
            ],
            [
                188,
                204,
                "        try:\n            header = None\n            with open(self.baseFilename) as fp:\n                header = fp.readline().strip()\n        except FileNotFoundError:\n            return\n        else:\n            if header == record_header:\n                return\n\n            # Header changed; move the old file\n            hcnt = 0\n            while os.path.exists(self.baseFilename + f'.h{hcnt}'):\n                hcnt += 1\n                continue\n\n            os.rename(self.baseFilename, self.baseFilename + f'.h{hcnt}')"
            ]
        ]
    },
    {
        "blob_id": "5a308f6b7f9ceacdf803dead7dbd5a2dfc85628e",
        "matched_blocks": [
            [
                70,
                77,
                "            try:\n                di = json.loads(body)\n            except ValueError:\n                path = body\n                headers = {}\n            else:\n                path = di[\"path\"]\n                headers = di[\"headers\"]"
            ],
            [
                80,
                101,
                "            try:\n                if host:\n                    final_headers = {\"Host\": host}\n                    final_headers.update(headers)\n                    response = requests.request(\n                        \"PURGE\", \"http://\" \\\n                            + self.config.get(\"proxy-address\", \"127.0.0.1\") + path,\n                        headers=final_headers,\n                        timeout=10\n                    )\n                else:\n                    response = requests.request(\n                        \"PURGE\", \"http://\" \\\n                            + self.config.get(\"proxy-address\", \"127.0.0.1\") + path,\n                        timeout=10,\n                        headers=headers\n                    )\n            except Exception as exception:\n                msg = traceback.format_exc()\n                self.log(\"Error purging %s: %s\" % (path, msg))\n            else:\n                content = response.content"
            ]
        ]
    },
    {
        "blob_id": "37428d98877fdb8321f7407dd5c71f5904ddfde6",
        "matched_blocks": [
            [
                163,
                168,
                "    try:\n        pickle.dumps(val)\n    except:\n        return False\n    else:\n        return True"
            ],
            [
                172,
                177,
                "    try:\n        json.dumps(val)\n    except:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "1099e40b6a420049aa66c9efe1dffc09c240475a",
        "matched_blocks": [
            [
                85,
                107,
                "    try:\n        estimator.fit(y_train, exogenous=exog_train)\n\n    except Exception as e:\n        fit_time = time.time() - start_time\n        score_time = 0.0\n        if error_score == 'raise':\n            raise\n        else:\n            test_scores = error_score\n            warnings.warn(\"Estimator fit failed. The score on this train-test \"\n                          \"partition will be set to %f. Details: \\n%s\"\n                          % (error_score,\n                             format_exception_only(type(e), e)[0]),\n                          ModelFitWarning)\n\n    else:\n        fit_time = time.time() - start_time\n\n        # forecast h periods into the future and compute the score\n        preds = estimator.predict(n_periods=len(test), exogenous=exog_test)\n        test_scores = scorer(y_test, preds)\n        score_time = time.time() - start_time - fit_time"
            ]
        ]
    },
    {
        "blob_id": "5d9d6c025131f2a3f97852b760a240950735157f",
        "matched_blocks": [
            [
                126,
                146,
                "        try:\n            from docutils.core import publish_parts\n            from docutils.parsers.rst import directives\n        except ImportError:\n            raise Exception(\"The Python docutils library isn't installed. \" +\n                            \"Install with `pip install docutils`\")\n        else:\n            # if pygments is installed, register the \"sourcecode\" directive\n            try:\n                import pygments\n            except ImportError:\n                pass\n            else:\n                directives.register_directive('sourcecode',\n                                              self.pygments_directive)\n            self.text = publish_parts(source=self.text,\n                                      settings_overrides={\n                                            \"doctitle_xform\": False,\n                                            \"initial_header_level\": 2\n                                      },\n                                      writer_name='html4css1')['fragment']"
            ],
            [
                154,
                161,
                "        try:\n            import markdown\n        except ImportError:\n            raise Exception(\"The Python markdown library isn't installed. \" +\n                            \"Install with `pip install markdown`\")\n        else:\n            self.text = markdown.markdown(self.text,\n                                          ['codehilite(css_class=highlight)'])"
            ],
            [
                134,
                140,
                "            try:\n                import pygments\n            except ImportError:\n                pass\n            else:\n                directives.register_directive('sourcecode',\n                                              self.pygments_directive)"
            ]
        ]
    },
    {
        "blob_id": "d31b52e52dec3f9c2451a6cdfffb3ece25202e08",
        "matched_blocks": [
            [
                20,
                25,
                "try:  # Import pandas, if it's installed:\n    import pandas as pd\nexcept ImportError:\n    pass\nelse:\n    imports['pd'] = pd"
            ],
            [
                34,
                45,
                "try:  # This lets us play nicely with IPython:\n\n    from builtins import __IPYTHON__  # type: ignore\n\n    from IPython import embed\n    from IPython import get_ipython\n\nexcept ImportError:\n    is_ipython = False\n\nelse:\n    is_ipython = __IPYTHON__"
            ]
        ]
    },
    {
        "blob_id": "a527639510ff821b91fe8501552ad4cc17f1ed59",
        "matched_blocks": [
            [
                53,
                63,
                "        try:\n            result = Event.objects.get(id=eid)\n        except ObjectDoesNotExist:\n            return JsonResponse({'status':10022, 'message':'query result is empty'})\n        else:\n            event['name'] = result.name\n            event['limit'] = result.limit\n            event['status'] = result.status\n            event['address'] = result.address\n            event['start_time'] = result.start_time\n            return JsonResponse({'status':200, 'message':'success', 'data':event})"
            ],
            [
                150,
                159,
                "        try:\n            result = Guest.objects.get(phone=phone,event_id=eid)\n        except ObjectDoesNotExist:\n            return JsonResponse({'status':10022, 'message':'query result is empty'})\n        else:\n            guest['realname'] = result.realname\n            guest['phone'] = result.phone\n            guest['email'] = result.email\n            guest['sign'] = result.sign\n            return JsonResponse({'status':200, 'message':'success', 'data':guest})"
            ]
        ]
    },
    {
        "blob_id": "48e60a05f222102e719311be1a90a1be88b93574",
        "matched_blocks": [
            [
                153,
                161,
                "            try:\n                _, hub_name = await _validate_input(self.hass, data)\n            except InputValidationError as error:\n                errors[\"base\"] = error.base\n            else:\n                return self.async_create_entry(\n                    title=hub_name,\n                    data=data,\n                )"
            ],
            [
                181,
                188,
                "            try:\n                bond_id, hub_name = await _validate_input(self.hass, user_input)\n            except InputValidationError as error:\n                errors[\"base\"] = error.base\n            else:\n                await self.async_set_unique_id(bond_id)\n                self._abort_if_unique_id_configured()\n                return self.async_create_entry(title=hub_name, data=user_input)"
            ]
        ]
    },
    {
        "blob_id": "c49df3b7148427ccab8d418470e85866a904febc",
        "matched_blocks": [
            [
                88,
                99,
                "try:\n    action = text.split()[0]\n    parameter = text.split()[1]\n    pin = text.split()[2]\nexcept IndexError:\n    error('SMS Format not validated')\n    exit(ERROR_SMS_FORMAT)\nelse:\n    debug('action={}'.format(action))\n    debug('parameter={}'.format(parameter))\n    debug('pin from SMS={}'.format(pin))\n    debug('pin from API={}'.format(pincode))"
            ]
        ]
    },
    {
        "blob_id": "e16dcee46b6896c565cd3e4f89addc19e1a257c8",
        "matched_blocks": [
            [
                61,
                69,
                "        try:\n            value = field.deserialize(value)\n        except ma.ValidationError as err:\n            raise EnvError(\n                'Environment variable \"{}\" invalid: {}'.format(name, err.args[0])\n            )\n        else:\n            self._values[parsed_key] = value\n            return value"
            ]
        ]
    },
    {
        "blob_id": "a966522c3996bdfa4751c8455443c1137d7fdb38",
        "matched_blocks": [
            [
                566,
                574,
                "        try:\n            pd_result = fn(pandas_df, **pd_kwargs)\n        except Exception as e:\n            with pytest.raises(type(e)):\n                # repr to force materialization\n                repr(fn(modin_df, **md_kwargs))\n        else:\n            md_result = fn(modin_df, **md_kwargs)\n            return (md_result, pd_result) if not __inplace__ else (modin_df, pandas_df)"
            ]
        ]
    },
    {
        "blob_id": "5c24a1ee69d25a6ceb65fd98d211de660454b797",
        "matched_blocks": [
            [
                65,
                72,
                "    try:\n        value_as_bytes = codecs.decode(value_to_decode, \"hex\")  # type: ignore\n    except binascii.Error:\n        return False\n    except TypeError:\n        return False\n    else:\n        return bool(value_as_bytes)"
            ],
            [
                92,
                99,
                "    try:\n        value_as_bytes = codecs.decode(value_to_decode, \"hex\")  # type: ignore\n    except binascii.Error:\n        return False\n    except TypeError:\n        return False\n    else:\n        return bool(value_as_bytes)"
            ]
        ]
    },
    {
        "blob_id": "65a9b03f547a18f4099ac0b376b2b11c40f01b68",
        "matched_blocks": [
            [
                128,
                133,
                "    try:\n        validate_df(song_df)\n    except:\n        print(\"An error has occured. Data validation failed.\")\n    else:\n        load(song_df)"
            ]
        ]
    },
    {
        "blob_id": "95f87ca3f746b6ebf3a4f8a588fde8c7852bf984",
        "matched_blocks": [
            [
                172,
                179,
                "            try:\n                label_line = txt2label(txt, sfsfile=sfs_file)\n            except Exception:\n                logger.error('Error at %s, please check your txt %s' % (numstr, txt))\n            else:\n                with open (label_file, 'w') as oid:\n                    for item in label_line:\n                        oid.write(item + '\\n')"
            ]
        ]
    },
    {
        "blob_id": "6552d9183af03d74317017484658fa393ebb53bc",
        "matched_blocks": [
            [
                206,
                219,
                "        try:\n            del self._file_data[key]\n        except KeyError:\n            pass\n        else:\n            env_var = self._config_map[key].env_var\n            if env_var is not None and env_var in os.environ:\n                stream.echo(\n                    stream.yellow(\n                        \"WARNING: the config is shadowed by env var '{}', \"\n                        \"set value won't take effect.\".format(env_var)\n                    )\n                )\n            self._save_config()"
            ]
        ]
    },
    {
        "blob_id": "9ac6a3833f40c5084192e54f33ca2514da3fabd4",
        "matched_blocks": [
            [
                151,
                188,
                "                    try:\n                        _check_tgz(input_file, target_file, asset_name)\n                        _copy_recipe(input_file, target_dir, asset_name, tag_name)\n                        _copy_log(input_file, target_dir, asset_name, tag_name)\n                    except OSError as e:\n                        _LOGGER.warning(e)\n                        continue\n                    else:\n                        _LOGGER.info(\"Updating '{}/{}:{}' tag attributes...\".format(genome, asset_name, tag_name))\n                        tag_attrs = {CFG_ASSET_PATH_KEY: file_name,\n                                     CFG_SEEK_KEYS_KEY: seek_keys,\n                                     CFG_ARCHIVE_CHECKSUM_KEY: checksum(target_file),\n                                     CFG_ARCHIVE_SIZE_KEY: size(target_file),\n                                     CFG_ASSET_SIZE_KEY: size(input_file),\n                                     CFG_ASSET_PARENTS_KEY: parents,\n                                     CFG_ASSET_CHILDREN_KEY: children,\n                                     CFG_ASSET_CHECKSUM_KEY: asset_digest}\n                        _LOGGER.debug(\"attr dict: {}\".format(tag_attrs))\n                        with rgc_server as r:\n                            for parent in parents:\n                                # here we update any pre-existing parents' children attr with the newly added asset\n                                _LOGGER.debug(\"Updating {} children list with {}\".\n                                              format(parent, \"{}/{}:{}\".format(genome, asset_name, tag_name)))\n                                rp = parse_registry_path(parent)\n                                parent_genome = rp[\"namespace\"]\n                                parent_asset = rp[\"item\"]\n                                parent_tag = rp[\"tag\"]\n                                try:\n                                    r.get_asset(parent_genome, parent_asset, parent_tag)\n                                except RefgenconfError:\n                                    _LOGGER.warning(\"'{}/{}:{}'s parent '{}' does not exist, \"\n                                                    \"skipping relationship updates\".\n                                                    format(genome, asset_name, tag_name, parent))\n                                    continue\n                                r.update_relatives_assets(parent_genome, parent_asset, parent_tag,\n                                                          [\"{}/{}:{}\".format(genome, asset_name, tag_name)],\n                                                          children=True)\n                            r.update_tags(genome, asset_name, tag_name, tag_attrs)"
            ]
        ]
    },
    {
        "blob_id": "582474a474055b9b63860d8fa1e1cb22d3389d5c",
        "matched_blocks": [
            [
                45,
                54,
                "\t\t\ttry:\n\t\t\t\tmy_id = self.my_queue.get(True, 1)\n\t\t\texcept:\n\t\t\t\tif time.time() - time_of_last_run > 3:\n\t\t\t\t\treturn\n\t\t\telse:\n\t\t\t\tif my_id:\n\t\t\t\t\ttime_of_last_run = time.time()\n\t\t\t\t\tsubprocess.call([\"php\", pathname+\"/../../testing/Regex/grabheaders.php\", \"\"+my_id])\n\t\t\t\t\tself.my_queue.task_done()"
            ]
        ]
    },
    {
        "blob_id": "593c1cae14fe12d40dfd25405b163319897491d2",
        "matched_blocks": [
            [
                7366,
                7380,
                "            try:\n                with self.assertRaisesRegex(RuntimeError, \"result type Float can't be cast to \"):\n                    cpu_result = getattr(cpu_tensor, op_str)(*cpu_args)\n                with self.assertRaisesRegex(RuntimeError, \"result type Float can't be cast to \"):\n                    device_result = getattr(device_tensor, op_str)(*device_args)\n            except Exception:\n                if self.device_type == 'meta':\n                    return\n                else:\n                    raise\n            else:\n                if self.device_type == 'meta' and op_str not in structured_inplace_ops:\n                    self.fail('expected test to fail on meta tensors, but it passed')\n                else:\n                    pass"
            ]
        ]
    },
    {
        "blob_id": "7bcb8fd48d5ffb65b57fc15df4d7345b8a6486d3",
        "matched_blocks": [
            [
                537,
                553,
                "                try:\n                    requirement.install(\n                        install_options,\n                        global_options,\n                        *args,\n                        **kwargs\n                    )\n                except:\n                    # if install did not succeed, rollback previous uninstall\n                    if (requirement.conflicts_with and not\n                            requirement.install_succeeded):\n                        requirement.rollback_uninstall()\n                    raise\n                else:\n                    if (requirement.conflicts_with and\n                            requirement.install_succeeded):\n                        requirement.commit_uninstall()"
            ],
            [
                228,
                238,
                "                            try:\n                                link = finder.find_requirement(\n                                    req_to_install, self.upgrade)\n                            except BestVersionAlreadyInstalled:\n                                best_installed = True\n                                install = False\n                            except DistributionNotFound as exc:\n                                not_found = exc\n                            else:\n                                # Avoid the need to call find_requirement again\n                                req_to_install.link = link"
            ]
        ]
    },
    {
        "blob_id": "fa7d47eb6b31ff567b140842fca6383e019c5073",
        "matched_blocks": [
            [
                251,
                265,
                "    try:\n        if args.get is not None:\n            pools = [api_client.get_pool(name=args.get)]\n        elif args.set:\n            pools = [api_client.create_pool(name=args.set[0],\n                                            slots=args.set[1],\n                                            description=args.set[2])]\n        elif args.delete:\n            pools = [api_client.delete_pool(name=args.delete)]\n        else:\n            pools = api_client.get_pools()\n    except (AirflowException, IOError) as err:\n        log.error(err)\n    else:\n        log.info(_tabulate(pools=pools))"
            ],
            [
                306,
                322,
                "    try:\n        d = json.loads(var)\n    except Exception:\n        print(\"Invalid variables file.\")\n    else:\n        try:\n            n = 0\n            for k, v in d.items():\n                if isinstance(v, dict):\n                    Variable.set(k, v, serialize_json=True)\n                else:\n                    Variable.set(k, v)\n                n += 1\n        except Exception:\n            pass\n        finally:\n            print(\"{} of {} variables successfully updated.\".format(n, len(d)))"
            ],
            [
                1055,
                1077,
                "        try:\n            to_delete = (session\n                         .query(Connection)\n                         .filter(Connection.conn_id == args.conn_id)\n                         .one())\n        except exc.NoResultFound:\n            msg = '\\n\\tDid not find a connection with `conn_id`={conn_id}\\n'\n            msg = msg.format(conn_id=args.conn_id)\n            print(msg)\n            return\n        except exc.MultipleResultsFound:\n            msg = ('\\n\\tFound more than one connection with ' +\n                   '`conn_id`={conn_id}\\n')\n            msg = msg.format(conn_id=args.conn_id)\n            print(msg)\n            return\n        else:\n            deleted_conn_id = to_delete.conn_id\n            session.delete(to_delete)\n            session.commit()\n            msg = '\\n\\tSuccessfully deleted `conn_id`={conn_id}\\n'\n            msg = msg.format(conn_id=deleted_conn_id)\n            print(msg)"
            ]
        ]
    },
    {
        "blob_id": "b80f98705acca28dd03ee1c8842a46b886af7646",
        "matched_blocks": [
            [
                92,
                98,
                "    try:\n        backlight_state = (data[0] >> 7) & 1\n        shutdown_state = (data[1] >> 2) & 1\n    except: \n        logging.warning(\"SubModule Frame is corrupted, parsing failed.\")\n    else:\n        GPIO.output(GPIO_LCD_BACKLIGHT, backlight_state)"
            ],
            [
                103,
                117,
                "    try:\n        rtc = datetime(data[5], data[4], data[3], data[2], data[1], data[0], 0)\n    except:\n        logging.warning(\"RTC Frame is corrupted, parsing failed.\")\n    else:\n        now = datetime.now()\n        delta_seconds = abs(rtc - now).total_seconds()\n\n        # check time dilation\n        if delta_seconds > SECONDS_DILATION_MAX:\n            # set system datetime\n            os.system(\"sudo timedatectl set-time '{}-{}-{} {}:{}:{}'\".format(\n                rtc.year, rtc.month, rtc.day, rtc.hour, rtc.minute, rtc.second\n            ))       \n            time.sleep(0.1)"
            ],
            [
                147,
                158,
                "    try:\n        bus = can.ThreadSafeBus(\n            bustype='socketcan_native', channel=CHANNEL, bitrate=BITRATE, \n        )\n    except OSError:\n        logging.error(\"Bus {} is error.\".format(CHANNEL))\n        exit()\n    else: \n        logging.info(\"Bus {} is ready.\".format(CHANNEL))\n        # disable ntp sync\n        os.system(\"sudo timedatectl set-ntp no\") \n        time.sleep(0.1)"
            ],
            [
                28,
                42,
                "        try:\n            frame = bus.recv()\n        except: \n            logging.warning(\"Receiving failed.\")\n        else:\n            # debugging\n            logging.debug(\"RX {}\".format(canFormatFrame(frame)))\n\n            # set Backlight Control from Submodule.Daylight frame\n            if(frame.arbitration_id == CAN_ID_SUBMODULE):\n                SHUTDOWN_REQUEST = canRxSubModule(frame.data)\n\n            # set Datetime from RTC frame\n            elif(frame.arbitration_id == CAN_ID_RTC):\n                canRxRTC(frame.data)"
            ],
            [
                53,
                65,
                "        try:\n            device_count = len(shell(\"lsusb\").splitlines())\n        except: \n            logging.error(\"Executing command 'lsusb' failed\")\n        else:\n            # count usb device (default 1: HUB)\n            if device_count > 1:\n                msg.data[0] = int(device_count > 1)\n                # indicator\n                GPIO.output(GPIO_LCD_POWER, (GPIO.HIGH, GPIO.LOW)[toggle_indicator])\n                toggle_indicator = not toggle_indicator\n            else:\n                GPIO.output(GPIO_LCD_POWER, GPIO.HIGH)"
            ],
            [
                68,
                73,
                "        try:\n            bus.send(msg)\n        except:\n            logging.warning(\"Sending failed.\")\n        else:\n            logging.debug(\"TX {}\".format(canFormatFrame(msg)))"
            ]
        ]
    },
    {
        "blob_id": "407382906d18459b6b057a2453814c34e5276414",
        "matched_blocks": [
            [
                830,
                1593,
                "    try:\n        import win32file\n        import win32event\n        import pywintypes\n        import winerror\n    except:\n        logger.warning('Could not load pywin32 for I/O Completion Ports; '\n                       'using inefficient polling for sockets')\n    else:\n        # for UDP we need 'select' polling (pywin32 doesn't yet support\n        # UDP); _AsyncPoller below is combination of the other\n        # _AsyncPoller for epoll/poll/kqueue/select and _SelectNotifier\n        # below. (Un)fortunately, most of it is duplicate code\n\n        class _AsyncPoller(object, metaclass=MetaSingleton):\n            \"\"\"Internal use only.\n            \"\"\"\n\n            __instance = None\n\n            _Read = 0x1\n            _Write = 0x2\n            _Error = 0x4\n\n            @classmethod\n            def instance(cls):\n                # assert cls.__instance is not None\n                return cls.__instance\n\n            def __init__(self, iocp_notifier):\n                if not hasattr(self, 'poller'):\n                    self.__class__.__instance = self\n                    self._fds = {}\n                    self._events = {}\n                    self._lock = threading.Lock()\n                    self.polling = False\n                    self._terminate = False\n                    self.rset = set()\n                    self.wset = set()\n                    self.xset = set()\n                    self.iocp_notifier = iocp_notifier\n                    self.cmd_rsock, self.cmd_wsock = _AsyncPoller._socketpair()\n                    self.cmd_rsock.setblocking(0)\n                    self.cmd_wsock.setblocking(0)\n                    self.poller = select.select\n                    self.poll_thread = threading.Thread(target=self.poll)\n                    self.poll_thread.daemon = True\n                    self.poll_thread.start()\n\n            def unregister(self, fd, update=True):\n                fid = fd._fileno\n                if fd._timeout:\n                    self.iocp_notifier._del_timeout(fd)\n                self._lock.acquire()\n                if update:\n                    if self._fds.pop(fid, None) != fd:\n                        self._lock.release()\n                        logger.debug('fd %s is not registered', fid)\n                        return\n                    event = self._events.pop(fid, 0)\n                else:\n                    event = self._events.get(fd, 0)\n                self._lock.release()\n                if event & _AsyncPoller._Read:\n                    self.rset.discard(fid)\n                if event & _AsyncPoller._Write:\n                    self.wset.discard(fid)\n                if event & _AsyncPoller._Error:\n                    self.xset.discard(fid)\n                if update and self.polling:\n                    self.cmd_wsock.send(b'u')\n\n            def add(self, fd, event):\n                fid = fd._fileno\n                if fd._timeout:\n                    self.iocp_notifier._del_timeout(fd)\n                cur_event = self._events.get(fid, 0)\n                if cur_event & _AsyncPoller._Read:\n                    self.rset.discard(fid)\n                if cur_event & _AsyncPoller._Write:\n                    self.wset.discard(fid)\n                if cur_event & _AsyncPoller._Error:\n                    self.xset.discard(fid)\n                event |= cur_event\n                self._events[fid] = event\n                self._fds[fid] = fd\n                if event:\n                    if event & _AsyncPoller._Read:\n                        self.rset.add(fid)\n                    if event & _AsyncPoller._Write:\n                        self.wset.add(fid)\n                    if event & _AsyncPoller._Error:\n                        self.xset.add(fid)\n                    if fd._timeout:\n                        self.iocp_notifier._add_timeout(fd)\n                        self.iocp_notifier.interrupt(fd._timeout)\n                if self.polling:\n                    self.cmd_wsock.send(b'm')\n\n            def clear(self, fd, event=0):\n                fid = fd._fileno\n                cur_event = self._events.get(fid, 0)\n                if cur_event:\n                    if cur_event & _AsyncPoller._Read:\n                        self.rset.discard(fid)\n                    if cur_event & _AsyncPoller._Write:\n                        self.wset.discard(fid)\n                    if cur_event & _AsyncPoller._Error:\n                        self.xset.discard(fid)\n                    if event:\n                        cur_event &= ~event\n                    else:\n                        cur_event = 0\n                    self._events[fid] = cur_event\n                    if cur_event:\n                        if cur_event & _AsyncPoller._Read:\n                            self.rset.add(fid)\n                        if cur_event & _AsyncPoller._Write:\n                            self.wset.add(fid)\n                        if cur_event & _AsyncPoller._Error:\n                            self.xset.add(fid)\n                    elif fd._timeout_id:\n                        self.iocp_notifier._del_timeout(fd)\n                    if self.polling:\n                        self.cmd_wsock.send(b'm')\n\n            def poll(self):\n                self.cmd_rsock = AsyncSocket(self.cmd_rsock)\n                setattr(self.cmd_rsock, '_read_task', lambda: self.cmd_rsock._rsock.recv(128))\n                self.add(self.cmd_rsock, _AsyncPoller._Read)\n                while True:\n                    self.polling = True\n                    rlist, wlist, xlist = self.poller(self.rset, self.wset, self.xset)\n                    self.polling = False\n                    if self._terminate:\n                        break\n                    events = {}\n                    for fid in rlist:\n                        events[fid] = _AsyncPoller._Read\n                    for fid in wlist:\n                        events[fid] = events.get(fid, 0) | _AsyncPoller._Write\n                    for fid in xlist:\n                        events[fid] = events.get(fid, 0) | _AsyncPoller._Error\n\n                    self._lock.acquire()\n                    events = [(self._fds.get(fid, None), event)\n                              for (fid, event) in events.items()]\n                    self._lock.release()\n                    iocp_notify = False\n                    for fd, event in events:\n                        if fd is None:\n                            logger.debug('invalid fd')\n                            continue\n                        if event & _AsyncPoller._Read:\n                            if fd._read_task:\n                                if fd != self.cmd_rsock:\n                                    iocp_notify = True\n                                fd._read_task()\n                            else:\n                                logger.debug('fd %s is not registered for reading!', fd._fileno)\n                        if event & _AsyncPoller._Write:\n                            if fd._write_task:\n                                iocp_notify = True\n                                fd._write_task()\n                            else:\n                                logger.debug('fd %s is not registered for writing!', fd._fileno)\n                        if event & _AsyncPoller._Error:\n                            if fd._read_coro:\n                                fd._read_coro.throw(socket.error(_AsyncPoller._Error))\n                            if fd._write_coro:\n                                fd._write_coro.throw(socket.error(_AsyncPoller._Error))\n                    if iocp_notify:\n                        self.iocp_notifier.interrupt()\n\n                self.rset = set()\n                self.wset = set()\n                self.xset = set()\n                self.cmd_rsock.close()\n                self.cmd_wsock.close()\n\n            def terminate(self):\n                self._terminate = True\n                self.cmd_wsock.send(b'x')\n                self.poll_thread.join()\n                self.__class__.__instance = None\n\n            @staticmethod\n            def _socketpair():\n                srv_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                srv_sock.bind(('127.0.0.1', 0))\n                srv_sock.listen(1)\n\n                sock1 = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                conn_thread = threading.Thread(target=lambda sock, addr_port: sock.connect(addr_port),\n                                               args=(sock1, srv_sock.getsockname()))\n                conn_thread.daemon = True\n                conn_thread.start()\n                sock2, caddr = srv_sock.accept()\n                srv_sock.close()\n                return (sock1, sock2)\n\n        class _AsyncNotifier(object, metaclass=MetaSingleton):\n            \"\"\"Internal use only.\n            \"\"\"\n\n            __instance = None\n\n            _Block = win32event.INFINITE\n\n            @classmethod\n            def instance(cls, *args, **kwargs):\n                if cls.__instance is None:\n                    cls.__instance = cls(*args, **kwargs)\n                return cls.__instance\n\n            def __init__(self):\n                if not hasattr(self, 'iocp'):\n                    self.__class__.__instance = self\n                    self.iocp = win32file.CreateIoCompletionPort(win32file.INVALID_HANDLE_VALUE,\n                                                                 None, 0, 0)\n                    self._timeouts = []\n                    self.poll_timeout = 0\n                    self._lock = threading.Lock()\n                    self.async_poller = _AsyncPoller(self)\n                    self.cmd_rsock, self.cmd_wsock = _AsyncPoller._socketpair()\n                    self.cmd_wsock.setblocking(0)\n                    self.cmd_rsock = AsyncSocket(self.cmd_rsock)\n                    self.cmd_rsock_buf = win32file.AllocateReadBuffer(128)\n                    self.cmd_rsock._read_overlap.object = self.cmd_rsock_recv\n                    err, n = win32file.WSARecv(self.cmd_rsock._fileno, self.cmd_rsock_buf,\n                                               self.cmd_rsock._read_overlap, 0)\n                    if err and err != winerror.ERROR_IO_PENDING:\n                        logger.warning('WSARecv error: %s', err)\n                    logger.debug('poller: IOCP')\n\n            def cmd_rsock_recv(self, err, n):\n                if n == 0:\n                    err = winerror.ERROR_CONNECTION_INVALID\n                if err:\n                    logger.warning('iocp cmd recv error: %s', err)\n                err, n = win32file.WSARecv(self.cmd_rsock._fileno, self.cmd_rsock_buf,\n                                           self.cmd_rsock._read_overlap, 0)\n                if err and err != winerror.ERROR_IO_PENDING:\n                    logger.warning('WSARecv error: %s', err)\n\n            def interrupt(self, timeout=None):\n                if timeout is None:\n                    self.cmd_wsock.send(b'i')\n                elif self.poll_timeout == _AsyncNotifier._Block or timeout < self.poll_timeout:\n                    self.cmd_wsock.send(b'I')\n\n            def register(self, handle, event=0):\n                win32file.CreateIoCompletionPort(handle, self.iocp, 1, 0)\n\n            def unregister(self, handle):\n                pass\n\n            def modify(self, fd, event):\n                pass\n\n            def poll(self, timeout):\n                self._lock.acquire()\n                if timeout == 0:\n                    self.poll_timeout = 0\n                elif self._timeouts:\n                    self.poll_timeout = self._timeouts[0][0] - _time()\n                    if self.poll_timeout < 0.0001:\n                        self.poll_timeout = 0\n                    elif timeout is not None:\n                        self.poll_timeout = min(timeout, self.poll_timeout)\n                elif timeout is None:\n                    self.poll_timeout = _AsyncNotifier._Block\n                else:\n                    self.poll_timeout = timeout\n                timeout = self.poll_timeout\n                self._lock.release()\n                if timeout and timeout != _AsyncNotifier._Block:\n                    timeout = int(timeout * 1000)\n                err, n, key, overlap = win32file.GetQueuedCompletionStatus(self.iocp, timeout)\n                while err != winerror.WAIT_TIMEOUT:\n                    if overlap and overlap.object:\n                        overlap.object(err, n)\n                    else:\n                        logger.warning('invalid overlap!')\n                    err, n, key, overlap = win32file.GetQueuedCompletionStatus(self.iocp, 0)\n                self.poll_timeout = 0\n                if timeout == 0:\n                    now = _time()\n                    self._lock.acquire()\n                    while self._timeouts and self._timeouts[0][0] <= now:\n                        fd_timeout, fd = self._timeouts.pop(0)\n                        if fd._timeout_id == fd_timeout:\n                            fd._timeout_id = None\n                            fd._timed_out()\n                    self._lock.release()\n\n            def _add_timeout(self, fd):\n                if fd._timeout:\n                    self._lock.acquire()\n                    fd._timeout_id = _time() + fd._timeout\n                    i = bisect_left(self._timeouts, (fd._timeout_id, fd))\n                    self._timeouts.insert(i, (fd._timeout_id, fd))\n                    self._lock.release()\n                else:\n                    fd._timeout_id = None\n\n            def _del_timeout(self, fd):\n                if fd._timeout_id:\n                    self._lock.acquire()\n                    i = bisect_left(self._timeouts, (fd._timeout_id, fd))\n                    while i < len(self._timeouts):\n                        if self._timeouts[i] == (fd._timeout_id, fd):\n                            del self._timeouts[i]\n                            fd._timeout_id = None\n                            break\n                        if fd._timeout_id != self._timeouts[i][0]:\n                            logger.warning('fd %s with %s is not found', fd._fileno, fd._timeout_id)\n                            break\n                        i += 1\n                    self._lock.release()\n\n            def terminate(self):\n                self.async_poller.terminate()\n                self.cmd_rsock.close()\n                self.cmd_wsock.close()\n                if len(self._timeouts):\n                    logger.warning('pending timeouts: %s' % (len(self._timeouts)))\n                win32file.CloseHandle(self.iocp)\n                self.iocp = None\n                self.cmd_rsock_buf = None\n                self.__class__.__instance = None\n\n        class AsyncSocket(_AsyncSocket):\n            \"\"\"AsyncSocket with I/O Completion Ports (under\n            Windows). See _AsyncSocket above for more details.  UDP\n            traffic is handled by _AsyncPoller.\n            \"\"\"\n\n            __slots__ = _AsyncSocket.__slots__ + ('_read_overlap', '_write_overlap')\n\n            def __init__(self, *args, **kwargs):\n                self._read_overlap = None\n                self._write_overlap = None\n                _AsyncSocket.__init__(self, *args, **kwargs)\n\n            def _register(self):\n                if not self._blocking:\n                    if self._rsock.type & socket.SOCK_STREAM:\n                        self._read_overlap = pywintypes.OVERLAPPED()\n                        self._write_overlap = pywintypes.OVERLAPPED()\n                        self._notifier.register(self._fileno)\n                    else:\n                        self._notifier = _AsyncPoller.instance()\n                else:\n                    _AsyncSocket._register(self)\n\n            def _unregister(self):\n                if self._notifier:\n                    self._notifier.unregister(self)\n                    if self._rsock.type & socket.SOCK_STREAM:\n                        if ((self._read_overlap and self._read_overlap.object) or\n                           (self._write_overlap and self._write_overlap.object)):\n                            def _cleanup_(self, rc, n):\n                                self._read_overlap.object = self._write_overlap.object = None\n                                if rc == winerror.ERROR_OPERATION_ABORTED:\n                                    self._read_result = self._write_result = None\n                                    self._read_coro = self._write_coro = None\n                                    self._read_overlap = self._write_overlap = None\n                                    self._notifier = None\n                                else:\n                                    logger.warning('CancelIo failed?: %x' % rc)\n                            if self._read_overlap and self._read_overlap.object:\n                                self._read_overlap.object = functools.partial(_cleanup_, self)\n                            if self._write_overlap and self._write_overlap.object:\n                                self._read_overlap.object = functools.partial(_cleanup_, self)\n                            win32file.CancelIo(self._fileno)\n                        else:\n                            self._read_overlap = self._write_overlap = None\n                            self._read_result = self._write_result = None\n                            self._read_coro = self._write_coro = None\n                            self._notifier = None\n                    else:\n                        self._notifier = None\n\n            def _timed_out(self):\n                if self._rsock and self._rsock.type & socket.SOCK_STREAM:\n                    if self._read_overlap or self._write_overlap:\n                        win32file.CancelIo(self._fileno)\n                if self._read_coro:\n                    if self._rsock and self._rsock.type & socket.SOCK_DGRAM:\n                        self._notifier.clear(self, _AsyncPoller._Read)\n                        self._read_task = None\n                    self._read_coro.throw(socket.timeout('timed out'))\n                    self._read_result = self._read_coro = None\n                if self._write_coro:\n                    if self._rsock and self._rsock.type & socket.SOCK_DGRAM:\n                        self._notifier.clear(self, _AsyncPoller._Write)\n                        self._write_task = None\n                    self._write_coro.throw(socket.timeout('timed out'))\n                    self._write_result = self._write_coro = None\n\n            def setblocking(self, blocking):\n                _AsyncSocket.setblocking(self, blocking)\n                if not self._blocking and self._rsock.type & socket.SOCK_STREAM:\n                    self.recv = self._iocp_recv\n                    self.send = self._iocp_send\n                    self.recvall = self._iocp_recvall\n                    self.sendall = self._iocp_sendall\n                    self.connect = self._iocp_connect\n                    self.accept = self._iocp_accept\n\n            def _iocp_recv(self, bufsize, *args):\n                \"\"\"Internal use only; use 'recv' with 'yield' instead.\n                \"\"\"\n                def _recv(self, err, n):\n                    if self._timeout and self._notifier:\n                        self._notifier._del_timeout(self)\n                    if err or n == 0:\n                        self._read_overlap.object = self._read_result = None\n                        if err == winerror.ERROR_OPERATION_ABORTED:\n                            self._read_coro = None\n                        else:\n                            if not err:\n                                err = winerror.ERROR_CONNECTION_INVALID\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                if err == winerror.ERROR_CONNECTION_INVALID:\n                                    coro._proceed_(b'')\n                                else:\n                                    coro.throw(socket.error(err))\n                    else:\n                        buf = self._read_result[:n]\n                        self._read_overlap.object = self._read_result = None\n                        coro, self._read_coro = self._read_coro, None\n                        if coro:\n                            coro._proceed_(buf)\n\n                self._read_result = win32file.AllocateReadBuffer(bufsize)\n                self._read_overlap.object = functools.partial(_recv, self)\n                self._read_coro = AsynCoro.cur_coro()\n                self._read_coro._await_()\n                if self._timeout:\n                    self._notifier._add_timeout(self)\n                err, n = win32file.WSARecv(self._fileno, self._read_result, self._read_overlap, 0)\n                if err and err != winerror.ERROR_IO_PENDING:\n                    self._read_overlap.object = self._read_result = self._read_coro = None\n                    raise socket.error(err)\n\n            def _iocp_send(self, buf, *args):\n                \"\"\"Internal use only; use 'send' with 'yield' instead.\n                \"\"\"\n                def _send(self, err, n):\n                    if self._timeout and self._notifier:\n                        self._notifier._del_timeout(self)\n                    if err or n == 0:\n                        self._write_overlap.object = self._write_result = None\n                        if err == winerror.ERROR_OPERATION_ABORTED:\n                            self._write_coro = None\n                        else:\n                            if not err:\n                                err = winerror.ERROR_CONNECTION_INVALID\n                            coro, self._write_coro = self._write_coro, None\n                            if coro:\n                                coro.throw(socket.error(err))\n                    else:\n                        self._write_overlap.object = None\n                        coro, self._write_coro = self._write_coro, None\n                        if coro:\n                            coro._proceed_(n)\n\n                self._write_overlap.object = functools.partial(_send, self)\n                self._write_coro = AsynCoro.cur_coro()\n                self._write_coro._await_()\n                if self._timeout:\n                    self._notifier._add_timeout(self)\n                err, n = win32file.WSASend(self._fileno, buf, self._write_overlap, 0)\n                if err and err != winerror.ERROR_IO_PENDING:\n                    self._write_overlap.object = self._write_coro = None\n                    raise socket.error(err)\n\n            def _iocp_recvall(self, bufsize, *args):\n                \"\"\"Internal use only; use 'recvall' with 'yield' instead.\n                \"\"\"\n                def _recvall(self, view, err, n):\n                    if err or n == 0:\n                        if self._timeout and self._notifier:\n                            self._notifier._del_timeout(self)\n                        view.release()\n                        self._read_overlap.object = self._read_result = None\n                        if err == winerror.ERROR_OPERATION_ABORTED:\n                            self._read_coro = None\n                        else:\n                            if not err:\n                                err = winerror.ERROR_CONNECTION_INVALID\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                if err == winerror.ERROR_CONNECTION_INVALID:\n                                    coro._proceed_(b'')\n                                else:\n                                    coro.throw(socket.error(err))\n                    else:\n                        view = view[n:]\n                        if len(view) == 0:\n                            buf = self._read_result.tobytes()\n                            self._read_result.release()\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro._proceed_(buf)\n                        else:\n                            self._read_overlap.object = functools.partial(_recvall, self, view)\n                            err, n = win32file.WSARecv(self._fileno, view, self._read_overlap, 0)\n                            if err and err != winerror.ERROR_IO_PENDING:\n                                if self._timeout and self._notifier:\n                                    self._notifier._del_timeout(self)\n                                view.release()\n                                self._read_overlap.object = self._read_result = None\n                                coro, self._read_coro = self._read_coro, None\n                                if coro:\n                                    coro.throw(socket.error(err))\n\n                self._read_result = win32file.AllocateReadBuffer(bufsize)\n                # buffer is memoryview object\n                view = self._read_result\n                self._read_overlap.object = functools.partial(_recvall, self, view)\n                self._read_coro = AsynCoro.cur_coro()\n                self._read_coro._await_()\n                if self._timeout:\n                    self._notifier._add_timeout(self)\n                err, n = win32file.WSARecv(self._fileno, view, self._read_overlap, 0)\n                if err and err != winerror.ERROR_IO_PENDING:\n                    self._read_overlap.object = self._read_result = self._read_coro = None\n                    raise socket.error(err)\n\n            def _iocp_sendall(self, data):\n                \"\"\"Internal use only; use 'sendall' with 'yield' instead.\n                \"\"\"\n                def _sendall(self, err, n):\n                    if err or n == 0:\n                        if self._timeout and self._notifier:\n                            self._notifier._del_timeout(self)\n                        self._write_overlap.object = self._write_result = None\n                        if err == winerror.ERROR_OPERATION_ABORTED:\n                            self._write_coro = None\n                        else:\n                            if not err:\n                                err = winerror.ERROR_CONNECTION_INVALID\n                            coro, self._write_coro = self._write_coro, None\n                            if coro:\n                                coro.throw(socket.error(err))\n                    else:\n                        self._write_result = self._write_result[n:]\n                        if len(self._write_result) == 0:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._write_result.release()\n                            self._write_overlap.object = self._write_result = None\n                            coro, self._write_coro = self._write_coro, None\n                            if coro:\n                                coro._proceed_(0)\n                        else:\n                            err, n = win32file.WSASend(self._fileno, self._write_result,\n                                                       self._write_overlap, 0)\n                            if err and err != winerror.ERROR_IO_PENDING:\n                                if self._timeout and self._notifier:\n                                    self._notifier._del_timeout(self)\n                                self._write_overlap.object = self._write_result = None\n                                coro, self._write_coro = self._write_coro, None\n                                if coro:\n                                    coro.throw(socket.error(err))\n\n                self._write_result = memoryview(data)\n                self._write_overlap.object = functools.partial(_sendall, self)\n                self._write_coro = AsynCoro.cur_coro()\n                self._write_coro._await_()\n                if self._timeout:\n                    self._notifier._add_timeout(self)\n                err, n = win32file.WSASend(self._fileno, self._write_result, self._write_overlap, 0)\n                if err and err != winerror.ERROR_IO_PENDING:\n                    self._write_overlap.object = self._write_result = self._write_coro = None\n                    raise socket.error(err)\n\n            def _iocp_connect(self, host_port):\n                \"\"\"Internal use only; use 'connect' with 'yield' instead.\n                \"\"\"\n                def _connect(self, err, n):\n                    def _ssl_handshake(self, err, n):\n                        try:\n                            self._rsock.do_handshake()\n                        except ssl.SSLError as err:\n                            if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                                err, n = win32file.WSARecv(self._fileno, self._read_result,\n                                                           self._read_overlap, 0)\n                            elif err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                                err, n = win32file.WSASend(self._fileno, b'', self._read_overlap, 0)\n                            else:\n                                if self._timeout and self._notifier:\n                                    self._notifier._del_timeout(self)\n                                self._read_overlap.object = self._read_result = None\n                                coro = self._read_coro\n                                self.close()\n                                if coro:\n                                    coro.throw(*sys.exc_info())\n                        except:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro = self._read_coro\n                            self.close()\n                            if err != winerror.ERROR_OPERATION_ABORTED and coro:\n                                coro.throw(socket.error(err))\n                        else:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro._proceed_(0)\n\n                    if err:\n                        if self._timeout and self._notifier:\n                            self._notifier._del_timeout(self)\n                        self._read_overlap.object = self._read_result = None\n                        if err == winerror.ERROR_OPERATION_ABORTED:\n                            self._read_coro = None\n                        else:\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro.throw(socket.error(err))\n                    else:\n                        self._rsock.setsockopt(socket.SOL_SOCKET,\n                                               win32file.SO_UPDATE_CONNECT_CONTEXT, b'')\n                        if self._certfile:\n                            self._rsock = ssl.wrap_socket(self._rsock, ca_certs=self._certfile,\n                                                          cert_reqs=ssl.CERT_REQUIRED,\n                                                          server_side=False,\n                                                          do_handshake_on_connect=False)\n                            self._read_result = win32file.AllocateReadBuffer(0)\n                            self._read_overlap.object = functools.partial(_ssl_handshake, self)\n                            self._read_overlap.object(None, 0)\n                        else:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro._proceed_(0)\n\n                # ConnectEX requires socket to be bound!\n                try:\n                    self._rsock.bind(('0.0.0.0', 0))\n                except socket.error as exc:\n                    if exc[0] != EINVAL:\n                        raise\n                self._read_overlap.object = functools.partial(_connect, self)\n                self._read_coro = AsynCoro.cur_coro()\n                self._read_coro._await_()\n                if self._timeout:\n                    self._notifier._add_timeout(self)\n                err, n = win32file.ConnectEx(self._rsock, host_port, self._read_overlap)\n                if err and err != winerror.ERROR_IO_PENDING:\n                    self._read_overlap.object = self._read_result = self._read_coro = None\n                    raise socket.error(err)\n\n            def _iocp_accept(self):\n                \"\"\"Internal use only; use 'accept' with 'yield'\n                instead. Socket in returned pair is asynchronous\n                socket (instance of AsyncSocket with blocking=False).\n                \"\"\"\n                def _accept(self, conn, err, n):\n                    def _ssl_handshake(self, conn, addr, err, n):\n                        try:\n                            conn._rsock.do_handshake()\n                        except ssl.SSLError as err:\n                            if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                                err, n = win32file.WSARecv(conn._fileno, self._read_result,\n                                                           self._read_overlap, 0)\n                            elif err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                                err, n = win32file.WSASend(conn._fileno, b'', self._read_overlap, 0)\n                            else:\n                                if self._timeout and self._notifier:\n                                    self._notifier._del_timeout(self)\n                                self._read_overlap.object = self._read_result = None\n                                coro, self._read_coro = self._read_coro, None\n                                conn.close()\n                                if coro:\n                                    coro.throw(*sys.exc_info())\n                        except:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            conn.close()\n                            if err != winerror.ERROR_OPERATION_ABORTED and coro:\n                                coro.throw(socket.error(err))\n                        else:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro._proceed_((conn, addr))\n\n                    if err:\n                        if self._timeout and self._notifier:\n                            self._notifier._del_timeout(self)\n                        self._read_overlap.object = self._read_result = None\n                        coro, self._read_coro = self._read_coro, None\n                        if err != winerror.ERROR_OPERATION_ABORTED and coro:\n                            coro.throw(socket.error(err))\n                    else:\n                        family, laddr, raddr = win32file.GetAcceptExSockaddrs(conn, self._read_result)\n                        # it seems getpeername returns IP address as\n                        # string, but GetAcceptExSockaddrs returns\n                        # bytes, so decode address\n                        raddr = (raddr[0].decode('ascii'), raddr[1])\n                        # TODO: unpack raddr if family != AF_INET\n                        conn._rsock.setsockopt(socket.SOL_SOCKET, win32file.SO_UPDATE_ACCEPT_CONTEXT,\n                                               struct.pack('P', self._fileno))\n                        if self._certfile:\n                            if not self.ssl_server_ctx and hasattr(ssl, 'create_default_context'):\n                                self.ssl_server_ctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n                                self.ssl_server_ctx.load_cert_chain(certfile=self._certfile,\n                                                                    keyfile=self._keyfile)\n\n                            if self.ssl_server_ctx:\n                                conn._rsock = self.ssl_server_ctx.wrap_socket(conn._rsock,\n                                                                              server_side=True,\n                                                                              do_handshake_on_connect=False)\n                            else:\n                                conn._rsock = ssl.wrap_socket(conn._rsock, certfile=self._certfile,\n                                                              keyfile=self._keyfile,\n                                                              server_side=True,\n                                                              ssl_version=self._ssl_version,\n                                                              do_handshake_on_connect=False)\n\n                            self._read_result = win32file.AllocateReadBuffer(0)\n                            self._read_overlap.object = functools.partial(_ssl_handshake, self,\n                                                                          conn, raddr)\n                            self._read_overlap.object(None, 0)\n                        else:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro._proceed_((conn, raddr))\n\n                sock = socket.socket(self._rsock.family, self._rsock.type, self._rsock.proto)\n                conn = AsyncSocket(sock, keyfile=self._keyfile, certfile=self._certfile,\n                                   ssl_version=self._ssl_version)\n                self._read_result = win32file.AllocateReadBuffer(win32file.CalculateSocketEndPointSize(sock))\n                self._read_overlap.object = functools.partial(_accept, self, conn)\n                self._read_coro = AsynCoro.cur_coro()\n                self._read_coro._await_()\n                if self._timeout:\n                    self._notifier._add_timeout(self)\n                err = win32file.AcceptEx(self._fileno, conn._fileno, self._read_result,\n                                         self._read_overlap)\n                if err and err != winerror.ERROR_IO_PENDING:\n                    self._read_overlap.object = self._read_result = self._read_coro = None\n                    raise socket.error(err)"
            ],
            [
                317,
                336,
                "            try:\n                buf = self._rsock.recv(bufsize, *args)\n            except ssl.SSLError as err:\n                if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                    pass\n                else:\n                    self._notifier.clear(self, _AsyncPoller._Read)\n                    self._read_task = None\n                    coro, self._read_coro = self._read_coro, None\n                    coro.throw(*sys.exc_info())\n            except:\n                self._notifier.clear(self, _AsyncPoller._Read)\n                self._read_task = None\n                coro, self._read_coro = self._read_coro, None\n                coro.throw(*sys.exc_info())\n            else:\n                self._notifier.clear(self, _AsyncPoller._Read)\n                self._read_task = None\n                coro, self._read_coro = self._read_coro, None\n                coro._proceed_(buf)"
            ],
            [
                343,
                356,
                "            try:\n                buf = self._rsock.recv(bufsize)\n            except socket.error as err:\n                if err.args[0] != EWOULDBLOCK:\n                    self._read_task = None\n                    self._notifier.clear(self, _AsyncPoller._Read)\n                    coro, self._read_coro = self._read_coro, None\n                    coro.throw(*sys.exc_info())\n            else:\n                if buf:\n                    self._read_task = None\n                    self._notifier.clear(self, _AsyncPoller._Read)\n                    coro, self._read_coro = self._read_coro, None\n                    coro._proceed_(buf)"
            ],
            [
                368,
                405,
                "            try:\n                recvd = self._rsock.recv_into(view, len(view), *args)\n            except ssl.SSLError as err:\n                if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                    pass\n                else:\n                    view.release()\n                    self._notifier.clear(self, _AsyncPoller._Read)\n                    self._read_task = self._read_result = None\n                    coro, self._read_coro = self._read_coro, None\n                    coro.throw(*sys.exc_info())\n            except:\n                view.release()\n                self._notifier.clear(self, _AsyncPoller._Read)\n                self._read_task = self._read_result = None\n                coro, self._read_coro = self._read_coro, None\n                coro.throw(*sys.exc_info())\n            else:\n                if recvd:\n                    view = view[recvd:]\n                    if len(view) == 0:\n                        view.release()\n                        buf = self._read_result\n                        self._notifier.clear(self, _AsyncPoller._Read)\n                        self._read_task = self._read_result = None\n                        coro, self._read_coro = self._read_coro, None\n                        coro._proceed_(buf)\n                    else:\n                        if self._timeout:\n                            self._notifier._del_timeout(self)\n                            self._notifier._add_timeout(self)\n                        self._read_task = functools.partial(_recvall, self, view, *args)\n                else:\n                    view.release()\n                    self._notifier.clear(self, _AsyncPoller._Read)\n                    self._read_task = self._read_result = None\n                    coro, self._read_coro = self._read_coro, None\n                    coro._proceed_(b'')"
            ],
            [
                414,
                432,
                "            try:\n                recvd = self._rsock.recv_into(view, bufsize)\n            except socket.error as err:\n                if err.args[0] != EWOULDBLOCK:\n                    self._read_task = self._read_result = None\n                    self._notifier.clear(self, _AsyncPoller._Read)\n                    coro, self._read_coro = self._read_coro, None\n                    coro.throw(*sys.exc_info())\n            else:\n                if recvd == bufsize:\n                    view.release()\n                    buf = self._read_result\n                    self._read_task = self._read_result = None\n                    self._notifier.clear(self, _AsyncPoller._Read)\n                    coro, self._read_coro = self._read_coro, None\n                    coro._proceed_(buf)\n                elif recvd:\n                    view = view[recvd:]\n                    self._read_task = functools.partial(_recvall, self, view, *args)"
            ],
            [
                458,
                469,
                "            try:\n                res = self._rsock.recvfrom(*args)\n            except:\n                self._notifier.clear(self, _AsyncPoller._Read)\n                self._read_task = None\n                coro, self._read_coro = self._read_coro, None\n                coro.throw(*sys.exc_info())\n            else:\n                self._notifier.clear(self, _AsyncPoller._Read)\n                self._read_task = None\n                coro, self._read_coro = self._read_coro, None\n                coro._proceed_(res)"
            ],
            [
                482,
                501,
                "            try:\n                sent = self._rsock.send(*args)\n            except ssl.SSLError as err:\n                if err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                    pass\n                else:\n                    self._notifier.clear(self, _AsyncPoller._Write)\n                    self._write_task = None\n                    coro, self._write_coro = self._write_coro, None\n                    coro.throw(*sys.exc_info())\n            except:\n                self._notifier.clear(self, _AsyncPoller._Write)\n                self._write_task = None\n                coro, self._write_coro = self._write_coro, None\n                coro.throw(*sys.exc_info())\n            else:\n                self._notifier.clear(self, _AsyncPoller._Write)\n                self._write_task = None\n                coro, self._write_coro = self._write_coro, None\n                coro._proceed_(sent)"
            ],
            [
                514,
                525,
                "            try:\n                sent = self._rsock.sendto(*args)\n            except:\n                self._notifier.clear(self, _AsyncPoller._Write)\n                self._write_task = None\n                coro, self._write_coro = self._write_coro, None\n                coro.throw(*sys.exc_info())\n            else:\n                self._notifier.clear(self, _AsyncPoller._Write)\n                self._write_task = None\n                coro, self._write_coro = self._write_coro, None\n                coro._proceed_(sent)"
            ],
            [
                542,
                576,
                "            try:\n                sent = self._rsock.send(self._write_result)\n                if sent < 0:\n                    self._write_result.release()\n                    self._notifier.clear(self, _AsyncPoller._Write)\n                    self._write_task = self._write_result = None\n                    coro, self._write_coro = self._write_coro, None\n                    coro.throw(*sys.exc_info())\n            except ssl.SSLError as err:\n                if err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                    pass\n                else:\n                    self._write_result.release()\n                    self._notifier.clear(self, _AsyncPoller._Write)\n                    self._write_task = self._write_result = None\n                    coro, self._write_coro = self._write_coro, None\n                    coro.throw(*sys.exc_info())\n            except:\n                self._write_result.release()\n                self._notifier.clear(self, _AsyncPoller._Write)\n                self._write_task = self._write_result = None\n                coro, self._write_coro = self._write_coro, None\n                coro.throw(*sys.exc_info())\n            else:\n                if sent > 0:\n                    self._write_result = self._write_result[sent:]\n                    if len(self._write_result) == 0:\n                        self._write_result.release()\n                        self._notifier.clear(self, _AsyncPoller._Write)\n                        self._write_task = self._write_result = None\n                        coro, self._write_coro = self._write_coro, None\n                        coro._proceed_(None)\n                    elif self._timeout:\n                        self._notifier._del_timeout(self)\n                        self._notifier._add_timeout(self)"
            ],
            [
                2836,
                2841,
                "            try:\n                self._subscribers.remove(subscriber)\n            except KeyError:\n                reply = -1\n            else:\n                reply = 0"
            ],
            [
                644,
                664,
                "                try:\n                    if self.ssl_server_ctx:\n                        conn._rsock = self.ssl_server_ctx.wrap_socket(conn._rsock,\n                                                                      server_side=True,\n                                                                      do_handshake_on_connect=False)\n                    else:\n                        conn._rsock = ssl.wrap_socket(conn._rsock, certfile=self._certfile,\n                                                      keyfile=self._keyfile,\n                                                      ssl_version=self._ssl_version,\n                                                      server_side=True,\n                                                      do_handshake_on_connect=False)\n                except:\n                    coro, self._read_coro = self._read_coro, None\n                    conn.close()\n                    coro.throw(*sys.exc_info())\n                else:\n                    conn._read_task = conn._write_task = functools.partial(_ssl_handshake, conn, addr)\n                    conn._read_coro = conn._write_coro = self._read_coro\n                    self._read_coro = None\n                    conn._notifier.add(conn, _AsyncPoller._Read | _AsyncPoller._Write)\n                    conn._read_task()"
            ],
            [
                3385,
                3534,
                "                try:\n                    if coro._exceptions:\n                        exc = coro._exceptions.pop(0)\n                        if exc[0] == GeneratorExit:\n                            # assert str(exc[1]) == 'close'\n                            coro._generator.close()\n                            retval = coro._value\n                        else:\n                            retval = coro._generator.throw(*exc)\n                    else:\n                        retval = coro._generator.send(coro._value)\n                except:\n                    self._lock.acquire()\n                    exc = sys.exc_info()\n                    if exc[0] == StopIteration:\n                        v = exc[1].args\n                        if v:\n                            if len(v) == 1:\n                                coro._value = v[0]\n                            else:\n                                coro._value = v\n                        coro._exceptions = []\n                    elif exc[0] == HotSwapException:\n                        v = exc[1].args\n                        if isinstance(v, tuple) and len(v) == 1 and inspect.isgenerator(v[0]) and \\\n                           coro._hot_swappable and not coro._callers:\n                            try:\n                                coro._generator.close()\n                            except:\n                                logger.warning('closing %s/%s raised exception: %s',\n                                               coro._name, coro._id, traceback.format_exc())\n                            coro._generator = v[0]\n                            coro._name = coro._generator.__name__\n                            coro._exceptions = []\n                            coro._value = None\n                            # coro._msgs is not reset, so new\n                            # coroutine can process pending messages\n                            coro._state = AsynCoro._Scheduled\n                        else:\n                            logger.warning('invalid HotSwapException from %s/%s ignored',\n                                           coro._name, coro._id)\n                        self._lock.release()\n                        continue\n                    else:\n                        coro._exceptions.append(exc)\n\n                    if coro._callers:\n                        # return to caller\n                        caller = coro._callers.pop(-1)\n                        coro._generator = caller[0]\n                        if coro._swap_generator and not coro._callers and coro._hot_swappable:\n                            coro._exceptions.append((HotSwapException,\n                                                     HotSwapException(coro._swap_generator)))\n                            coro._swap_generator = None\n                            coro._state = AsynCoro._Scheduled\n                        elif coro._exceptions:\n                            # exception in callee, restore saved value\n                            coro._value = caller[1]\n                            self._suspended.discard(coro._id)\n                            self._scheduled.add(coro._id)\n                            coro._state = AsynCoro._Scheduled\n                        elif coro._state == AsynCoro._Running:\n                            coro._state = AsynCoro._Scheduled\n                    else:\n                        if coro._exceptions:\n                            exc = coro._exceptions[0]\n                            assert isinstance(exc, tuple)\n                            if len(exc) == 2:\n                                exc = ''.join(traceback.format_exception_only(*exc))\n                            else:\n                                exc = ''.join(traceback.format_exception(*exc))\n                            logger.warning('uncaught exception in %s:\\n%s', coro, exc)\n                            try:\n                                coro._generator.close()\n                            except:\n                                logger.warning('closing %s raised exception: %s',\n                                               coro._name, traceback.format_exc())\n                        # delete this coro\n                        if coro._state not in (AsynCoro._Scheduled, AsynCoro._Running):\n                            logger.warning('coro \"%s\" is in state: %s' % (coro._name, coro._state))\n                        monitors = list(coro._monitors)\n                        for monitor in monitors:\n                            if monitor._location == self._location:\n                                if coro._exceptions:\n                                    exc = MonitorException(coro, coro._exceptions[0])\n                                else:\n                                    exc = MonitorException(coro, (StopIteration, coro._value))\n                                if self._coros.get(monitor._id, None) == monitor:\n                                    monitor.send(exc)\n                                else:\n                                    logger.warning('monitor for %s/%s has gone away!',\n                                                   coro._name, coro._id)\n                                    coro._monitors.discard(monitor)\n                            else:\n                                # remote monitor; prepare serializable data\n                                if coro._exceptions:\n                                    exc = coro._exceptions[0][:2]\n                                    try:\n                                        serialize(exc[1])\n                                    except pickle.PicklingError:\n                                        # send only the type\n                                        exc = (exc[0], type(exc[1].args[0]))\n                                    exc = MonitorException(coro, exc)\n                                    coro._exceptions = []\n                                else:\n                                    exc = coro._value\n                                    try:\n                                        serialize(exc)\n                                    except pickle.PicklingError:\n                                        exc = type(exc)\n                                    exc = MonitorException(coro, (StopIteration, exc))\n                                monitor.send(exc)\n                        if not coro._monitors or not coro._exceptions:\n                            coro._msgs.clear()\n                            coro._monitors.clear()\n                            coro._exceptions = []\n                            if self._coros.pop(coro._id, None) != coro:\n                                logger.warning('invalid coro: %s, %s' % (coro._id, coro._state))\n                            if coro._daemon is True:\n                                self._daemons -= 1\n                        elif coro._monitors:\n                            # a (local) monitor can restart it with hot_swap\n                            coro._hot_swappable = True\n                            coro._exceptions = []\n                        coro._state = None\n                        coro._generator = None\n                        if coro._complete:\n                            coro._complete.set()\n                        else:\n                            coro._complete = 0\n                        self._scheduled.discard(coro._id)\n                        if len(self._coros) == self._daemons:\n                            self._complete.set()\n                    self._lock.release()\n                else:\n                    self._lock.acquire()\n                    if coro._state == AsynCoro._Running:\n                        coro._state = AsynCoro._Scheduled\n                        # if this coroutine is suspended, don't update\n                        # the value; when it is resumed, it will be\n                        # updated with the 'update' value\n                        coro._value = retval\n\n                    if isinstance(retval, types.GeneratorType):\n                        # push current generator onto stack and activate\n                        # new generator\n                        coro._callers.append((coro._generator, coro._value))\n                        coro._generator = retval\n                        coro._value = None\n                    self._lock.release()"
            ],
            [
                619,
                641,
                "                    try:\n                        conn._rsock.do_handshake()\n                    except ssl.SSLError as err:\n                        if (err.args[0] == ssl.SSL_ERROR_WANT_READ or\n                           err.args[0] == ssl.SSL_ERROR_WANT_WRITE):\n                            pass\n                        else:\n                            conn._read_task = conn._write_task = None\n                            coro, conn._read_coro = conn._read_coro, None\n                            conn._write_coro = None\n                            conn.close()\n                            coro.throw(*sys.exc_info())\n                    except:\n                        conn._read_task = conn._write_task = None\n                        coro, conn._read_coro = conn._read_coro, None\n                        conn._write_coro = None\n                        conn.close()\n                        coro.throw(*sys.exc_info())\n                    else:\n                        conn._read_task = conn._write_task = None\n                        coro, conn._read_coro = conn._read_coro, None\n                        conn._notifier.clear(conn)\n                        coro._proceed_((conn, addr))"
            ],
            [
                714,
                728,
                "                try:\n                    # TODO: provide 'ca_certs' as special parameter to 'accept'?\n                    # For now this setup wrks for self-signed certs\n                    self._rsock = ssl.wrap_socket(self._rsock, ca_certs=self._certfile,\n                                                  cert_reqs=ssl.CERT_REQUIRED, server_side=False,\n                                                  do_handshake_on_connect=False)\n                except:\n                    coro, self._write_coro = self._write_coro, None\n                    self.close()\n                    coro.throw(*sys.exc_info())\n                else:\n                    self._read_task = self._write_task = functools.partial(_ssl_handshake, self)\n                    self._read_coro = self._write_coro\n                    self._notifier.add(self, _AsyncPoller._Read)\n                    self._write_task()"
            ],
            [
                689,
                712,
                "                    try:\n                        self._rsock.do_handshake()\n                    except ssl.SSLError as err:\n                        if (err.args[0] == ssl.SSL_ERROR_WANT_READ or\n                           err.args[0] == ssl.SSL_ERROR_WANT_WRITE):\n                            pass\n                        else:\n                            self._read_task = self._write_task = None\n                            coro, self._write_coro = self._write_coro, None\n                            self._read_coro = None\n                            self.close()\n                            coro.throw(*sys.exc_info())\n                    except:\n                        self._read_task = self._write_task = None\n                        coro, self._write_coro = self._write_coro, None\n                        self._read_coro = None\n                        self.close()\n                        coro.throw(*sys.exc_info())\n                    else:\n                        self._notifier.clear(self)\n                        self._read_task = self._write_task = None\n                        coro, self._write_coro = self._write_coro, None\n                        self._read_coro = None\n                        coro._proceed_(0)"
            ],
            [
                1419,
                1449,
                "                        try:\n                            self._rsock.do_handshake()\n                        except ssl.SSLError as err:\n                            if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                                err, n = win32file.WSARecv(self._fileno, self._read_result,\n                                                           self._read_overlap, 0)\n                            elif err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                                err, n = win32file.WSASend(self._fileno, b'', self._read_overlap, 0)\n                            else:\n                                if self._timeout and self._notifier:\n                                    self._notifier._del_timeout(self)\n                                self._read_overlap.object = self._read_result = None\n                                coro = self._read_coro\n                                self.close()\n                                if coro:\n                                    coro.throw(*sys.exc_info())\n                        except:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro = self._read_coro\n                            self.close()\n                            if err != winerror.ERROR_OPERATION_ABORTED and coro:\n                                coro.throw(socket.error(err))\n                        else:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro._proceed_(0)"
            ],
            [
                1503,
                1533,
                "                        try:\n                            conn._rsock.do_handshake()\n                        except ssl.SSLError as err:\n                            if err.args[0] == ssl.SSL_ERROR_WANT_READ:\n                                err, n = win32file.WSARecv(conn._fileno, self._read_result,\n                                                           self._read_overlap, 0)\n                            elif err.args[0] == ssl.SSL_ERROR_WANT_WRITE:\n                                err, n = win32file.WSASend(conn._fileno, b'', self._read_overlap, 0)\n                            else:\n                                if self._timeout and self._notifier:\n                                    self._notifier._del_timeout(self)\n                                self._read_overlap.object = self._read_result = None\n                                coro, self._read_coro = self._read_coro, None\n                                conn.close()\n                                if coro:\n                                    coro.throw(*sys.exc_info())\n                        except:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            conn.close()\n                            if err != winerror.ERROR_OPERATION_ABORTED and coro:\n                                coro.throw(socket.error(err))\n                        else:\n                            if self._timeout and self._notifier:\n                                self._notifier._del_timeout(self)\n                            self._read_overlap.object = self._read_result = None\n                            coro, self._read_coro = self._read_coro, None\n                            if coro:\n                                coro._proceed_((conn, addr))"
            ]
        ]
    },
    {
        "blob_id": "9250680d4b5d68902f597d45ca7b9a1fcad029a9",
        "matched_blocks": [
            [
                271,
                276,
                "    try:\n        title\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.title(title,fontsize=font['size']*1.35)   "
            ],
            [
                278,
                283,
                "    try:\n        xlabl\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.xlabel(xlabl,fontsize=font['size']*scale)            "
            ],
            [
                285,
                290,
                "    try:\n        ylabl\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.ylabel(ylabl,fontsize=font['size']*scale)        "
            ],
            [
                292,
                297,
                "    try:\n        xlimt\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.xlim(xlimt)   "
            ],
            [
                299,
                304,
                "    try:\n        ylimt\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.ylim(ylimt)   "
            ],
            [
                763,
                768,
                "    try:\n        title\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.title(title,fontsize=font['size']*1.35)   "
            ],
            [
                770,
                775,
                "    try:\n        xlabl\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.xlabel(xlabl,fontsize=font['size']*scale)            "
            ],
            [
                777,
                782,
                "    try:\n        ylabl\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.ylabel(ylabl,fontsize=font['size']*scale)        "
            ],
            [
                784,
                789,
                "    try:\n        xlimt\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.xlim(xlimt)   "
            ],
            [
                791,
                796,
                "    try:\n        ylimt\n    except NameError:\n        pass  # do nothing! \n    else:\n        plt.ylim(ylimt)   "
            ]
        ]
    },
    {
        "blob_id": "cb601b6849d3998b47d3bd029693d9a1e37a592e",
        "matched_blocks": [
            [
                50,
                56,
                "        try:\n            pass\n        except RuntimeError:\n            result = 'it broke'\n            pass\n        else:\n            result = 'no damage done'"
            ]
        ]
    },
    {
        "blob_id": "1b5e747a4b2642018e32c6e08f4f4180972ecebd",
        "matched_blocks": [
            [
                336,
                353,
                "            try:\n                # RFC 7230 section 3.3.2 specifies multiple content lengths can\n                # be sent in a single Content-Length header\n                # (e.g. Content-Length: 42, 42). This line ensures the values\n                # are all valid ints and that as long as the `set` length is 1,\n                # all values are the same. Otherwise, the header is invalid.\n                lengths = set([int(val) for val in length.split(\",\")])\n                if len(lengths) > 1:\n                    raise InvalidHeader(\n                        \"Content-Length contained multiple \"\n                        \"unmatching values (%s)\" % length\n                    )\n                length = lengths.pop()\n            except ValueError:\n                length = None\n            else:\n                if length < 0:\n                    length = None"
            ]
        ]
    },
    {
        "blob_id": "9d60edd37c96b1e94d4032e27875828b0b90e3c8",
        "matched_blocks": [
            [
                6,
                107,
                "try:\n    from ctypes import windll\nexcept ImportError:\n    windll = None\n    SetConsoleTextAttribute = lambda *_: None\nelse:\n    from ctypes import (\n        byref, Structure, c_char, c_short, c_uint32, c_ushort\n    )\n\n    handles = {\n        STDOUT: windll.kernel32.GetStdHandle(STDOUT),\n        STDERR: windll.kernel32.GetStdHandle(STDERR),\n    }\n\n    SHORT = c_short\n    WORD = c_ushort\n    DWORD = c_uint32\n    TCHAR = c_char\n\n    class COORD(Structure):\n        \"\"\"struct in wincon.h\"\"\"\n        _fields_ = [\n            ('X', SHORT),\n            ('Y', SHORT),\n        ]\n\n    class  SMALL_RECT(Structure):\n        \"\"\"struct in wincon.h.\"\"\"\n        _fields_ = [\n            (\"Left\", SHORT),\n            (\"Top\", SHORT),\n            (\"Right\", SHORT),\n            (\"Bottom\", SHORT),\n        ]\n\n    class CONSOLE_SCREEN_BUFFER_INFO(Structure):\n        \"\"\"struct in wincon.h.\"\"\"\n        _fields_ = [\n            (\"dwSize\", COORD),\n            (\"dwCursorPosition\", COORD),\n            (\"wAttributes\", WORD),\n            (\"srWindow\", SMALL_RECT),\n            (\"dwMaximumWindowSize\", COORD),\n        ]\n\n        def __str__(self):\n            return '(%d,%d,%d,%d,%d,%d,%d,%d,%d,%d,%d)' % (\n                self.dwSize.Y, self.dwSize.X,\n                 self.dwCursorPosition.Y, self.dwCursorPosition.X,\n                 self.wAttributes,\n                 self.srWindow.Top, self.srWindow.Left,\n                 self.srWindow.Bottom, self.srWindow.Right,\n                 self.dwMaximumWindowSize.Y, self.dwMaximumWindowSize.X\n            )\n\n    def GetConsoleScreenBufferInfo(stream_id=STDOUT):\n        handle = handles[stream_id]\n        csbi = CONSOLE_SCREEN_BUFFER_INFO()\n        windll.kernel32.GetConsoleScreenBufferInfo(handle, byref(csbi))\n        return csbi\n\n    def SetConsoleTextAttribute(stream_id, attrs):\n        handle = handles[stream_id]\n        return windll.kernel32.SetConsoleTextAttribute(handle, attrs)\n\n    def SetConsoleCursorPosition(stream_id, position):\n        position = COORD(*position)\n        # If the position is out of range, do nothing.\n        if position.Y <= 0 or position.X <= 0:\n            return\n        # Adjust for Windows' SetConsoleCursorPosition:\n        #    1. being 0-based, while ANSI is 1-based.\n        #    2. expecting (x,y), while ANSI uses (y,x).\n        adjusted_position = COORD(position.Y - 1, position.X - 1)\n        # Adjust for viewport's scroll position\n        sr = GetConsoleScreenBufferInfo(STDOUT).srWindow\n        adjusted_position.Y += sr.Top\n        adjusted_position.X += sr.Left\n        # Resume normal processing\n        handle = handles[stream_id]\n        return windll.kernel32.SetConsoleCursorPosition(handle, adjusted_position)\n\n    def FillConsoleOutputCharacter(stream_id, char, length, start):\n        handle = handles[stream_id]\n        char = TCHAR(char)\n        length = DWORD(length)\n        num_written = DWORD(0)\n        # Note that this is hard-coded for ANSI (vs wide) bytes.\n        windll.kernel32.FillConsoleOutputCharacterA(handle, char, length,\n            start, byref(num_written))\n        return num_written.value\n\n    def FillConsoleOutputAttribute(stream_id, attr, length, start):\n        ''' FillConsoleOutputAttribute( hConsole, csbi.wAttributes, dwConSize, coordScreen, &cCharsWritten )'''\n        handle = handles[stream_id]\n        attribute = WORD(attr)\n        length = DWORD(length)\n        num_written = DWORD(0)\n        # Note that this is hard-coded for ANSI (vs wide) bytes.\n        return windll.kernel32.FillConsoleOutputAttribute(\n            handle, attribute, length, start, byref(num_written))"
            ]
        ]
    },
    {
        "blob_id": "ee93cddd16945c87b62476643878d8e30493b53a",
        "matched_blocks": [
            [
                14,
                19,
                "try:\n    import objgraph\nexcept ImportError:\n    OBJGRAPH_INSTALLED = False\nelse:\n    OBJGRAPH_INSTALLED = True"
            ],
            [
                62,
                69,
                "    try:\n        from glue.utils.qt import get_qapp\n    except Exception:\n        # Note that we catch any exception, not just ImportError, because\n        # QtPy can raise a PythonQtError.\n        pass\n    else:\n        get_qapp()"
            ]
        ]
    },
    {
        "blob_id": "d5baa1faff9f4d00231718d2daf693d838aae255",
        "matched_blocks": [
            [
                62,
                75,
                "        try:\n            identity_client.users.add_to_group(user_id, group_id)\n        except Exception:\n            msg = _(\"%(user)s not added to group %(group)s\\n\") % {\n                'user': parsed_args.user,\n                'group': parsed_args.group,\n            }\n            sys.stderr.write(msg)\n        else:\n            msg = _(\"%(user)s added to group %(group)s\\n\") % {\n                'user': parsed_args.user,\n                'group': parsed_args.group,\n            }\n            sys.stdout.write(msg)"
            ],
            [
                107,
                120,
                "        try:\n            identity_client.users.check_in_group(user_id, group_id)\n        except Exception:\n            msg = _(\"%(user)s not in group %(group)s\\n\") % {\n                'user': parsed_args.user,\n                'group': parsed_args.group,\n            }\n            sys.stderr.write(msg)\n        else:\n            msg = _(\"%(user)s in group %(group)s\\n\") % {\n                'user': parsed_args.user,\n                'group': parsed_args.group,\n            }\n            sys.stdout.write(msg)"
            ],
            [
                293,
                306,
                "        try:\n            identity_client.users.remove_from_group(user_id, group_id)\n        except Exception:\n            msg = _(\"%(user)s not removed from group %(group)s\\n\") % {\n                'user': parsed_args.user,\n                'group': parsed_args.group,\n            }\n            sys.stderr.write(msg)\n        else:\n            msg = _(\"%(user)s removed from group %(group)s\\n\") % {\n                'user': parsed_args.user,\n                'group': parsed_args.group,\n            }\n            sys.stdout.write(msg)"
            ]
        ]
    },
    {
        "blob_id": "2a10e7bef34bdb10181c6a62a9e338aec04431c8",
        "matched_blocks": [
            [
                118,
                170,
                "try:\n    import ecdsa\n\nexcept ImportError:\n    pass\n\nelse:\n    class secp256k1_secretkey(secretkey):\n        NAME = \"secp256k1\"\n\n        @classmethod\n        def generate(cls):\n            sk = ecdsa.SigningKey.generate(\n                curve=ecdsa.curves.SECP256k1,\n                hashfunc=hashlib.sha256,\n            ).to_string()\n            return cls(sk)\n\n        def public(self):\n            k = self._h.get_verifying_key().to_string()\n            return secp256k1_key(k)\n\n        def __init__(self, raw):\n            super().__init__(raw)\n            self._h = ecdsa.SigningKey.from_string(\n                self.raw,\n                curve=ecdsa.curves.SECP256k1,\n                hashfunc=hashlib.sha256,\n            )\n\n        def sign(self, h):\n            return self._h.sign(h)\n\n    class secp256k1_key(key):\n        NAME = \"secp256k1\"\n\n        def __init__(self, raw):\n            super().__init__(raw)\n            self._h = ecdsa.VerifyingKey.from_string(\n                self.raw,\n                curve=ecdsa.curves.SECP256k1,\n                hashfunc=hashlib.sha256,\n            )\n\n        def verify(self, proof, h):\n            try:\n                self._h.verify(proof, h)\n\n            except ecdsa.keys.BadSignatureError:\n                return False\n\n            else:\n                return True"
            ],
            [
                172,
                205,
                "try:\n    import pysodium as sodium\n\nexcept ImportError:\n    pass\n\nelse:\n    class ed25519_secretkey(secretkey):\n        NAME = 'ed25519'\n\n        @classmethod\n        def generate(cls):\n            _, sk = sodium.crypto_sign_keypair()\n            return cls(sk)\n\n        def public(self):\n            k = sodium.crypto_sign_sk_to_pk(self.raw)\n            return ed25519_key(k)\n\n        def sign(self, h):\n            return sodium.crypto_sign_detached(h, self.raw)\n\n    class ed25519_key(key):\n        NAME = 'ed25519'\n\n        def verify(self, proof, h):\n            try:\n                sodium.crypto_sign_verify_detached(proof, h, self.raw)\n\n            except ValueError:\n                return False\n\n            else:\n                return True"
            ],
            [
                163,
                170,
                "            try:\n                self._h.verify(proof, h)\n\n            except ecdsa.keys.BadSignatureError:\n                return False\n\n            else:\n                return True"
            ],
            [
                198,
                205,
                "            try:\n                sodium.crypto_sign_verify_detached(proof, h, self.raw)\n\n            except ValueError:\n                return False\n\n            else:\n                return True"
            ]
        ]
    },
    {
        "blob_id": "94bf08a7ce82fd2b63625597118eb7bbeb7fe531",
        "matched_blocks": [
            [
                42,
                63,
                "        try:\n            subst1.try_add_variable('i4.3.1.0_1', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 141899\n            if len(subjects) >= 1:\n                tmp2 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i4.3.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 141900\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*b\n                        yield 0, subst2\n                subjects.appendleft(tmp2)"
            ],
            [
                52,
                62,
                "                try:\n                    subst2.try_add_variable('i4.3.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 141900\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*b\n                        yield 0, subst2"
            ]
        ]
    },
    {
        "blob_id": "ae124f95dfb74a92c94a4bdb45c0fae10c363ce9",
        "matched_blocks": [
            [
                45,
                59,
                "    try:\n        selected_choice = question.choice_set.get(pk = request.POST[\"choice\"])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, \"polls/detail.html\", {\n            \"question\": question,\n            \"error_message\": \"You didn't select a choice.\"\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse(\"polls:results\", args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "747cbd53ce5e8a06b1fe6676245d9a0d08362bf7",
        "matched_blocks": [
            [
                136,
                141,
                "                        try:\n                            qid = insert_quote(args.decode(\"utf-8\"), target.lower())\n                        except Exception:\n                            pass\n                        else:\n                            write_line(server, \"PRIVMSG\", [target, \"Quote {} added.\".format(qid)])"
            ]
        ]
    },
    {
        "blob_id": "60990ad16c085890d930ad6a9a48be8afc3d4dd0",
        "matched_blocks": [
            [
                75,
                89,
                "        try:\n            smtp_server = smtplib.SMTP(self.server)  # \u8fde\u63a5sever\n        except (gaierror and error) as e:\n            logger.exception('\u53d1\u9001\u90ae\u4ef6\u5931\u8d25,\u65e0\u6cd5\u8fde\u63a5\u5230SMTP\u670d\u52a1\u5668\uff0c\u68c0\u67e5\u7f51\u7edc\u4ee5\u53caSMTP\u670d\u52a1\u5668. %s', e)\n        else:\n            try:\n                smtp_server.login(self.sender, self.password)  # \u767b\u5f55\n            except smtplib.SMTPAuthenticationError as e:\n                logger.exception('\u7528\u6237\u540d\u5bc6\u7801\u9a8c\u8bc1\u5931\u8d25\uff01%s', e)\n            else:\n                smtp_server.sendmail(self.sender, self.receiver.split(';'), self.msg.as_string())  # \u53d1\u9001\u90ae\u4ef6\n            finally:\n                smtp_server.quit()  # \u65ad\u5f00\u8fde\u63a5\n                logger.info('\u53d1\u9001\u90ae\u4ef6\"{0}\"\u6210\u529f! \u6536\u4ef6\u4eba\uff1a{1}\u3002\u5982\u679c\u6ca1\u6709\u6536\u5230\u90ae\u4ef6\uff0c\u8bf7\u68c0\u67e5\u5783\u573e\u7bb1\uff0c'\n                            '\u540c\u65f6\u68c0\u67e5\u6536\u4ef6\u4eba\u5730\u5740\u662f\u5426\u6b63\u786e'.format(self.title, self.receiver))"
            ],
            [
                80,
                85,
                "            try:\n                smtp_server.login(self.sender, self.password)  # \u767b\u5f55\n            except smtplib.SMTPAuthenticationError as e:\n                logger.exception('\u7528\u6237\u540d\u5bc6\u7801\u9a8c\u8bc1\u5931\u8d25\uff01%s', e)\n            else:\n                smtp_server.sendmail(self.sender, self.receiver.split(';'), self.msg.as_string())  # \u53d1\u9001\u90ae\u4ef6"
            ]
        ]
    },
    {
        "blob_id": "760d79c5be432579218ffbdbeddd28f6e85a16d8",
        "matched_blocks": [
            [
                130,
                136,
                "        try:\n            value = self[key]\n        except KeyError:\n            self[key] = default\n            return default\n        else:\n            return value"
            ]
        ]
    },
    {
        "blob_id": "a9fbf13bfa8cd5e3bfda872b864aed92b33a0ab3",
        "matched_blocks": [
            [
                29,
                38,
                "        try:\n            current_date = datetime.strptime(row[0], \"%Y-%m-%d\")\n            high = int(row[1])  # \u4f7f\u5176\u53d8\u4e3a\u6574\u578b\u6570\u636e\u5217\u8868\n            low = int(row[3])\n        except ValueError:\n            print(current_date, 'Missing data')\n        else:\n            dates.append(current_date)\n            highs.append(high)  # \u4ee5\u7d22\u5f15\u51fa\u6765\u7684\u6570\u636e\uff0c\u4f5c\u4e3a\u53c2\u6570\u6dfb\u52a0\u8fdb\u5217\u8868\n            lows.append(low)"
            ]
        ]
    },
    {
        "blob_id": "a9a07601ec97d7ee3afb3eeb9f6ca71b508b9621",
        "matched_blocks": [
            [
                164,
                180,
                "                try:\n                    obj = self._parser.gets()\n                except ProtocolError as exc:\n                    # ProtocolError is fatal\n                    # so connection must be closed\n                    if self._in_transaction is not None:\n                        self._transaction_error = exc\n                    self._closing = True\n                    self._do_close(exc)\n                    return\n                else:\n                    if obj is False:\n                        break\n                    if self._in_pubsub:\n                        self._process_pubsub(obj)\n                    else:\n                        self._process_data(obj)"
            ]
        ]
    },
    {
        "blob_id": "9c078dab05f51b5062c60738aa7641391f4c06b7",
        "matched_blocks": [
            [
                154,
                170,
                "        try:\n            user = User.objects.get(username__iexact=username)\n        except User.DoesNotExist:\n            pass\n        else:\n            query = UserenaSignup.objects\\\n                .filter(user__username__iexact=username)\\\n                .exclude(activation_key=userena_settings.USERENA_ACTIVATED)\n            if (userena_settings.USERENA_ACTIVATION_REQUIRED and\n                query.exists()):\n                raise serializers.ValidationError(\n                    _('This username is already taken but not confirmed. '\n                      'Please check your email for verification steps.')\n                    )\n            raise serializers.ValidationError(\n                    _('This username is already taken.')\n                    )"
            ]
        ]
    },
    {
        "blob_id": "88fdfd7865c6d9ba713535f1b8f1f9e7e1ba41a4",
        "matched_blocks": [
            [
                320,
                336,
                "        try:\n            f = open(script, 'rb')\n        except IOError:  # pragma: no cover\n            if not self.dry_run:\n                raise\n            f = None\n        else:\n            first_line = f.readline()\n            if not first_line:  # pragma: no cover\n                logger.warning('%s: %s is an empty file (skipping)',\n                               self.get_command_name(),  script)\n                return\n\n            match = FIRST_LINE_RE.match(first_line.replace(b'\\r\\n', b'\\n'))\n            if match:\n                adjust = True\n                post_interp = match.group(1) or b''"
            ]
        ]
    },
    {
        "blob_id": "ca8c4fe15042d561dd8645bb48bd2fae1c1b468f",
        "matched_blocks": [
            [
                56,
                65,
                "            try:\n                data = sock.recv(1024).decode()\n                #print('cur', curServoAngles)\n            except socket.timeout as e:\n                pass\n            except socket.error as e:\n                print(e)\n                sys.exit(1)\n            else:\n                print(data)"
            ]
        ]
    },
    {
        "blob_id": "de2b3ca082ab4f20ce2b31fbaee41e83bbb2fcf7",
        "matched_blocks": [
            [
                206,
                212,
                "\t\ttry:\n\t\t\tinput.ChangeValue(self.get_value(parameter))\n\t\texcept KeyError:\n\t\t\t# No default value set.\n\t\t\tpass\n\t\telse:\n\t\t\tinput.SetBackgroundColour(OK_BACKGROUND_COLOR)"
            ],
            [
                273,
                280,
                "\t\ttry:\n\t\t\tlabel = self.resource_labels[parameter]\n\t\texcept KeyError:\n\t\t\tpass\n\t\telse:\n\t\t\tdel self.resource_labels[parameter]\n\t\t\tdel self.resources[parameter]\n\t\t\tdel self.global_store.resources[label]"
            ]
        ]
    },
    {
        "blob_id": "96dfc223c67a66f0514a680a2e6adbd6444c30d6",
        "matched_blocks": [
            [
                618,
                633,
                "        try:\n            task.driver.deploy.clean_up(task)\n            task.driver.deploy.tear_down(task)\n        except Exception as e:\n            with excutils.save_and_reraise_exception():\n                LOG.exception(_LE('Error in tear_down of node %(node)s: '\n                                  '%(err)s'),\n                              {'node': node.uuid, 'err': e})\n                node.last_error = _(\"Failed to tear down. Error: %s\") % e\n                task.process_event('error')\n        else:\n            # NOTE(deva): When tear_down finishes, the deletion is done,\n            # cleaning will start next\n            LOG.info(_LI('Successfully unprovisioned node %(node)s with '\n                         'instance %(instance)s.'),\n                     {'node': node.uuid, 'instance': node.instance_uuid})"
            ],
            [
                1062,
                1074,
                "        try:\n            task.driver.power.validate(task)\n        except Exception as e:\n            error = (_('Failed to validate power driver interface for node '\n                       '%(node)s. Error: %(msg)s') %\n                     {'node': node.uuid, 'msg': e})\n        else:\n            try:\n                power_state = task.driver.power.get_power_state(task)\n            except Exception as e:\n                error = (_('Failed to get power state for node '\n                           '%(node)s. Error: %(msg)s') %\n                         {'node': node.uuid, 'msg': e})"
            ],
            [
                1671,
                1689,
                "        try:\n            if enabled:\n                task.driver.console.start_console(task)\n                # TODO(deva): We should be updating conductor_affinity here\n                # but there is no support for console sessions in\n                # take_over() right now.\n            else:\n                task.driver.console.stop_console(task)\n        except Exception as e:\n            op = _('enabling') if enabled else _('disabling')\n            msg = (_('Error %(op)s the console on node %(node)s. '\n                     'Reason: %(error)s') % {'op': op,\n                                             'node': node.uuid,\n                                             'error': e})\n            node.last_error = msg\n            LOG.error(msg)\n        else:\n            node.console_enabled = enabled\n            node.last_error = None"
            ],
            [
                827,
                833,
                "            try:\n                skip_current_step = info.pop('skip_current_clean_step')\n            except KeyError:\n                skip_current_step = True\n            else:\n                node.driver_internal_info = info\n                node.save()"
            ],
            [
                1842,
                1882,
                "            try:\n                lock_purpose = 'getting sensors data'\n                with task_manager.acquire(context,\n                                          node_uuid,\n                                          shared=True,\n                                          purpose=lock_purpose) as task:\n                    if not getattr(task.driver, 'management', None):\n                        continue\n                    task.driver.management.validate(task)\n                    sensors_data = task.driver.management.get_sensors_data(\n                        task)\n            except NotImplementedError:\n                LOG.warning(_LW(\n                    'get_sensors_data is not implemented for driver'\n                    ' %(driver)s, node_uuid is %(node)s'),\n                    {'node': node_uuid, 'driver': driver})\n            except exception.FailedToParseSensorData as fps:\n                LOG.warning(_LW(\n                    \"During get_sensors_data, could not parse \"\n                    \"sensor data for node %(node)s. Error: %(err)s.\"),\n                    {'node': node_uuid, 'err': str(fps)})\n            except exception.FailedToGetSensorData as fgs:\n                LOG.warning(_LW(\n                    \"During get_sensors_data, could not get \"\n                    \"sensor data for node %(node)s. Error: %(err)s.\"),\n                    {'node': node_uuid, 'err': str(fgs)})\n            except exception.NodeNotFound:\n                LOG.warning(_LW(\n                    \"During send_sensor_data, node %(node)s was not \"\n                    \"found and presumed deleted by another process.\"),\n                    {'node': node_uuid})\n            except Exception as e:\n                LOG.warning(_LW(\n                    \"Failed to get sensor data for node %(node)s. \"\n                    \"Error: %(error)s\"), {'node': node_uuid, 'error': str(e)})\n            else:\n                message['payload'] = (\n                    self._filter_out_unsupported_types(sensors_data))\n                if message['payload']:\n                    self.notifier.info(context, \"hardware.ipmi.metrics\",\n                                       message)"
            ]
        ]
    },
    {
        "blob_id": "8bf62a53d6d5bf5cf09f3d56f723d8ac56a108b6",
        "matched_blocks": [
            [
                1773,
                1808,
                "        try:\n            # Insert val at index for each column\n            for name, col, val, mask_ in izip(colnames, self.columns.values(), vals, mask):\n                # If the new row caused a change in self.ColumnClass then\n                # Column-based classes need to be converted first.  This is\n                # typical for adding a row with mask values to an unmasked table.\n                if isinstance(col, Column) and not isinstance(col, self.ColumnClass):\n                    col = self.ColumnClass(col, copy=False)\n\n                newcol = col.insert(index, val)\n                if not isinstance(newcol, BaseColumn):\n                    newcol.info.name = name\n                    if self.masked:\n                        newcol.mask = FalseArray(newcol.shape)\n\n                if len(newcol) != N + 1:\n                    raise ValueError('Incorrect length for column {0} after inserting {1}'\n                                     ' (expected {2}, got {3})'\n                                     .format(name, val, len(newcol), N + 1))\n                newcol.info.parent_table = self\n\n                # Set mask if needed\n                if self.masked:\n                    newcol.mask[index] = mask_\n\n                columns[name] = newcol\n\n        except Exception as err:\n            raise ValueError(\"Unable to insert row because of exception in column '{0}':\\n{1}\"\n                             .format(name, err))\n        else:\n            self.columns = columns\n\n            # Revert groups to default (ungrouped) state\n            if hasattr(self, '_groups'):\n                del self._groups"
            ]
        ]
    },
    {
        "blob_id": "9bf24903265c1bc14d6e5a9f7216a605a464b36c",
        "matched_blocks": [
            [
                54,
                63,
                "try:\n    from combi._python_toolbox.third_party.unittest2.signals import (\n        installHandler, registerResult, removeResult, removeHandler\n    )\nexcept ImportError:\n    # Compatibility with platforms that don't have the signal module\n    pass\nelse:\n    __all__.extend(['installHandler', 'registerResult', 'removeResult',\n                    'removeHandler'])"
            ]
        ]
    },
    {
        "blob_id": "014291a1cee41cd67c3c08d37f2569b903a00e6b",
        "matched_blocks": [
            [
                211,
                216,
                "    try:\n        mpl._get_executable_info(\"gs\")\n    except mpl.ExecutableNotFoundError:\n        pass\n    else:\n        converter['pdf'] = converter['eps'] = _GSConverter()"
            ],
            [
                217,
                222,
                "    try:\n        mpl._get_executable_info(\"inkscape\")\n    except mpl.ExecutableNotFoundError:\n        pass\n    else:\n        converter['svg'] = _SVGConverter()"
            ]
        ]
    },
    {
        "blob_id": "2f35fff3419098191fc15f33676c7e84cd49e36d",
        "matched_blocks": [
            [
                45,
                50,
                "    try:\n        op_clc.run('/', 1, 0)\n    except CalculatorError as exc:\n        assert type(exc.__cause__) == ZeroDivisionError\n    else:\n        raise AssertionError"
            ],
            [
                76,
                81,
                "    try:\n        op_clc.in_memory()\n    except CalculatorError as exc:\n        assert type(exc) is EmptyMemory\n    else:\n        raise AssertionError"
            ],
            [
                84,
                89,
                "    try:\n        op_clc.run(\"-\", 2)\n    except CalculatorError as exc:\n        assert type(exc) is EmptyMemory\n    else:\n        raise AssertionError"
            ],
            [
                92,
                97,
                "    try:\n        op_clc.run('^', 2, 3)\n    except CalculatorError as exc:\n        assert type(exc) == WrongOperation\n    else:\n        raise AssertionError"
            ],
            [
                100,
                105,
                "    try:\n        op_clc.run('+', param_1, param_2)\n    except CalculatorError as exc:\n        assert type(exc) == NotNumberArgument\n    else:\n        raise AssertionError"
            ]
        ]
    },
    {
        "blob_id": "0af258f665b55591b45499c6c802b90726deb6d8",
        "matched_blocks": [
            [
                1180,
                1186,
                "            try:\n                unocontext = resolver.resolve(\"uno:%s\" % op.connection)\n            except NoConnectException as e:\n                pass\n            else:\n                info(1, \"Existing %s listener found, nothing to do.\" % product.ooName)\n                return"
            ],
            [
                1037,
                1046,
                "                try:\n                    document.refresh()\n                    indexes = document.getDocumentIndexes()\n                except AttributeError:\n                    # the document doesn't implement the XRefreshable and/or\n                    # XDocumentIndexesSupplier interfaces\n                    break\n                else:\n                    for i in range(0, indexes.getCount()):\n                        indexes.getByIndex(i).update()"
            ]
        ]
    },
    {
        "blob_id": "60649a047ebbee6783e9aa2a8353da3376dbccc4",
        "matched_blocks": [
            [
                2024,
                2029,
                "    try:\n        compile(text, filename, \"exec\")\n    except (SyntaxError, TypeError):\n        return False\n    else:\n        return True"
            ],
            [
                613,
                654,
                "        try:\n            if ok_exists:\n                os.unlink(ok_file)\n            dirname = os.path.dirname(ok_file)\n            pkg_resources.py31compat.makedirs(dirname, exist_ok=True)\n            f = open(pth_file, \"w\")\n        except (OSError, IOError):\n            self.cant_write_to_target()\n        else:\n            try:\n                f.write(tmpl.format(**locals()))\n                f.close()\n                f = None\n                executable = sys.executable\n                if os.name == \"nt\":\n                    dirname, basename = os.path.split(executable)\n                    alt = os.path.join(dirname, \"pythonw.exe\")\n                    use_alt = (\n                        basename.lower() == \"python.exe\"\n                        and os.path.exists(alt)\n                    )\n                    if use_alt:\n                        # use pythonw.exe to avoid opening a console window\n                        executable = alt\n\n                from distutils.spawn import spawn\n\n                spawn([executable, \"-E\", \"-c\", \"pass\"], 0)\n\n                if os.path.exists(ok_file):\n                    log.info(\n                        \"TEST PASSED: %s appears to support .pth files\",\n                        instdir,\n                    )\n                    return True\n            finally:\n                if f:\n                    f.close()\n                if os.path.exists(ok_file):\n                    os.unlink(ok_file)\n                if os.path.exists(pth_file):\n                    os.unlink(pth_file)"
            ]
        ]
    },
    {
        "blob_id": "980c33a47c6ceef797f8d31e3d610483992d6419",
        "matched_blocks": [
            [
                460,
                469,
                "            try:\n                await asyncio.wait_for(self._search_now.wait(),\n                                       timeout=wait_time)\n            except asyncio.TimeoutError:\n                ...\n            else:\n                # New searches have been requested. Reset the interval between\n                # subseqent searches and force a check on the \"retirees\".\n                time_to_check_on_retirees = last_send_time\n                interval = common.MIN_RETRY_SEARCHES_INTERVAL"
            ],
            [
                2000,
                2008,
                "            try:\n                command = self.pv.channel.unsubscribe(subscriptionid)\n            except ca.CaprotoKeyError:\n                pass\n            except ca.CaprotoValueError:\n                self.log.exception('TODO')\n            else:\n                await self.pv.circuit_manager.send(command,\n                                                   extra={'pv': self.pv.name})"
            ],
            [
                261,
                287,
                "            try:\n                name, queue = self.results.received_search_response(\n                    cid, address)\n            except UnknownSearchResponse:\n                self.log.debug('Unknown search response cid=%d', cid)\n            except DuplicateSearchResponse as ex:\n                if len(ex.addresses) <= 1:\n                    return\n\n                name = ex.name\n                accepted_address = ex.addresses[0]\n                other_addresses = ', '.join(\n                    '%s:%d' % addr for addr in ex.addresses[1:]\n                )\n\n                search_logger.warning(\n                    \"PV %s with cid %d found on multiple servers. \"\n                    \"Accepted address is %s:%d.  Also found on %s\",\n                    name, cid, *accepted_address, other_addresses,\n                    extra={\n                        'pv': name,\n                        'their_address': accepted_address,\n                        'our_address': self.broadcaster.client_address,\n                    },\n                )\n            else:\n                queues[(queue, address)].append(name)"
            ],
            [
                1108,
                1120,
                "            try:\n                sub = self.subscriptions[command.subscriptionid]\n            except KeyError:\n                # This subscription has been removed. We assume that this\n                # response was in flight before the server processed our\n                # unsubscription.\n                pass\n            else:\n                # This method submits jobs to the Contexts's\n                # ThreadPoolExecutor for user callbacks.\n                sub.process(command)\n                tags = tags.copy()\n                tags['pv'] = sub.pv.name"
            ]
        ]
    },
    {
        "blob_id": "7367d4ad520688d3659a5c083d27fe2bc42f0e0c",
        "matched_blocks": [
            [
                65,
                74,
                "                try:\n                    kwargs = {k: encodeutils.safe_decode(v)\n                              for k, v in kwargs.items()}\n                except UnicodeDecodeError:\n                    # NOTE(jamielennox): This is the complete failure case\n                    # at least by showing the template we have some idea\n                    # of where the error is coming from\n                    message = self.message_format\n                else:\n                    message = self.message_format % kwargs"
            ]
        ]
    },
    {
        "blob_id": "159bafbca9d8225e91b350e8bd633513f6f0b18b",
        "matched_blocks": [
            [
                13,
                27,
                "    try:\n        num_tickets = int(num_tickets)\n        if num_tickets > tickets_remaining:\n            raise ValueError(\"Sorry, {}! You tried to purchase {} tickets, but only {} are available...\".format(name, num_tickets, tickets_remaining))\n    except ValueError as err:\n        print(\"An error occourred: {} Please try again.\".format(err))\n    else:\n        amount_due = calculate_price(num_tickets)\n        print(\"Final price: ${}\".format(amount_due))\n        proceed = input(\"{}, would you like to proceed to checkout? (Y/N) \".format(name))\n        if proceed.lower() == 'y':\n            print(\"SOLD!\")\n            tickets_remaining -= num_tickets\n        else:\n            print(\"Thanks anyway, {}!\".format(name))"
            ]
        ]
    },
    {
        "blob_id": "0d97b7a0ec8e8b977b8369a64d5521329bae48f6",
        "matched_blocks": [
            [
                10,
                15,
                "    try:\n        __import__(module_name)\n    except ImportError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "8c29c649b3978019eeed3be8f5dc569bdb79d861",
        "matched_blocks": [
            [
                94,
                108,
                "    try:\n        translation_f = split_format_specifiers(\n            find_format_specifiers(translation))\n    except IndexError:\n        errors.append(\"Parse error in translation for '%s': '%s'\" % (\n            sanitize_string(source), sanitize_string(translation)))\n        return False\n    else:\n        if source_f != translation_f:\n            if numerus and source_f == (set(), ['n']) and translation_f == (set(), []) and translation.find('%') == -1:\n                # Allow numerus translations to omit %n specifier (usually when it only has one possible value)\n                return True\n            errors.append(\"Mismatch between '%s' and '%s'\" % (\n                sanitize_string(source), sanitize_string(translation)))\n            return False"
            ]
        ]
    },
    {
        "blob_id": "ee44bd9403d965734f8cccd64c37a5995b76953c",
        "matched_blocks": [
            [
                55,
                62,
                "            try:\n                if (not module.check_mode):\n                    client.delete_security_group(GroupId=group['GroupId'])\n            except botocore.exceptions.ClientError as e:\n                module.fail_json(msg=(\"Unable to delete security group '%s' - %s\" % (group, e)), exception=traceback.format_exc(), **camel_dict_to_snake_dict(e.response))\n            else:\n                group = None\n                changed = True"
            ]
        ]
    },
    {
        "blob_id": "8ec304ea61f54ca67416aaf806c559cc17a859fc",
        "matched_blocks": [
            [
                621,
                627,
                "        try:\n            self.field.name\n        except FieldError:\n            pass\n        else:\n            raise FieldError('name/attribute_name/source should '\n                             'not be passed to a wrapped field.')"
            ]
        ]
    },
    {
        "blob_id": "55b337fac4106e2175784ea24e38d1e3950fe0d4",
        "matched_blocks": [
            [
                69,
                80,
                "    try:\n        with open(opj(user_config_dir, \"user-dirs.dirs\")) as fp:\n            _udc = fp.read()\n    except IOError as e:\n        log.warning(\"failed to load user dirs config (%s)\" % e)\n        media_dirs[\"audio\"] = [\"~/Music\"]\n        media_dirs[\"video\"] = [\"~/Videos\"]\n    else:\n        m = re.search(r'XDG_MUSIC_DIR=\"([^\"]+)', _udc)\n        media_dirs[\"audio\"] = [m and m.groups()[0] or \"~/Music\"]\n        m = re.search(r'XDG_VIDEOS_DIR=\"([^\"]+)', _udc)\n        media_dirs[\"video\"] = [m and m.groups()[0] or \"~/Video\"]"
            ],
            [
                182,
                195,
                "        try:\n            bus = dbus.SystemBus()\n            obj = bus.get_object(_DBA_NAME, _DBA_PATH_SERVER)\n            server = dbus.Interface(obj, _DBA_INTERFACE_SERVER)\n            obj = bus.get_object(_DBA_NAME, server.EntryGroupNew())\n            group = dbus.Interface(obj, _DBA_INTERFACE_ENTRY_GROUP)\n            group.AddService(-1, -1, 0, \"Remuco %s\" % player, _ZC_TYPE, \"local\",\n                             \"\", port, \"\")\n            group.Commit()\n        except dbus.DBusException as e:\n            log.warning(\"failed to publish zeroconf service (%s)\" % e)\n            group = None\n        else:\n            log.debug(\"published zeroconf service\")"
            ]
        ]
    },
    {
        "blob_id": "a67ef990e808a61cbd88a96d5fd1e42d2ab3f62f",
        "matched_blocks": [
            [
                90,
                104,
                "            try:\n                result = self.client.cluster.health(wait_for_status=expected_cluster_status, wait_for_relocating_shards=0, timeout=\"3s\")\n            except (socket.timeout, elasticsearch.exceptions.ConnectionError, elasticsearch.exceptions.TransportError):\n                pass\n            else:\n                reached_cluster_status = result[\"status\"]\n                relocating_shards = result[\"relocating_shards\"]\n                logger.info(\"GOT: %s\" % str(result))\n                logger.info(\"ALLOC:\\n%s\" % self.client.cat.allocation(v=True))\n                logger.info(\"RECOVERY:\\n%s\" % self.client.cat.recovery(v=True))\n                logger.info(\"SHARDS:\\n%s\" % self.client.cat.shards(v=True))\n                if reached_cluster_status == expected_cluster_status and relocating_shards == 0:\n                    return reached_cluster_status, relocating_shards\n                else:\n                    time.sleep(0.5)"
            ]
        ]
    },
    {
        "blob_id": "48b3f79c1d01f273cc5b97875cce94dba4849cfb",
        "matched_blocks": [
            [
                42,
                55,
                "try:\n    afwdataDir = lsst.utils.getPackageDir(\"afwdata\")\nexcept pexExcept.NotFoundError:\n    afwdataDir = None\n    dataDir = None\nelse:\n    dataDir = os.path.join(afwdataDir, \"data\")\n    originalExposureName = \"medexp.fits\"\n    originalExposurePath = os.path.join(dataDir, originalExposureName)\n    subExposureName = \"medsub.fits\"\n    subExposurePath = os.path.join(dataDir, originalExposureName)\n    originalFullExposureName = os.path.join(\n        \"CFHT\", \"D4\", \"cal-53535-i-797722_1.fits\")\n    originalFullExposurePath = os.path.join(dataDir, originalFullExposureName)"
            ]
        ]
    },
    {
        "blob_id": "cab5ec73309abc6f8c1a012ccccd0e4dc50f50b4",
        "matched_blocks": [
            [
                37,
                46,
                "    try:\n        # It is present\n        dashboard.left_nav.gns.wait_until_absent(\"settings\")\n    except GuiWidgetForLabelPresentError as e:\n        print(\"Exception as Expected\")\n        print(str(e))\n    except Exception as e:\n        raise Exception(\"Unexpected exception raise: \", str(e))\n    else:\n        raise Exception(\"Exception not raised.\")"
            ],
            [
                52,
                61,
                "    try:\n        # It is present\n        dashboard.left_nav.wait_until_absent(link=\"Settings\")\n    except GuiWidgetPresentError as e:\n        print(\"Exception as Expected\")\n        print(str(e))\n    except Exception as e:\n        raise Exception(\"Unexpected exception raise: \", str(e))\n    else:\n        raise Exception(\"Exception not raised.\")"
            ]
        ]
    },
    {
        "blob_id": "17877800503b0a64ce2972444c9fa06f1cd529eb",
        "matched_blocks": [
            [
                801,
                815,
                "        try:\n            parsed_new_label.parse()\n        except InvalidTitle:\n            pass\n        else:\n            parsed_link_title = title_section(parsed_new_label)\n            new_link_title = title_section(new_link)\n            # compare title, but only with parts if linktrail works\n            if not linktrail.sub('',\n                                 parsed_link_title[len(new_link_title):]):\n                # TODO: This must also compare everything that was used as a\n                #       prefix (in case insensitive)\n                must_piped = (\n                    not parsed_link_title.startswith(new_link_title)\n                    or parsed_new_label.namespace != new_link.namespace)"
            ],
            [
                1276,
                1287,
                "        try:\n            cat = pywikibot.Category(pywikibot.Link(\n                                     '%s:%s' %\n                                     (match.group('namespace'), title),\n                                     site),\n                                     sort_key=sortKey)\n        except InvalidTitle:\n            # Category title extracted contains invalid characters\n            # Likely due to on-the-fly category name creation, see T154309\n            pywikibot.warning('Invalid category title extracted: %s' % title)\n        else:\n            result.append(cat)"
            ],
            [
                854,
                859,
                "            try:\n                next_heading = headings[i + 1]\n            except IndexError:\n                contents.append(text[heading.end:])\n            else:\n                contents.append(text[heading.end:next_heading.start])"
            ],
            [
                2183,
                2190,
                "            try:\n                value = self.origNames2monthNum[dateDict['month']['value']]\n            except KeyError:\n                pywikibot.output('incorrect month name \"%s\" in page in site %s'\n                                 % (dateDict['month']['value'], self.site))\n                raise KeyError\n            else:\n                dateDict['month']['value'] = value"
            ]
        ]
    },
    {
        "blob_id": "42499fc2f051b56c4c4ec3113f61c2d0327f6fe2",
        "matched_blocks": [
            [
                95,
                102,
                "    try:\n        value = clause._limit_offset_value\n    except AttributeError:\n        raise exc.CompileError(\n            \"This SELECT structure does not use a simple \"\n            \"integer value for %s\" % attrname)\n    else:\n        return util.asint(value)"
            ]
        ]
    },
    {
        "blob_id": "46bb51490ebff49d214f39c06b122e5380a53c96",
        "matched_blocks": [
            [
                49,
                63,
                "      try:\n        response = func(*args, **kwargs)\n      except (httpclient.HTTPException, socket.error, urlerror.URLError) as e:\n        time.sleep(5)\n        if (isinstance(e, urlerror.HTTPError) and\n            e.getcode() == httpclient.SERVICE_UNAVAILABLE):\n          continue\n        elif isinstance(e, socket.timeout):\n          continue\n        raise\n      else:\n        if response.getcode() == httpclient.OK:\n          return response\n        else:\n          raise StatusException(response)"
            ]
        ]
    },
    {
        "blob_id": "89d363676bee6d1b2d3d8bfa6606163fdb344a24",
        "matched_blocks": [
            [
                26,
                31,
                "\t\t\ttry:\n\t\t\t\tk = filter_args[k]\n\t\t\texcept KeyError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tlookup[k] = clean_query_value(v)"
            ]
        ]
    },
    {
        "blob_id": "a9ce49aadae5bb7546d8fffefc7834f013afb78e",
        "matched_blocks": [
            [
                2789,
                2796,
                "            try:\n                np = npath.index(nloc, p + 1)\n            except ValueError:\n                break\n            else:\n                del npath[np], path[np]\n                # ha!\n                p = np"
            ],
            [
                861,
                879,
                "                try:\n                    resolvees = shadow_set.resolve(req, env, installer)\n\n                except ResolutionError as v:\n                    # save error info\n                    error_info[dist] = v\n                    if fallback:\n                        # try the next older version of project\n                        continue\n                    else:\n                        # give up on this project, keep going\n                        break\n\n                else:\n                    list(map(shadow_set.add, resolvees))\n                    distributions.update(dict.fromkeys(resolvees))\n\n                    # success, no need to try any more versions of this project\n                    break"
            ]
        ]
    },
    {
        "blob_id": "c7784ce9b4355dd34e6aa6bffd236cddc92c45b3",
        "matched_blocks": [
            [
                131,
                137,
                "        try:\n            reason = kwargs.pop('reason')\n        except KeyError:\n            pass\n        else:\n            if reason:\n                headers['X-Audit-Log-Reason'] = _uriquote(reason, safe='/ ')"
            ]
        ]
    },
    {
        "blob_id": "c9f5edd190669adc51c576f8c808c25d6cb5bb27",
        "matched_blocks": [
            [
                12,
                17,
                "            try:\n                message_id = message_desc.enum_values_by_name['ID'].number\n            except KeyError:\n                pass\n            else:\n                yield message_id, getattr(module, name)"
            ]
        ]
    },
    {
        "blob_id": "67ce5f27dab128f9f85ad58351accbfd05ed465a",
        "matched_blocks": [
            [
                21,
                31,
                "    try:\n        import simplejson\n    except Exception:\n        try:\n            import json\n        except Exception:\n            raise Exception(\"Can not import any json library\")\n        else:\n            _jsonEnode = json.dumps\n    else:\n        _jsonEnode = simplejson.dumps"
            ],
            [
                24,
                29,
                "        try:\n            import json\n        except Exception:\n            raise Exception(\"Can not import any json library\")\n        else:\n            _jsonEnode = json.dumps"
            ]
        ]
    },
    {
        "blob_id": "ac6de3c65242858fd243ac9a16b29ad30476d158",
        "matched_blocks": [
            [
                428,
                455,
                "    try:\n        resp = _get_html_response(url, session=session)\n    except _NotHTTP:\n        logger.warning(\n            'Skipping page %s because it looks like an archive, and cannot '\n            'be checked by a HTTP HEAD request.', link,\n        )\n    except _NotHTML as exc:\n        logger.warning(\n            'Skipping page %s because the %s request got Content-Type: %s.'\n            'The only supported Content-Type is text/html',\n            link, exc.request_desc, exc.content_type,\n        )\n    except NetworkConnectionError as exc:\n        _handle_get_page_fail(link, exc)\n    except RetryError as exc:\n        _handle_get_page_fail(link, exc)\n    except SSLError as exc:\n        reason = \"There was a problem confirming the ssl certificate: \"\n        reason += str(exc)\n        _handle_get_page_fail(link, reason, meth=logger.info)\n    except requests.ConnectionError as exc:\n        _handle_get_page_fail(link, f\"connection error: {exc}\")\n    except requests.Timeout:\n        _handle_get_page_fail(link, \"timed out\")\n    else:\n        return _make_html_page(resp,\n                               cache_link_parsing=link.cache_link_parsing)"
            ]
        ]
    },
    {
        "blob_id": "712e512fcf676ef9f4d1d9531b4b35ed3ccc8678",
        "matched_blocks": [
            [
                511,
                528,
                "                try:\n                    await self._async_establish_connection()\n                except AvrTimoutError:\n                    _LOGGER.debug(\n                        \"%s: Timeout exception on telnet reconnect\",\n                        self.host\n                    )\n                except AvrNetworkError as ex:\n                    _LOGGER.debug(\"%s: %s\", self.host, ex, exc_info=True)\n                except Exception:    # pylint: disable=broad-except\n                    _LOGGER.error(\n                        \"%s: Unexpected exception on telnet reconnect\",\n                        self.host,\n                        exc_info=True\n                    )\n                else:\n                    _LOGGER.info(\"%s: Telnet reconnected\", self.host)\n                    return"
            ]
        ]
    },
    {
        "blob_id": "71f3c682ec9645119c00b1857f62d3e2d4bef92b",
        "matched_blocks": [
            [
                3238,
                3247,
                "        try:\n            sorter = np.lexsort((val, ids))\n        except TypeError:  # catches object dtypes\n            assert val.dtype == object, \\\n                'val.dtype must be object, got %s' % val.dtype\n            val, _ = algorithms.factorize(val, sort=False)\n            sorter = np.lexsort((val, ids))\n            _isna = lambda a: a == -1\n        else:\n            _isna = isna"
            ]
        ]
    },
    {
        "blob_id": "e801407fcc8ebb74705772faad89f977063db781",
        "matched_blocks": [
            [
                16,
                21,
                "try:\n  from inverse_covariance import quic\nexcept ImportError:\n  HAS_SKGGM = False\nelse:\n  HAS_SKGGM = True"
            ]
        ]
    },
    {
        "blob_id": "38db5ea716fb55495b42848a7a8c9387ebfafca4",
        "matched_blocks": [
            [
                267,
                272,
                "        try:\n            schema = spec['$schema']\n        except KeyError:\n            major_version = None\n        else:\n            major_version = schema.split('/')[-1].split('.')[0].lstrip('v')"
            ]
        ]
    },
    {
        "blob_id": "1ac92f3f02e685cc0ce22bf8ebaa800fb95796df",
        "matched_blocks": [
            [
                148,
                155,
                "            try:\n                addon_data = parse_addon(file_, check=False)\n            except ValidationError as form_error:\n                log.info('could not parse addon for upload {}: {}'\n                         .format(file_.pk, form_error))\n                addon_data = None\n            else:\n                file_.update(version=addon_data.get('version'))"
            ]
        ]
    },
    {
        "blob_id": "31015086cb3c4c905af5db3e7c2ca5c376ff75d5",
        "matched_blocks": [
            [
                35,
                40,
                "try:\n    num=float(input(\"\\nInput the number: \"))\nexcept ValueError:\n    print(\"It`s not a number!\")\nelse:\n    print(\"You entered number: \",num)"
            ]
        ]
    },
    {
        "blob_id": "1ed2df321002914cdd3a4ee1a29fc9e886584572",
        "matched_blocks": [
            [
                62,
                69,
                "        try:\n            driver.find_element_by_id('login-btn')\n        except NoSuchElementException:  # if it does not exist the login button, which means you have logged in\n            logged_in = True\n        else:\n            print('Wrong email or password. Please try again.')\n            email = input('Enter your email: ')\n            password = getpass.getpass()"
            ]
        ]
    },
    {
        "blob_id": "cdc01dc644ff793aa38e047c231c8265a0729538",
        "matched_blocks": [
            [
                722,
                730,
                "        try:\n            record_id = form.vars.id\n        except AttributeError:\n            pass\n        else:\n            otable = db.org_organisation\n            query = (otable.id == record_id) & \\\n                    (otable.root_organisation == None)\n            db(query).update(root_organisation = otable.id)"
            ],
            [
                4540,
                4550,
                "            try:\n                instance_type = row[\"org_site.instance_type\"]\n                id = row[instance_type].id\n            except AttributeError:\n                return v\n            else:\n                c, f = instance_type.split(\"_\", 1)\n                return A(v, _href=URL(c=c, f=f, args=[id],\n                                      # remove the .aaData extension in paginated views\n                                      extension=\"\"\n                                      ))"
            ]
        ]
    },
    {
        "blob_id": "42c75c056f242e7e057cfeaa7d10706ce2698b87",
        "matched_blocks": [
            [
                48,
                55,
                "    try:\n        res = requests.post(url=url, headers=headers, data=payload)\n        token = json.loads(res.text)[\"data\"]['token']\n    except:\n        logger.info(\"\u9752\u9f99\u767b\u5f55\u5931\u8d25, \u8bf7\u68c0\u67e5\u9762\u677f\u72b6\u6001!\")\n        sys.exit(1)\n    else:\n        return token"
            ],
            [
                180,
                198,
                "    try:\n        res = requests.post(url=url, params=params, headers=headers, data=data, verify=False, timeout=10)\n        res_json = json.loads(res.text)\n        # logger.info(res_json)\n        tokenKey = res_json['tokenKey']\n        # logger.info(\"Token:\", tokenKey)\n    except:\n        try:\n            res = requests.post(url=url, params=params, headers=headers, data=data, verify=False, timeout=20)\n            res_json = json.loads(res.text)\n            # logger.info(res_json)\n            tokenKey = res_json['tokenKey']\n            # logger.info(\"Token:\", tokenKey)\n            return appjmp(wskey, tokenKey)\n        except:\n            logger.info(\"WSKEY\u8f6c\u6362\u63a5\u53e3\u51fa\u9519, \u8bf7\u7a0d\u540e\u5c1d\u8bd5, \u811a\u672c\u9000\u51fa\")\n            sys.exit(1)\n    else:\n        return appjmp(wskey, tokenKey)"
            ],
            [
                293,
                301,
                "    try:\n        sock.connect(('127.0.0.1', port))\n    except:\n        # logger.info(port, \"\u7aef\u53e3\u68c0\u6d4b\u5931\u8d25\")\n        sock.close()\n        return False\n    else:\n        sock.close()\n        return True"
            ],
            [
                239,
                261,
                "        try:\n            res = requests.get(url=url, verify=False, timeout=20)\n        except requests.exceptions.ConnectTimeout:\n            logger.info(\"\\n\u83b7\u53d6Sign\u8d85\u65f6, \u6b63\u5728\u91cd\u8bd5!\" + str(i))\n            time.sleep(1)\n        except requests.exceptions.ReadTimeout:\n            logger.info(\"\\n\u83b7\u53d6Sign\u8d85\u65f6, \u6b63\u5728\u91cd\u8bd5!\" + str(i))\n            time.sleep(1)\n        except Exception as err:\n            logger.info(str(err) + \"\\n\u672a\u77e5\u9519\u8bef, \u9000\u51fa\u811a\u672c!\")\n            sys.exit(1)\n        else:\n            try:\n                sign_list = json.loads(res.text)\n            except:\n                logger.info(\"Sign Json\u9519\u8bef\")\n                sys.exit(1)\n            else:\n                svv = sign_list['sv']\n                stt = sign_list['st']\n                suid = sign_list['uuid']\n                jign = sign_list['sign']\n                return svv, stt, suid, jign"
            ],
            [
                388,
                404,
                "        try:\n            res = requests.get(url=url, verify=False, timeout=20).text\n        except requests.exceptions.ConnectTimeout:\n            logger.info(\"\\n\u83b7\u53d6\u4e91\u7aef\u53c2\u6570\u8d85\u65f6, \u6b63\u5728\u91cd\u8bd5!\" + str(i))\n        except requests.exceptions.ReadTimeout:\n            logger.info(\"\\n\u83b7\u53d6\u4e91\u7aef\u53c2\u6570\u8d85\u65f6, \u6b63\u5728\u91cd\u8bd5!\" + str(i))\n        except Exception as err:\n            logger.info(str(err) + \"\\n\u672a\u77e5\u9519\u8bef, \u9000\u51fa\u811a\u672c!\")\n            sys.exit(1)\n        else:\n            try:\n                c_info = json.loads(res)\n            except:\n                logger.info(\"\u4e91\u7aef\u53c2\u6570\u89e3\u6790\u5931\u8d25\")\n                sys.exit(1)\n            else:\n                return c_info"
            ],
            [
                251,
                261,
                "            try:\n                sign_list = json.loads(res.text)\n            except:\n                logger.info(\"Sign Json\u9519\u8bef\")\n                sys.exit(1)\n            else:\n                svv = sign_list['sv']\n                stt = sign_list['st']\n                suid = sign_list['uuid']\n                jign = sign_list['sign']\n                return svv, stt, suid, jign"
            ],
            [
                398,
                404,
                "            try:\n                c_info = json.loads(res)\n            except:\n                logger.info(\"\u4e91\u7aef\u53c2\u6570\u89e3\u6790\u5931\u8d25\")\n                sys.exit(1)\n            else:\n                return c_info"
            ]
        ]
    },
    {
        "blob_id": "ea0437398c5d2f0e423bd627eaa886ffd929f096",
        "matched_blocks": [
            [
                77,
                83,
                "try:\n    import psycopg2\n    import psycopg2.extras\nexcept ImportError:\n    postgresqldb_found = False\nelse:\n    postgresqldb_found = True"
            ]
        ]
    },
    {
        "blob_id": "bb5bf27549da60b54e5a034ea948dda8c9c4d2d6",
        "matched_blocks": [
            [
                87,
                92,
                "            try:\n                verta.Client(host, max_retries=0)\n            except requests.HTTPError as e:\n                assert e.request.url.split(':', 1)[0] == \"http\"\n            else:\n                raise RuntimeError(\"faulty test; expected error\")"
            ],
            [
                95,
                100,
                "            try:\n                verta.Client(\"http://{}\".format(host), max_retries=0)\n            except requests.HTTPError as e:\n                assert e.request.url.split(':', 1)[0] == \"http\"\n            else:\n                raise RuntimeError(\"faulty test; expected error\")"
            ],
            [
                103,
                108,
                "            try:\n                verta.Client(\"https://{}\".format(host), max_retries=0)\n            except requests.HTTPError as e:\n                assert e.request.url.split(':', 1)[0] == \"https\"\n            else:\n                raise RuntimeError(\"faulty test; expected error\")"
            ]
        ]
    },
    {
        "blob_id": "84b884376ef9c3408b64b2418c9bdb6bf06775f0",
        "matched_blocks": [
            [
                12,
                17,
                "try:\n\timport tabulate\nexcept ImportError:\n\thave_tabulate = False\nelse:\n\thave_tabulate = True"
            ]
        ]
    },
    {
        "blob_id": "1231bd89f2f237302e83353f9c48dc96e2f1174c",
        "matched_blocks": [
            [
                700,
                708,
                "        try:\n            cat = site.expand_text(\n                site.mediawiki_message(maintenance_category))\n        except:\n            pass\n        else:\n            cat = pywikibot.Category(site, \"{0!s}:{1!s}\".format(\n                site.namespaces.CATEGORY, cat))\n            gen = cat.articles(namespaces=genFactory.namespaces or [0])"
            ]
        ]
    },
    {
        "blob_id": "f57094df06d8ea290d2c443f27c9e74a6c6f9829",
        "matched_blocks": [
            [
                2083,
                2090,
                "        try:\n            row = next(rows)\n        except StopIteration:\n            # no rows\n            raise tds_base.DataError(\"Cannot infer columns from rows for TVP because there are no rows\")\n        else:\n            # put row back\n            self._rows = itertools.chain([row], rows)"
            ]
        ]
    },
    {
        "blob_id": "3c6d1df4a078962da98463d4f64e2fde79dabb3f",
        "matched_blocks": [
            [
                215,
                220,
                "    try:\n        import tensorflow\n    except ImportError:\n        return \"\"\n    else:\n        return tensorflow.__version__"
            ],
            [
                58,
                64,
                "        try:\n            from tensorboardX import SummaryWriter\n        except ImportError:\n            pass\n        else:\n            self.log.debug(\"wrapping tensorboardX.SummaryWriter.add_scalar\")\n            python_util.listen_method(SummaryWriter, \"add_scalar\", self._handle_scalar)"
            ],
            [
                67,
                79,
                "        try:\n            import tensorflow as _\n        except ImportError:\n            pass\n        else:\n            util.try_apply(\n                [\n                    self._try_listen_tf_v2,\n                    self._try_listen_tf_v1,\n                    self._try_listen_tf_legacy,\n                    self._listen_tf_failed,\n                ]\n            )"
            ],
            [
                115,
                127,
                "        try:\n            # pylint: disable=import-error,no-name-in-module\n            from tensorflow.compat.v1.summary import FileWriter\n        except Exception as e:\n            self.log.debug(\n                \"error importing tensorflow.compat.v1.summary.FileWriter: %s\", e\n            )\n            raise util.TryFailed()\n        else:\n            self.log.debug(\n                \"wrapping tensorflow.compat.v1.summary.FileWriter.add_summary\"\n            )\n            python_util.listen_method(FileWriter, \"add_summary\", self._handle_summary)"
            ],
            [
                132,
                140,
                "        try:\n            # pylint: disable=import-error,no-name-in-module\n            from tensorflow.summary import FileWriter\n        except Exception as e:\n            self.log.debug(\"error importing tensorflow.summary.FileWriter: %s\", e)\n            raise util.TryFailed()\n        else:\n            self.log.debug(\"wrapping tensorflow.summary.FileWriter.add_summary\")\n            python_util.listen_method(FileWriter, \"add_summary\", self._handle_summary)"
            ]
        ]
    },
    {
        "blob_id": "a48cc5f99932ad1cb65d9cf20b449ded9b64ec57",
        "matched_blocks": [
            [
                64,
                71,
                "        try:\n            len(X())\n        except OverflowError:\n            # 32-bit\n            MAXSIZE = int((1 << 31) - 1)\n        else:\n            # 64-bit\n            MAXSIZE = int((1 << 63) - 1)"
            ]
        ]
    },
    {
        "blob_id": "673aa93a3b26e9d6bca5e41668f943af3b6fbab9",
        "matched_blocks": [
            [
                111,
                137,
                "        try:\n            response, next_state, side_effect = self._find(command, sudo)\n        except KeyError:\n            page = command.args.get('page')\n            if page == 0:\n                no_page_args = dict((k, v) for k, v in command.args.items() if k not in ['page', 'per_page'])\n                try:\n                    return self.call(command._replace(args=no_page_args))\n                except MockedEndpointNotFound:\n                    pass  # raise the right exception below\n            elif page:  # page is not None\n                try:\n                    # only return an empty list if the command exists\n                    self.call(command.for_page(0))\n                except MockedEndpointNotFound:\n                    pass  # raise the right exception below\n                else:\n                    return []\n\n            raise MockedEndpointNotFound(command, sudo, self.state)\n        else:\n            if next_state:\n                self.state = next_state\n\n            if side_effect:\n                side_effect()\n            return response()"
            ],
            [
                122,
                128,
                "                try:\n                    # only return an empty list if the command exists\n                    self.call(command.for_page(0))\n                except MockedEndpointNotFound:\n                    pass  # raise the right exception below\n                else:\n                    return []"
            ]
        ]
    },
    {
        "blob_id": "bf6968b3fe93f9bfdc172b22c5e718cc65dddd99",
        "matched_blocks": [
            [
                5437,
                5443,
                "        try:\n            self.chunks\n        except ValueError:  # \"inconsistent chunks\"\n            pass\n        else:\n            # No variables with dask backend, or all chunks are already aligned\n            return self.copy()"
            ]
        ]
    },
    {
        "blob_id": "87a0e4458217736a0b6f590fc8e23a0f56189a86",
        "matched_blocks": [
            [
                196,
                203,
                "            try:\n                return self.env[env_key]\n            except KeyError:\n                return None\n            else:\n                logging.debug(\n                    f\"Found ENV variable {env_key} for {self._env_namespace}:{name}\"\n                )"
            ]
        ]
    },
    {
        "blob_id": "198ee3129c4d1c35e445b785a839c9e4640bc1b0",
        "matched_blocks": [
            [
                9,
                15,
                "try:\n    data = pandas.read_csv(\"data/words_to_learn.csv\")\nexcept FileNotFoundError:\n    original_data = pandas.read_csv(\"data/french_words.csv\")\n    to_learn = original_data.to_dict(orient=\"records\")\nelse:\n    to_learn = data.to_dict(orient=\"records\")"
            ]
        ]
    },
    {
        "blob_id": "968a997606f2e8b3e7ac7c062294d75ec4d208c0",
        "matched_blocks": [
            [
                702,
                711,
                "    try:\n        follow_request = models.UserFollowRequest.objects.get(\n            user_subject=requester,\n            user_object=request.user\n        )\n    except models.UserFollowRequest.DoesNotExist:\n        # Request already dealt with.\n        pass\n    else:\n        outgoing.handle_accept(follow_request)"
            ]
        ]
    },
    {
        "blob_id": "354335a4af4d357ab0f090ed34153d0b327c5635",
        "matched_blocks": [
            [
                39,
                58,
                "        try:\n            self.hub = phue.Bridge(\n                ip_addr, config_file_path=os.path.join(os.getcwd(), 'bridges'))\n        except phue.PhueRegistrationException:\n            self.poly.send_error('IP Address OK. Node Server not registered.')\n            return False\n        except Exception:\n            self.poly.send_error('Cannot find hub at {}'.format(ip_addr))\n            return False  # bad ip Addressse:\n        else:\n            # ensure hub is connectable\n            api = self._get_api()\n\n            if api:\n                hub.set_driver('GV5', 1)\n                hub.report_driver()\n                return True\n            else:\n                self.hub = None\n                return False"
            ]
        ]
    },
    {
        "blob_id": "f40e634544428a621295a1dd266baea981118fd8",
        "matched_blocks": [
            [
                45,
                62,
                "try:\n    from django.core.exceptions import ImproperlyConfigured\nexcept ImportError:\n    DjangoHttpRequest = None\n    RestFrameworkRequest = None\n\nelse:\n    try:\n        from django.http import HttpRequest as DjangoHttpRequest\n    except (ImportError, ImproperlyConfigured):\n        DjangoHttpRequest = None\n\n    try:\n        from rest_framework.request import Request as RestFrameworkRequest\n    except (ImportError, ImproperlyConfigured):\n        RestFrameworkRequest = None\n\n    del ImproperlyConfigured"
            ],
            [
                813,
                823,
                "    try:\n        person_data = _build_person_data(request)\n    except Exception as e:\n        log.exception(\"Exception while building person data for Rollbar payload: %r\", e)\n    else:\n        if person_data:\n            if not SETTINGS['capture_username'] and 'username' in person_data:\n                person_data['username'] = None\n            if not SETTINGS['capture_email'] and 'email' in person_data:\n                person_data['email'] = None\n            data['person'] = person_data"
            ],
            [
                1012,
                1019,
                "    try:\n        request_data = _build_request_data(request)\n    except Exception as e:\n        log.exception(\"Exception while building request_data for Rollbar payload: %r\", e)\n    else:\n        if request_data:\n            _filter_ip(request_data, SETTINGS['capture_ip'])\n            data['request'] = request_data"
            ],
            [
                1549,
                1563,
                "    try:\n        json_data = json.loads(data)\n    except (TypeError, ValueError):\n        log.exception('Could not decode Rollbar api response:\\n%s', data)\n        raise ApiException('Request to %s returned invalid JSON response', path)\n    else:\n        if json_data.get('err'):\n            raise ApiError(json_data.get('message') or 'Unknown error')\n\n        result = json_data.get('result', {})\n\n        if 'page' in result:\n            return PagedResult(access_token, path, result['page'], params, result, endpoint=endpoint)\n        else:\n            return Result(access_token, path, params, result)"
            ]
        ]
    },
    {
        "blob_id": "6a88d8cb0858eb1d9019503f33ad6a8fc118c03e",
        "matched_blocks": [
            [
                11,
                16,
                "try:\n    from scipy import stats\nexcept ImportError:  # pragma: no cover\n    HAS_SCIPY = False\nelse:\n    HAS_SCIPY = True"
            ]
        ]
    },
    {
        "blob_id": "e4944b1b43ee05a56b2e875b6344b52e18ed8f74",
        "matched_blocks": [
            [
                117,
                142,
                "        try:\n            request_json = json.loads(request.body.decode(\"utf-8\"))\n            secret = request_json[\"secret\"]\n            serial_number = request_json[\"serial_number\"]\n            uuid = request_json[\"uuid\"]\n            es_request = verify_enrollment_secret(\n                \"monolith_enrollment\", secret,\n                user_agent, ip, serial_number, uuid\n            )\n        except (KeyError, ValueError, EnrollmentSecretVerificationFailed):\n            raise SuspiciousOperation\n        else:\n            # get or create enrolled machine\n            enrolled_machine, enrolled_machine_created = EnrolledMachine.objects.get_or_create(\n                enrollment=es_request.enrollment_secret.monolith_enrollment,\n                serial_number=serial_number,\n                defaults={\"token\": get_random_string(64)}\n            )\n\n            # apply enrollment secret tags\n            for tag in es_request.enrollment_secret.tags.all():\n                MachineTag.objects.get_or_create(serial_number=serial_number, tag=tag)\n\n            # post event\n            post_monolith_enrollment_event(serial_number, user_agent, ip,\n                                           {'action': \"enrollment\" if enrolled_machine_created else \"re-enrollment\"})"
            ],
            [
                1053,
                1062,
                "        try:\n            printer_ppd = PrinterPPD.objects.get_with_token(kwargs[\"token\"])\n        except ValueError:\n            logger.error(\"Invalid token %s\", kwargs[\"token\"])\n            raise Http404\n        except PrinterPPD.DoesNotExist:\n            logger.warning(\"Could not find printer PPD with token %s\", kwargs[\"token\"])\n            raise Http404\n        else:\n            return FileResponse(printer_ppd.file)"
            ],
            [
                1082,
                1090,
                "        try:\n            enrolled_machine = (EnrolledMachine.objects.select_related(\"enrollment__manifest__meta_business_unit\")\n                                                       .get(token=token))\n        except EnrolledMachine.DoesNotExist:\n            raise PermissionDenied(\"Enrolled machine does not exist\")\n        else:\n            self.token_machine_serial_number = enrolled_machine.serial_number\n            self.manifest = enrolled_machine.enrollment.manifest\n            self.meta_business_unit = self.manifest.meta_business_unit"
            ],
            [
                1095,
                1102,
                "        try:\n            api_data = verify_secret(token, 'zentral.contrib.monolith')\n        except APIAuthError:\n            raise PermissionDenied(\"Invalid API secret\")\n        else:\n            self.token_machine_serial_number = api_data.get(\"machine_serial_number\")\n            self.meta_business_unit = api_data['business_unit'].meta_business_unit\n            self.manifest = get_object_or_404(Manifest, meta_business_unit=self.meta_business_unit)"
            ],
            [
                1257,
                1265,
                "                try:\n                    sma = SubManifestAttachment.objects.active().get(sub_manifest=sub_manifest,\n                                                                     name=req_sma.name)\n                except SubManifestAttachment.DoesNotExist:\n                    pass\n                else:\n                    event_payload[\"sub_manifest_attachment\"].update({\"id\": sma.id,\n                                                                     \"filename\": sma.file.name})\n                    return FileResponse(sma.file)"
            ]
        ]
    },
    {
        "blob_id": "9bff0d072db579de1e09a306043557e220adee60",
        "matched_blocks": [
            [
                150,
                166,
                "        try:\n            form_model = helper.update_questionnaire_with_questions(form_model, question_set, manager)\n        except QuestionCodeAlreadyExistsException as e:\n            return HttpResponseServerError(e)\n        except EntityQuestionAlreadyExistsException as e:\n            return HttpResponseServerError(e.message)\n        else:\n            try:\n                form_model.form_code = questionnaire_code.lower()\n            except DataObjectAlreadyExists as e:\n                if e.message.find(\"Form\") >= 0:\n                    return HttpResponseServerError(\"Questionnaire with this code already exists\")\n                return HttpResponseServerError(e.message)\n            form_model.name = project.name\n            form_model.entity_id = project.entity_type\n            form_model.save()\n            return HttpResponseRedirect(reverse(finish, args=[pid]))"
            ]
        ]
    },
    {
        "blob_id": "cd727db391dfa5e09053466eeb9f19b48676214b",
        "matched_blocks": [
            [
                269,
                274,
                "    try:\n      self.scheduler.run()\n    except BeaconException:\n      pass\n    else:\n      assert False"
            ],
            [
                290,
                295,
                "    try:\n      scheduler.run()\n    except BeaconException:\n      assert beacon[0] == 1\n    else:\n      assert False"
            ],
            [
                307,
                312,
                "    try:\n      scheduler.run()\n    except BeaconException:\n      assert beacon[0] == 0\n    else:\n      assert False"
            ]
        ]
    },
    {
        "blob_id": "10d5c023241ed962289832426257dcc00543e648",
        "matched_blocks": [
            [
                52,
                57,
                "        try:\n            evenement = importeur.calendrier.evenements[id]\n        except IndexError:\n            personnage << \"|err|L'ID entr\u00e9e est invalide. |ff|\"\n        else:\n            personnage << evenement.str_detail"
            ]
        ]
    },
    {
        "blob_id": "22517e0b31686d302d52dab1d9967ded3e843d4d",
        "matched_blocks": [
            [
                183,
                193,
                "\t\ttry:\n\t\t\tInpInt = int(InpStr)\n\t\texcept:\n\t\t\tprint(\"Input Error\")\n\t\t\tcontinue\n\t\telse:\n\t\t\tif InpInt < 0 or InpInt > 30:\n\t\t\t\tprint(\"Input Error\")\n\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\tbreak"
            ],
            [
                88,
                98,
                "\t\t\ttry:\n\t\t\t\tCenX = int(InpStr)\n\t\t\texcept:\n\t\t\t\tprint(\"Input Error\")\n\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\tif CenX < 0 or CenX >= len(kernel):\n\t\t\t\t\tprint(\"Input Error\")\n\t\t\t\t\tcontinue\t\n\t\t\t\telse:\n\t\t\t\t\tbreak"
            ],
            [
                102,
                112,
                "\t\t\ttry:\n\t\t\t\tCenY = int(InpStr)\n\t\t\texcept:\n\t\t\t\tprint(\"Input Error\")\n\t\t\t\tcontinue\n\t\t\telse:\n\t\t\t\tif CenY < 0 or CenY >= len(kernel):\n\t\t\t\t\tprint(\"Input Error\")\n\t\t\t\t\tcontinue\t\n\t\t\t\telse:\n\t\t\t\t\tbreak\t\t\t\t\t\t\t\t"
            ]
        ]
    },
    {
        "blob_id": "f954902979c5fca813dce14098fbfaa47ec001a2",
        "matched_blocks": [
            [
                1138,
                1144,
                "        try:\n            rally(\"task sla-check --json\", getjson=True)\n        except utils.RallyCliError as expected_error:\n            self.assertEqual(expected, json.loads(expected_error.output))\n        else:\n            self.fail(\"`rally task sla-check` command should return non-zero \"\n                      \"exit code\")"
            ],
            [
                1173,
                1179,
                "        try:\n            rally(\"task sla-check --json\", getjson=True)\n        except utils.RallyCliError as expected_error:\n            self.assertEqual(expected, json.loads(expected_error.output))\n        else:\n            self.fail(\"`rally task sla-check` command should return non-zero \"\n                      \"exit code\")"
            ]
        ]
    },
    {
        "blob_id": "cc186c2a251e43a186ea75cb092c388466c6344d",
        "matched_blocks": [
            [
                355,
                361,
                "        try:\n            content = from_db.get(blob_id, bucket)\n        except NotFound:\n            self.not_found += 1\n        else:\n            with content:\n                self.db.copy_blob(content, info, bucket)"
            ],
            [
                370,
                376,
                "        try:\n            content = db.get(blob_id)\n        except NotFound:\n            self.not_found += 1\n        else:\n            with content:\n                self.db.copy_blob(content, info, DEFAULT_BUCKET)"
            ],
            [
                263,
                269,
                "            try:\n                content = self.db.old_db.get(meta.id, bucket)\n            except NotFound:\n                self.not_found += 1\n            else:\n                with content:\n                    self.db.copy_blob(content, meta.info, bucket)"
            ],
            [
                302,
                308,
                "            try:\n                content = from_db.get(meta.id, bucket)\n            except NotFound:\n                self.not_found += 1\n            else:\n                with content:\n                    self.db.copy_blob(content, meta.info, bucket)"
            ]
        ]
    },
    {
        "blob_id": "3349efc3b8db1aa6e2a7ddc8e4126425eefcbda8",
        "matched_blocks": [
            [
                1016,
                1039,
                "        try:\n            max_length = int(self.max_length)\n            if max_length <= 0:\n                raise ValueError()\n        except TypeError:\n            return [\n                checks.Error(\n                    'The field must have \"max_length\" attribute.',\n                    hint=None,\n                    obj=self,\n                    id='E038',\n                )\n            ]\n        except ValueError:\n            return [\n                checks.Error(\n                    '\"max_length\" must be a positive integer.',\n                    hint=None,\n                    obj=self,\n                    id='E039',\n                )\n            ]\n        else:\n            return []"
            ],
            [
                1326,
                1349,
                "        try:\n            decimal_places = int(self.decimal_places)\n            if decimal_places < 0:\n                raise ValueError()\n        except TypeError:\n            return [\n                checks.Error(\n                    'The field requires a \"decimal_places\" attribute.',\n                    hint=None,\n                    obj=self,\n                    id='E041',\n                )\n            ]\n        except ValueError:\n            return [\n                checks.Error(\n                    '\"decimal_places\" attribute must be a non-negative integer.',\n                    hint=None,\n                    obj=self,\n                    id='E042',\n                )\n            ]\n        else:\n            return []"
            ],
            [
                1352,
                1375,
                "        try:\n            max_digits = int(self.max_digits)\n            if max_digits <= 0:\n                raise ValueError()\n        except TypeError:\n            return [\n                checks.Error(\n                    'The field requires a \"max_digits\" attribute.',\n                    hint=None,\n                    obj=self,\n                    id='E043',\n                )\n            ]\n        except ValueError:\n            return [\n                checks.Error(\n                    '\"max_digits\" attribute must be a positive integer.',\n                    hint=None,\n                    obj=self,\n                    id='E044',\n                )\n            ]\n        else:\n            return []"
            ]
        ]
    },
    {
        "blob_id": "e7508ee1867fb4646f24cf56843b4f2a7430336d",
        "matched_blocks": [
            [
                271,
                277,
                "                try:\n                    args.func(device, args)\n                except IOError:\n                    logging.error('RSU operation failed')\n                else:\n                    exit_code = os.EX_OK\n                    logging.info('RSU operation complete')"
            ]
        ]
    },
    {
        "blob_id": "0c21c5840ceb3f530ffe9fd9023dd94fc7e1d071",
        "matched_blocks": [
            [
                809,
                815,
                "    try:\n        importer(filename)\n    except FileImportFailed as e:\n        electrum_window.show_critical(str(e))\n    else:\n        electrum_window.show_message(_(\"Your {} were successfully imported\").format(title))\n        on_success()"
            ],
            [
                824,
                830,
                "    try:\n        exporter(filename)\n    except FileExportFailed as e:\n        electrum_window.show_critical(str(e))\n    else:\n        electrum_window.show_message(_(\"Your {0} were exported to '{1}'\")\n                                     .format(title, str(filename)))"
            ]
        ]
    },
    {
        "blob_id": "db332ce82cc05ce3fb762147b91938e86b89f9a5",
        "matched_blocks": [
            [
                528,
                548,
                "        try:\n            # reference the attr inside the try block before we attempt\n            # to delete the network and potentially invalidate the\n            # relationship\n            net_id = ha_network.network_id\n            self._delete_ha_network(context, ha_network)\n        except (n_exc.NetworkNotFound,\n                orm.exc.ObjectDeletedError):\n            LOG.debug(\n                \"HA network for tenant %s was already deleted.\", tenant_id)\n        except sa.exc.InvalidRequestError:\n            LOG.info(_LI(\"HA network %s can not be deleted.\"), net_id)\n        except n_exc.NetworkInUse:\n            # network is still in use, this is normal so we don't\n            # log anything\n            pass\n        else:\n            LOG.info(_LI(\"HA network %(network)s was deleted as \"\n                         \"no HA routers are present in tenant \"\n                         \"%(tenant)s.\"),\n                     {'network': net_id, 'tenant': tenant_id})"
            ]
        ]
    },
    {
        "blob_id": "518d931a27183701f9109b5232fe0cffaa3d14f6",
        "matched_blocks": [
            [
                1546,
                1559,
                "                try:\n                    label, path = line.split(None, 1)\n                except ValueError:\n                    return False\n                else:\n                    # This file should only contain a single line. However, we\n                    # loop here to handle the corner case where .git is a large\n                    # binary file, so that we do not read the entire file into\n                    # memory at once. We'll hit a return statement before this\n                    # loop enters a second iteration.\n                    if label == 'gitdir:' and os.path.isabs(path):\n                        return True\n                    else:\n                        return False"
            ]
        ]
    },
    {
        "blob_id": "7ce752665c7304aed97aafd1b138ae12dcb9d903",
        "matched_blocks": [
            [
                156,
                166,
                "    try:\n        len(cons)\n    except TypeError as e:\n        if callable(cons):\n            cons = [cons]\n        else:\n            raise TypeError(err) from e\n    else:\n        for thisfunc in cons:\n            if not callable(thisfunc):\n                raise TypeError(err)"
            ],
            [
                240,
                252,
                "        try:\n            ctype = con['type'].lower()\n        except KeyError as e:\n            raise KeyError('Constraint %d has no type defined.' % ic) from e\n        except TypeError as e:\n            raise TypeError('Constraints must be defined using a '\n                            'dictionary.') from e\n        except AttributeError as e:\n            raise TypeError(\"Constraint's type must be a string.\") from e\n        else:\n            if ctype != 'ineq':\n                raise ValueError(\"Constraints of type '%s' not handled by \"\n                                 \"COBYLA.\" % con['type'])"
            ]
        ]
    },
    {
        "blob_id": "41783f6cd99c7b929bf77c9029ac35890c0097a7",
        "matched_blocks": [
            [
                356,
                373,
                "        try:\n            strings_schema(strings)\n        except vol.Invalid as err:\n            integration.add_error(\n                \"translations\", f\"Invalid {name}: {humanize_error(strings, err)}\"\n            )\n        else:\n            if strings_file.name == \"strings.json\":\n                find_references(strings, name, references)\n\n                if strings.get(\n                    \"title\"\n                ) == integration.name and not allow_name_translation(integration):\n                    integration.add_error(\n                        \"translations\",\n                        \"Don't specify title in translation strings if it's a brand name \"\n                        \"or add exception to ALLOW_NAME_TRANSLATION\",\n                    )"
            ],
            [
                390,
                399,
                "        try:\n            platform_string_schema(strings)\n        except vol.Invalid as err:\n            msg = f\"Invalid {path.name}: {humanize_error(strings, err)}\"\n            if config.specific_integrations:\n                integration.add_warning(\"translations\", msg)\n            else:\n                integration.add_error(\"translations\", msg)\n        else:\n            find_references(strings, path.name, references)"
            ]
        ]
    },
    {
        "blob_id": "29c49f468a82a5b92f378131e9279efddc0511bd",
        "matched_blocks": [
            [
                70,
                76,
                "    try:\n        with spinner():\n            n = export()\n    except RuntimeError as error:\n        click.secho(str(error), fg='red')\n    else:\n        click.secho(f\"Success! Imported {n} entries.\", fg='green')"
            ]
        ]
    },
    {
        "blob_id": "c0008b5d6f63884391b3cec6d4819b877dd7bf97",
        "matched_blocks": [
            [
                29,
                40,
                "        try:\n            ans = int(input('Where do you want to place your ' + currentPlayer + '?\\n' + changer(array)))\n        except ValueError:\n            print(\"This is an incorrect number. Try again.\")\n        else:\n            if ans > 9 or ans < 1:\n                print(\"Please type a number between 1 and 9.\")\n            else:\n                if not isinstance(array[ans - 1], int):\n                    print(\"This has already been claimed.\")\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "4f5051b736e5d738c659f61b16ec0fcb360ef749",
        "matched_blocks": [
            [
                387,
                392,
                "        try:\n            reaction, user = await client.wait_for('reaction_add', timeout=15.0, check=check)\n        except asyncio.TimeoutError:\n            return False\n        else:\n            return reaction, user"
            ],
            [
                140,
                197,
                "            try:\n                reaction, user = await client.wait_for('reaction_add', timeout=30.0, check=check)\n            except asyncio.TimeoutError:\n                emb = await main.embedMake(\n                    title='Claim Timed Out',\n                    desc='You were automatically claimed as Millionaire',\n                    thumbnail='https://images-ext-1.discordapp.net/external/a73EwOYEEHydxTjLBJARbB4LBsi46-tKH_m0mbcOMtI/https/images-ext-1.discordapp.net/external/p3Ujz5sOddyXFf6T_F_59ae7c779w8ax47Epd9v2Wy0/https/images-ext-2.discordapp.net/external/BAeOdPzafgkr43ervKSOByd063AO0MeENKlda4_FHW0/https/media.discordapp.net/attachments/724362941792649287/747969861061312632/mat6.png?width=438&height=438')\n                for eye in ppl[str(self.id)]:\n                    if eye not in claimed:\n                        user = client.get_user(int(eye))\n                        await client.get_user(int(eye)).send(embed=emb)\n                        emb = await main.embedMake(\n                            ['`' + str(user) + '` Claims that they are the ',\n                             '**Millionaire**'],\n                            title='Role Claim!',\n                            thumbnail='https://images-ext-1.discordapp.net/external/p3Ujz5sOddyXFf6T_F_59ae7c779w8ax47Epd9v2Wy0/https/images-ext-2.discordapp.net/external/BAeOdPzafgkr43ervKSOByd063AO0MeENKlda4_FHW0/https/media.discordapp.net/attachments/724362941792649287/747969861061312632/mat6.png',\n                            desc='Hopefully they are truthful...',\n                            footer='interesting...',\n                            color=0xFFFF00\n                        )\n                        claimed.append(str(user))\n                        for b in range(len(ppl[str(self.id)])):\n                            await client.get_user(int(ppl[str(self.id)][b])).send(embed=emb)\n            else:\n                if str(reaction) == \"\ud83d\udde1\ufe0f\":\n                    role = \"Murder\"\n                elif str(reaction) == \"\ud83d\udd0e\":\n                    role = \"Detective\"\n                elif str(reaction) == \"\ud83d\udcbb\":\n                    role = \"Hacker\"\n                elif str(reaction) == \"\ud83c\udff9\":\n                    role = \"Hunter\"\n                elif str(reaction) == \"\ud83d\udcda\":\n                    role = \"Workhorse Dad\"\n                elif str(reaction) == \"\ud83c\udf73\":\n                    role = \"Overprotective Mom\"\n                elif str(reaction) == \"\u2764\":\n                    role = \"MVP Simp\"\n                elif str(reaction) == \"\ud83e\uddea\":\n                    role = \"Scientist\"\n                elif str(reaction) == \"\ud83e\uddf9\":\n                    role = \"Witch\"\n                elif str(reaction) == \"\ud83d\udcb0\":\n                    role = \"Millionaire\"\n                else:\n                    role = \"Millionaire\"\n                emb = await main.embedMake(\n                    ['`' + str(user) + '` Claims that they are the ',\n                     '**' + str(role) + '**'],\n                    title='Role Claim!',\n                    thumbnail='https://images-ext-1.discordapp.net/external/p3Ujz5sOddyXFf6T_F_59ae7c779w8ax47Epd9v2Wy0/https/images-ext-2.discordapp.net/external/BAeOdPzafgkr43ervKSOByd063AO0MeENKlda4_FHW0/https/media.discordapp.net/attachments/724362941792649287/747969861061312632/mat6.png',\n                    desc='Hopefully they are truthful...',\n                    footer='interesting...',\n                    color=0xFFFF00\n                )\n                claimed.append(str(user))\n                for b in range(len(ppl[str(self.id)])):\n                    await client.get_user(int(ppl[str(self.id)][b])).send(embed=emb)"
            ]
        ]
    },
    {
        "blob_id": "38682846174ebf28907dec0acc8e91a95e9ba82b",
        "matched_blocks": [
            [
                23,
                39,
                "    try:\n        f = open(\"./html/index.html\", \"rb\")\n    except:\n        response = \"HTTP/1.1 404 NOT FOUND\\r\\n\"\n        response += \"\\r\\n\"\n        response += \"----- file not found --- \"\n        new_socket.send(response.encode(\"utf-8\"))\n\n    else:\n        html_content = f.read()\n        f.close()\n        # 2. \u8fd4\u56dehttp\u683c\u5f0f\u7684\u6570\u636e\u7ed9\u6d4f\u89c8\u5668\n        # 2.1 \u51c6\u5907\u597d\u53d1\u9001\u7ed9\u6d4f\u89c8\u5668\u7684\u6570\u636e ---  header\n        response = \"HTTP/1.1 200 0K\\r\\n\"\n        response += \"\\r\\n\"\n        new_socket.send(response.encode(\"utf-8\"))  # \u53d1\u9001\u5934\u90e8\u4fe1\u606f\n        new_socket.send(html_content)  # \u53d1\u9001body\u4fe1\u606f"
            ]
        ]
    },
    {
        "blob_id": "b7c6cb163f6f35915e4fd76d905f8bb4b2ff6646",
        "matched_blocks": [
            [
                2733,
                2740,
                "        try:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT VERSION() LIKE '%MariaDB%'\")\n            val = cursor.fetchone()[0]\n        except:\n            raise\n        else:\n            return bool(val)"
            ]
        ]
    },
    {
        "blob_id": "4816a2acbc1cf68841ea04a6f45ec025e1faa0e9",
        "matched_blocks": [
            [
                48,
                61,
                "        try:\n            path, buf, cert = authority.get_signed(cn)\n        except IOError:\n            raise falcon.HTTPNotFound()\n        else:\n            try:\n                inner_address = getxattr(path, \"user.lease.inner_address\").decode(\"ascii\")\n            except IOError:\n                raise falcon.HTTPForbidden(\"Forbidden\", \"Remote address %s not whitelisted\" % req.context.get(\"remote_addr\"))\n            else:\n                if req.context.get(\"remote_addr\") != ip_address(inner_address):\n                    raise falcon.HTTPForbidden(\"Forbidden\", \"Remote address %s mismatch\" % req.context.get(\"remote_addr\"))\n                else:\n                   return func(self, req, resp, cn, *args, **kwargs)"
            ],
            [
                53,
                61,
                "            try:\n                inner_address = getxattr(path, \"user.lease.inner_address\").decode(\"ascii\")\n            except IOError:\n                raise falcon.HTTPForbidden(\"Forbidden\", \"Remote address %s not whitelisted\" % req.context.get(\"remote_addr\"))\n            else:\n                if req.context.get(\"remote_addr\") != ip_address(inner_address):\n                    raise falcon.HTTPForbidden(\"Forbidden\", \"Remote address %s mismatch\" % req.context.get(\"remote_addr\"))\n                else:\n                   return func(self, req, resp, cn, *args, **kwargs)"
            ]
        ]
    },
    {
        "blob_id": "15a6d14843554798056efd81cebcb4396d5f12b5",
        "matched_blocks": [
            [
                135,
                153,
                "        try:\n            date_obj = datetime.strptime(date_string, date_format)\n        except ValueError:\n            continue\n        else:\n            # If format does not include the day, use last day of the month\n            # instead of first, because the first is usually out of range.\n            if '%d' not in date_format:\n                period = 'month'\n                date_obj = date_obj.replace(\n                    day=get_last_day_of_month(date_obj.year, date_obj.month))\n\n            if not ('%y' in date_format or '%Y' in date_format):\n                today = datetime.today()\n                date_obj = date_obj.replace(year=today.year)\n\n            date_obj = apply_timezone_from_settings(date_obj, settings)\n\n            return {'date_obj': date_obj, 'period': period}"
            ]
        ]
    },
    {
        "blob_id": "b5ed70bcad0557d3a391505675cd7fb76f19e7c3",
        "matched_blocks": [
            [
                18,
                25,
                "try:\n    # pylint: disable=unused-import\n    import google.cloud.pubsub._gax\n    # pylint: enable=unused-import\nexcept ImportError:  # pragma: NO COVER\n    _HAVE_GAX = False\nelse:\n    _HAVE_GAX = True"
            ]
        ]
    },
    {
        "blob_id": "ef00bb6c55f03705ce5ee9027d152a76d79f979d",
        "matched_blocks": [
            [
                76,
                85,
                "    try:\n        validate(instance=request.json, schema=add_subcategory_schema)\n    except:\n        return 'Bad request', 400\n    else:\n        db = get_db().cursor()\n\n        db.execute('INSERT INTO subcategories (cat_id, name, desc) VALUES (?, ?, ?)', (request.json['cat_id'], request.json['name'], request.json['desc']))\n\n        return jsonify({'success' : True})"
            ],
            [
                97,
                106,
                "    try:\n        validate(instance=request.json, schema=remove_post_schema)\n    except:\n        return 'Bad request', 400\n    else:\n        db = get_db().cursor()\n\n        db.execute('DELETE FROM posts WHERE id=?', request.json['id'])\n\n        return jsonify({'success' : True})"
            ]
        ]
    },
    {
        "blob_id": "ba6ea9a18f945a738128ed875f080211bb346872",
        "matched_blocks": [
            [
                52,
                88,
                "                try:\n                    result = yield from wait_for(shield(wrapped_func(self, *args, **kwargs)), 60*10)\n\n                except TimeoutError as e:\n                    Stats.http_stats['timedout'] += 1\n                    status = 'timeout'\n                    success = False\n                    _logger.exception(\"HTTP request had a timeout for method %s\", func.__name__)\n\n                except VykedServiceException as e:\n                    Stats.http_stats['total_responses'] += 1\n                    status = 'handled_exception'\n                    _logger.error('Handled exception %s for method %s ', e.__class__.__name__, func.__name__)\n                    raise e\n\n                except Exception as e:\n                    Stats.http_stats['total_errors'] += 1\n                    status = 'unhandled_exception'\n                    success = False\n                    _logger.exception('Unhandled exception %s for method %s ', e.__class__.__name__, func.__name__)\n                    raise e\n\n                else:\n                    t2 = time.time()\n                    hostname = socket.gethostname()\n                    service_name = '_'.join(setproctitle.getproctitle().split('_')[:-1])\n                    status = result.status\n\n                    logd = {\n                        'status': result.status,\n                        'time_taken': int((t2 - t1) * 1000),\n                        'type': 'http',\n                        'hostname': hostname, 'service_name': service_name\n                    }\n                    logging.getLogger('stats').debug(logd)\n                    Stats.http_stats['total_responses'] += 1\n                    return result"
            ]
        ]
    },
    {
        "blob_id": "5cfa9ce5c59fad91ec62018641f1f8e3be5b7d6b",
        "matched_blocks": [
            [
                93,
                116,
                "    try:\n        req     = urllib.request.Request(PageUrl, None, Headers)\n        content = urllib.request.urlopen(req, timeout = 30)         # set Timeout as 10s\n    except urllib.error.URLError as UrlErr:\n        print('[DBG ERR ] URLError ', end = '')\n        if hasattr(UrlErr, 'code'):\n            print('Error Code: ', UrlErr.code)\n        if hasattr(UrlErr, 'reason'):\n            print('Error Reason: ', UrlErr.reason)\n        return\n    except socket.error as SocketErr:\n        print('[DBG ERR ] Sokect Error: ', SocketErr)\n        return\n    except requests.exceptions.RequestException as ReqErr:\n        print('[DBG ERR ] RequestException')\n        return\n    else:\n        print('[DBG INFO] Get Title Url Here')\n        data    = content.read().decode('utf-8')\n        print(data)\n        Cookie.save(CookieFile, ignore_discard = True, ignore_expires = True)       # save the cookie file  \n        setUrl = re.compile(RegExp_UrlTitle,re.S).findall(data)\n        # setUrl = list(set(setUrl))\n        return setUrl"
            ]
        ]
    },
    {
        "blob_id": "3afd9866a37000da97a5bae4e35cf4934ba1a2ad",
        "matched_blocks": [
            [
                69,
                82,
                "                try:\n                    compinfo = get_compInfo(v['\u673a\u6784\u540d\u79f0'])\n                    print('\u6210\u529f\u83b7\u5f97 ',compinfo['\u540d\u79f0'])\n                    v['\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801'] = compinfo['\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801']\n                    v['\u7ecf\u8425\u8303\u56f4'] = compinfo['\u7ecf\u8425\u8303\u56f4']\n                except:\n                    print(\"\u9700\u8981\u9a8c\u8bc1\u7801\u66f4\u65b0\")\n                    wait = input(\"Press Enter to continue.\")\n                    compinfo = get_compInfo(v['\u673a\u6784\u540d\u79f0'])\n                    v['\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801'] = compinfo['\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801']\n                    v['\u7ecf\u8425\u8303\u56f4'] = compinfo['\u7ecf\u8425\u8303\u56f4']\n                else:\n                    j+=1\n                    time.sleep(3)"
            ]
        ]
    },
    {
        "blob_id": "bb0d79f69470ef24542249f66cf746e3291c6036",
        "matched_blocks": [
            [
                92,
                106,
                "    try:\n        selected_choice = p.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'portfolio/detail.html', {\n            'question': p,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('portfolio:results', args=(p.id,)))"
            ]
        ]
    },
    {
        "blob_id": "55782bca4fc53bfb30a3d26d1336c6538a21a16a",
        "matched_blocks": [
            [
                54,
                69,
                "        try:\n            if endpoint is None:\n                endpoint = keystone.service_catalog.url_for(\n                    attr='region',\n                    filter_value=region,\n                    service_type='orchestration',\n                    endpoint_type='publicURL')\n        except keystoneclient.exceptions.EndpointNotFound:\n            return None\n        else:\n            return heatclient.client.Client(\n                self.HEATCLIENT_VERSION,\n                endpoint,\n                token=token,\n                username=self.conf.username,\n                password=self.conf.password)"
            ],
            [
                147,
                169,
                "        try:\n            endpoint = keystone.service_catalog.url_for(\n                attr='region',\n                filter_value=self.conf.region,\n                service_type='metering',\n                endpoint_type='publicURL')\n\n        except keystoneclient.exceptions.EndpointNotFound:\n            return None\n        else:\n            args = {\n                'username': self.conf.username,\n                'password': self.conf.password,\n                'tenant_name': self.conf.tenant_name,\n                'auth_url': self.conf.auth_url,\n                'insecure': dscv,\n                'region_name': self.conf.region,\n                'endpoint_type': 'publicURL',\n                'service_type': 'metering',\n            }\n\n            return ceilometerclient.client.Client(self.CEILOMETER_VERSION,\n                                                  endpoint, **args)"
            ]
        ]
    },
    {
        "blob_id": "655ca34106da480d21ec9bb6da7b33271375ad14",
        "matched_blocks": [
            [
                231,
                247,
                "                try:\n                    self._curl_setup_request(\n                        curl, request, curl.info[\"buffer\"], curl.info[\"headers\"]\n                    )\n                except Exception as e:\n                    # If there was an error in setup, pass it on\n                    # to the callback. Note that allowing the\n                    # error to escape here will appear to work\n                    # most of the time since we are still in the\n                    # caller's original stack frame, but when\n                    # _process_queue() is called from\n                    # _finish_pending_requests the exceptions have\n                    # nowhere to go.\n                    self._free_list.append(curl)\n                    callback(HTTPResponse(request=request, code=599, error=e))\n                else:\n                    self._multi.add_handle(curl)"
            ]
        ]
    },
    {
        "blob_id": "94fdaa48e8dfc5aefebe7593cdb638d8faf18a9c",
        "matched_blocks": [
            [
                25,
                35,
                "\ttry:\n\t\tselected_choice = p.choice_set.get(pk=request.POST['choice'])\n\texcept (KeyError, Choice.DoesNotExist):\n\t\treturn render(request, 'polls/detail.html', {\n\t\t\t'question': p,\n\t\t\t'error_message': \"pls select a choice\",\n\t\t\t})\n\telse:\n\t\tselected_choice.votes += 1\n\t\tselected_choice.save()\n\t\treturn HttpResponseRedirect(reverse('polls:results', args=(p.id,)))"
            ]
        ]
    },
    {
        "blob_id": "940aa6623da3e7a1f0a207535670d77cb2507b2f",
        "matched_blocks": [
            [
                94,
                101,
                "        try:\n            valid_range = self._image.attrs['valid_range']\n        except AttributeError:\n            valid_range = [info.min, info.max]\n        else:\n            if valid_range[0] < info.min or valid_range[1] > info.max:\n                raise ValueError('Valid range outside input '\n                                 'data type range')"
            ],
            [
                128,
                133,
                "            try:\n                raw_data = self._image[sliceobj]\n            except (ValueError, TypeError):\n                raw_data = np.asanyarray(self._image)[sliceobj]\n            else:\n                raw_data = np.asanyarray(raw_data)"
            ]
        ]
    },
    {
        "blob_id": "2a58af80f155244867970e5a9fa1b81b38c15d2c",
        "matched_blocks": [
            [
                6,
                20,
                "try:\n\tfrom tkinter import *\n\tfrom tkinter.scrolledtext import ScrolledText\nexcept ImportError:\t #Python 2.x\n\tPythonVersion = 2\n\tfrom Tkinter import *\n\tfrom tkFont import Font\n\tfrom ttk import *\n\tfrom tkMessageBox import *\n\tfrom tkinter.scrolledtext import ScrolledText\nelse:  #Python 3.x\n\tPythonVersion = 3\n\tfrom tkinter.font import Font\n\tfrom tkinter.ttk import *\n\tfrom tkinter.messagebox import *"
            ]
        ]
    },
    {
        "blob_id": "03d8d151bc1223cad792f68132b3f16cdc1fc9f3",
        "matched_blocks": [
            [
                27,
                32,
                "        try:\n            self.post_user = User.objects.prefetch_related('posts').get(username__iexact=self.kwargs.get('username'))\n        except User.DoesNotExist:\n            raise Http404\n        else:\n            return self.post_user.posts.all()"
            ]
        ]
    },
    {
        "blob_id": "f2df0a5b18ace630467007d86e19afacb3556e85",
        "matched_blocks": [
            [
                450,
                459,
                "try:\n    socket.inet_aton(\"255.255.255.255\")\nexcept socket.error:\n    def inet_aton(x):\n        if x == \"255.255.255.255\":\n            return b\"\\xff\" * 4\n        else:\n            return socket.inet_aton(x)\nelse:\n    inet_aton = socket.inet_aton"
            ],
            [
                1667,
                1672,
                "        try:\n            tmpfile.writelines(iter(lambda: pktlist.read(1048576), b\"\"))\n        except AttributeError:\n            wrpcap(tmpfile, pktlist, linktype=linktype)\n        else:\n            tmpfile.close()"
            ],
            [
                1688,
                1695,
                "        try:\n            proc.stdin.writelines(iter(lambda: pktlist.read(1048576), b\"\"))\n        except AttributeError:\n            wrpcap(proc.stdin, pktlist, linktype=linktype)\n        except UnboundLocalError:\n            raise IOError(\"%s died unexpectedly !\" % prog)\n        else:\n            proc.stdin.close()"
            ]
        ]
    },
    {
        "blob_id": "e8a65b29d8f745add8ba7f64dbbc7c7044bb8505",
        "matched_blocks": [
            [
                7,
                12,
                "        try:\n            getTempNumber = int(getNumber)\n        except ValueError:\n            print('\"' + getNumber + '\"' + ' - \u043d\u0435 \u044f\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u0447\u0438\u0441\u043b\u043e\u043c')\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "a6bb620dcc0dd22f9e98466cc33336cf6c723d2f",
        "matched_blocks": [
            [
                137,
                141,
                "            try:  line = self.stdout_queue.get_nowait() # or q.get(timeout=.1)\n            except Empty:\n                pass # do nothing\n            else: # got line\n                l += \"\\n\" + str(line)"
            ]
        ]
    },
    {
        "blob_id": "625966c2593a5ddd165c1684f4d98a3750669162",
        "matched_blocks": [
            [
                92,
                101,
                "            try:\n                sql, params = persons_query.distinct(\"pk\").only(\"pk\").query.sql_with_params()\n            except EmptyResultSet:\n                query = DELETE_QUERY.format(cohort_id=self.pk)\n                params = {}\n            else:\n                query = \"{}{}\".format(DELETE_QUERY, UPDATE_QUERY).format(\n                    cohort_id=self.pk,\n                    values_query=sql.replace('FROM \"posthog_person\"', ', {} FROM \"posthog_person\"'.format(self.pk), 1,),\n                )"
            ]
        ]
    },
    {
        "blob_id": "c14c19f3d21ac20996ca67d5b9be0eeb45789819",
        "matched_blocks": [
            [
                45,
                50,
                "        try:\n            self.peers.remove(node)\n        except ValueError:\n            pass\n        else:\n            self._save()"
            ]
        ]
    },
    {
        "blob_id": "4f56e6665110bb50afcfad478ddd605eaf21e59c",
        "matched_blocks": [
            [
                112,
                120,
                "        try:\n            retcode = subprocess.check_call(['vagrant', 'up'], cwd=target.path)\n        except OSError:\n            logging.critical(\"vagrant executable not found\")\n            sys.exit(1)\n        else:\n            if retcode != 0:\n                logging.critical(\"vagrant up failed with code %d\", retcode)\n                sys.exit(1)"
            ],
            [
                300,
                305,
                "                        try:\n                            rpz_pack.get_data(path)\n                        except KeyError:\n                            logging.info(\"Missing file %s\", path)\n                        else:\n                            pathlist.append(path)"
            ]
        ]
    },
    {
        "blob_id": "473ed0c8228213807035e478b4d328692fb8ebc6",
        "matched_blocks": [
            [
                204,
                220,
                "        try:\n            self.assert_connection(direction, protocol, src_port, dst_port)\n        except ConnectionTesterException:\n            pass\n        else:\n            dst_port_info = str()\n            src_port_info = str()\n            if dst_port is not None:\n                dst_port_info = \" and destination port %d\" % dst_port\n            if src_port is not None:\n                src_port_info = \" and source port %d\" % src_port\n            raise ConnectionTesterException(\"%s connection with protocol %s, \"\n                                            \"source port %s, destination \"\n                                            \"port %s was established but it \"\n                                            \"shouldn't be possible\" % (\n                                                direction, protocol,\n                                                src_port_info, dst_port_info))"
            ],
            [
                250,
                259,
                "        try:\n            self.assert_established_connection(direction, protocol, src_port,\n                                               dst_port)\n        except ConnectionTesterException:\n            pass\n        else:\n            raise ConnectionTesterException(\n                'Established %s connection with protocol %s, source port %s, '\n                'destination port %s can still send packets through' % (\n                    direction, protocol, src_port, dst_port))"
            ]
        ]
    },
    {
        "blob_id": "a6ba03e0e4a8062c8b63455aa01e52a7f24e0db4",
        "matched_blocks": [
            [
                1623,
                1633,
                "        try:\n            module = importlib.import_module(backend)\n        except ImportError:\n            # We re-raise later on.\n            pass\n        else:\n            if hasattr(module, \"plot\"):\n                # Validate that the interface is implemented when the option\n                # is set, rather than at plot time.\n                _backends[backend] = module\n                return module"
            ]
        ]
    },
    {
        "blob_id": "43c2d7552ae0cb24985f97e002e8cd52c67c1543",
        "matched_blocks": [
            [
                3,
                8,
                "try:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context"
            ]
        ]
    },
    {
        "blob_id": "173f9b783d3033c4edc6bd203f6145a9d52d9831",
        "matched_blocks": [
            [
                46,
                51,
                "    try:\n        os.mkdir(path_good)\n    except OSError:\n        print(f\"\u0421\u043e\u0437\u0434\u0430\u0442\u044c \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044e {path_good} \u043d\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c\")\n    else:\n        print(f\"\u0423\u0441\u043f\u0435\u0448\u043d\u043e \u0441\u043e\u0437\u0434\u0430\u043d\u0430 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f {path_good}\")"
            ],
            [
                55,
                61,
                "    try:\n        os.mkdir(path_bad)\n    except OSError:\n        print(f\"\u0421\u043e\u0437\u0434\u0430\u0442\u044c \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044e {path_bad} \u043d\u0435 \u0443\u0434\u0430\u043b\u043e\u0441\u044c\")\n        print(OSError)\n    else:\n        print(f\"\u0423\u0441\u043f\u0435\u0448\u043d\u043e \u0441\u043e\u0437\u0434\u0430\u043d\u0430 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f {path_bad}\")"
            ]
        ]
    },
    {
        "blob_id": "c0068ec6b5fb9837acbf36369a60a2c33db08bb3",
        "matched_blocks": [
            [
                92,
                104,
                "try:\n    PAM_START = LIBPAM.pam_start\n    PAM_START.restype = c_int\n    PAM_START.argtypes = [c_char_p, c_char_p, POINTER(PamConv),\n            POINTER(PamHandle)]\n\n    PAM_AUTHENTICATE = LIBPAM.pam_authenticate\n    PAM_AUTHENTICATE.restype = c_int\n    PAM_AUTHENTICATE.argtypes = [PamHandle, c_int]\nexcept Exception:\n    HAS_PAM = False\nelse:\n    HAS_PAM = True"
            ]
        ]
    },
    {
        "blob_id": "dbf18c69d786794b53b59bc7bead76e444ab2f9e",
        "matched_blocks": [
            [
                86,
                94,
                "        try:\n            import_module(app_code)\n        except ImportError:\n            pass\n        else:\n            raise CommandError('%r conflicts with the name of an existing '\n                               'Python module and cannot be used as a '\n                               'project name. Please try another name.' %\n                               app_code)"
            ]
        ]
    },
    {
        "blob_id": "b1a48b404cef952e203b19b3d0a78243594f0388",
        "matched_blocks": [
            [
                54,
                60,
                "        try:\n            guess = int(input(f'Please guess a number between 1-{max_num}: '))\n            attempts += 1\n        except ValueError:\n            print('Please enter a number.')\n        else:\n            break"
            ],
            [
                66,
                71,
                "        try:\n            max_number = int(input('Please enter the maximum number range: '))\n        except ValueError:\n            print('Please enter a number.')\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "dbed2a85e85458a64ddba3eb266945ed0f13a0de",
        "matched_blocks": [
            [
                32,
                46,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "68a3df6c0377dc1399e5b7410bc5a493031893e5",
        "matched_blocks": [
            [
                28,
                35,
                "        try:\n            GroupMember.objects.create(user=self.request.user, group=group)\n        except IntegrityError:\n            messages.warning(self.request, \"Warning, You are already member of {}\".format(group.name))\n        except Exception as e:\n            print(str(e))\n        else:\n            messages.success(self.request, \"You are now member of {} group\".format(group.name))"
            ],
            [
                49,
                55,
                "        try:\n            membership = GroupMember.objects.filter(user=self.request.user, group__slug=self.kwargs.get('slug'))\n        except GroupMember.DoesNotExist:\n            messages.warning(self.request, \"You cannot leave this group, because you are not a part of this\")\n        else:\n            membership.delete()\n            messages.success(self.request, \"You are successfully left the group\")"
            ]
        ]
    },
    {
        "blob_id": "f9b1ac42f013c89dbd7aaf9bcb5ea7ba62c3199e",
        "matched_blocks": [
            [
                41,
                48,
                "    try:\n        for i in range(num):\n            ex(i)\n            print(i)\n    except BaseException as msg:\n        print(msg)\n    else:\n        print(\"over\")"
            ]
        ]
    },
    {
        "blob_id": "4894236295787d0bb66c0692901d406cee22aea6",
        "matched_blocks": [
            [
                371,
                386,
                "                try:\n                    ensure_App_Foreground(u\"\u5bcc\u57fa\u878d\u901a\u5546\u4e1a\u8fde\u9501\u95e8\u5e97\u7ba1\u7406\u7cfb\u7edf\", 3)\n                except Exception as e:\n                    tkinter.messagebox.showinfo(\"\u8b66\u544a\uff01\", \"\u5c1a\u672a\u6253\u5f00\u8d39\u7528\u5f55\u5165\u5355\u754c\u9762\uff01\")\n                else:\n                    if analyze_rowinfo(rowinfo)[0] == -1:\n                        tkinter.messagebox.showinfo(\n                            \"\u8b66\u544a\uff01\", analyze_rowinfo(rowinfo)[1])\n                    else:\n                        time.sleep(1)\n                        check_window(u\"\u5bcc\u57fa\u878d\u901a\u5546\u4e1a\u8fde\u9501\u95e8\u5e97\u7ba1\u7406\u7cfb\u7edf\")\n                        ensure_CapsLock()\n                        program = Simulation_operation(\n                            int(wait_time), analyze_rowinfo(rowinfo), pending)\n                        do_and_check_pause(\n                            program, float(trim_time), True, False)"
            ]
        ]
    },
    {
        "blob_id": "a239a13d734f2f85c901126fa077257bd88ba16d",
        "matched_blocks": [
            [
                151,
                202,
                "    try:\n        abstest = get_abs_module(ns, test)\n        clear_caches()\n        with saved_test_environment(test, ns.verbose, ns.quiet, pgo=ns.pgo) as environment:\n            start_time = time.time()\n            the_module = importlib.import_module(abstest)\n            # If the test has a test_main, that will run the appropriate\n            # tests.  If not, use normal unittest test loading.\n            test_runner = getattr(the_module, \"test_main\", None)\n            if test_runner is None:\n                def test_runner():\n                    loader = unittest.TestLoader()\n                    tests = loader.loadTestsFromModule(the_module)\n                    for error in loader.errors:\n                        print(error, file=sys.stderr)\n                    if loader.errors:\n                        raise Exception(\"errors while loading tests\")\n                    support.run_unittest(tests)\n            test_runner()\n            if ns.huntrleaks:\n                refleak = dash_R(the_module, test, test_runner, ns.huntrleaks)\n            test_time = time.time() - start_time\n    except support.ResourceDenied as msg:\n        if not ns.quiet and not ns.pgo:\n            print(test, \"skipped --\", msg, flush=True)\n        return RESOURCE_DENIED, test_time\n    except unittest.SkipTest as msg:\n        if not ns.quiet and not ns.pgo:\n            print(test, \"skipped --\", msg, flush=True)\n        return SKIPPED, test_time\n    except KeyboardInterrupt:\n        raise\n    except support.TestFailed as msg:\n        if not ns.pgo:\n            if display_failure:\n                print(\"test\", test, \"failed --\", msg, file=sys.stderr,\n                      flush=True)\n            else:\n                print(\"test\", test, \"failed\", file=sys.stderr, flush=True)\n        return FAILED, test_time\n    except:\n        msg = traceback.format_exc()\n        if not ns.pgo:\n            print(\"test\", test, \"crashed --\", msg, file=sys.stderr,\n                  flush=True)\n        return FAILED, test_time\n    else:\n        if refleak:\n            return FAILED, test_time\n        if environment.changed:\n            return ENV_CHANGED, test_time\n        return PASSED, test_time"
            ]
        ]
    },
    {
        "blob_id": "44dd251a71f2ecd6938f781b741f5b0c22767724",
        "matched_blocks": [
            [
                41,
                47,
                "    try:\n        db.session.commit()\n    except DatabaseError as e:\n        db.session.rollback()\n        raise SystemException(SystemError.DATABASE_ERROR)\n    else:\n        return ok(msg=msg)"
            ]
        ]
    },
    {
        "blob_id": "4ae5635228c44773b49cdbe96fb416c3cd974988",
        "matched_blocks": [
            [
                1337,
                1348,
                "    try:\n        np.zeros(tuple(), dtype=a.dtype).astype(bool)\n    except ValueError:\n        ######################################################\n        # Handle special cases where conversion to bool does #\n        # not work correctly.                                #\n        #                                                    #\n        # xref: https://github.com/numpy/numpy/issues/9479   #\n        ######################################################\n        return a.map_blocks(_isnonzero_vec, dtype=bool)\n    else:\n        return a.astype(bool)"
            ]
        ]
    },
    {
        "blob_id": "b9205e80acdc42ad3f4c15527fd1bf360b251502",
        "matched_blocks": [
            [
                122,
                133,
                "                        try:\n                            x = v.upper() == c.upper()\n                        except AttributeError:\n                            if v == c:\n                                newValueList.append( v )\n                                break\n                        else:\n                            if x:\n                                if v != c:\n                                    v = c\n                                newValueList.append( v )\n                                break"
            ],
            [
                395,
                404,
                "                    try:\n                        # test if it is a negative number\n                        float(name)  # covers both float and int\n                    except Exception:\n                        raise TransformArgumentError('option %s not supported' % name)\n                    else:\n                        # it is a negative number: add it to the list, and go to next\n                        cleanList.append( arg )\n                        iArg += 1\n                        continue"
            ]
        ]
    },
    {
        "blob_id": "e775b54c71ec0cdd966af1fb9e2f85aeab8aefe3",
        "matched_blocks": [
            [
                54,
                61,
                "    try:\n        validate_entities = entities_domain('media_player')\n        validate_entities(conf_entities)\n    except vol.Invalid as e:\n        _LOGGER.error(e)\n        return False\n    else:\n        _LOGGER.debug(f\"Monitoring media players: {monitored_entities}\")"
            ]
        ]
    },
    {
        "blob_id": "8f2f6ecc32daa61b5f5e9632ca2a876e1cb72fc9",
        "matched_blocks": [
            [
                19,
                29,
                "        try:\n            cls.select().where(\n                (cls.email == email) | (cls.username**username)\n            ).get()\n        except cls.DoesNotExist:\n            user = cls(username=username, email=email)\n            user.password = user.set_password(password)\n            user.save()\n            return user\n        else:\n            raise AlreadyExistsException()"
            ],
            [
                34,
                40,
                "        try:\n            data = serializer.loads(token)\n        except (SignatureExpired, BadSignature):\n            return None\n        else:\n            user = User.get(User.id == data['id'])\n            return user"
            ]
        ]
    },
    {
        "blob_id": "96b9e5e8b1b17460d4c3846c6aed262b27507927",
        "matched_blocks": [
            [
                84,
                86,
                "    try: obj+1\n    except: return False\n    else: return True"
            ]
        ]
    },
    {
        "blob_id": "e493ec74baf27b357c4eab05c6e45130d60ba96b",
        "matched_blocks": [
            [
                130,
                135,
                "    try:\n      patt = Chem.MolFromSmarts(sma)\n    except:\n      sys.stderr.write('WARNING: problems with pattern %s (name: %s), skipped.\\n'%(sma,name))\n    else:\n      esPatterns[i] = name,patt"
            ]
        ]
    },
    {
        "blob_id": "e28cc26a92908ba847d4c7008f544a2ddef9df16",
        "matched_blocks": [
            [
                53,
                64,
                "try:\n\timport GeoIP\n\tMODULE_GEOIP = True\nexcept ImportError:\n\tMODULE_GEOIP = False\n\tpass\nelse:\n\ttry:\n\t\t_ = GeoIP.new(GeoIP.GEOIP_MEMORY_CACHE)\n\texcept Exception:\n\t\tMODULE_GEOIP = False\n\t\tpass"
            ],
            [
                195,
                212,
                "\t\ttry:\n\t\t\tfrom tld import parse_tld\n\t\texcept ImportError:\n\t\t\tctld = ['org', 'com', 'net', 'gov', 'edu', 'co', 'mil', 'nom', 'ac', 'info', 'biz']\n\t\t\td = domain.rsplit('.', 3)\n\t\t\tif len(d) == 2:\n\t\t\t\treturn '', d[0], d[1]\n\t\t\tif len(d) > 2:\n\t\t\t\tif d[-2] in ctld:\n\t\t\t\t\treturn '.'.join(d[:-3]), d[-3], '.'.join(d[-2:])\n\t\t\t\telse:\n\t\t\t\t\treturn '.'.join(d[:-2]), d[-2], d[-1]\n\t\telse:\n\t\t\td = parse_tld(domain, fix_protocol=True)[::-1]\n\t\t\tif d[1:] == d[:-1] and None in d:\n\t\t\t\td = tuple(domain.rsplit('.', 2))\n\t\t\t\td = ('',) * (3-len(d)) + d\n\t\t\treturn d"
            ],
            [
                451,
                464,
                "\t\ttry:\n\t\t\thttp = socket.socket()\n\t\t\thttp.settimeout(1)\n\t\t\thttp.connect((ip, 80))\n\t\t\thttp.send('HEAD / HTTP/1.1\\r\\nHost: {}\\r\\nUser-agent: {}\\r\\n\\r\\n'.format(vhost, self.useragent).encode())\n\t\t\tresponse = http.recv(1024).decode()\n\t\t\thttp.close()\n\t\texcept Exception:\n\t\t\tpass\n\t\telse:\n\t\t\theaders = response.splitlines()\n\t\t\tfor field in headers:\n\t\t\t\tif field.lower().startswith('server: '):\n\t\t\t\t\treturn field[8:]"
            ],
            [
                467,
                479,
                "\t\ttry:\n\t\t\tsmtp = socket.socket()\n\t\t\tsmtp.settimeout(1)\n\t\t\tsmtp.connect((mx, 25))\n\t\t\tresponse = smtp.recv(1024).decode()\n\t\t\tsmtp.close()\n\t\texcept Exception:\n\t\t\tpass\n\t\telse:\n\t\t\thello = response.splitlines()[0]\n\t\t\tif hello.startswith('220'):\n\t\t\t\treturn hello[4:].strip()\n\t\t\treturn hello[:40]"
            ],
            [
                484,
                491,
                "\t\ttry:\n\t\t\tsmtp = smtplib.SMTP(mx, 25, timeout=REQUEST_TIMEOUT_SMTP)\n\t\t\tsmtp.sendmail(from_addr, to_addr, 'And that\\'s how the cookie crumbles')\n\t\t\tsmtp.quit()\n\t\texcept Exception:\n\t\t\treturn False\n\t\telse:\n\t\t\treturn True"
            ],
            [
                842,
                864,
                "\t\ttry:\n\t\t\treq = requests.get(request_url, timeout=REQUEST_TIMEOUT_HTTP, headers={'User-Agent': args.useragent})\n\t\texcept requests.exceptions.ConnectionError:\n\t\t\tp_cli('Connection error\\n')\n\t\t\t_exit(1)\n\t\texcept requests.exceptions.HTTPError:\n\t\t\tp_cli('Invalid HTTP response\\n')\n\t\t\t_exit(1)\n\t\texcept requests.exceptions.Timeout:\n\t\t\tp_cli('Timeout (%d seconds)\\n' % REQUEST_TIMEOUT_HTTP)\n\t\t\t_exit(1)\n\t\texcept Exception:\n\t\t\tp_cli('Failed!\\n')\n\t\t\t_exit(1)\n\t\telse:\n\t\t\tif len(req.history) > 1:\n\t\t\t\tp_cli('\u2794 %s ' % req.url.split('?')[0])\n\t\t\tp_cli('%d %s (%.1f Kbytes)\\n' % (req.status_code, req.reason, float(len(req.text))/1000))\n\t\t\tif req.status_code // 100 == 2:\n\t\t\t\tssdeep_init = ssdeep.hash(''.join(req.text.split()).lower())\n\t\t\t\tssdeep_effective_url = req.url.split('?')[0]\n\t\t\telse:\n\t\t\t\targs.ssdeep = False"
            ],
            [
                577,
                597,
                "\t\t\t\ttry:\n\t\t\t\t\tip = socket.getaddrinfo(domain['domain-name'], 80)\n\t\t\t\texcept socket.gaierror as e:\n\t\t\t\t\tif e.errno == -3:\n\t\t\t\t\t\tdomain['dns-a'] = ['!ServFail']\n\t\t\t\t\tpass\n\t\t\t\texcept Exception as e:\n\t\t\t\t\tself.__debug(e)\n\t\t\t\t\tpass\n\t\t\t\telse:\n\t\t\t\t\tdomain['dns-a'] = list()\n\t\t\t\t\tdomain['dns-aaaa'] = list()\n\t\t\t\t\tfor j in ip:\n\t\t\t\t\t\tif '.' in j[4][0]:\n\t\t\t\t\t\t\tdomain['dns-a'].append(j[4][0])\n\t\t\t\t\t\tif ':' in j[4][0]:\n\t\t\t\t\t\t\tdomain['dns-aaaa'].append(j[4][0])\n\t\t\t\t\tdomain['dns-a'] = sorted(domain['dns-a'])\n\t\t\t\t\tdomain['dns-aaaa'] = sorted(domain['dns-aaaa'])\n\t\t\t\t\tdns_a = True\n\t\t\t\t\tdns_aaaa = True"
            ],
            [
                607,
                614,
                "\t\t\t\t\ttry:\n\t\t\t\t\t\tcountry = GeoIP.new(GeoIP.GEOIP_MEMORY_CACHE).country_name_by_addr(domain['dns-a'][0])\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\tself.__debug(e)\n\t\t\t\t\t\tpass\n\t\t\t\t\telse:\n\t\t\t\t\t\tif country:\n\t\t\t\t\t\t\tdomain['geoip-country'] = country.split(',')[0]"
            ],
            [
                628,
                637,
                "\t\t\t\t\ttry:\n\t\t\t\t\t\treq = requests.get(self.uri_scheme + '://' + domain['domain-name'] + self.uri_path + self.uri_query,\n\t\t\t\t\t\t\ttimeout=REQUEST_TIMEOUT_HTTP, headers={'User-Agent': self.useragent}, verify=False)\n\t\t\t\t\texcept Exception as e:\n\t\t\t\t\t\tself.__debug(e)\n\t\t\t\t\t\tpass\n\t\t\t\t\telse:\n\t\t\t\t\t\tif req.status_code // 100 == 2 and req.url.split('?')[0] != self.ssdeep_effective_url:\n\t\t\t\t\t\t\tssdeep_curr = ssdeep.hash(''.join(req.text.split()).lower())\n\t\t\t\t\t\t\tdomain['ssdeep-score'] = ssdeep.compare(self.ssdeep_init, ssdeep_curr)"
            ]
        ]
    },
    {
        "blob_id": "0b8d0459e119ef9c1a883d86bb05e946ecebc777",
        "matched_blocks": [
            [
                32,
                37,
                "\ttry:\n\t\tssh.connect(host, username=user, password=passwords)\n\texcept paramiko.AuthenticationException:\n\t\tprint (\"Failed: %s:%s\" % (user,passwords))\n\telse:\n\t\tprint (\"Found: %s:%s\" % (user,passwords))"
            ]
        ]
    },
    {
        "blob_id": "e1d02811f5cf8e54ec65eb5fec773b4d4256cf5e",
        "matched_blocks": [
            [
                700,
                711,
                "    try:\n        for count in range(100):\n            (failures, tests) = doctest.testmod()\n            if failures:\n                break\n\n            if (count % 10 == 0 and count) or count == 1:\n                print('%i times' % count)\n    except KeyboardInterrupt:\n        print('Aborted')\n    else:\n        print('Doctests done')"
            ]
        ]
    },
    {
        "blob_id": "d5495db0e429600a31a5d1d454b62cb0cd1fab11",
        "matched_blocks": [
            [
                283,
                288,
                "        try:\n            fac = type_registry.match(ty)\n        except KeyError:\n            pass\n        else:\n            return fac(self, ty)"
            ],
            [
                531,
                542,
                "                try:\n                    pyval = getattr(typ.pymod, attr)\n                    llval = self.get_constant(attrty, pyval)\n                except NotImplementedError:\n                    # Module attribute is not a simple constant\n                    # (e.g. it's a function), it will be handled later on.\n                    pass\n                else:\n                    @impl_attribute(typ, attr, attrty)\n                    def imp(context, builder, typ, val):\n                        return llval\n                    return imp"
            ],
            [
                332,
                337,
                "            try:\n                impl = struct_registry.match(ty)\n            except KeyError:\n                pass\n            else:\n                return self.get_struct_type(impl(ty))"
            ]
        ]
    },
    {
        "blob_id": "8d125b512185baf607fec608da08e61e3dfba30c",
        "matched_blocks": [
            [
                154,
                174,
                "                        try:\n                            params, results, param_results =  \\\n                                run_eval_alg(algorithm, train, test, dataset_obj, processed_dataset,\n                                             all_sensitive_attributes, sensitive, supported_tag)\n                        except Exception as e:\n                            import traceback\n                            traceback.print_exc(file=sys.stderr)\n                            print(\"Failed: %s\" % e, file=sys.stderr)\n                        else:\n                            row_starter = [algorithm.get_name(), i, str(supported_tag)]\n                            data_to_write.append(row_starter + results)\n                            # write_alg_results(detailed_files[supported_tag],\n                            #                   algorithm.get_name(), params, i, results)\n                            if algorithm.__class__ is ParamGridSearch:\n                                for params, results in param_results:\n                                    row_end = []\n                                    for (k,v) in params.items():\n                                        row_end.append(k)\n                                        row_end.append(v)\n                                    \n                                    data_to_write.append(row_starter + results + row_end)"
            ]
        ]
    },
    {
        "blob_id": "a1929366007d966a57e731bac88fc7ff87d6ef75",
        "matched_blocks": [
            [
                149,
                159,
                "            try:\n                b = self.queue.get(timeout=self._timeout)  # XXX inter char timeout\n            except queue.Empty:\n                if self._timeout == 0:\n                    break\n            else:\n                if b is not None:\n                    data += b\n                    size -= 1\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "685183591cc68992807cb442bab71157d4a2f293",
        "matched_blocks": [
            [
                422,
                594,
                "    try:\n  \n#       solver_parameter = {\n#            'OutputFlag': 0,\n#            }\n\n      # Ask solvers to automatically output log files. The log file for Gurobi is \"gurobi.log\".  \n      #  prob.solve(solver = 'GUROBI', verbose = True)\n        print('Trying with NumericFocus')\n#        prob.solve(solver = 'GUROBI', NumericFocus = 3,BarConvTol = 1e-8, FeasibilityTol = 1e-5)\n        prob.solve(solver = 'GUROBI', NumericFocus = 3)\n        print(prob.status)\n#        prob.solve(solver = 'GUROBI')\n#    prob.solve(solver = 'GUROBI',BarConvTol = 1e-11, feasibilityTol = 1e-9)\n#    prob.solve(solver = 'GUROBI',BarConvTol = 1e-10, feasibilityTol = 1e-8)\n#    prob.solve(solver = 'GUROBI',BarConvTol = 1e-8, FeasibilityTol = 1e-6)\n        \n        end_time = time.time()  # timer ends\n  \n    except cvx.error.SolverError as err:\n\n        print('Solver error encounterd!', err)\n        \n        result = {\n            'SYSTEM_COST': -1,\n            'PROBLEM_STATUS':prob.status\n            }\n                \n        result['CAPACITY_NATGAS'] = -1\n        result['CAPACITY_NATGAS_CCS'] = -1\n        result['CAPACITY_SOLAR'] = -1\n        result['CAPACITY_WIND'] = -1\n        result['CAPACITY_NUCLEAR'] = -1\n        result['CAPACITY_STORAGE'] = -1\n        result['CAPACITY_PGP_STORAGE'] = -1\n        result['CAPACITY_TO_PGP_STORAGE'] = -1\n        result['CAPACITY_FROM_PGP_STORAGE'] = -1\n        \n        result['PRICE'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_NATGAS'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_NATGAS_CCS'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_SOLAR'] = -1 * np.ones(demand_series.size) \n        result['DISPATCH_WIND'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_NUCLEAR'] = -1 * np.ones(demand_series.size)\n        result['CURTAILMENT_SOLAR'] = -1 * np.ones(demand_series.size) \n        result['CURTAILMENT_WIND'] = -1 * np.ones(demand_series.size)\n        result['CURTAILMENT_NUCLEAR'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_TO_STORAGE'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_FROM_STORAGE'] = -1 * np.ones(demand_series.size)\n        result['ENERGY_STORAGE'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_TO_PGP_STORAGE'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_FROM_PGP_STORAGE'] = -1 * np.ones(demand_series.size)\n        result['ENERGY_PGP_STORAGE'] = -1 * np.ones(demand_series.size)\n        result['DISPATCH_UNMET_DEMAND'] = -1 * np.ones(demand_series.size)\n        \n    else:        \n    \n        if verbose:\n            print ('system cost ',prob.value/(numerics_cost_scaling * numerics_demand_scaling))\n            print ('runtime: ', (end_time - start_time), 'seconds')\n         \n        # -----------------------------------------------------------------------------\n    \n        \n        result={\n                'SYSTEM_COST':prob.value/(numerics_cost_scaling * numerics_demand_scaling),\n                'PROBLEM_STATUS':prob.status\n                }\n        \n        result['PRICE'] = np.array(-1.0 * num_time_periods * constraints[-1].dual_value/ numerics_cost_scaling).flatten()\n        # note that hourly pricing can be determined from the dual of the constraint on energy balance\n        # The num_time_periods is in the above because the influence on the cost of an hour is much bigger then\n        # the impact of average cost over the period. The divide by the cost scaling corrects for the cost scaling.\n        \n        \n        if 'NATGAS' in system_components:\n            if case_dic['CAPACITY_NATGAS'] < 0:\n                result['CAPACITY_NATGAS'] = np.asscalar(capacity_natgas.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_NATGAS'] = case_dic['CAPACITY_NATGAS']\n            result['DISPATCH_NATGAS'] = np.array(dispatch_natgas.value).flatten()/numerics_demand_scaling\n        else:\n            result['CAPACITY_NATGAS'] = capacity_natgas/numerics_demand_scaling\n            result['DISPATCH_NATGAS'] = dispatch_natgas/numerics_demand_scaling\n    \n        if 'NATGAS_CCS' in system_components:\n            if case_dic['CAPACITY_NATGAS_CCS'] < 0:\n                result['CAPACITY_NATGAS_CCS'] = np.asscalar(capacity_natgas_ccs.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_NATGAS_CCS'] = case_dic['CAPACITY_NATGAS_CCS']\n            result['DISPATCH_NATGAS_CCS'] = np.array(dispatch_natgas_ccs.value).flatten()/numerics_demand_scaling\n        else:\n            result['CAPACITY_NATGAS_CCS'] = capacity_natgas_ccs/numerics_demand_scaling\n            result['DISPATCH_NATGAS_CCS'] = dispatch_natgas_ccs/numerics_demand_scaling\n    \n        if 'SOLAR' in system_components:\n            if case_dic['CAPACITY_SOLAR'] < 0:\n                result['CAPACITY_SOLAR'] = np.asscalar(capacity_solar.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_SOLAR'] = case_dic['CAPACITY_SOLAR']\n            result['DISPATCH_SOLAR'] = np.array(dispatch_solar.value).flatten()/numerics_demand_scaling\n            result['CURTAILMENT_SOLAR'] = result['CAPACITY_SOLAR'] * solar_series - result['DISPATCH_SOLAR']\n        else:\n            result['CAPACITY_SOLAR'] = capacity_solar/numerics_demand_scaling\n            result['DISPATCH_SOLAR'] = dispatch_solar/numerics_demand_scaling\n            result['CURTAILMENT_SOLAR'] = (capacity_solar-dispatch_solar)/numerics_demand_scaling \n    \n        if 'WIND' in system_components:\n            if case_dic['CAPACITY_WIND'] < 0:\n                result['CAPACITY_WIND'] = np.asscalar(capacity_wind.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_WIND'] = case_dic['CAPACITY_WIND']\n            result['DISPATCH_WIND'] = np.array(dispatch_wind.value).flatten()/numerics_demand_scaling\n            result['CURTAILMENT_WIND'] = result['CAPACITY_WIND'] * wind_series - result['DISPATCH_WIND']\n        else:\n            result['CAPACITY_WIND'] = capacity_wind/numerics_demand_scaling\n            result['DISPATCH_WIND'] = dispatch_wind/numerics_demand_scaling\n            result['CURTAILMENT_WIND'] = (capacity_wind-dispatch_wind)/numerics_demand_scaling\n    \n        if 'NUCLEAR' in system_components:\n            if case_dic['CAPACITY_NUCLEAR'] < 0:\n                result['CAPACITY_NUCLEAR'] = np.asscalar(capacity_nuclear.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_NUCLEAR'] = case_dic['CAPACITY_NUCLEAR']\n            result['DISPATCH_NUCLEAR'] = np.array(dispatch_nuclear.value).flatten()/numerics_demand_scaling\n            result['CURTAILMENT_NUCLEAR'] = result['CAPACITY_NUCLEAR'] * np.ones(num_time_periods) - result['DISPATCH_NUCLEAR']\n        else:\n            result['CAPACITY_NUCLEAR'] = capacity_nuclear/numerics_demand_scaling\n            result['DISPATCH_NUCLEAR'] = dispatch_nuclear/numerics_demand_scaling\n            result['CURTAILMENT_NUCLEAR'] = (capacity_nuclear-dispatch_nuclear)/numerics_demand_scaling  \n          \n        if 'STORAGE' in system_components:\n            if case_dic['CAPACITY_STORAGE'] < 0:\n                result['CAPACITY_STORAGE'] = np.asscalar(capacity_storage.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_STORAGE'] = case_dic['CAPACITY_STORAGE']\n            result['DISPATCH_TO_STORAGE'] = np.array(dispatch_to_storage.value).flatten()/numerics_demand_scaling\n            result['DISPATCH_FROM_STORAGE'] = np.array(dispatch_from_storage.value).flatten()/numerics_demand_scaling\n            result['ENERGY_STORAGE'] = np.array(energy_storage.value).flatten()/numerics_demand_scaling\n        else:\n            result['CAPACITY_STORAGE'] = capacity_storage/numerics_demand_scaling\n            result['DISPATCH_TO_STORAGE'] = dispatch_to_storage/numerics_demand_scaling\n            result['DISPATCH_FROM_STORAGE'] = dispatch_from_storage/numerics_demand_scaling\n            result['ENERGY_STORAGE'] = energy_storage/numerics_demand_scaling\n            \n        if 'PGP_STORAGE' in system_components:\n            if case_dic['CAPACITY_PGP_STORAGE'] < 0:\n                result['CAPACITY_PGP_STORAGE'] = np.asscalar(capacity_pgp_storage.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_PGP_STORAGE'] = case_dic['CAPACITY_PGP_STORAGE']\n            if case_dic['CAPACITY_TO_PGP_STORAGE'] < 0:\n                result['CAPACITY_TO_PGP_STORAGE'] = np.asscalar(capacity_to_pgp_storage.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_TO_PGP_STORAGE'] = case_dic['CAPACITY_TO_PGP_STORAGE']\n            if case_dic['CAPACITY_FROM_PGP_STORAGE'] < 0:\n                result['CAPACITY_FROM_PGP_STORAGE'] = np.asscalar(capacity_from_pgp_storage.value)/numerics_demand_scaling\n            else:\n                result['CAPACITY_FROM_PGP_STORAGE'] = case_dic['CAPACITY_FROM_PGP_STORAGE']\n            result['DISPATCH_TO_PGP_STORAGE'] = np.array(dispatch_to_pgp_storage.value).flatten()/numerics_demand_scaling\n            result['DISPATCH_FROM_PGP_STORAGE'] = np.array(dispatch_from_pgp_storage.value).flatten()/numerics_demand_scaling\n            result['ENERGY_PGP_STORAGE'] = np.array(energy_pgp_storage.value).flatten()/numerics_demand_scaling\n        else:\n            result['CAPACITY_PGP_STORAGE'] = capacity_pgp_storage/numerics_demand_scaling\n            result['CAPACITY_TO_PGP_STORAGE'] = capacity_to_pgp_storage/numerics_demand_scaling\n            result['CAPACITY_FROM_PGP_STORAGE'] = capacity_from_pgp_storage/numerics_demand_scaling\n            result['DISPATCH_TO_PGP_STORAGE'] = dispatch_to_pgp_storage/numerics_demand_scaling\n            result['DISPATCH_FROM_PGP_STORAGE'] = dispatch_from_pgp_storage/numerics_demand_scaling\n            result['ENERGY_PGP_STORAGE'] = energy_pgp_storage/numerics_demand_scaling\n                        \n        if 'UNMET_DEMAND' in system_components:\n            result['DISPATCH_UNMET_DEMAND'] = np.array(dispatch_unmet_demand.value).flatten()/numerics_demand_scaling\n        else:\n            result['DISPATCH_UNMET_DEMAND'] = dispatch_unmet_demand/numerics_demand_scaling"
            ]
        ]
    },
    {
        "blob_id": "d541731a871f9f9d13040f08cd87d7ab9d5c1bab",
        "matched_blocks": [
            [
                12,
                33,
                "try:\n    result = subprocess.run(\n            ['lsof', '-n', \"-i4TCP:%s\" % port],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE)\nexcept subprocess.CalledProcessError:\n    print(f\"No process listening on port {port}\")\nelse:\n    listening = None\n\n    for line in result.stdout.splitlines():\n        if \"LISTEN\" in str(line):\n            listening = line\n            break\n\n    if listening:\n        # PID is the second column in the output\n        pid = int(listening.split()[1])\n        os.kill(pid, 9)\n        print(f\"Killed process {pid}\")\n    else:\n        print(f\"No process listening on port {port}\")"
            ]
        ]
    },
    {
        "blob_id": "41583ea6e01c8e99c165c21c63182ebb7c6c41b6",
        "matched_blocks": [
            [
                13,
                22,
                "            try:\n                c.execute(\n                    \"\"\"\n                    DELETE FROM credentials WHERE username=:username\n                    \"\"\",{'username':username}\n                )\n            except:\n                print(\"The given username doesn't exist in the database...\")\n            else:\n                print(username,\"removed successfully from the admin list\")"
            ]
        ]
    },
    {
        "blob_id": "106fee030e27c20844b58844b8eafde975ced42d",
        "matched_blocks": [
            [
                969,
                974,
                "    try:\n        _run_edit_test(\"foo\")\n    except code.InteractivelyDefined as e:\n        nt.assert_equal(e.index, n)\n    else:\n        raise AssertionError(\"Should have raised InteractivelyDefined\")"
            ],
            [
                832,
                837,
                "        try:\n            find_cmd(cmd)\n        except Exception:\n            pass\n        else:\n            nt.assert_in(cmd, ip.magics_manager.magics['cell'])"
            ]
        ]
    },
    {
        "blob_id": "b6a5c86074392c7bcd0cf4245639e879e0d2517e",
        "matched_blocks": [
            [
                1051,
                1057,
                "          try:\n              temp_text = IO_queue.get(block = False)\n          except Queue.Empty:\n              continue_updates = False  # queue is exhausted so no need for further updates\n          else:\n              self.insert('end', temp_text[0], temp_text[1])\n              self.see(\"end\")  # make the last line visible (scroll text off the top)"
            ]
        ]
    },
    {
        "blob_id": "befb49d4dbdb7cb938cabe95b0ce64fc371134a3",
        "matched_blocks": [
            [
                314,
                320,
                "            try:\n                resolver = resolve(self.request.path_info)\n            except Resolver404:\n                return False\n            else:\n                from cms.views import details\n                return resolver.func != details"
            ]
        ]
    },
    {
        "blob_id": "7027d267d55dd34f4335b5ae71ba77455ec34778",
        "matched_blocks": [
            [
                101,
                106,
                "            try:\n                vpool = lexeme(word)\n            except:\n                print('pattern error')\n            else:\n                break"
            ]
        ]
    },
    {
        "blob_id": "820056fcf0b577123f661318b8224a7db503cb03",
        "matched_blocks": [
            [
                91,
                99,
                "        try:\n            X, y = next(self.reader_X_lst[self.partition_index]), next(self.reader_Y)\n        except Exception as e:\n            self.partition_index += 1\n            X, y = next(self.reader_X_lst[self.partition_index]), next(self.reader_Y)\n        else:\n            if len(X) < 64:\n                self.partition_index += 1\n                X, y = next(self.reader_X_lst[self.partition_index]), next(self.reader_Y)"
            ]
        ]
    },
    {
        "blob_id": "06e6396b46f25922b1b9828171a146e6ebaa955f",
        "matched_blocks": [
            [
                266,
                290,
                "                    try:\n                        field = through._meta.get_field(field_name)\n                    except exceptions.FieldDoesNotExist:\n                        errors.append(\n                            checks.Error(\n                                (\"The intermediary model '%s' has no field '%s'.\") % (\n                                    qualified_model_name, field_name),\n                                hint=hint,\n                                obj=self,\n                                id='fields.E338',\n                            )\n                        )\n                    else:\n                        if not (hasattr(field, 'remote_field') and\n                                getattr(field.remote_field, 'model', None) == related_model):\n                            errors.append(\n                                checks.Error(\n                                    \"'%s.%s' is not a foreign key to '%s'.\" % (\n                                        through._meta.object_name, field_name,\n                                        related_model._meta.object_name),\n                                    hint=hint,\n                                    obj=self,\n                                    id='fields.E339',\n                                )\n                            )"
            ]
        ]
    },
    {
        "blob_id": "e22f8f1abbad54031bc34f80763d355d99ef3f94",
        "matched_blocks": [
            [
                2,
                7,
                "try:\n    f = open(\"does.txt\")\nexcept Exception as e:\n    print(e)\nelse:\n    print(\"this will run only when except is not running \")"
            ]
        ]
    },
    {
        "blob_id": "0a09280c89654cb0781a9f25aab1d0b60f64be90",
        "matched_blocks": [
            [
                716,
                721,
                "                try:\n                    div = next(divs)\n                except StopIteration:\n                    return None\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "802118261b60b061deee2d6c2d86ec63d9bac3e6",
        "matched_blocks": [
            [
                341,
                346,
                "        try:\n            assert isinstance(rank, int) and isinstance(File, int)\n        except AssertionError:\n            raise TypeError(\"Both initialisation parameters must be integers.\")\n        else:\n            self.vector = (rank, File)"
            ]
        ]
    },
    {
        "blob_id": "f7b3500ae91f51a525d53781d284efa1a7bfc990",
        "matched_blocks": [
            [
                331,
                338,
                "            try:\n                head = r[remote_refs[b\"HEAD\"]]\n            except KeyError:\n                pass\n            else:\n                r[b'HEAD'] = head.id\n                errstream.write(b'Checking out ' + head.id + b'\\n')\n                r.reset_index(head.tree)"
            ],
            [
                392,
                416,
                "                try:\n                    st = os.lstat(full_path)\n                except OSError:\n                    pass\n                else:\n                    try:\n                        blob = blob_from_path_and_stat(full_path, st)\n                    except IOError:\n                        pass\n                    else:\n                        try:\n                            committed_sha = tree_lookup_path(\n                                r.__getitem__, r[r.head()].tree, tree_path)[1]\n                        except KeyError:\n                            committed_sha = None\n\n                        if blob.id != index_sha and index_sha != committed_sha:\n                            raise Exception(\n                                'file has staged content differing '\n                                'from both the file and head: %s' % p)\n\n                        if index_sha != committed_sha:\n                            raise Exception(\n                                'file has staged changes: %s' % p)\n                        os.remove(full_path)"
            ],
            [
                397,
                416,
                "                    try:\n                        blob = blob_from_path_and_stat(full_path, st)\n                    except IOError:\n                        pass\n                    else:\n                        try:\n                            committed_sha = tree_lookup_path(\n                                r.__getitem__, r[r.head()].tree, tree_path)[1]\n                        except KeyError:\n                            committed_sha = None\n\n                        if blob.id != index_sha and index_sha != committed_sha:\n                            raise Exception(\n                                'file has staged content differing '\n                                'from both the file and head: %s' % p)\n\n                        if index_sha != committed_sha:\n                            raise Exception(\n                                'file has staged changes: %s' % p)\n                        os.remove(full_path)"
            ]
        ]
    },
    {
        "blob_id": "ea07070f24155b2a2f81e7356747bec6671eff82",
        "matched_blocks": [
            [
                2513,
                2521,
                "    try:\n        import numpy\n    except ImportError:\n        pass\n    else:\n        if isinstance(A, numpy.ndarray):\n            return B.__class__\n        if isinstance(B, numpy.ndarray):\n            return A.__class__"
            ]
        ]
    },
    {
        "blob_id": "8dcadf9cb0ccc7446858d1968eaa910bab2fd914",
        "matched_blocks": [
            [
                66,
                71,
                "\ttry:\n\t\tread_wait([popen.stdout, popen.stderr], read_timeout)\n\texcept TimeoutError:\n\t\terr = traceback.format_exc()\n\telse:\n\t\terr = popen.stdout.read() + popen.stderr.read()"
            ],
            [
                375,
                385,
                "\t\ttry:\n\t\t\tval = next(self.data_stream)\n\t\texcept StopIteration:\n\t\t\treturn False\n\t\telse:\n\t\t\ttry:\n\t\t\t\tself.write_line(stream, val)\n\t\t\texcept:\n\t\t\t\tself.data_stream = chain([val], self.data_stream)\n\t\t\t\traise\n\t\t\treturn True"
            ]
        ]
    },
    {
        "blob_id": "3ae6f30fa3fe13c41d94fe3ebd8e028f058ef13e",
        "matched_blocks": [
            [
                81,
                93,
                "        try:\n\n            print(\"[RUNNER] Executing : {0}\".format(code))\n            exec(code, user_ns, user_ns)\n\n        except Exception as e:\n            logger.warning(\"Caught errors but will not handled %s\", e)\n            raise e\n\n        else :\n            #print(\"Done : {0}\".format(locals()))\n            print(\"[RUNNER] Result    : {0}\".format(user_ns.get(resultname)))\n            return user_ns.get(resultname)"
            ],
            [
                97,
                143,
                "        try:\n            # Blocking wait on the queue\n            msg = incoming_q.get(block=True, timeout=10)\n            #logger.debug(\"[RUNNER] Got message : %s\", msg)\n\n        except queue.Empty:\n            # Handle case where no items were on queue\n            logger.debug(\"[RUNNER] got nothing\")\n\n        except IOError as ioerror:\n            logger.debug(\"[RUNNER] broken pipe, error: %s\", ioerror)\n            try:\n                # Attempt to send a stop notification to the management thread\n                outgoing_q.put(None)\n\n            except Exception :\n                pass\n\n            break\n\n        except Exception as e:\n            logger.debug(\"[RUNNER] caught unknown exception : %s\", e)\n\n        else:\n            # Handle received message\n            if not msg :\n                # Empty message is a die request\n                logger.debug(\"[RUNNER] Received exit request\")\n                outgoing_q.put(None)\n                break\n            else:\n                # Received a valid message, handle it\n                logger.debug(\"[RUNNER] Got a valid task : %s\", msg[\"task_id\"])\n                try:\n                    response_obj = execute_task(msg['buffer'])\n                    response = {\"task_id\" : msg[\"task_id\"],\n                                \"result\"  : serialize_object(response_obj)}\n\n                    logger.warning(\"[RUNNER] Returing result : %s\",\n                                   deserialize_object(response[\"result\"]) )\n\n                except Exception as e:\n                    logger.debug(\"[RUNNER] Caught task exception\")\n                    response = {\"task_id\" : msg[\"task_id\"],\n                                \"exception\"  : serialize_object(e)}\n\n                outgoing_q.put(response)"
            ],
            [
                204,
                234,
                "            try:\n                msg = self.incoming_q.get(block=True, timeout=1)\n\n            except queue.Empty as e:\n                # timed out.\n                pass\n\n            except IOError as e:\n                logger.debug(\"[MTHREAD] caught broken queue : %s : errno:%s\", e, e.errno)\n                return\n\n            except Exception as e:\n                logger.debug(\"[MTHREAD] caught unknown exception : %s\", e)\n                pass\n\n            else:\n\n                if msg is None:\n                    logger.debug(\"[MTHREAD] Got None\")\n                    return\n\n                else:\n                    logger.debug(\"[MTHREAD] Got message : %s\", msg)\n                    task_fut = self.tasks[msg['task_id']]\n                    if 'result' in msg:\n                        result, _ = deserialize_object(msg['result'])\n                        task_fut.set_result(result)\n\n                    elif 'exception' in msg:\n                        exception, _ = deserialize_object(msg['exception'])\n                        task_fut.set_exception(exception)"
            ]
        ]
    },
    {
        "blob_id": "f731efcbe16170f0445cf997c68994a1f3a467a3",
        "matched_blocks": [
            [
                747,
                757,
                "                    try:\n                        # save image into the static folder\n                        new_img_name = image_manager.resave_img(\n                            img_path=get_abs_img_path(img_path),\n                            img_name=\"_\".join(class_name.lower().split()),\n                        )\n                    except ImageManager.errors as e:\n                        print(f\"{C_CLR_ERROR}{e}\")\n                        exit_with_delay()\n                    else:\n                        print(f\"{C_CLR_OKBLUE} Saved image for class {class_name}\")"
            ]
        ]
    },
    {
        "blob_id": "62dff433a46415b9e041b768085e88be6374ecc3",
        "matched_blocks": [
            [
                1349,
                1356,
                "            try:\n                steps = [buckets[i + 1] - buckets[i] for i in range(len(buckets) - 1)]\n            except TypeError:\n                pass  # objects in buckets do not support '-'\n            else:\n                if max(steps) - min(steps) < 1e-10:  # handle precision errors\n                    even = True\n                    inc = (maxv - minv) / (len(buckets) - 1)"
            ]
        ]
    },
    {
        "blob_id": "7372e914f94e3c5b6b61b4cd9d53682397e2b2a7",
        "matched_blocks": [
            [
                121,
                126,
                "        try:\n            iter(obj)\n        except Exception:\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "9d1b7c4312244fba539d79dfb6fc1c1efa794b0a",
        "matched_blocks": [
            [
                178,
                184,
                "    try:\n        import wsproto\n    except ImportError:\n        say(\"wsproto must be on python path -- set PYTHONPATH or install it\")\n        sys.exit(2)\n    else:\n        coverage_settings[\"wsproto-path\"] = os.path.dirname(wsproto.__file__)"
            ],
            [
                78,
                86,
                "        try:\n            sock.connect((\"localhost\", port))\n        except socket.error as exc:\n            if exc.errno == errno.ECONNREFUSED:\n                time.sleep(0.01)\n            else:\n                raise\n        else:\n            return"
            ]
        ]
    },
    {
        "blob_id": "4a3a2bf306a496008b27fbee6b086d38997eed22",
        "matched_blocks": [
            [
                9,
                50,
                "try:\n    import distributed.protocol as _dp\n    from distributed.utils import has_keyword\nexcept ImportError:\n    def register_distributed_serializer(cls):\n        \"\"\"Dummy no-op function.\n        \"\"\"\n        pass\nelse:\n    CUSTOM_SERIALIZATION_AVAILABLE = True\n\n    def register_distributed_serializer(cls):\n        \"\"\"Register serialization methods for dask.distributed.\n        \"\"\"\n        _dp.register_serialization(cls, _serialize, _deserialize)\n\n    def has_context_keyword(meth):\n        if isinstance(meth, MethodType):\n            return has_keyword(meth.__func__, 'context')\n        else:\n            return has_keyword(meth, 'context')\n\n    def _serialize(df, context=None):\n        def do_serialize(x):\n            return _dp.serialize(x, context=context)\n\n        def call_with_context(meth, x):\n            if has_context_keyword(meth):\n                return meth(x, context=context)\n            else:\n                return meth(x)\n\n        header, frames = call_with_context(df.serialize, do_serialize)\n        assert 'reconstructor' not in header\n        meth_deserial = getattr(type(df), 'deserialize')\n        header['reconstructor'] = do_serialize(meth_deserial)\n        return header, frames\n\n    def _deserialize(header, frames):\n        reconstructor = _dp.deserialize(*header['reconstructor'])\n        assert reconstructor is not None, 'None {}'.format(header['type'])\n        return reconstructor(_dp.deserialize, header, frames)"
            ]
        ]
    },
    {
        "blob_id": "f1702544cc64b0b33921a5e070d660325fd1ae48",
        "matched_blocks": [
            [
                125,
                130,
                "        try:\n            self.commit()\n        except Exception:\n            self.rollback()\n        else:\n            self.close()"
            ]
        ]
    },
    {
        "blob_id": "f16923e24dab06b3bc5648ef66acc72cf73711b4",
        "matched_blocks": [
            [
                193,
                200,
                "        try:\n            blocks = len(self.result)\n        except (TypeError,AttributeError,NotImplementedError):\n            pass\n        else:\n            if blocks==1:\n                self.headers['Content-Length'] = str(self.bytes_sent)\n                return"
            ]
        ]
    },
    {
        "blob_id": "dab9d36b8c73fe53c08593529ac46e9be7d0d02a",
        "matched_blocks": [
            [
                16,
                22,
                "    try:\n        percent = find_percent(user)\n    except KeyError:\n        print(\"Incorrect values provided to calculation function\")\n        raise\n    else:\n        print(f\"User {user.name} got {percent}% marks\")"
            ]
        ]
    },
    {
        "blob_id": "6f8524311c4daba1891bb1f2acf250e6288f9817",
        "matched_blocks": [
            [
                861,
                866,
                "                            try:\n                                getcallargs(current)\n                            except TypeError:  # arguments *were* required\n                                current = context.template.engine.string_if_invalid  # invalid method call\n                            else:\n                                raise"
            ]
        ]
    },
    {
        "blob_id": "5f281cdea57df4eaeb7337c443d1779713e1fbf3",
        "matched_blocks": [
            [
                36,
                43,
                "            try:\n                self.process_risks()\n            except Exception as e:\n                logger.exception(e)\n                sleep_seconds = self.queue_error_interval\n            else:\n                run_time = datetime.now() - start\n                sleep_seconds = (self.run_interval - run_time).seconds"
            ],
            [
                182,
                196,
                "            try:\n                response = func(url, timeout=timeout, **kwargs)\n            except Exception as e:\n                logger.exception(e)\n            else:\n                status_ok = 201 if method == \"post\" else 200\n                if response.status_code == status_ok:\n                    try:\n                        json_res = response.json()\n                    except Exception as e:\n                        logger.exception(e)\n                    else:\n                        return json_res\n                else:\n                    logger.error(\"Unsuccessful response code: {}\".format(response.status_code))"
            ],
            [
                189,
                194,
                "                    try:\n                        json_res = response.json()\n                    except Exception as e:\n                        logger.exception(e)\n                    else:\n                        return json_res"
            ]
        ]
    },
    {
        "blob_id": "8d11cbc6dd0035bf24777ebc7c1664a25e47373c",
        "matched_blocks": [
            [
                13,
                30,
                "    try:\n        response = table.delete_item(\n            Key={\n                'year': year,\n                'title': title\n            },\n            ConditionExpression=\"info.rating <= :val\",\n            ExpressionAttributeValues={\n                \":val\": Decimal(rating)\n            }\n        )\n    except ClientError as e:\n        if e.response['Error']['Code'] == \"ConditionalCheckFailedException\":\n            print(e.response['Error']['Message'])\n        else:\n            raise\n    else:\n        return response"
            ]
        ]
    },
    {
        "blob_id": "77c0bee803a76518c5cd4da69b783eed5664e2fb",
        "matched_blocks": [
            [
                367,
                375,
                "            try:\n                result = function(*args, **kwargs)\n            except DoNotCache as e:\n                result = e.result\n            else:\n                try:\n                    storer(cache_key, result, expire)\n                except redis.ConnectionError as e:\n                    logging.exception(e)"
            ]
        ]
    },
    {
        "blob_id": "39af451cd7eb487341e9f22b2dc82c7c97ae97f4",
        "matched_blocks": [
            [
                88,
                103,
                "                try:\n                    computation.gas_meter.consume_gas(\n                        contract_code_gas_fee,\n                        reason=\"Write contract code for CREATE\",\n                    )\n                except OutOfGas:\n                    computation.output = b''\n                else:\n                    self.logger.debug(\n                        \"SETTING CODE: %s -> length: %s | hash: %s\",\n                        encode_hex(self.msg.storage_address),\n                        len(contract_code),\n                        encode_hex(keccak(contract_code))\n                    )\n                    with self.vm_state.state_db() as state_db:\n                        state_db.set_code(self.msg.storage_address, contract_code)"
            ]
        ]
    },
    {
        "blob_id": "bf676537a89da5673703b3507daf8b5d7be47720",
        "matched_blocks": [
            [
                44,
                52,
                "        try:\n            await Prison.change_lang(language, ctx.guild.id)\n        except TypeError as ex:\n            await ctx.send(embed=Embed(\n                title=__(\"\u0412\u044b\u0431\u0440\u0430\u043d \u043d\u0435\u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u044b\u0439 \u044f\u0437\u044b\u043a\"), description=f\"```{str(ex)}```\"\n            ))\n            return\n        else:\n            await ctx.send(__(\"\u0423\u0441\u043f\u0435\u0448\u043d\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d \u044f\u0437\u044b\u043a \u043d\u0430 {language}\").format(language))"
            ]
        ]
    },
    {
        "blob_id": "a264a71e67b64eb00d4cde1553abbc6e2d0250c2",
        "matched_blocks": [
            [
                1076,
                1082,
                "        try:\n            idx = self.popped.pop(val)\n        except KeyError:\n            warn('Could not find value: %s' % (val,))\n        else:\n            loc = np.searchsorted(self.indices, idx)\n            self.indices.insert(loc, idx)"
            ]
        ]
    },
    {
        "blob_id": "f96f89d9b4a367edb8f8dbf294ee4d21024402b0",
        "matched_blocks": [
            [
                48,
                53,
                "        try:\n            event.full_clean()\n        except ValidationError as err:\n            messages.error(request, repr(err))\n        else:\n            event.save()"
            ]
        ]
    },
    {
        "blob_id": "59948c00e4905df5fa1638c82f7126e0f1b85ed8",
        "matched_blocks": [
            [
                9,
                23,
                "\ttry:\n\t\tselected_choice = p.choice_set.get(pk=request.POST['choice'])\n\texcept (KeyError, Choice.DoesNotExist):\n\t\t# Redisplay the poll voting form.\n\t\treturn render_to_response('polls/detail.html', {\n\t\t\t'poll': p,\n\t\t\t'error_message': \"You didn't select a choice.\",\n\t\t\t}, context_instance=RequestContext(request))\n\telse:\n\t\tselected_choice.votes += 1\n\t\tselected_choice.save()\n\t\t# Always return an HttpResponseRedirect after successfully dealing\n\t\t# with POST data. This prevents data from being posted twice if a\n\t\t# user hits the Back button.\n\t\treturn HttpResponseRedirect(reverse('poll_results', args=(p.id,)))"
            ]
        ]
    },
    {
        "blob_id": "aa620b009579c0384555f668a03809e43558389d",
        "matched_blocks": [
            [
                29,
                43,
                "            try:\n                facebook_age_range = response_dict['age_range']['min']\n            except KeyError:\n                facebook_generation = ''\n            else:\n                if facebook_age_range < 12:\n                    facebook_generation = '1'\n                elif facebook_age_range < 22:\n                    facebook_generation = '2'\n                elif facebook_age_range < 32:\n                    facebook_generation = '3'\n                elif facebook_age_range < 42:\n                    facebook_generation = '4'\n                else:\n                    facebook_generation = '5'"
            ],
            [
                44,
                52,
                "            try:\n                facebook_gender = response_dict['gender']\n            except KeyError:\n                facebook_gender = ''\n            else:\n                if facebook_gender == 'male':\n                    facebook_gender = 'm'\n                elif facebook_gender == 'femal':\n                    facebook_gender = 'f'"
            ]
        ]
    },
    {
        "blob_id": "049c12ca9c2ec403bf4f152a25d45aee9f1d0c8c",
        "matched_blocks": [
            [
                1,
                6,
                "try:\n    num =int(input('\uc22b\uc790\ub97c \uc785\ub825\ud558\uc138\uc694:'))\nexcept ValueError:\n    print('\uc22b\uc790\uac00 \uc544\ub2d9\ub2c8\ub2e4.')\nelse:\n    print(num)"
            ]
        ]
    },
    {
        "blob_id": "ef05db1955755b1e2edc119db0de554e17ea0b06",
        "matched_blocks": [
            [
                665,
                680,
                "    try:\n        n = len(bins)\n    except TypeError:\n        # bins should be an integer (or at least definitely not a Quantity).\n        if isinstance(bins, Quantity):\n            raise NotImplementedError\n\n    else:\n        if n == 1:\n            raise NotImplementedError\n        elif n == 2 and not isinstance(bins, Quantity):\n            bins = [_check_bins(b, unit)\n                    for (b, unit) in zip(bins, (x.unit, y.unit))]\n        else:\n            bins = _check_bins(bins, x.unit)\n            y = y.to(x.unit)"
            ],
            [
                699,
                710,
                "    try:\n        # Sample is an ND-array.\n        _, D = sample.shape\n    except (AttributeError, ValueError):\n        # Sample is a sequence of 1D arrays.\n        sample = _as_quantities(*sample)\n        sample_units = [s.unit for s in sample]\n        sample = [s.value for s in sample]\n        D = len(sample)\n    else:\n        sample = _as_quantity(sample)\n        sample_units = [sample.unit] * D"
            ],
            [
                712,
                726,
                "    try:\n        M = len(bins)\n    except TypeError:\n        # bins should be an integer\n        from astropy.units import Quantity\n\n        if isinstance(bins, Quantity):\n            raise NotImplementedError\n    else:\n        if M != D:\n            raise ValueError(\n                'The dimension of bins must be equal to the dimension of the '\n                ' sample x.')\n        bins = [_check_bins(b, unit)\n                for (b, unit) in zip(bins, sample_units)]"
            ]
        ]
    },
    {
        "blob_id": "66ee784a1e03822e3de660bf82ef3235ebe27b0e",
        "matched_blocks": [
            [
                208,
                224,
                "        try:\n            environment_id = self._get_environment_id_from_request(\n                request, group.project.organization_id)\n        except Environment.DoesNotExist:\n            get_range = lambda model, keys, start, end, **kwargs: \\\n                {k: tsdb.make_series(0, start, end) for k in keys}\n            tags = []\n            user_reports = UserReport.objects.none()\n\n        else:\n            get_range = functools.partial(tsdb.get_range, environment_id=environment_id)\n            tags = tagstore.get_group_tag_keys(\n                group.project_id, group.id, environment_id, limit=100)\n            if environment_id is None:\n                user_reports = UserReport.objects.filter(group=group)\n            else:\n                user_reports = UserReport.objects.filter(group=group, environment_id=environment_id)"
            ]
        ]
    },
    {
        "blob_id": "a28fbe0ac1272ed404582adee28841fa50652775",
        "matched_blocks": [
            [
                408,
                416,
                "    try:\n        # wrapped in try block in case Trimmed_reads is not reported in this\n        # pipeline.\n        tr = float(pm.get_stat(\"Trimmed_reads\"))\n    except:\n        print(\"Trimmed reads is not reported.\")\n    else:\n        res_key = \"Alignment_rate_\" + assembly_identifier\n        pm.report_result(res_key, round(float(ar) * 100 / float(tr), 2))"
            ],
            [
                889,
                895,
                "        try:\n            rr = float(pm.get_stat(\"Raw_reads\"))\n        except:\n            pm.warning(\"Can't calculate trim loss rate without raw read result.\")\n        else:\n            pm.report_result(\n                \"Trim_loss_rate\", round((rr - n_trim) * 100 / rr, 2))"
            ]
        ]
    },
    {
        "blob_id": "753e2730effda2ec1bcd6228e0c59500fcae0a63",
        "matched_blocks": [
            [
                409,
                430,
                "            try:\n                # Check that backend is running, communicable, and caught up with the blockchain.\n                # Check that the database has caught up with bitcoind.\n                if time.time() - self.last_database_check > 10 * 60: # Ten minutes since last check.\n                    if not config.FORCE:\n                        code = 11\n                        logger.debug('Checking backend state.')\n                        check_backend_state()\n                        code = 12\n                        logger.debug('Checking database state.')\n                        check_database_state(db, backend.getblockcount())\n                        self.last_database_check = time.time()\n            except (BackendError, DatabaseError) as e:\n                exception_name = e.__class__.__name__\n                exception_text = str(e)\n                logger.debug(\"API Status Poller: %s\", exception_text)\n                jsonrpc_response = jsonrpc.exceptions.JSONRPCServerError(message=exception_name, data=exception_text)\n                current_api_status_code = code\n                current_api_status_response_json = jsonrpc_response.json.encode()\n            else:\n                current_api_status_code = None\n                current_api_status_response_json = None"
            ],
            [
                673,
                678,
                "            try:\n                check_database_state(db, latestBlockIndex)\n            except DatabaseError:\n                caught_up = False\n            else:\n                caught_up = True"
            ]
        ]
    },
    {
        "blob_id": "1d4d93b22ba6af54959fc83201e284ab2d6a4946",
        "matched_blocks": [
            [
                1380,
                1389,
                "        try:\n            name = x.__class__.__name__\n        except Exception:\n            pass\n        else:\n            raise TypeError(\n                'This low-level function only operates on np.ndarray '\n                f'instances. To get a {kind} {name} instance, use a method '\n                f'like `inst_new = inst.copy().{alternative}(...)` '\n                'instead.')"
            ]
        ]
    },
    {
        "blob_id": "c0251aca1b79106e751b7b395c7dc2821f0a98b3",
        "matched_blocks": [
            [
                4,
                9,
                "    try:\n        c=int(num1)+int(num2)                           #10.6 10.7\u5df2\u5b8c\u6210\n    except  ValueError:\n        print('\u7a0b\u5e8f\u51fa\u9519\uff0c\u8bf7\u786e\u4fdd\u8bf7\u8f93\u5165\u7684\u662f\u6570\uff01')\n    else:\n        print(c)"
            ]
        ]
    },
    {
        "blob_id": "1637d259f45d4f576399785540d3276be1f6a314",
        "matched_blocks": [
            [
                96,
                102,
                "            try:\n                password = tokens.popleft()\n            except IndexError:\n                self._consumer.atlantis(faction=faction)\n            else:\n                self._consumer.atlantis(faction=faction,\n                                        password=password)"
            ],
            [
                143,
                149,
                "            try:\n                dirs = [OrdersParser._parse_dir(d.lower()) for d in tokens]\n            except SyntaxError as e:\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_advance(dirs=dirs, permanent=permanent,\n                                             comment=comment)"
            ],
            [
                152,
                159,
                "            try:\n                unit = OrdersParser._parse_unit(tokens)\n            except SyntaxError as e:\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_assassinate(unit=unit,\n                                                 permanent=permanent,\n                                                 comment=comment)"
            ],
            [
                163,
                174,
                "            try:\n                while tokens:\n                    targets.append(OrdersParser._parse_unit(tokens))\n            except SyntaxError as e:\n                self._consumer.order_attack(targets=targets,\n                                            permanent=permanent,\n                                            comment=comment)\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_attack(targets=targets,\n                                            permanent=permanent,\n                                            comment=comment)"
            ],
            [
                215,
                222,
                "                    try:\n                        target = OrdersParser._parse_unit(tokens)\n                    except SyntaxError as e:\n                        raise SyntaxError('{}: {}'.format(line, e))\n                    else:\n                        self._consumer.order_build(target=target,\n                                                   permanent=permanent,\n                                                   comment=comment)"
            ],
            [
                340,
                351,
                "            try:\n                while tokens:\n                    targets.append(OrdersParser._parse_unit(tokens))\n            except SyntaxError as e:\n                self._consumer.order_evict(targets=targets,\n                                           permanent=permanent,\n                                           comment=comment)\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_evict(targets=targets,\n                                           permanent=permanent,\n                                           comment=comment)"
            ],
            [
                518,
                524,
                "            try:\n                dirs = [OrdersParser._parse_dir(d.lower()) for d in tokens]\n            except SyntaxError as e:\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_move(dirs=dirs, permanent=permanent,\n                                          comment=comment)"
            ],
            [
                661,
                667,
                "            try:\n                unit = OrdersParser._parse_unit(tokens)\n            except SyntaxError as e:\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_promote(unit=unit, permanent=permanent,\n                                             comment=comment)"
            ],
            [
                701,
                708,
                "            try:\n                dirs = [OrdersParser._parse_dir(d.lower(), allow_enter=False) \\\n                        for d in tokens]\n            except SyntaxError as e:\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_sail(dirs=dirs, permanent=permanent,\n                                          comment=comment)"
            ],
            [
                845,
                856,
                "            try:\n                while tokens:\n                    targets.append(OrdersParser._parse_unit(tokens))\n            except SyntaxError as e:\n                self._consumer.order_teach(targets=targets,\n                                           permanent=permanent,\n                                           comment=comment)\n                raise SyntaxError('{}: {}'.format(line, e))\n            else:\n                self._consumer.order_teach(targets=targets,\n                                           permanent=permanent,\n                                           comment=comment)"
            ]
        ]
    },
    {
        "blob_id": "0c8c29ae00b620614383c24a6b9db48d3c488117",
        "matched_blocks": [
            [
                47,
                57,
                "    try:\n        sticker.remove_from_set(context.bot)\n    except error.PackInvalid:\n        update.message.reply_html(Strings.REMOVE_STICKER_FOREIGN_PACK.format(pack_link), quote=True)\n    except error.PackNotModified:\n        update.message.reply_html(Strings.REMOVE_STICKER_ALREADY_DELETED.format(pack_link), quote=True)\n    except error.UnknwonError as e:\n        update.message.reply_html(Strings.REMOVE_STICKER_GENERIC_ERROR.format(pack_link, e.message), quote=True)\n    else:\n        # success\n        update.message.reply_html(Strings.REMOVE_STICKER_SUCCESS.format(pack_link), quote=True)"
            ]
        ]
    },
    {
        "blob_id": "d6c9753209f03bbc04f224dcb0139f4274fba36f",
        "matched_blocks": [
            [
                129,
                136,
                "        try:\n            ret = refine_function(x[slc], y[slc], **refine_args)\n        except PeakRejection:\n            # We are catching the PeakRejections raised here as\n            # an indication that no suitable peak was found\n            continue\n        else:\n            out_tmp.append(ret)"
            ]
        ]
    },
    {
        "blob_id": "0d5b7d435e2794c64185da16d19a4a167cedfd70",
        "matched_blocks": [
            [
                14,
                21,
                "    try:\n        image = Image.open(img)\n    except:\n        print('Open Error! Try again!')\n        continue\n    else:\n        r_image = frcnn.detect_image(image)\n        r_image.show()"
            ]
        ]
    },
    {
        "blob_id": "753e3a23b2b5a537ac4955e54d683a5aed6c27a7",
        "matched_blocks": [
            [
                102,
                107,
                "    try:\n        timer = time.perf_counter_ns\n    except AttributeError:\n        timer = time.perf_counter\n    else:\n        is_ns_timer = True"
            ]
        ]
    },
    {
        "blob_id": "415afafae8f4ff49384a3f05f62f86edc19498b1",
        "matched_blocks": [
            [
                7643,
                7650,
                "            try:\n                record._start_flux()\n                yield record\n            except:\n                record._rollback_flux()\n                raise\n            else:\n                record._commit_flux()"
            ]
        ]
    },
    {
        "blob_id": "8e42bda10804fa7bacc1020bc117869d71ecbf6b",
        "matched_blocks": [
            [
                8,
                13,
                "try:\n    from leveldb_service import LevelDB\nexcept ImportError:\n    pass\nelse:\n    dbs['LevelDB'] = LevelDB"
            ],
            [
                15,
                20,
                "try:\n    from codernitydb_service import CodernityDB\nexcept ImportError:\n    pass\nelse:\n    dbs['CodernityDB'] = CodernityDB"
            ]
        ]
    },
    {
        "blob_id": "e8a8ecb58043ca609ec177e0f5e27fae7d5abada",
        "matched_blocks": [
            [
                370,
                376,
                "            try:\n                self.length = int(length)\n            except ValueError:\n                self.length = None\n            else:\n                if self.length < 0:  # ignore nonsensical negative lengths\n                    self.length = None"
            ],
            [
                1066,
                1082,
                "                try:\n                    # this is solely to check to see if message_body\n                    # implements the buffer API.  it /would/ be easier\n                    # to capture if PyObject_CheckBuffer was exposed\n                    # to Python.\n                    memoryview(message_body)\n                except TypeError:\n                    try:\n                        chunks = iter(message_body)\n                    except TypeError:\n                        raise TypeError(\"message_body should be a bytes-like \"\n                                        \"object or an iterable, got %r\"\n                                        % type(message_body))\n                else:\n                    # the object implements the buffer interface and\n                    # can be passed directly into socket methods\n                    chunks = (message_body,)"
            ]
        ]
    },
    {
        "blob_id": "0d1c07214d02cff04c05d3e2658206175b689f11",
        "matched_blocks": [
            [
                22,
                28,
                "try:\n    os.getenv('ROOT')\nexcept KeyError:\n    subprocess.Popen('SetX {} %CD%'.format('ROOT'), shell=True).wait()\nelse:\n    if os.getenv('ROOT') != ROOT:\n        subprocess.Popen('SetX {} %CD%'.format('ROOT'), shell=True).wait()"
            ]
        ]
    },
    {
        "blob_id": "18b2c55eadbd92a669c723bece524f58044dcc68",
        "matched_blocks": [
            [
                88,
                94,
                "        try:\n            user = User.objects.get(username_or_email, is_active=True)\n        except User.DoesNotExist:\n            raise forms.ValidationError(\n                             ugettext(\"Invalid username/email\"))\n        else:\n            self._user = user"
            ]
        ]
    },
    {
        "blob_id": "2cb1b08ed78ba1f7af4b2d62d28e84f0291436db",
        "matched_blocks": [
            [
                23,
                28,
                "try:\n    dangerous_call()\nexcept OSError:\n    log('OSError ...')\nelse:\n    after_call()"
            ]
        ]
    },
    {
        "blob_id": "a00a12ee310e1354391335ee2fc3d536dd7695b8",
        "matched_blocks": [
            [
                258,
                269,
                "    try:\n        oc(\"rollout\", \"latest\", \"dc/{}\".format(dc_name), _reraise=True)\n    except ErrorReturnCode as err:\n        if \"is already in progress\" in str(err):\n            pass\n    else:\n        # Wait for the new revision to start deploying\n        for _ in range(0, 60):\n            if _get_revision() != old_revision:\n                break\n            log.info(\"Waiting for rollout on dc/%s to begin\", dc_name)\n            time.sleep(1)"
            ]
        ]
    },
    {
        "blob_id": "a6b07925ad745b8be7937bfeb0c1c2786ded3dab",
        "matched_blocks": [
            [
                30,
                55,
                "        try:\n            import psutil  # @UnresolvedImport @Reimport\n        except:\n            self._available = False\n        else:\n            self._available = True\n\n            self.cpu = Collect('cpu', lambda: psutil.cpu_percent(interval=0),\n                               interval, history_len)\n\n            try:\n                # new in 0.8\n                psutil.virtual_memory().percent\n                get_mem = lambda: psutil.virtual_memory().percent\n            except:\n                get_mem = lambda: psutil.phymem_usage().percent\n\n            self.mem = Collect('mem', get_mem, interval, history_len)\n            try:\n                # new in 0.8\n                psutil.swap_memory().percent\n                get_mem = lambda: psutil.swap_memory().percent\n            except:\n                get_mem = lambda: psutil.virtmem_usage().percent\n\n            self.swap_mem = Collect('swap', get_mem, interval, history_len)"
            ]
        ]
    },
    {
        "blob_id": "573267c8a7fbd3b444cf1eaf94fc8f0252acd821",
        "matched_blocks": [
            [
                267,
                272,
                "        try:\n            get = _imagingcms.get_display_profile\n        except AttributeError:\n            return None\n        else:\n            profile = get()"
            ]
        ]
    },
    {
        "blob_id": "a44071f32887e40ce0d4932d4b101acb4e435fde",
        "matched_blocks": [
            [
                252,
                284,
                "        try:\n            if diff_tag_keys:\n                diff_tag_keys.sort()\n                self.client.remove_tags_from_resource(\n                    ResourceId=self.args.name,\n                    ResourceType=\"Parameter\",\n                    TagKeys=diff_tag_keys,\n                )\n                LOGGER.debug(\n                    \"removed tags for parameter %s: %s\", self.args.name, diff_tag_keys\n                )\n\n            if self.args.tags:\n                tags_to_add = [\n                    cast(\"TagTypeDef\", tag.dict(by_alias=True))\n                    for tag in self.args.tags\n                ]\n                self.client.add_tags_to_resource(\n                    ResourceId=self.args.name,\n                    ResourceType=\"Parameter\",\n                    Tags=tags_to_add,\n                )\n                LOGGER.debug(\n                    \"added tags to parameter %s: %s\",\n                    self.args.name,\n                    [tag[\"Key\"] for tag in tags_to_add],\n                )\n        except self.client.exceptions.InvalidResourceId:\n            LOGGER.info(\n                \"skipped updating tags; parameter %s does not exist\", self.args.name\n            )\n        else:\n            LOGGER.info(\"updated tags for parameter %s\", self.args.name)"
            ]
        ]
    },
    {
        "blob_id": "9d8d94cc822ba870dc547224bff9250489265410",
        "matched_blocks": [
            [
                299,
                310,
                "        try:\n            factor = self.unit.physical_unit._to(other.physical_unit)\n        except UnitConversionError:\n            # Maybe via equivalencies?  Now we do make a temporary copy.\n            try:\n                value = self._to_value(other)\n            except UnitConversionError:\n                return NotImplemented\n\n            self.view(np.ndarray)[...] = value\n        else:\n            self.view(np.ndarray)[...] += self.unit.from_physical(factor)"
            ]
        ]
    },
    {
        "blob_id": "d6e677ac1447f8278ddff36b140132e55441832c",
        "matched_blocks": [
            [
                50,
                55,
                "        try:\n            fd = open(get_file)\n        except IOError:\n            response = \"404\"\n        else:\n            response = fd.read()"
            ]
        ]
    },
    {
        "blob_id": "cf87d63f1b7cf3d1b2109d02afb96178ab90f758",
        "matched_blocks": [
            [
                40,
                46,
                "    try:\n        seq = TestDataEmptyArray.get_array()\n        result = minimum_index(seq)\n    except ValueError as e:\n        pass\n    else:\n        assert False"
            ]
        ]
    },
    {
        "blob_id": "351a62ef62e5c0a3728e80b1907eeba6a9fd57fc",
        "matched_blocks": [
            [
                153,
                158,
                "try:\n    from oracle2postgre import __version__ as version\nexcept ImportError:\n    pass\nelse:\n    release = version"
            ]
        ]
    },
    {
        "blob_id": "ca92165b0120c5f8a149fb5aca3fe9666b1a93c5",
        "matched_blocks": [
            [
                45,
                50,
                "            try:\n                await ctx.guild.kick(member, reason=reason)\n            except:\n                success = False\n            else:\n                success = True"
            ],
            [
                72,
                77,
                "            try:\n                await ctx.guild.ban(member, reason=reason)\n            except:\n                success = False\n            else:\n                success = True"
            ],
            [
                103,
                108,
                "            try:\n                await ctx.guild.unban(ban.user, reason=reason)\n            except:\n                success = False\n            else:\n                success = True"
            ],
            [
                239,
                244,
                "            try:\n                await ctx.guild.ban(discord.Object(userid), reason=reason)\n            except:\n                success = False\n            else:\n                success = True"
            ],
            [
                283,
                292,
                "            try:\n                for channel in ctx.guild.text_channels:\n                    await channel.set_permissions(member, overwrite=discord.PermissionOverwrite(send_messages = False), reason=reason)\n\n                for channel in ctx.guild.voice_channels:\n                    await channel.set_permissions(member, overwrite=discord.PermissionOverwrite(speak=False), reason=reason)\n            except:\n                success = False\n            else:\n                success = True"
            ],
            [
                320,
                326,
                "            try:\n                for channel in ctx.message.guild.channels:\n                    await channel.set_permissions(member, overwrite=None, reason=reason)\n            except:\n                success = False\n            else:\n                success = True"
            ]
        ]
    },
    {
        "blob_id": "f06d15627081a53fffc54483095cdcc1096aed83",
        "matched_blocks": [
            [
                43,
                54,
                "        try:\n            runner = self._runners[flavour]\n        except KeyError:\n            if self.running.is_set():\n                raise RuntimeError(f\"unknown runner {NameRepr(flavour)}\") from None\n            self._runner_queues.setdefault(flavour, []).extend(payloads)\n        else:\n            for payload in payloads:\n                self._logger.debug(\n                    \"registering payload %s (%s)\", NameRepr(payload), NameRepr(flavour)\n                )\n                runner.register_payload(payload)"
            ]
        ]
    },
    {
        "blob_id": "1c753e13c189d825f461eabc45b5e49284b23651",
        "matched_blocks": [
            [
                163,
                174,
                "    try:\n        result_json = result.json()\n    except:\n        if result.status_code != 200:\n            raise ApiHTTPException(method_name, result)\n        else:\n            raise ApiInvalidJSONException(method_name, result)\n    else:    \n        if not result_json['ok']:\n            raise ApiTelegramException(method_name, result, result_json)\n            \n        return result_json"
            ]
        ]
    },
    {
        "blob_id": "460a5f4a032121c254f1e60a432315653fa13d15",
        "matched_blocks": [
            [
                764,
                769,
                "    try:\n        arg = random.randint(1, 10)\n    except ValueError:\n        await client.say(\"Invalid number\")\n    else:\n        await client.say('The correct answer is ' + str(arg))"
            ]
        ]
    },
    {
        "blob_id": "c97200edd3289bc742f4771a37ae118ebe0817da",
        "matched_blocks": [
            [
                53,
                60,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        return render(request, 'polls/detail.html', {'question': question, 'error_message': \"You didn't select a choice.\",})\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "1507450f62b8f598aac68342ea3ab2acae872656",
        "matched_blocks": [
            [
                592,
                616,
                "        try:\n            ns = sys.modules['__main__']\n            parts = qname.split('.')\n            # self.debug(\"get_candidates() got parts: %s\", parts)\n            for i in range(0, len(parts) - 1):\n                ns = getattr(ns, parts[i])\n        except Exception as e:\n            # self.debug(\"get_candidates() got exception:\\n%s\", traceback.format_exc())\n            pass\n        else:\n            # search in the namespace\n            last_token = parts[-1]\n            results = self.dir_namespace(ns, last_token)\n            # self.debug(\"get_candidates() completions for %s in %s: %s\", last_token, ns, results)\n\n            # no completion found? looking from the global scope? then try the builtins\n            if not results and len(parts) == 1:\n                results = self.dir_namespace(builtins, last_token)\n                # self.debug(\"get_candidates() completions for %s in %s: %s\", last_token, builtins, results)\n\n            results = map(lambda r: self.maybe_extend_syntactically(ns, r, line, match_syntax_char), results)\n            ns_parts = parts[:-1]\n            results = list(map(lambda r: \".\".join(ns_parts + [r]), results))\n            # self.debug(\"get_candidates() => '%s'\", str(results))\n            return results"
            ]
        ]
    },
    {
        "blob_id": "948dd23e156209332099443262532e5d2a461b27",
        "matched_blocks": [
            [
                36,
                41,
                "try:\n    import faulthandler\nexcept ImportError:\n    pass\nelse:\n    faulthandler.enable()"
            ]
        ]
    },
    {
        "blob_id": "d56744355a003073f709623b3f34ab6fd2fda34f",
        "matched_blocks": [
            [
                345,
                353,
                "        try:\n            kwargs[self._request_param['name']] = client._deserialize(  # pylint: disable=protected-access\n                self._request_param['model'], json_obj)\n        except DeserializationError as error:\n            message += \": {}\".format(error)\n            raise ValueError(message.format(self._request_param['model']))\n        else:\n            if kwargs[self._request_param['name']] is None:\n                raise ValueError(message.format(self._request_param['model']))"
            ]
        ]
    },
    {
        "blob_id": "a00157b7f648870f3f0aa366f3d430cc5b94b837",
        "matched_blocks": [
            [
                103,
                121,
                "        try:\n            reaction, user = await self.bot.wait_for(\"reaction_add\", timeout=600,\n                                                     check=lambda _reaction, _user: _reaction.message == message and (\n                                                             not _user.bot and not users) or _user in users\n                                                                                    and _reaction.emoji == '\\N{PARTY POPPER}')\n        except asyncio.TimeoutError:\n\n            embed = embed_create(ctx.author, title='Test timed out!',\n                                 description=f'No one reacted within 10 minutes!', color=discord.Color.red())\n        else:\n            if user == ctx.author:\n                embed = embed_create(ctx.author, title='Test canceled!',\n                                     description=f'You reacted to your own test, so it was canceled.\\nAnyways, '\n                                                 f'your time is {round(time.perf_counter() - t, 2)} seconds.',\n                                     color=discord.Color.red())\n            else:\n                embed = embed_create(ctx.author, title='Reaction found!',\n                                     description=f'{user} (ID: {user.id})\\nreacted with {reaction} in '\n                                                 f'{round(time.perf_counter() - t, 2)} seconds')"
            ]
        ]
    },
    {
        "blob_id": "ff97908a8f54afb35129c8421de9c5f2107337f4",
        "matched_blocks": [
            [
                67,
                98,
                "        try:\n            sleep(0.2)\n            response = requests.get(url=f'{URL}{method}', params=parametrs)\n            resp = response.json()['response'][0]\n        except KeyError:\n            resp = response.json()[\"error\"]\n            KE = f'\\n\u0412\u044b \u0432\u0432\u0435\u043b\u0438: {id}. \u0412\u0435\u0440\u043e\u044f\u0442\u043d\u043e \u0412\u044b \u043e\u0448\u0438\u0431\u043b\u0438\u0441\u044c \u0441 \u0432\u0432\u043e\u0434\u043e\u043c. \u041f\u043e\u0434\u0440\u043e\u0431\u043d\u0430\u044f \u043e\u0448\u0438\u0431\u043a\u0430:' \\\n                f'\\n{\" \"*3}\u043a\u043e\u0434_\u043e\u0448\u0438\u0431\u043a\u0438: {resp[\"error_code\"]}\\n{\" \"*3}\u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435: {translate(resp[\"error_msg\"])}'\n            print(KE)\n        else:\n            if 'deactivated' in resp.keys():\n                self.delete = True\n                self.close = True\n                self.can_access_closed = False\n            elif resp['is_closed'] & (not resp['can_access_closed']):\n                self.close = True\n                self.can_access_closed = False\n                self.delete = False\n            elif resp['is_closed'] & resp['can_access_closed']:\n                self.close = True\n                self.can_access_closed = True\n                self.delete = False\n            else:\n                self.can_access_closed = True\n                self.close = False\n                self.delete = False\n            self.user_id = resp['id']\n            self.family = resp['last_name']\n            self.name = resp['first_name']\n            self.domain = resp['domain']\n            self.fio = self.family + ' ' + self.name\n            self.url = f'https://vk.com/{self.domain}'"
            ],
            [
                119,
                130,
                "            try:\n                sleep(0.2)\n                response = requests.get(url=f'{URL}{method}', params=parametrs)\n                resp = response.json()['response']['items']\n            except KeyError:\n                resp = response.json()[\"error\"]\n                KE = f'\\n\u041f\u0440\u043e\u0438\u0437\u043e\u0448\u043b\u0430 \u043e\u0448\u0438\u0431\u043a\u0430 \u043e\u0431\u0440\u0430\u0449\u0435\u043d\u0438\u044f \u043a \u043a\u043b\u044e\u0447\u0443. \u0412\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0441\u0435\u0440\u0432\u0435\u0440 \u0432\u0435\u0440\u043d\u0443\u043b \u043d\u0435 \u0442\u043e, \u0447\u0442\u043e \u043e\u0436\u0438\u0434\u0430\u043b\u043e\u0441\u044c.' \\\n                    f'\\n{\" \"*3}\u043a\u043e\u0434_\u043e\u0448\u0438\u0431\u043a\u0438: {resp[\"error_code\"]}\\n{\" \"*3}\u043e\u043f\u0438\u0441\u0430\u043d\u0438\u0435: {translate(resp[\"error_msg\"])}'\n                print(KE)\n                return KE\n            else:\n                return resp"
            ]
        ]
    },
    {
        "blob_id": "d3c41e315478007c33f0845a85c9b27592fdf163",
        "matched_blocks": [
            [
                29,
                37,
                "    try:\n        response = requests.get((api_url + '&offset=' + str(50 * n)), params=headers)\n    except Exception as e:\n        print(e)\n        if 'Too many requests' in e:\n            print('\u0421\u043b\u0438\u0448\u043a\u043e\u043c \u043c\u043d\u043e\u0433\u043e \u0437\u0430\u043f\u0440\u043e\u0441\u043e\u0432, \u0434\u0440\u0443\u0436\u043e\u043a-\u043f\u0438\u0440\u043e\u0436\u043e\u043a. \u041e\u0442\u0434\u043e\u0445\u043d\u0438 \u043d\u0435\u043c\u043d\u043e\u0433\u043e. \\n\u041d\u043e\u043c\u0435\u0440 \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b = {}'.format(n))\n            time.sleep(30)\n    else:\n        df = pd.concat([df, pd.DataFrame(response.json()['result'])], axis=0)"
            ]
        ]
    },
    {
        "blob_id": "2309594889f7eaf0567ecb3881e41ae564d04ca9",
        "matched_blocks": [
            [
                7,
                13,
                "        try:\n            user = UserModel.objects.get(mobile_number=kwargs.get('username'))\n        except UserModel.DoesNotExist:\n            return None\n        else:\n            if user.check_password(kwargs.get('password')):\n                return user"
            ]
        ]
    },
    {
        "blob_id": "8c1543e3df295a85ad395b63aa823c968a2e0f4f",
        "matched_blocks": [
            [
                25,
                36,
                "        try:\n            user_input = int(input('Choose a cell: '))\n        except:\n            print('Seems like you enter invalid information. Lets try again!')\n        else:\n            if user_input in range(1, 10) and board[user_input - 1] != 'X' \\\n                    and board[user_input - 1] != '0':\n                board[user_input - 1] = f'{symbol}'\n                return True\n            else:\n                print('You can not do that. Sell may not exist or there is already'\n                      'exists.')"
            ]
        ]
    },
    {
        "blob_id": "089f7924ad7a7daeda16855e8b61d5126578c13c",
        "matched_blocks": [
            [
                99,
                105,
                "    try:\n        u = 'https://api.gotinder.com/like/%s/super' % user_id\n        d = requests.get(u, headers=headers, timeout=0.7).json()\n    except KeyError:\n        raise\n    else:\n        return d['match']"
            ],
            [
                109,
                115,
                "    try:\n        u = 'https://api.gotinder.com/like/%s' % user_id\n        d = requests.get(u, headers=headers, timeout=0.7).json()\n    except KeyError:\n        raise\n    else:\n        return d['match']"
            ],
            [
                38,
                43,
                "        try:\n            x = self.d['bio'].encode('ascii', 'ignore').replace('\\n', '')[:50].strip()\n        except (UnicodeError, UnicodeEncodeError, UnicodeDecodeError):\n            return '[garbled]'\n        else:\n            return x"
            ]
        ]
    },
    {
        "blob_id": "b5b156cdd0e5a59512ec09150e8dfd07ed2350af",
        "matched_blocks": [
            [
                57,
                63,
                "        try:\n            args, kwargs = self._sub_cache[sub_type]\n        except KeyError:\n            pass\n        else:\n            # Cached kwargs includes sub_type\n            self._run_sub(cb, *args, **kwargs)"
            ]
        ]
    },
    {
        "blob_id": "5a3eff3018732151493f63284d3e3356dcb504f2",
        "matched_blocks": [
            [
                24,
                32,
                "    try:\n        inverse = np.linalg.inv(np.dot(phi_k.T, phi_k))\n    except np.linalg.LinAlgError:\n        print(\"ERROR!! Matrix not invertible\")\n        pass\n    else:\n        temp = np.dot(inverse, phi_k.T)\n        w_MLE = np.dot(temp, Y)\n        return w_MLE"
            ]
        ]
    },
    {
        "blob_id": "4ea931b66ee2473b13527da21d8e8b4fdc42b47b",
        "matched_blocks": [
            [
                29,
                34,
                "            try:\n                board = Board(os.path.join(base_dir, device), layout)\n            except serial.SerialException:\n                pass\n            else:\n                boards.append(board)"
            ]
        ]
    },
    {
        "blob_id": "d52e1b9efac5abb673617df3f24e11fb3f500df1",
        "matched_blocks": [
            [
                85,
                92,
                "            try:\n                self.check_errors(response, response_data[\"response\"])\n            except RateExceeded:\n                self._handle_rate_exceeded()\n            except NoAuth:\n                self.update_token()\n            else:\n                valid_response = True"
            ]
        ]
    },
    {
        "blob_id": "07598ec0823d646e203f8bb0c35c69f41f4e2f13",
        "matched_blocks": [
            [
                348,
                354,
                "    try:\n        socket.inet_aton(host)\n        hostname = dns_lookup_reverse(host)\n    except (socket.error, IOError):\n        return \"[ldap://%s%s]\" % (host, port and \":\" + port or \"\")\n    else:\n        return \"[ldap://%s%s [%s]]\" % (hostname, port and \":\" + port or \"\", host)"
            ],
            [
                250,
                264,
                "        try:\n            ips = dns_lookup_forward(hostname)\n        except IOError as e:\n            # Forward DNS resolution failed. Continue with the next host.\n            failed_ldaps[ldap_url] = str(e)\n            continue\n        else:\n            for ip in ips:\n                ldap_url_ip = \"%s%s:%s\" % (proto or \"\", ip, port)\n\n                rc, error = __ldap_bind_CLI(ldap_url_ip, net_timeout)\n                if rc:\n                    return ldap_url_ip\n                host_ip = ldap_url2hostname_ip(ldap_url_ip)\n                failed_ldaps[host_ip] = error"
            ]
        ]
    },
    {
        "blob_id": "0a06a1af1bd774cd4ea1106f94f1566e382efbe9",
        "matched_blocks": [
            [
                147,
                152,
                "            try:\n                request.urlretrieve(url=img_url, filename=name)\n            except Exception as e:\n                print(e)\n            else:\n                print('%s is download' % name)"
            ]
        ]
    },
    {
        "blob_id": "344d79ef99e3f2d869a4b5a4d9c790c1754d46c8",
        "matched_blocks": [
            [
                573,
                610,
                "        try:\n            # board.move_piece(direction, selected_marbles)\n            self.game.make_move(direction, selected_marbles)\n            # print(board)\n        except CannotMoveException as e:\n            print(e)\n            print(\"invalid move\")\n        except IndexError as e:\n            print(e)\n        else:\n            self.parent.check_for_game_won(self.game.current_turn_color)\n            self.draw_board()\n\n            player_human = self.game.get_human_player()\n            player_comp = self.game.get_comp_player()\n            move_type = direction.name\n            from_pos = marble_tuple_to_string(selected_marbles)\n            to_pos = marble_tuple_to_string(new_marbles)\n            color_human = player_human.piece_type\n            color_comp = player_comp.piece_type\n            time_taken = self.update_suggested_move()\n            sumito = False\n\n            # if it is human's turn\n            if self.game.current_turn_color == self.game.human_piece_type:\n                # update score, moves left and history\n                player_human.record_move_to_history(from_pos, to_pos, move_type, time_taken, sumito, color_human)\n                self.parent.output.update_human_output()\n            # if it is computer's turn\n            else:\n                player_comp.record_move_to_history(from_pos, to_pos, move_type, time_taken, sumito, color_comp)\n                self.parent.output.update_comp_output()\n\n            # update current_turn to another player\n            self.game.next_turn()\n            self.parent.current_turn_info.update_current_turn()\n            # Only run if human is black (as suggested move not showing on first turn bug only happens then)\n            self.update_suggested_move()"
            ],
            [
                741,
                756,
                "        try:\n            if self.game.current_turn_color == PieceType.BLACK:\n                self.game.black_player.remove_recent_move()  # Remove the player's most recent move history\n            else:\n                self.game.white_player.remove_recent_move()\n        except IndexError:\n            print(\"Could not undo move, no previous move to remove\")\n            self.game.next_turn()  # Revert next turn update\n            self.parent.current_turn_info.update_current_turn()\n        else:\n            self.game.undo_move()\n            # The BoardOperation class doesnt seem to be tied to the Game classes board, needs to be manually updated\n            self.game.board.update_marble_counts()  # Updating game/board outputs\n            self.parent.output.update_human_output()\n            self.parent.output.update_comp_output()\n            self.parent.board_operation.draw_board()"
            ]
        ]
    },
    {
        "blob_id": "b17424f8332624c3d113275b09cd79f7b5d2537b",
        "matched_blocks": [
            [
                46,
                64,
                "    try:\n        print(\"Try to open version file {}\".format(version_file))\n        verfile = open(version_file, \"rt\")\n        verstrline = verfile.read()\n        verfile.close()\n    except EnvironmentError:\n        print(\"WARNING! There is no version file {}\".format(version_file))\n        from phenome_core.version import __version__\n        if __version__ is not None:\n            print(\"Using version module to get version {}\".format(__version__))\n            verstr = __version__\n    else:\n        VSRE = r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\"\n        mo = re.search(VSRE, verstrline, re.M)\n        if mo:\n            verstr = mo.group(1)\n        else:\n            print(\"unable to find version in %s\" % (version_file,))\n            raise RuntimeError(\"if %s exists, it is required to be well-formed\" % (version_file,))"
            ]
        ]
    },
    {
        "blob_id": "36641b439a101f2895653de388cfb25e45911f74",
        "matched_blocks": [
            [
                38,
                50,
                "    try:\n        request = requests.get(location)\n        driver.get(location)\n        time.sleep(2)\n        current_url = driver.current_url\n        if current_url == location:\n            tradable.append(ticker)\n        else:\n            print(\"no page but request= \", request)\n    except ConnectionError:\n        print('Ticker isn\\'t tradable')\n    else:\n        tradable.append(ticker)"
            ]
        ]
    },
    {
        "blob_id": "aa44c41fdaccc86076a84851568b8ec26dc5c0e1",
        "matched_blocks": [
            [
                37,
                45,
                "        try:\n            template = super(Loader, self).get_template(\n                template_name, template_dirs, skip,\n            )\n        except TemplateDoesNotExist as e:\n            self.get_template_cache[key] = e\n            raise\n        else:\n            self.get_template_cache[key] = template"
            ],
            [
                106,
                117,
                "                try:\n                    template, display_name = loader(name, dirs)\n                except TemplateDoesNotExist:\n                    pass\n                else:\n                    origin = Origin(\n                        name=display_name,\n                        template_name=name,\n                        loader=loader,\n                    )\n                    result = template, origin\n                    break"
            ]
        ]
    },
    {
        "blob_id": "9caf69336a7ca6d21906e124db6cf6537075c9c7",
        "matched_blocks": [
            [
                35,
                67,
                "    try:\n        data = json_dic['data']\n    except KeyError:\n        print(\"\u8bbf\u95ee\u53d7\u9650\"+\" \"+keyword)\n        exit()\n    else:\n        totalCount = data['totalCount']\n        if totalCount != 0:\n            encryStr = data['results'][0]['encryStr']  # \u83b7\u53d6\u9a8c\u8bc1\u7801\n        else:\n            encryStr = 0\n        if encryStr != 0:\n            url_sec = \"https://www.creditchina.gov.cn/api/credit_info_detail?encryStr=\" \\\n                      + urllib.parse.quote(encryStr)\n            xml_info = request.urlopen(url_sec)\n            page_sec = xml_info.read().decode('utf-8')\n            try:\n                json_dic_sec = json.loads(page_sec)  # JSON\u8f6c\u6362\u4e3a\u5b57\u5178\n                result = json_dic_sec['result']\n            except KeyError:\n                print(\"json\u683c\u5f0f\u9519\u8bef\"+\" \"+keyword)\n                creditCode = ''\n            else:\n                try:\n                    result['creditCode']\n                except TypeError:\n                    print(\"\u67e5\u65e0\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801\" + \" \" + keyword)\n                    creditCode = ''\n                else:\n                    creditCode = result['creditCode']  # \u83b7\u53d6\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801\n        else:\n            print(\"\u67e5\u65e0\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801\"+\" \"+keyword)\n            creditCode = ''"
            ],
            [
                51,
                64,
                "            try:\n                json_dic_sec = json.loads(page_sec)  # JSON\u8f6c\u6362\u4e3a\u5b57\u5178\n                result = json_dic_sec['result']\n            except KeyError:\n                print(\"json\u683c\u5f0f\u9519\u8bef\"+\" \"+keyword)\n                creditCode = ''\n            else:\n                try:\n                    result['creditCode']\n                except TypeError:\n                    print(\"\u67e5\u65e0\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801\" + \" \" + keyword)\n                    creditCode = ''\n                else:\n                    creditCode = result['creditCode']  # \u83b7\u53d6\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801"
            ],
            [
                58,
                64,
                "                try:\n                    result['creditCode']\n                except TypeError:\n                    print(\"\u67e5\u65e0\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801\" + \" \" + keyword)\n                    creditCode = ''\n                else:\n                    creditCode = result['creditCode']  # \u83b7\u53d6\u7edf\u4e00\u793e\u4f1a\u4fe1\u7528\u4ee3\u7801"
            ]
        ]
    },
    {
        "blob_id": "6dc7a6e31675edd6350d5b2d63b46fe20ee33182",
        "matched_blocks": [
            [
                1423,
                1478,
                "        try:\n            argument = utils.safe_infer(utils.get_argument_from_call(node, position=0))\n        except utils.NoSuchArgumentError:\n            pass\n        else:\n            if argument is astroid.Uninferable:\n                return\n            if argument is None:\n                # Nothing was inferred.\n                # Try to see if we have iter().\n                if isinstance(node.args[0], astroid.Call):\n                    try:\n                        func = next(node.args[0].func.infer())\n                    except astroid.InferenceError:\n                        return\n                    if getattr(\n                        func, \"name\", None\n                    ) == \"iter\" and utils.is_builtin_object(func):\n                        self.add_message(\"bad-reversed-sequence\", node=node)\n                return\n\n            if isinstance(argument, (astroid.List, astroid.Tuple)):\n                return\n\n            if isinstance(argument, astroid.Instance):\n                if argument._proxied.name == \"dict\" and utils.is_builtin_object(\n                    argument._proxied\n                ):\n                    self.add_message(\"bad-reversed-sequence\", node=node)\n                    return\n                if any(\n                    ancestor.name == \"dict\" and utils.is_builtin_object(ancestor)\n                    for ancestor in argument._proxied.ancestors()\n                ):\n                    # Mappings aren't accepted by reversed(), unless\n                    # they provide explicitly a __reversed__ method.\n                    try:\n                        argument.locals[REVERSED_PROTOCOL_METHOD]\n                    except KeyError:\n                        self.add_message(\"bad-reversed-sequence\", node=node)\n                    return\n\n            if hasattr(argument, \"getattr\"):\n                # everything else is not a proper sequence for reversed()\n                for methods in REVERSED_METHODS:\n                    for meth in methods:\n                        try:\n                            argument.getattr(meth)\n                        except astroid.NotFoundError:\n                            break\n                    else:\n                        break\n                else:\n                    self.add_message(\"bad-reversed-sequence\", node=node)\n            else:\n                self.add_message(\"bad-reversed-sequence\", node=node)"
            ],
            [
                845,
                857,
                "            try:\n                redefinition_index = redefinitions.index(node)\n            except ValueError:\n                pass\n            else:\n                for redefinition in redefinitions[:redefinition_index]:\n                    inferred = utils.safe_infer(redefinition)\n                    if (\n                        inferred\n                        and isinstance(inferred, astroid.Instance)\n                        and inferred.qname() == TYPING_FORWARD_REF_QNAME\n                    ):\n                        return"
            ]
        ]
    },
    {
        "blob_id": "98ae49cc4f9efdbb765230a3157360b3e6d55412",
        "matched_blocks": [
            [
                6,
                80,
                "    try:\n        if len(actualClassList) != len(predictedClassList):\n            raise ValueError('Error: actualCLassList and predictedClassList do not match.')\n\n        global DClasses, DClasses_len;\n\n        length = len(actualClassList);\n\n        tpr = [0]*DClasses_len;\n        tnr = [0]*DClasses_len;\n        precision = [0]*DClasses_len;\n        accuracy = [0]*DClasses_len;\n\n        confusionMatrix = [[copy.deepcopy(0) for x in range(DClasses_len)] for y in range(DClasses_len)]\n\n        for i in range(length):\n            confusionMatrix[actualClassList[i]][predictedClassList[i]] +=1;\n\n        # formatted confusion matrix\n        tableCM = Texttable();\n        printCM = copy.deepcopy(confusionMatrix);\n        printCM.insert(0,DClasses)\n        tableCM.add_rows(printCM)  \n        print(\"***************************CONFUSION MATRIX***************************\")  \n        print(tableCM.draw())\n\n        results = [[copy.deepcopy(0) for x in range(4)] for y in range(DClasses_len)]\n\n        total = 0;\n        for i in range(DClasses_len):\n            tp = confusionMatrix[i][i]\n\n            fn = 0\n            fp = 0\n            tn = 0\n            for j in range(DClasses_len):\n                total += confusionMatrix[i][j];\n                if i!=j:\n                    fn += confusionMatrix[i][j];\n                    fp += confusionMatrix[j][i];\n                    #tn += confusionMatrix[j][j]; \n                    \n            for k in range(DClasses_len):\n                if k!=i:\n                    for l in range(DClasses_len):\n                        if l!= i:\n                           tn += confusionMatrix[k][l];  \n                                               \n\n            if tp!=0:\n                results[i][0] = tp/(tp+fn);\n                results[i][1] = tp/(tp+fp);\n            else:\n                results[i][0] = 0\n                results[i][1] = 0\n\n            if tn!=0:\n                results[i][2] = tn/(tn+fp);\n            else:\n                results[i][2]\n\n            results[i][3] = (tp+tn)/total;\n\n        tableResults = Texttable();\n        results.insert(0,[\"TP Rate\", \"Precision\", \"TN Rate\", \"Accuracy\"])\n        tableResults.add_rows(results)\n        print(\"*******************************RESULTS*******************************\")     \n        print(tableResults.draw())\n        print(\"*********************************************************************\")\n\n\n    except ValueError as e:\n        print(e);\n    else:\n        pass"
            ]
        ]
    },
    {
        "blob_id": "8751c874b89ae3a59ee30d8e9e5a57d594a9ade6",
        "matched_blocks": [
            [
                873,
                881,
                "        try:\n            yield\n        except:\n            if session.in_transaction():\n                session.rollback()\n            raise\n        else:\n            if outermost and session.in_transaction():\n                session.commit()"
            ],
            [
                904,
                910,
                "            try:\n                yield\n            except:\n                if session.in_transaction():\n                    session.rollback()\n            else:\n                session.commit()"
            ]
        ]
    },
    {
        "blob_id": "5c3f5f397459ba10ccc43505f8f9921ca7e031b7",
        "matched_blocks": [
            [
                59,
                67,
                "    try:\n        waiting_payment = order.payments.get(status=PaymentStatus.WAITING)\n    except Payment.DoesNotExist:\n        waiting_payment = None\n        waiting_payment_form = None\n    else:\n        form_data = None\n        waiting_payment_form = PaymentDeleteForm(\n            None, order=order, initial={'payment_id': waiting_payment.id})"
            ]
        ]
    },
    {
        "blob_id": "04a510d1c2ca99c8b30d9f29be2ab84d6ebaf2e1",
        "matched_blocks": [
            [
                977,
                1003,
                "            try:\n                self.firewall_driver.unfilter_instance(instance,\n                                                    network_info=network_info)\n            except libvirt.libvirtError as e:\n                try:\n                    state = self.get_info(instance)['state']\n                except exception.InstanceNotFound:\n                    state = power_state.SHUTDOWN\n\n                if state != power_state.SHUTDOWN:\n                    LOG.warn(_(\"Instance may be still running, destroy \"\n                               \"it again.\"), instance=instance)\n                    self._destroy(instance)\n                else:\n                    retry = False\n                    errcode = e.get_error_code()\n                    LOG.exception(_('Error from libvirt during unfilter. '\n                                'Code=%(errcode)s Error=%(e)s') %\n                              {'errcode': errcode, 'e': e},\n                              instance=instance)\n                    reason = \"Error unfiltering instance.\"\n                    raise exception.InstanceTerminationFailure(reason=reason)\n            except Exception:\n                retry = False\n                raise\n            else:\n                retry = False"
            ],
            [
                3677,
                3684,
                "                try:\n                    vcpus = dom.vcpus()\n                except libvirt.libvirtError as e:\n                    LOG.warn(_(\"couldn't obtain the vpu count from domain id:\"\n                               \" %(id)s, exception: %(ex)s\") %\n                               {\"id\": dom_id, \"ex\": e})\n                else:\n                    total += len(vcpus[1])"
            ]
        ]
    },
    {
        "blob_id": "a5b09396f7bfff3dd6bd7b212bb7444ce2f75536",
        "matched_blocks": [
            [
                871,
                891,
                "        try:\n            proc = Popen(command,\n                         env=env,\n                         cwd=cwd,\n                         bufsize=-1,\n                         stdin=istream,\n                         stderr=PIPE,\n                         stdout=stdout_sink,\n                         shell=shell is not None and shell or self.USE_SHELL,\n                         close_fds=is_posix,  # unsupported on windows\n                         universal_newlines=universal_newlines,\n                         creationflags=PROC_CREATIONFLAGS,\n                         **subprocess_kwargs\n                         )\n\n        except cmd_not_found_exception as err:\n            raise GitCommandNotFound(redacted_command, err) from err\n        else:\n            # replace with a typeguard for Popen[bytes]?\n            proc.stdout = cast(BinaryIO, proc.stdout)\n            proc.stderr = cast(BinaryIO, proc.stderr)"
            ]
        ]
    },
    {
        "blob_id": "f1ee15bddbd470f45f3cbca8aebf25a5b4196cfd",
        "matched_blocks": [
            [
                39,
                55,
                "    try:\n        dictionary\n    except:\n        print(\"The object for {0} is undefined. You may have to replace it manually\".format(key))\n        return \"<0>\".format(key)\n    else:\n        try:\n            dictionary[key]\n        except:\n            print(\"A key for {0} is undefined. You may have to replace it manually.\".format(key))\n            return \"<0>\".format(key)\n        else:\n            if dictionary[key] == \"\":\n                print (\"missing {0} variable. You may have to replace it manually.\".format(key))\n                return \"{0}\".format(key)\n            else:\n                return dictionary[key]"
            ],
            [
                45,
                55,
                "        try:\n            dictionary[key]\n        except:\n            print(\"A key for {0} is undefined. You may have to replace it manually.\".format(key))\n            return \"<0>\".format(key)\n        else:\n            if dictionary[key] == \"\":\n                print (\"missing {0} variable. You may have to replace it manually.\".format(key))\n                return \"{0}\".format(key)\n            else:\n                return dictionary[key]"
            ]
        ]
    },
    {
        "blob_id": "3df17cdbf0160778d54fac13b7233848d68544cd",
        "matched_blocks": [
            [
                74,
                79,
                "\t\t\ttry:\n\t\t\t\tcallback, args = self.callbackQ.get(block=False)\n\t\t\texcept queue.Empty:\n\t\t\t\tbreak\n\t\t\telse:\n\t\t\t\tcallback(*args)"
            ]
        ]
    },
    {
        "blob_id": "75a797cd08b1ca2936259f385850d626c08fbe74",
        "matched_blocks": [
            [
                1069,
                1080,
                "    try:\n        coordsets = atoms._getCoordsets(csets)\n    except AttributeError:\n        try:\n            coordsets = atoms._getCoords()\n        except AttributeError:\n            raise TypeError('atoms must be an object with coordinate sets')\n        if coordsets is not None:\n            coordsets = [coordsets]\n    else:\n        if coordsets.ndim == 2:\n            coordsets = [coordsets]"
            ],
            [
                1101,
                1106,
                "    try:\n        atoms.getIndex()\n    except AttributeError:\n        pass\n    else:\n        atoms = atoms.select('all')"
            ],
            [
                1087,
                1099,
                "        try:\n            atoms = atoms.getAtoms()\n        except AttributeError:\n            raise TypeError('atoms must be an Atomic instance or an object '\n                            'with `getAtoms` method')\n        else:\n            if atoms is None:\n                raise ValueError('atoms is not associated with an Atomic '\n                                 'instance')\n            try:\n                acsi = atoms.getACSIndex()\n            except AttributeError:\n                raise TypeError('atoms does not have a valid type')"
            ]
        ]
    },
    {
        "blob_id": "8a25d45193f88d63bbed9c49ba4d9e688afdfd38",
        "matched_blocks": [
            [
                17,
                35,
                "        try:\n            reduce(dict.__getitem__, [\n                   \"responses\", \"GET_INVENTORY\", \"inventory_delta\", \"inventory_items\"], response_dict)\n        except KeyError:\n            pass\n        else:\n            for item in response_dict['responses']['GET_INVENTORY']['inventory_delta']['inventory_items']:\n                try:\n                    reduce(dict.__getitem__, [\n                           \"inventory_item_data\", \"pokemon_data\"], item)\n                except KeyError:\n                    pass\n                else:\n                    try:\n                        pokemon = item['inventory_item_data']['pokemon_data']\n                        self._execute_pokemon_evolve(pokemon, cache)\n                        sleep(1.2)\n                    except:\n                        pass"
            ],
            [
                24,
                35,
                "                try:\n                    reduce(dict.__getitem__, [\n                           \"inventory_item_data\", \"pokemon_data\"], item)\n                except KeyError:\n                    pass\n                else:\n                    try:\n                        pokemon = item['inventory_item_data']['pokemon_data']\n                        self._execute_pokemon_evolve(pokemon, cache)\n                        sleep(1.2)\n                    except:\n                        pass"
            ]
        ]
    },
    {
        "blob_id": "46aeedfe4204e224d40719a4f021ca4eb5bb7a86",
        "matched_blocks": [
            [
                137,
                144,
                "        try:\n            data = self.get_data()\n        except InvalidArgumentError as e:\n            self.parser.error(str(e))\n        else:\n            self.logger.info('Sending data')\n            self.client.post(uri=settings.DEPLOYMENT_API_URI, data=data)\n            self.logger.info('Done')"
            ]
        ]
    },
    {
        "blob_id": "13351c5fd51203c124719b1f8a43e935562f92a1",
        "matched_blocks": [
            [
                650,
                656,
                "            try:\n                ia = order.invoice_address\n            except InvoiceAddress.DoesNotExist:\n                return True\n            else:\n                if str(ia.country) not in restricted_countries:\n                    return False"
            ]
        ]
    },
    {
        "blob_id": "95408599f7cf90f3dc081e43b6699d7d41f29d00",
        "matched_blocks": [
            [
                32,
                41,
                "            try:\n                message = self.decrypt(ciphertext, bytes(nonce))\n            except ValueError:\n                print(\"Failed to decrypt the message (client, {}).\".format(messageid))\n                self.server.loseConnection()\n                return False\n            else:\n                self.decrypt_nonce = self.server.encrypt_nonce = message[:24]\n                self.k = message[24:56]\n                return messageid, unknown, message[56:]"
            ]
        ]
    },
    {
        "blob_id": "84bb47bd0a81b73ef1fb8f53eddef56f70422ecb",
        "matched_blocks": [
            [
                230,
                252,
                "    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        print('matplotlib is not available.')\n    else:\n        if ax is None:\n            _, ax = plt.subplots(1, 1, figsize=(8, 5))\n\n        ax.set_prop_cycle('color', ['b', 'r', 'b', 'g', 'b', 'y', 'b', 'c', 'b', 'm'])\n        #ax.set_color_cycle(['b', 'r', 'b', 'g', 'b', 'y', 'b', 'c', 'b', 'm'])\n        for col in np.arange(y.shape[1]):\n            if y.shape[1] == 1:\n                ax.plot(t, y[:, col], 'o-', lw=1, label='Original data')\n                ax.plot(tn, yn[:, col], '.-', lw=2,\n                        label='Interpolated')\n            else:\n                ax.plot(t, y[:, col], 'o-', lw=1)\n                ax.plot(tn, yn[:, col], '.-', lw=2, label='Col= %d' % col)\n            ax.locator_params(axis='y', nbins=7)\n            ax.legend(fontsize=12, loc='best', framealpha=.5, numpoints=1)\n        plt.xlabel('[%]')\n        plt.tight_layout()\n        plt.show()"
            ]
        ]
    },
    {
        "blob_id": "a1a6271153ef74e850bfee4fa09a66089ad7f7f7",
        "matched_blocks": [
            [
                84,
                101,
                "    try:\n        # ip\uc8fc\uc18c\uc640 \uac8c\uc2dc\uae00 \ubc88\ud638\ub85c \uae30\ub85d\uc744 \uc870\ud68c\ud568\n        hits = HitCount.objects.get(ip=ip, post=board)\n    except Exception as e:\n        # \ucc98\uc74c \uac8c\uc2dc\uae00\uc744 \uc870\ud68c\ud55c \uacbd\uc6b0\uc5d4 \uc870\ud68c \uae30\ub85d\uc774 \uc5c6\uc74c\n        print(e)\n        hits = HitCount(ip=ip, post=board)\n        Board.objects.filter(id=board.id).update(hit=board.hit + 1)\n        hits.save()\n    else:\n        # \uc870\ud68c \uae30\ub85d\uc740 \uc788\uc73c\ub098, \ub0a0\uc9dc\uac00 \ub2e4\ub978 \uacbd\uc6b0\n        if not hits.date == timezone.now().date():\n            Board.objects.filter(id=id).update(hits=board.hit + 1)\n            hits.date = timezone.now()\n            hits.save()\n        # \ub0a0\uc9dc\uac00 \uac19\uc740 \uacbd\uc6b0\n        else:\n            print(str(ip) + ' has already hit this post.\\n\\n')"
            ]
        ]
    },
    {
        "blob_id": "50147ed4fee7f2d5baa730041242352c151d83e2",
        "matched_blocks": [
            [
                84,
                152,
                "        try:\n            self.assure_protocol_requirements(environ)\n            request = WSGIRequest(environ)\n            if callable(private_settings.WS4REDIS_PROCESS_REQUEST):\n                private_settings.WS4REDIS_PROCESS_REQUEST(request)\n            else:\n                self.process_request(request)\n            channels, echo_message = self.process_subscriptions(request)\n            if callable(private_settings.WS4REDIS_ALLOWED_CHANNELS):\n                channels = list(private_settings.WS4REDIS_ALLOWED_CHANNELS(request, channels))\n            elif private_settings.WS4REDIS_ALLOWED_CHANNELS is not None:\n                try:\n                    mod, callback = private_settings.WS4REDIS_ALLOWED_CHANNELS.rsplit('.', 1)\n                    callback = getattr(import_module(mod), callback, None)\n                    if callable(callback):\n                        channels = list(callback(request, channels))\n                except AttributeError:\n                    pass\n            websocket = self.upgrade_websocket(environ, start_response)\n            self._websockets.add(websocket)\n            logger.debug('Subscribed to channels: {0}'.format(', '.join(channels)))\n            subscriber.set_pubsub_channels(request, channels)\n            websocket_fd = websocket.get_file_descriptor()\n            listening_fds = [websocket_fd]\n            redis_fd = subscriber.get_file_descriptor()\n            if redis_fd:\n                listening_fds.append(redis_fd)\n            subscriber.send_persited_messages(websocket)\n            recvmsg = None\n            while websocket and not websocket.closed:\n                ready = self.select(listening_fds, [], [], 4.0)[0]\n                if not ready:\n                    # flush empty socket\n                    websocket.flush()\n                for fd in ready:\n                    if fd == websocket_fd:\n                        recvmsg = RedisMessage(websocket.receive())\n                        if recvmsg:\n                            subscriber.publish_message(recvmsg)\n                    elif fd == redis_fd:\n                        sendmsg = RedisMessage(subscriber.parse_response())\n                        if sendmsg and (echo_message or sendmsg != recvmsg):\n                            websocket.send(sendmsg)\n                    else:\n                        logger.error('Invalid file descriptor: {0}'.format(fd))\n                # Check again that the websocket is closed before sending the heartbeat,\n                # because the websocket can closed previously in the loop.\n                if private_settings.WS4REDIS_HEARTBEAT and not websocket.closed:\n                    websocket.send(private_settings.WS4REDIS_HEARTBEAT)\n                # Remove websocket from _websockets if closed\n                if websocket.closed:\n                    self._websockets.remove(websocket)\n        except WebSocketError as excpt:\n            logger.warning('WebSocketError: {}'.format(excpt), exc_info=sys.exc_info())\n            response = http.HttpResponse(status=1001, content='Websocket Closed')\n        except UpgradeRequiredError as excpt:\n            logger.info('Websocket upgrade required')\n            response = http.HttpResponseBadRequest(status=426, content=excpt)\n        except HandshakeError as excpt:\n            logger.warning('HandshakeError: {}'.format(excpt), exc_info=sys.exc_info())\n            response = http.HttpResponseBadRequest(content=excpt)\n        except PermissionDenied as excpt:\n            logger.warning('PermissionDenied: {}'.format(excpt), exc_info=sys.exc_info())\n            response = http.HttpResponseForbidden(content=excpt)\n        except Exception as excpt:\n            logger.error('Other Exception: {}'.format(excpt), exc_info=sys.exc_info())\n            response = http.HttpResponseServerError(content=excpt)\n        else:\n            response = http.HttpResponse()"
            ]
        ]
    },
    {
        "blob_id": "61c08e8e50ca23fb59f64c63715afde92c21f62d",
        "matched_blocks": [
            [
                151,
                157,
                "            try:\n                r = conn.execute(sql, *args)\n            except Exception as e:\n                logging.error(\"Error Occured: %s\\n%s\" % (e.args, errormsg))\n                df = pd.DataFrame({})\n            else:\n                df = pd.DataFrame.from_records(r, columns = r.keys())"
            ]
        ]
    },
    {
        "blob_id": "54db0bfcbb5b33027d20bfc5b6708708375f4e86",
        "matched_blocks": [
            [
                86,
                92,
                "    try:\n        cindex.Index.create()\n    except cindex.LibclangError as error:\n        pass\n    else:\n        # it works out of the box, nothing to do\n        return"
            ]
        ]
    },
    {
        "blob_id": "e90ed36824a79fce603693f32a18011f3235f8b2",
        "matched_blocks": [
            [
                36,
                46,
                "        try:\n            dbs = influxdb_client.get_list_database()\n            if DB_NAME not in dbs:\n                influxdb_client.create_database(DB_NAME)\n        except Exception:\n            logger.exception(\"Error connecting to InfluxDB. Retrying in 30sec\")\n            time.sleep(30)\n            continue\n        else:\n            logging.info(\"connected to influxdb\")\n            break"
            ],
            [
                60,
                71,
                "        try:\n            conn = event.container.connect(amqp_url, allowed_mechs=\"PLAIN\")\n            event.container.create_receiver(conn, partition_name + \"/ConsumerGroups/$default/Partitions/0\",\n                                            options=selector)\n            event.container.create_receiver(conn, partition_name + \"/ConsumerGroups/$default/Partitions/1\",\n                                            options=selector)\n        except Exception:\n            logger.exception(\"Error connecting to IotHub. Retrying in 30sec\")\n            time.sleep(30)\n            continue\n        else:\n            break"
            ],
            [
                76,
                83,
                "        try:\n            influxdb_client.write_points(payload)\n        except Exception:\n            logger.exception(\"Error writing to InfluxDB. Retrying in 30sec\")\n            time.sleep(30)\n            continue\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "ed2fa2d7393d424a1fc95380166eb30a69b19171",
        "matched_blocks": [
            [
                1904,
                1922,
                "    try:\n        if not package:\n            module = import_module(name)\n        else:\n            module = import_module('.' + name, package=package)\n    except ImportError:\n        if warn:\n            warnings.warn('failed to import module %s' % name)\n    else:\n        for attr in dir(module):\n            if ignore and attr.startswith(ignore):\n                continue\n            if prefix:\n                if attr in globals():\n                    globals()[prefix + attr] = globals()[attr]\n                elif warn:\n                    warnings.warn('no Python implementation of ' + attr)\n            globals()[attr] = getattr(module, attr)\n        return True"
            ]
        ]
    },
    {
        "blob_id": "167be2f80064570bcd68c85900c3950255dee414",
        "matched_blocks": [
            [
                85,
                87,
                "    try: this_tests(func)\n    except Exception as e: assert f\"'{func}' is not a function\" in str(e)\n    else: assert False, f'this_tests({func}) should have failed'"
            ],
            [
                91,
                93,
                "    try: this_tests(func)\n    except Exception as e: assert f\"'{func}' is not a function\" in str(e)\n    else: assert False, f'this_tests({func}) should have failed'"
            ],
            [
                98,
                100,
                "    try: this_tests(func)\n    except Exception as e: assert f\"'{func}' is not in the fastai API\" in str(e)\n    else: assert False, f'this_tests({func}) should have failed'"
            ]
        ]
    },
    {
        "blob_id": "61067f0e4176b3667325c9090332ba965bc7d1ba",
        "matched_blocks": [
            [
                34,
                39,
                "try:\n    import snappy\nexcept ImportError:\n    HAS_SNAPPY = False\nelse:\n    HAS_SNAPPY = True"
            ]
        ]
    },
    {
        "blob_id": "938d419f1aec103ded76d6b50183109d41214d7d",
        "matched_blocks": [
            [
                28,
                33,
                "        try:\n            int(k)\n        except ValueError:\n            pass\n        else:\n            removes.append(k)"
            ],
            [
                75,
                87,
                "        try:\n            for i, arg in enumerate(D['params']):\n                if not Any.kind(arg) == arg_types[i]:\n                    raise InvalidParamsError(\n                        '%s is not the correct type %s for %s' %\n                        (type(arg), arg_types[i], method.json_sig))\n        except IndexError:\n            raise InvalidParamsError('Too many params provided for %s' %\n                                     method.json_sig)\n        else:\n            if len(D['params']) != len(arg_types):\n                raise InvalidParamsError('Not enough params provided for %s' %\n                                         method.json_sig)"
            ]
        ]
    },
    {
        "blob_id": "ef89ebbee0f0db544ff5bf1b817aff77405ecae0",
        "matched_blocks": [
            [
                52,
                60,
                "        try:\n            sadm_contents = open('/var/sadm/install/contents', 'r').read()\n        except EnvironmentError:\n            pass\n        else:\n            sadm_re = re.compile('^(\\S*/bin/CC)(=\\S*)? %s$' % package_name, re.M)\n            sadm_match = sadm_re.search(sadm_contents)\n            if sadm_match:\n                pathname = os.path.dirname(sadm_match.group(1))"
            ],
            [
                62,
                73,
                "        try:\n            p = subprocess.Popen([pkginfo, '-l', package_name],\n                                 stdout=subprocess.PIPE,\n                                 stderr=open('/dev/null', 'w'))\n        except EnvironmentError:\n            pass\n        else:\n            pkginfo_contents = p.communicate()[0]\n            version_re = re.compile('^ *VERSION:\\s*(.*)$', re.M)\n            version_match = version_re.search(pkginfo_contents)\n            if version_match:\n                version = version_match.group(1)"
            ],
            [
                76,
                87,
                "            try:\n                p = subprocess.Popen([pkgchk, '-l', package_name],\n                                     stdout=subprocess.PIPE,\n                                     stderr=open('/dev/null', 'w'))\n            except EnvironmentError:\n                pass\n            else:\n                pkgchk_contents = p.communicate()[0]\n                pathname_re = re.compile(r'^Pathname:\\s*(.*/bin/CC)$', re.M)\n                pathname_match = pathname_re.search(pkgchk_contents)\n                if pathname_match:\n                    pathname = os.path.dirname(pathname_match.group(1))"
            ]
        ]
    },
    {
        "blob_id": "9ff8d50d04e1c3a41532a71268656516de3e367c",
        "matched_blocks": [
            [
                911,
                919,
                "            try:\n                sol = dsolve(eq, func(x))\n            except NotImplementedError:\n                continue\n            else:\n                if isinstance(sol, list):\n                    sols.extend(sol)\n                else:\n                    sols.append(sol)"
            ]
        ]
    },
    {
        "blob_id": "cd9bb1eb10be89931f7564472027e88621ad041e",
        "matched_blocks": [
            [
                38,
                44,
                "        try:\n            element = self.driver.find_element(*self.tip_commit)\n        except NoSuchElementException:\n            pass\n        else:\n            logging.info('\u8df3\u8fc7\u767b\u5f55\u8b66\u544a\u4fe1\u606f')\n            element.click()"
            ],
            [
                51,
                62,
                "        try:\n            self.driver.find_element(*self.button_mysefl).click()\n            self.driver.find_element(*self.usercenter_username)\n        except NoSuchElementException:\n            logging.error('\u767b\u9646\u5931\u8d25')\n            self.getScreenShot('\u767b\u9646\u5931\u8d25')\n            return False\n        else:\n            logging.info('\u767b\u9646\u6210\u529f')\n            self.getScreenShot('\u767b\u9646\u6210\u529f')\n            self.logout_action()\n            return True"
            ]
        ]
    },
    {
        "blob_id": "783c2579ae1c2d4da62f27215e905f8fcaf6831b",
        "matched_blocks": [
            [
                237,
                290,
                "            try:\n                if hasattr(classifier, \"location_\"):\n                    x_mean, x_std1, x_std2 = classifier.location_\n                else:\n                    x_mean, x_std1, x_std2 = np.median(data[classes == 1], axis=0)\n            except IndexError:\n                x_mean, x_std1, x_std2 = np.median(data, axis=0)\n            else:\n                x_inlier_indices = [\n                    i\n                    for i, v in enumerate(classes)\n                    if v in true_pred\n                    or common_peaks[keys[i][0]][keys[i][1]][keys[i][2]].get(\"valid\")\n                ]\n                x_inliers = set([keys[i][:2] for i in sorted(x_inlier_indices)])\n                x_outliers = [\n                    i\n                    for i, v in enumerate(classes)\n                    if keys[i][:2] not in x_inliers\n                    and (\n                        v in false_pred\n                        or common_peaks[keys[i][0]][keys[i][1]][keys[i][2]].get(\n                            \"interpolate\"\n                        )\n                    )\n                ]\n                if debug:\n                    print(\"inliers\", x_inliers)\n                    print(\"outliers\", x_outliers)\n                # print('x1o', x1_outliers)\n                min_x = x_mean - x_std1\n                max_x = x_mean + x_std2\n                for index in x_inlier_indices:\n                    indexer = keys[index]\n                    peak_info = common_peaks[indexer[0]][indexer[1]][indexer[2]]\n                    peak_min = peak_info[\"mean\"] - peak_info[\"std\"]\n                    peak_max = peak_info[\"mean\"] + peak_info[\"std2\"]\n                    if peak_min < min_x:\n                        min_x = peak_min\n                    if peak_max > max_x:\n                        max_x = peak_max\n                if x_inliers:\n                    for index in x_outliers:\n                        indexer = keys[index]\n                        if x_inliers is not None and indexer[:2] in x_inliers:\n                            # this outlier has a valid inlying value in x1_inliers, so we delete it\n                            to_delete.add(indexer)\n                        else:\n                            # there is no non-outlying data point. If this data point is > 1 sigma away, delete it\n                            peak_info = common_peaks[indexer[0]][indexer[1]][indexer[2]]\n                            if debug:\n                                print(indexer, peak_info, x_mean, x_std1, x_std2)\n                            if not (min_x < peak_info[\"mean\"] < max_x):\n                                to_delete.add(indexer)"
            ]
        ]
    },
    {
        "blob_id": "baa05ca51f5bbccbe658dac624ebc2f430ff06de",
        "matched_blocks": [
            [
                8,
                18,
                "try:\n\tfor recNo, record in enumerate(table):\n\t\tfor rowNo, row in enumerate(record):\n\t\t\tfor index, item in enumerate(row):\n\t\t\t\titem = random.randint(1, 10)\n\t\t\t\tif item == target:\n\t\t\t\t\traise foundException()\nexcept foundException as err:\n\tprint('{}:{}:{}'.format(record, row, index))\nelse:\n\tprint('not found the number')"
            ]
        ]
    },
    {
        "blob_id": "7a739e3752e95e948a98508bea948d514e69019d",
        "matched_blocks": [
            [
                65,
                70,
                "    try:\n        shift = int(input(\">>> \"))\n    except NameError as e:\n        print (\"Wow! Numbers please!\")\n    else:\n        break"
            ]
        ]
    },
    {
        "blob_id": "5f2966ec1f36c07526da05e9373204e613eb4e7c",
        "matched_blocks": [
            [
                176,
                253,
                "            try:\n                if not dcache.remote_file_exists(\n                    \"{}/{}\".format(dns, dcname), s[0], s[1]\n                ):\n                    logger.debug(\n                        \"File %s for %s/%s (%s/%s) not available in the \"\n                        \"destination cache, downloading.\",\n                        s[0],\n                        ns,\n                        comp,\n                        dns,\n                        dcname,\n                    )\n                    scache.download(\n                        \"{}/{}\".format(ns, scname),\n                        s[0],\n                        s[1],\n                        os.path.join(tempdir.name, s[0]),\n                        hashtype=s[2],\n                    )\n                    logger.debug(\n                        \"File %s for %s/%s (%s/%s) successfully downloaded.  \"\n                        \"Uploading to the destination cache.\",\n                        s[0],\n                        ns,\n                        comp,\n                        ns,\n                        scname,\n                    )\n                    if not dry_run:\n                        dcache.upload(\n                            \"{}/{}\".format(dns, dcname),\n                            os.path.join(tempdir.name, s[0]),\n                            s[1],\n                        )\n                        logger.debug(\n                            \"File %s for %s/%s (%s/%s) )successfully uploaded \"\n                            \"to the destination cache.\",\n                            s[0],\n                            ns,\n                            comp,\n                            dns,\n                            dcname,\n                        )\n                    else:\n                        logger.debug(\n                            \"Running in dry run mode, not uploading %s for %s/%s (%s/%s).\",\n                            s[0],\n                            ns,\n                            comp,\n                            dns,\n                            dcname,\n                        )\n                else:\n                    logger.debug(\n                        \"File %s for %s/%s (%s/%s) already uploaded, skipping.\",\n                        s[0],\n                        ns,\n                        comp,\n                        dns,\n                        dcname,\n                    )\n            except Exception:\n                logger.warning(\n                    \"Failed attempt #%d/%d handling %s for %s/%s (%s/%s -> %s/%s), retrying.\",\n                    attempt + 1,\n                    retry,\n                    s[0],\n                    ns,\n                    comp,\n                    ns,\n                    scname,\n                    dns,\n                    dcname,\n                    exc_info=True,\n                )\n            else:\n                break"
            ]
        ]
    },
    {
        "blob_id": "d5fa86aaa2e960a83458c8b29da65093687ad681",
        "matched_blocks": [
            [
                135,
                142,
                "    try:\n        response = json.loads(req.text)\n    except Exception as err:\n        log.exception('[{net[name]}] JSON error: {err}'\n                      .format(net=net, err=err))\n    else:\n        if response['response'] and 'id' in response:\n            return response['id']"
            ]
        ]
    },
    {
        "blob_id": "008aa1e18cfde53941e12be5136b276dfc3aa051",
        "matched_blocks": [
            [
                59,
                65,
                "        try:\n            value = Template(raw_value,\n                             undefined=StrictUndefined).render(**mapping)\n        except Exception as e:\n            exception = e\n        else:\n            exception = None"
            ]
        ]
    },
    {
        "blob_id": "13f4dce516b43c3869d4aa599bdcc9d7dcb6a354",
        "matched_blocks": [
            [
                48,
                53,
                "        try:\n            json.loads(text)\n        except json.JSONDecodeError:\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "8fa9147af37b711c05794bf2b0cc39c9ff014b00",
        "matched_blocks": [
            [
                43,
                48,
                "try:\n    import openbabel\nexcept ImportError:\n    BACKENDS = ['rdkit']\nelse:\n    BACKENDS = ['openbabel', 'rdkit']"
            ],
            [
                239,
                253,
                "    try:\n        if mol.isRadical():\n            output = RADICAL_LOOKUPS[mol.getFormula()]\n        else:\n            output = MOLECULE_LOOKUPS[mol.getFormula()]\n    except KeyError:\n        if backend == 'default':\n            for atom in mol.atoms:\n                if atom.isNitrogen():\n                    return _write(mol, 'smi', backend='openbabel')\n            return _write(mol, 'smi', backend='rdkit')\n        else:\n            return _write(mol, 'smi', backend=backend)\n    else:\n        return output"
            ]
        ]
    },
    {
        "blob_id": "a468fe60624b32c4061bf9e37b5a43a921d6156d",
        "matched_blocks": [
            [
                134,
                165,
                "        try:\n            print(request.session.items())\n            final_res = {}\n            if request.session.get('user_sk'):\n                res = User.read(\n                    pk = 'User',\n                    sk = request.session['user_sk'],\n                    attributes_to_get = [\n                        'ClosedUserData'\n                    ]\n                ).execute()\n                final_res = res['ClosedUserData']['RiotID']\n                for idx, v in enumerate(final_res):\n                    if not v['Authenticated'] and v['IconID'] == get_riot_id_icon(v['Name']):\n                        User.update(\n                            pk = 'USER',\n                            sk = request.session['user_sk'],\n                            expressions = [{  \n                                'utype' : 'SET', \n                                'path' : f'ClolsedUserData.RiotID[{idx}].Authenticated',\n                                'value' : True\n                            }]\n                        ).execute()\n                        final_res['ClosedUserData']['RiotID'][idx]['Authenticated'] = True\n            else:\n                return Response(status = status.HTTP_401_UNAUTHORIZED)\n                        \n        except Exception as err:\n            print(err)\n            return Response(status = status.HTTP_400_BAD_REQUEST)\n        else:\n            return Response(final_res, status = status.HTTP_200_OK)"
            ],
            [
                177,
                208,
                "        try:\n            res = json.loads(request.body)\n            riot_id = get_riot_id(res['name'])\n            print(riot_id)\n            riot_id_dict = dict()\n            if riot_id:\n                riot_id_dict['Name'] = riot_id['name']\n                riot_id_dict['PUUID'] = riot_id['puuid']\n                riot_id_dict['IconID'] = set_random_icon(riot_id)\n                riot_id_dict['Authenticated'] = False\n            else:\n                return Response(status = status.HTTP_400_BAD_REQUEST)\n            User.update(\n                pk = 'USER',\n                sk = request.session['user_sk'],\n                expressions = [{\n                    'utype' : 'LIST_APPEND',\n                    'path' : 'ClosedUserData.RiotID',\n                    'value' : riot_id_dict\n                }]\n            ).execute()\n            \n        except json.JSONDecodeError as err:\n            print(err)\n            return Response(status = status.HTTP_400_BAD_REQUEST)\n        except KeyError as err:\n            print(err)\n            return Response(status = status.HTTP_400_BAD_REQUEST)\n        except Exception as err:\n            return Response(status = status.HTTP_501_NOT_IMPLEMENTED)\n        else:\n            return Response(status = status.HTTP_200_OK)"
            ],
            [
                219,
                233,
                "        try:\n            idx = str(request.GET.get('riot_id_index'))\n            User.update(\n                pk = 'USER',\n                sk = request.session['user_sk'],\n                expressions = [{\n                    'utype' : 'REMOVE',\n                    'path' : f'ClosedUserData.RiotID[{idx}]',\n                }]\n            ).execute()\n        except Exception as err:\n            print(err)\n            return Response(status = status.HTTP_400_BAD_REQUEST)\n        else: \n            return Response(status = status.HTTP_200_OK)"
            ],
            [
                247,
                253,
                "        try:\n            request.session.flush()\n        except Exception as err:\n            print(err)\n            return Response(status = status.HTTP_404_NOT_FOUND)\n        else:\n            return Response(status = status.HTTP_200_OK)"
            ],
            [
                435,
                445,
                "        try:\n            res = User.read(\n                pk = 'USER',\n                sk = f'{logintype}#{userid}',\n                attributes_to_get = atbt2get\n            ).execute()\n        except Exception as err:\n            print(err)\n            return Response(status = status.HTTP_404_NOT_FOUND)\n        else:\n            return Response(res, status = status.HTTP_200_OK)"
            ],
            [
                461,
                477,
                "            try:\n                User.update(\n                    pk = 'USER',\n                    sk = userid,\n                    expressions = [{\n                            'utype' : 'SET',\n                            'path' : 'User',\n                            'nickname': request.POST.get('nickname'),\n                            'overwrite': True\n                        }\n                    ]\n                )\n            except Exception as err:\n                print(err)\n                return Response(status = status.HTTP_400_BAD_REQUEST)\n            else:\n                return Response(status = status.HTTP_200_OK)"
            ]
        ]
    },
    {
        "blob_id": "6f580b48403203be5a0dd63d2fb9098c93234597",
        "matched_blocks": [
            [
                139,
                146,
                "        try:\n            start, end = name.split('_')\n            start = int(start) + 1\n            end = int(end)  # don't add one here because postgres slices are weird\n        except ValueError:\n            pass\n        else:\n            return SliceTransformFactory(start, end)"
            ],
            [
                132,
                138,
                "            try:\n                index = int(name)\n            except ValueError:\n                pass\n            else:\n                index += 1  # postgres uses 1-indexing\n                return IndexTransformFactory(index, self.base_field)"
            ]
        ]
    },
    {
        "blob_id": "c6df998736872f9544992e558624401723fc3878",
        "matched_blocks": [
            [
                151,
                168,
                "        try:\n            target = task.materialize()\n            if isinstance(target, entity.Runnable):\n                if not target.parent:\n                  target.parent = self\n                if not target.cfg.parent:\n                  target.cfg.parent = self.cfg\n                result = target.run()\n            elif callable(target):\n                result = target()\n            else:\n                result = target.run()\n        except BaseException as exc:\n            task_result = TaskResult(\n                task=task, result=None, status=False,\n                reason=format_trace(inspect.trace(), exc))\n        else:\n            task_result = TaskResult(task=task, result=result, status=True)"
            ]
        ]
    },
    {
        "blob_id": "d1c7259dc9a54da513a03a3da2432ad2a15f75b2",
        "matched_blocks": [
            [
                1022,
                1032,
                "                try:\n                    header_row = next(reader)\n                    data_row = next(reader)\n                    for row in reader:\n                        pass\n                except StopIteration:\n                    pass\n                except csv.Error as e:\n                    raise Exception('CSV reader error - line %d: %s' % (reader.line_num, e))\n                else:\n                    data_lines = reader.line_num - 1"
            ]
        ]
    },
    {
        "blob_id": "b64ec8ccaf0a47dd9f85266b92faf3122e5e57ff",
        "matched_blocks": [
            [
                23,
                28,
                "    try:\n        r = a / b\n    except:\n        raise ValueError\n    else: # no exceptions , run this code\n        print('divide result is %s' % r)"
            ]
        ]
    },
    {
        "blob_id": "986752ad92786278390aa63561e50adacb61ec26",
        "matched_blocks": [
            [
                536,
                541,
                "        try:\n            find_non_syms(raw_numer)\n        except PolynomialError:\n            return\n        else:\n            ground, _ = construct_domain(non_syms, field=True)"
            ]
        ]
    },
    {
        "blob_id": "c33969059ecb95c934efc421be7c3dfdd6fc2365",
        "matched_blocks": [
            [
                144,
                157,
                "        try:\n            from sklearn.cluster import KMeans\n        except ModuleNotFoundError:\n            print('WARNING: no sklearn, skipping anchor clustering...')\n        else:\n            X = np.array(BBOX_WHS)\n            kmeans = KMeans(n_clusters=KMEANS_CLUSTERS, random_state=0).fit(X)\n            centers = kmeans.cluster_centers_\n            centers = centers[centers[:, 0].argsort()]  # sort by bbox w\n            print('\\n** for yolov5-%dx%d, ' % (INPUT_WIDTH, INPUT_HEIGHT), end='')\n            print('resized bbox width/height clusters are: ', end='')\n            print(' '.join(['(%.2f, %.2f)' % (c[0], c[1]) for c in centers]))\n            print('\\nanchors = ', end='')\n            print(',  '.join(['%d,%d' % (int(c[0]), int(c[1])) for c in centers]))"
            ]
        ]
    },
    {
        "blob_id": "322a6d1f7948d54415674bae1ded0b3b654f09e4",
        "matched_blocks": [
            [
                39,
                51,
                "        try:\n            if pre_code_id:\n                self.redis.delete(\"pic_code_%s\" % pre_code_id)\n                # self.redis.delete(\"\")\n            # self.redis.setex(name, expries, value)\n            self.redis.setex(\"pic_code_%s\" % cur_code_id, PIC_CODE_EXPIRES_SECONDS, text)\n        except Exception as e:\n            logging.error(e)\n            self.write(\"\")\n        else:\n            self.set_header(\"Content-Type\", \"image/jpg\")\n            # \u8fd4\u56de\u56fe\u7247\n            self.write(imgio.getvalue())"
            ]
        ]
    },
    {
        "blob_id": "7a8b58333685500dc2a271d37474d768546b5291",
        "matched_blocks": [
            [
                18,
                23,
                "try:\n    from gevent import monkey\nexcept ImportError:\n    sleep = time.sleep\nelse:\n    sleep = monkey.get_original(\"time\", \"sleep\")"
            ]
        ]
    },
    {
        "blob_id": "699268c6e0017ae2f6d11377c913becdf77996e0",
        "matched_blocks": [
            [
                62,
                69,
                "    try:\n      expected = func(*args)\n    except Exception as e:\n      expected_error = e\n    else:\n      raise AssertionError(\n          \"Expected an error, but executing with pandas successfully \"\n          f\"returned:\\n{expected}\")"
            ],
            [
                73,
                80,
                "      try:\n        _ = func(*deferred_args)._expr\n      except Exception as e:\n        actual = e\n      else:\n        raise AssertionError(\n            f\"Expected an error:\\n{expected_error}\\nbut Beam successfully \"\n            f\"generated an expression.\")"
            ],
            [
                87,
                94,
                "      try:\n        result = session_type({}).evaluate(expr)\n      except Exception as e:\n        actual = e\n      else:\n        raise AssertionError(\n            f\"Expected an error:\\n{expected_error}\\nbut Beam successfully \"\n            f\"Computed the result:\\n{result}.\")"
            ]
        ]
    },
    {
        "blob_id": "dc29b58c92f8d705a0d55b2e25bf2a720992ce86",
        "matched_blocks": [
            [
                54,
                70,
                "        try:\n            # Open the S5B stream in which to write to.\n            proxy = yield from self['xep_0065'].handshake(self.receiver)\n\n            # Send the entire file.\n            while True:\n                data = self.file.read(1048576)\n                if not data:\n                    break\n                yield from proxy.write(data)\n\n            # And finally close the stream.\n            proxy.transport.write_eof()\n        except (IqError, IqTimeout):\n            print('File transfer errored')\n        else:\n            print('File transfer finished')"
            ]
        ]
    },
    {
        "blob_id": "d12749166e72c3d2d8a52414c97f3277ae9429b0",
        "matched_blocks": [
            [
                291,
                299,
                "        try:\n            r = requests.get(\n                'http://169.254.169.254/2009-04-04/meta-data/public-ipv4', timeout=2)\n            r.raise_for_status()\n        except (requests.HTTPError, requests.Timeout) as err:\n            logger.warning(\n                f'Meta Data service unavailable could not get external IP addr{err}')\n        else:\n            info_lines += 'External IP addr: {}'.format(r.text)"
            ]
        ]
    },
    {
        "blob_id": "9ad77a3831c4a0d0b80e07824a559811f0f4e269",
        "matched_blocks": [
            [
                246,
                259,
                "            try:\n                all_data = json.loads(info.text)\n            except JSONDecodeError as e:\n                self.write_log('Account of user %s was deleted or link is '\n                               'invalid' % (user))\n            else:\n                # prevent exception if user have no media\n                id_user = all_data['user']['id']\n                # Update the user_name with the user_id\n                self.user_blacklist[user] = id_user\n                log_string = \"Blacklisted user %s added with ID: %s\" % (user,\n                                                                        id_user)\n                self.write_log(log_string)\n                time.sleep(5 * random.random())"
            ]
        ]
    },
    {
        "blob_id": "5c479fef2ba2a813946fd55f85dddcb13b08b531",
        "matched_blocks": [
            [
                41,
                57,
                "    try:\n\n        fp = open(f, \"rb\")\n\n        try:\n            p = PcfFontFile.PcfFontFile(fp)\n        except SyntaxError:\n            fp.seek(0)\n            p = BdfFontFile.BdfFontFile(fp)\n\n        p.save(f)\n\n    except (SyntaxError, IOError):\n        print(\"failed\")\n\n    else:\n        print(\"OK\")"
            ]
        ]
    },
    {
        "blob_id": "8fe85c165c882f31473b97cc238e98b2399d9522",
        "matched_blocks": [
            [
                599,
                604,
                "            try:\n                st = os.stat(f.path)\n            except FileNotFoundError:\n                pass\n            else:\n                assert stat.S_ISREG(st.st_mode), f"
            ],
            [
                620,
                630,
                "            try:\n                st = os.stat(ret)\n            except OSError as err:\n                if WINDOWS and err.errno in \\\n                        psutil._psplatform.ACCESS_DENIED_SET:\n                    pass\n                # directory has been removed in mean time\n                elif err.errno != errno.ENOENT:\n                    raise\n            else:\n                assert stat.S_ISDIR(st.st_mode)"
            ],
            [
                404,
                417,
                "                try:\n                    meth(value, info)\n                except AssertionError:\n                    s = '\\n' + '=' * 70 + '\\n'\n                    s += \"FAIL: test_%s pid=%s, ret=%s\\n\" % (\n                        name, info['pid'], repr(value))\n                    s += '-' * 70\n                    s += \"\\n%s\" % traceback.format_exc()\n                    s = \"\\n\".join((\" \" * 4) + i for i in s.splitlines())\n                    s += '\\n'\n                    failures.append(s)\n                else:\n                    if value not in (0, 0.0, [], None, '', {}):\n                        assert value, value"
            ]
        ]
    },
    {
        "blob_id": "80a26215894568d8f2e70b898e8eb8b04d380c9e",
        "matched_blocks": [
            [
                149,
                157,
                "    try:\n        related\n    except NameError:\n        # The value of the error is known at this moment because it do not depends on some other BASE error code\n        err_dict[num].append(ErrItem(words[1], idf_path, include_as, comment))\n        rev_err_dict[words[1]] = num\n    else:\n        # Store the information available now and compute the error code later\n        unproc_list.append(ErrItem(words[1], idf_path, include_as, comment, related, num))"
            ],
            [
                193,
                199,
                "    try:\n        i = spl_path.index('include')\n    except ValueError:\n        # no include in the path -> use just the filename\n        return os.path.basename(path)\n    else:\n        return os.sep.join(spl_path[i + 1:])  # subdirectories and filename in \"include\""
            ]
        ]
    },
    {
        "blob_id": "95323488f1a2f39dd31806aae172ae8687c22cab",
        "matched_blocks": [
            [
                28,
                39,
                "try:\n    cleaner = variable_stack([\n        HandleError(1),\n        ErrorOnEnter(2),\n    ])\nexcept RuntimeError as err:\n    print('caught error {}'.format(err))\nelse:\n    if cleaner is not None:\n        cleaner()\n    else:\n        print('no cleaner returned')"
            ],
            [
                42,
                53,
                "try:\n    cleaner = variable_stack([\n        PassError(1),\n        ErrorOnEnter(2),\n    ])\nexcept RuntimeError as err:\n    print('caught error {}'.format(err))\nelse:\n    if cleaner is not None:\n        cleaner()\n    else:\n        print('no cleaner returned')"
            ]
        ]
    },
    {
        "blob_id": "11bc9407b651db938ff3f6333da6b4972a5e9ef3",
        "matched_blocks": [
            [
                536,
                589,
                "                try:\n                    kwargs = self.feature_kwargs(feat)\n                except LayerMapError as msg:\n                    # Something borked the validation\n                    if strict:\n                        raise\n                    elif not silent:\n                        stream.write('Ignoring Feature ID %s because: %s\\n' % (feat.fid, msg))\n                else:\n                    # Constructing the model using the keyword args\n                    is_update = False\n                    if self.unique:\n                        # If we want unique models on a particular field, handle the\n                        # geometry appropriately.\n                        try:\n                            # Getting the keyword arguments and retrieving\n                            # the unique model.\n                            u_kwargs = self.unique_kwargs(kwargs)\n                            m = self.model.objects.using(self.using).get(**u_kwargs)\n                            is_update = True\n\n                            # Getting the geometry (in OGR form), creating\n                            # one from the kwargs WKT, adding in additional\n                            # geometries, and update the attribute with the\n                            # just-updated geometry WKT.\n                            geom = getattr(m, self.geom_field).ogr\n                            new = OGRGeometry(kwargs[self.geom_field])\n                            for g in new:\n                                geom.add(g)\n                            setattr(m, self.geom_field, geom.wkt)\n                        except ObjectDoesNotExist:\n                            # No unique model exists yet, create.\n                            m = self.model(**kwargs)\n                    else:\n                        m = self.model(**kwargs)\n\n                    try:\n                        # Attempting to save.\n                        m.save(using=self.using)\n                        num_saved += 1\n                        if verbose:\n                            stream.write('%s: %s\\n' % ('Updated' if is_update else 'Saved', m))\n                    except Exception as msg:\n                        if strict:\n                            # Bailing out if the `strict` keyword is set.\n                            if not silent:\n                                stream.write(\n                                    'Failed to save the feature (id: %s) into the '\n                                    'model with the keyword arguments:\\n' % feat.fid\n                                )\n                                stream.write('%s\\n' % kwargs)\n                            raise\n                        elif not silent:\n                            stream.write('Failed to save %s:\\n %s\\nContinuing\\n' % (kwargs, msg))"
            ]
        ]
    },
    {
        "blob_id": "42cecea00b7391ed5181646dc7c931c9a4f52077",
        "matched_blocks": [
            [
                168,
                180,
                "        try:\n            index = int(search)\n            \n        except ValueError: # if it's not an index, search by name\n            guild = discord.utils.find(lambda s: search.lower() in s.name.lower(), guilds)\n        \n        else:\n            index -= 1\n            \n            if (index >= 0 and index < len(guilds)):\n                guild = guilds[index]\n            else: # search in the guild name\n                guild = discord.utils.find(lambda s: search.lower() in s.name.lower(), guilds)"
            ]
        ]
    },
    {
        "blob_id": "d837d6c4186e8c5fc7a09f8d78c85c5dc9761c58",
        "matched_blocks": [
            [
                2647,
                2656,
                "            try:\n                # fallback to positional argument\n                linefmt = args[0]\n            except IndexError:\n                linecolor = 'C0'\n                linemarker = 'None'\n                linestyle = '-'\n            else:\n                linestyle, linemarker, linecolor = \\\n                    _process_plot_format(linefmt)"
            ],
            [
                2661,
                2670,
                "            try:\n                # fallback to positional argument\n                markerfmt = args[1]\n            except IndexError:\n                markercolor = 'C0'\n                markermarker = 'o'\n                markerstyle = 'None'\n            else:\n                markerstyle, markermarker, markercolor = \\\n                    _process_plot_format(markerfmt)"
            ],
            [
                2676,
                2688,
                "            try:\n                # fallback to positional argument\n                basefmt = args[2]\n            except IndexError:\n                if rcParams['_internal.classic_mode']:\n                    basecolor = 'C2'\n                else:\n                    basecolor = 'C3'\n                basemarker = 'None'\n                basestyle = '-'\n            else:\n                basestyle, basemarker, basecolor = \\\n                    _process_plot_format(basefmt)"
            ]
        ]
    },
    {
        "blob_id": "72f1f59bbbd15bb91ff2e22139d375f363c4fe26",
        "matched_blocks": [
            [
                57,
                62,
                "    try:\n        sys.argv.remove('--nolint')\n    except ValueError:\n        run_flake8 = True\n    else:\n        run_flake8 = False"
            ],
            [
                64,
                69,
                "    try:\n        sys.argv.remove('--lintonly')\n    except ValueError:\n        run_tests = True\n    else:\n        run_tests = False"
            ],
            [
                71,
                76,
                "    try:\n        sys.argv.remove('--benchmarks')\n    except ValueError:\n        run_benchmarks = False\n    else:\n        run_benchmarks = True"
            ],
            [
                78,
                84,
                "    try:\n        sys.argv.remove('--fast')\n    except ValueError:\n        style = 'default'\n    else:\n        style = 'fast'\n        run_flake8 = False"
            ],
            [
                90,
                100,
                "        try:\n            pytest_args.remove('--coverage')\n        except ValueError:\n            pass\n        else:\n            pytest_args = [\n                '--cov-report',\n                'xml',\n                '--cov',\n                APP_NAME\n            ] + pytest_args"
            ]
        ]
    },
    {
        "blob_id": "87952ccd9a2eb59e81b8c92ef355b23f757f7304",
        "matched_blocks": [
            [
                48,
                65,
                "                try:\n                    subst1.try_add_variable('i2.2.1.1', tmp3)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 141686\n                    if len(subjects2) >= 1 and subjects2[0] == Integer(2):\n                        tmp5 = subjects2.popleft()\n                        # State 141687\n                        if len(subjects2) == 0:\n                            pass\n                            # State 141688\n                            if len(subjects) == 0:\n                                pass\n                                # 0: x**2\n                                yield 0, subst1\n                        subjects2.appendleft(tmp5)"
            ]
        ]
    },
    {
        "blob_id": "b2675f662be96e49ab8d4e0c301e40732a490cef",
        "matched_blocks": [
            [
                23,
                28,
                "try:\n    from unittest.util import safe_repr\nexcept ImportError:\n    pass\nelse:\n    unittest.case.safe_repr = lambda obj, short=False: safe_repr(obj, False)"
            ]
        ]
    },
    {
        "blob_id": "cf7a5c949b145a86634b083e8acd0620cef804a3",
        "matched_blocks": [
            [
                857,
                877,
                "            try:\n                # pop it from pending - do not rely the order in pending but rather the order in the closure node\n                p_to_apply = pending.pop(fixturename)\n            except KeyError:\n                # not a parametrized fixture\n                continue\n            else:\n                if isinstance(p_to_apply, UnionParamz):\n                    raise ValueError(\"This should not happen !\")\n                elif isinstance(p_to_apply, NormalParamz):\n                    # ******** Normal parametrization **********\n                    if _DEBUG:\n                        print(\"[Node %s] Applying parametrization for NORMAL %s\"\n                              \"\" % (current_node.to_str(with_children=False, with_discarded=False),\n                                    p_to_apply.argnames))\n\n                    calls = self._parametrize_calls(calls, p_to_apply.argnames, p_to_apply.argvalues,\n                                                    indirect=p_to_apply.indirect, ids=p_to_apply.ids,\n                                                    scope=p_to_apply.scope, **p_to_apply.kwargs)\n                else:\n                    raise TypeError(\"Invalid parametrization type: %s\" % p_to_apply.__class__)"
            ],
            [
                884,
                932,
                "            try:\n                # pop it from pending - do not trust the order in pending.\n                p_to_apply = pending.pop(current_node.split_fixture_name)\n            except KeyError:\n                # not a parametrized fixture\n                raise ValueError(\"Error: fixture union parametrization not present\")\n            else:\n                if isinstance(p_to_apply, NormalParamz):\n                    raise ValueError(\"This should not happen !\")\n                elif isinstance(p_to_apply, UnionParamz):\n                    # ******** Union parametrization **********\n                    if _DEBUG:\n                        print(\"[Node %s] Applying parametrization for UNION %s\"\n                              \"\" % (current_node.to_str(with_children=False, with_discarded=False),\n                                    p_to_apply.union_fixture_name))\n\n                    # always use 'indirect' since that's a fixture.\n                    calls = self._parametrize_calls(calls, p_to_apply.union_fixture_name,\n                                                    p_to_apply.alternative_names, indirect=True,\n                                                    ids=p_to_apply.ids,\n                                                    scope=p_to_apply.scope, **p_to_apply.kwargs)\n\n                    # Change the ids\n                    for callspec in calls:\n                        callspec._idlist[-1] = apply_id_style(callspec._idlist[-1],\n                                                              p_to_apply.union_fixture_name,\n                                                              p_to_apply.alternative_names[0].idstyle)\n\n                    # now move to the children\n                    nodes_children = [None] * len(calls)\n                    for i in range(len(calls)):\n                        active_alternative = calls[i].params[p_to_apply.union_fixture_name]\n                        child_node = current_node.children[active_alternative.fixture_name]\n                        child_pending = pending.copy()\n\n                        # place the childs parameter in the first position if it is in the list\n                        # not needed anymore - already automatic\n                        # try:\n                        #     child_pending.move_to_end(child_alternative, last=False)\n                        # except KeyError:\n                        #     # not in the list: the child alternative is a non-parametrized fixture\n                        #     pass\n\n                        calls[i], nodes_children[i] = self._process_node(child_node, child_pending, [calls[i]])\n\n                    # finally flatten the list if needed\n                    calls = flatten_list(calls)\n                    nodes_children = flatten_list(nodes_children)\n                    return calls, nodes_children"
            ],
            [
                152,
                157,
                "                    try:\n                        fixturedefs = self.get_all_fixture_defs()[arg_name]\n                    except KeyError:\n                        return get_pytest_function_scopenum()\n                    else:\n                        return fixturedefs[-1].scopenum"
            ]
        ]
    },
    {
        "blob_id": "7b56d48d91936f9449bf341f94482ffc72672cfe",
        "matched_blocks": [
            [
                22,
                49,
                "try:\n    while qp1 and qp2:\n        p1 = qp1.popleft()\n        p2 = qp2.popleft()\n        left.append(p1)\n        right.append(p2)\n        print(\"FIGHT {} {}\".format(p1, p2), file=sys.stderr)\n        if p1 < p2:\n            qp2.extend(left)\n            qp2.extend(right)\n            left, right = [], []\n        elif p1 > p2:\n            qp1.extend(left)\n            qp1.extend(right)\n            left, right = [], []\n        else:\n            for i in range(3):\n                left.append(qp1.popleft())\n                right.append(qp2.popleft())\n            rounds -= 1\n        rounds += 1\nexcept IndexError:\n    print(\"PAT\")\nelse:\n    if not qp1:\n        print(\"2 {}\".format(rounds))\n    elif not qp2:\n        print(\"1 {}\".format(rounds))"
            ]
        ]
    },
    {
        "blob_id": "c54039e3563c74b40fec240512243e72321e9c9e",
        "matched_blocks": [
            [
                161,
                178,
                "            try:\n                body = self.show_resource(\n                    stack_identifier, resource_name)\n            except lib_exc.NotFound:\n                # ignore this, as the resource may not have\n                # been created yet\n                pass\n            else:\n                resource_name = body['resource_name']\n                resource_status = body['resource_status']\n                if resource_status == status:\n                    return\n                if fail_regexp.search(resource_status):\n                    raise exceptions.StackResourceBuildErrorException(\n                        resource_name=resource_name,\n                        stack_identifier=stack_identifier,\n                        resource_status=resource_status,\n                        resource_status_reason=body['resource_status_reason'])"
            ]
        ]
    },
    {
        "blob_id": "cc1d6285ff56f4057b468f19bb729b3441e6c7cf",
        "matched_blocks": [
            [
                163,
                217,
                "    try:\n        uw_i, elbo_current = f()\n        if np.isnan(elbo_current):\n            raise FloatingPointError('NaN occurred in ADVI optimization.')\n        for i in progress:\n            uw_i, e = f()\n            if np.isnan(e):\n                raise FloatingPointError('NaN occurred in ADVI optimization.')\n            elbos[i] = e\n\n            if progressbar:\n                if n < 10:\n                    progress.set_description('ELBO = {:,.5g}'.format(elbos[i]))\n                elif i % (n // 10) == 0 and i > 0:\n                    avg_elbo = infmean(elbos[i - n // 10:i])\n                    progress.set_description(\n                        'Average ELBO = {:,.5g}'.format(avg_elbo))\n\n            if i % eval_elbo == 0:\n                elbo_prev = elbo_current\n                elbo_current = elbos[i]\n                delta_elbo = abs((elbo_current - elbo_prev) / elbo_prev)\n                circ_buff.append(delta_elbo)\n                avg_delta = np.mean(circ_buff)\n                med_delta = np.median(circ_buff)\n\n                if i > 0 and avg_delta < tol_obj:\n                    pm._log.info('Mean ELBO converged.')\n                    elbos = elbos[:(i + 1)]\n                    break\n                elif i > 0 and med_delta < tol_obj:\n                    pm._log.info('Median ELBO converged.')\n                    elbos = elbos[:(i + 1)]\n                    break\n                if i > 10 * eval_elbo:\n                    if med_delta > 0.5 or avg_delta > 0.5:\n                        divergence_flag = True\n                    else:\n                        divergence_flag = False\n\n    except KeyboardInterrupt:\n        elbos = elbos[:i]\n        if n < 10:\n            pm._log.info('Interrupted at {:,d} [{:.0f}%]: ELBO = {:,.5g}'.format(\n                i, 100 * i // n, elbos[i]))\n        else:\n            avg_elbo = infmean(elbos[i - n // 10:i])\n            pm._log.info('Interrupted at {:,d} [{:.0f}%]: Average ELBO = {:,.5g}'.format(\n                i, 100 * i // n, avg_elbo))\n    else:\n        if n < 10:\n            pm._log.info('Finished [100%]: ELBO = {:,.5g}'.format(elbos[-1]))\n        else:\n            avg_elbo = infmean(elbos[-n // 10:])\n            pm._log.info('Finished [100%]: Average ELBO = {:,.5g}'.format(avg_elbo))"
            ]
        ]
    },
    {
        "blob_id": "dc0bda40ee6af7235dfde37fb5e7a37a7803e51a",
        "matched_blocks": [
            [
                395,
                429,
                "        try:\n            environment = self.environment_func()\n        except Environment.DoesNotExist:\n            user_counts = {}\n            first_seen = {}\n            last_seen = {}\n            times_seen = {}\n        else:\n            project_id = item_list[0].project_id\n            item_ids = [g.id for g in item_list]\n            user_counts = tagstore.get_groups_user_counts(\n                [project_id],\n                item_ids,\n                environment_ids=environment and [environment.id],\n            )\n            first_seen = {}\n            last_seen = {}\n            times_seen = {}\n            if environment is not None:\n                environment_tagvalues = tagstore.get_group_list_tag_value(\n                    [project_id],\n                    item_ids,\n                    [environment.id],\n                    'environment',\n                    environment.name,\n                )\n                for item_id, value in environment_tagvalues.items():\n                    first_seen[item_id] = value.first_seen\n                    last_seen[item_id] = value.last_seen\n                    times_seen[item_id] = value.times_seen\n            else:\n                for item in item_list:\n                    first_seen[item.id] = item.first_seen\n                    last_seen[item.id] = item.last_seen\n                    times_seen[item.id] = item.times_seen"
            ],
            [
                475,
                485,
                "            try:\n                environment = self.environment_func()\n            except Environment.DoesNotExist:\n                stats = {key: tsdb.make_series(0, **query_params) for key in group_ids}\n            else:\n                stats = tsdb.get_range(\n                    model=tsdb.models.group,\n                    keys=group_ids,\n                    environment_ids=environment and [environment.id],\n                    **query_params\n                )"
            ]
        ]
    },
    {
        "blob_id": "c70d686b8a66449aa75277ec024a414043f77dab",
        "matched_blocks": [
            [
                38,
                43,
                "            try:\n                await self._agen.asend(None)\n            except StopAsyncIteration:\n                return\n            else:\n                raise RuntimeError(\"async generator didn't stop\")"
            ]
        ]
    },
    {
        "blob_id": "7054b8e03ebd9cf2acc2697f4c92af8063d91948",
        "matched_blocks": [
            [
                40,
                46,
                "            try:\n                import_module(imp_path)\n            except ImportError:\n                pass\n            else:\n                if hasattr(imp_path, cls_name):\n                    return getattr(imp_path, cls_name)"
            ]
        ]
    },
    {
        "blob_id": "8d24cc2d78f5fd39172d51acefe72ccc68acd70a",
        "matched_blocks": [
            [
                3,
                9,
                "try:\n    file = open(fp)\nexcept FileNotFoundError:\n    print(\"Error! This file path does not exist.\")\n\nelse:\n    print(file.read())"
            ]
        ]
    },
    {
        "blob_id": "c6e82fb2562a85a47b32d272b9402f780db38b47",
        "matched_blocks": [
            [
                250,
                255,
                "        try:\n            options.default_configfile()\n        except DummyExitException as e:\n            self.assertEqual(e.exitcode, 2)\n        else:\n            self.fail(\"expected exception\")"
            ],
            [
                363,
                368,
                "        try:\n            instance.read_config('filename')\n        except ValueError as e:\n            self.assertTrue(\"could not find config file\" in str(e))\n        else:\n            self.fail(\"expected exception\")"
            ],
            [
                379,
                384,
                "        try:\n            instance.read_config('filename')\n        except ValueError as e:\n            self.assertTrue(\"could not read config file\" in str(e))\n        else:\n            self.fail(\"expected exception\")"
            ],
            [
                680,
                690,
                "        try:\n            instance.realize()\n        except DummyExitException as e:\n            # Caught expected exception\n            import traceback\n            self.assertEqual(\n                e.exitcode, 2,\n                \"Wrong exitcode for: %s\" % traceback.format_exc()\n                )\n        else:\n            self.fail(\"Did not get a DummyExitException.\")"
            ],
            [
                782,
                787,
                "        try:\n            instance.read_config('filename')\n        except ValueError as e:\n            self.assertTrue(\"could not find config file\" in str(e))\n        else:\n            self.fail(\"expected exception\")"
            ],
            [
                798,
                803,
                "        try:\n            instance.read_config('filename')\n        except ValueError as e:\n            self.assertTrue(\"could not read config file\" in str(e))\n        else:\n            self.fail(\"expected exception\")"
            ],
            [
                807,
                812,
                "        try:\n            readFile('/notthere', 0, 10)\n        except ValueError as inst:\n            self.assertEqual(inst.args[0], 'FAILED')\n        else:\n            raise AssertionError(\"Didn't raise\")"
            ],
            [
                1364,
                1373,
                "        try:\n            instance.processes_from_section(config, 'program:foo', None)\n        except ValueError as e:\n            self.assertEqual(\n                str(e),\n                \"Unexpected end of key/value pairs in value \"\n                \"'KEY1=val1,KEY2=val2,KEY3' in section 'program:foo'\")\n        else:\n            self.fail('instance.processes_from_section should '\n                      'raise a ValueError')"
            ]
        ]
    },
    {
        "blob_id": "1e607f9d441198acc3026f56bf81f596458e8c7b",
        "matched_blocks": [
            [
                25,
                34,
                "        try:\n            message = pickle.loads(raw)\n        except (pickle.PickleError, KeyError):\n            response = bytes('Expected a pickled message, got ' + str(raw)[:100] + '\\n', 'utf-8')\n        else:\n            if message != 'HELLO':\n                response = pickle.dumps('Unexpected message: ' + str(message))\n            else:\n                message = ('OK', 'Happy to meet you, {}'.format(self.client_address))\n                response = pickle.dumps(message)"
            ]
        ]
    },
    {
        "blob_id": "70f0ed7ac21574985a41d088b25940614ef3cc54",
        "matched_blocks": [
            [
                210,
                219,
                "        try:\n            print(\"Creating table {}: \".format(name), end='')\n            cursor.execute(ddl)\n        except mysql.connector.Error as err:\n            if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n                print(\"already exists.\")\n            else:\n                print(err.msg)\n        else:\n            print(\"OK\")"
            ]
        ]
    },
    {
        "blob_id": "93343708920188248d56b7182815d65a56fbde02",
        "matched_blocks": [
            [
                13,
                23,
                "        try:\n            headers = {'User-Agent': 'Mozilla/5.0'}  # use mozilla as a user agent\n            response_from_requests = requests.get(self.url, headers=headers)  # get requests by url\n            response_from_requests.raise_for_status()\n        except HTTPError as http_err:\n            print(f'HTTP error occurred: {http_err}')  \n        except Exception as err:\n            print(f'Other error occurred: {err}')  \n        else:\n            print('Success!')\n            return response_from_requests"
            ]
        ]
    },
    {
        "blob_id": "b5783391683a4befcbff12e70531ab5cce2ac01b",
        "matched_blocks": [
            [
                235,
                258,
                "    try:\n        resp = c.get_page(\n            page_title,\n            space_key,\n            parent=parent_page_id,\n            additional_params={\"expand\": \"body.storage,version\"},\n        )\n    except PageNotFound:\n        page_id = None\n        page_version_id = None\n        date = current_date.isoformat()\n        rows = []\n    else:\n        page_id = resp[\"id\"]\n        page_version_id = resp[\"version\"][\"number\"] + 1\n        existing_page_content = resp[\"body\"][\"storage\"][\"value\"]\n        date = extract_date(existing_page_content)\n        rows = [\n            row for row in extract_table(existing_page_content)\n            if not (\n                row[\"product\"] == component\n                and row[\"version\"] == version\n            )\n        ]"
            ]
        ]
    },
    {
        "blob_id": "d38191fa73340cb4127b28ff81cd00de74e6b5bc",
        "matched_blocks": [
            [
                30,
                40,
                "\ttry:\n\t\tselected_choice = p.choice_set.get(pk=request.POST['choice'])\n\texcept (KeyError, Choice.DoesNotExist):\n\t\treturn render(request, 'polls/detail.html', {\n\t\t\t\t'question': p,\n\t\t\t\t'error_message': \"You didn't select a choice.\",\n\t\t\t})\n\telse:\n\t\tselected_choice.votes += 1\n\t\tselected_choice.save()\n\t\treturn HttpResponseRedirect(reverse('polls:results', args=(p.id,)))"
            ]
        ]
    },
    {
        "blob_id": "296762195d2d3d164752320bacb36364f5300f95",
        "matched_blocks": [
            [
                56,
                65,
                "    try:\n        ip = ipQueue.get(timeout)\n    except:\n        pass\n    else:\n        r = detect(ip,t,h)\n        times += 1\n        if r == True:\n            passip.append(ip)\n            printx ('\u221a   '+ip , 1)"
            ]
        ]
    },
    {
        "blob_id": "db123b88102b476b1f7aa06f89b3742fe4ef29c6",
        "matched_blocks": [
            [
                1285,
                1297,
                "            try:\n                port = support.find_unused_port()\n                f = self.loop.create_server(TestMyProto, host=None, port=port)\n                server = self.loop.run_until_complete(f)\n            except OSError as ex:\n                if ex.errno == errno.EADDRINUSE:\n                    try_count += 1\n                    self.assertGreaterEqual(5, try_count)\n                    continue\n                else:\n                    raise\n            else:\n                break"
            ],
            [
                1391,
                1398,
                "            try:\n                sock = socket.socket(family=family, type=type, proto=proto)\n                sock.setblocking(False)\n                sock.bind(address)\n            except:\n                pass\n            else:\n                break"
            ],
            [
                1721,
                1727,
                "            try:\n                self.loop.call_soon(f.cancel)\n                yield from f\n            except asyncio.CancelledError:\n                res = 'cancelled'\n            else:\n                res = None"
            ],
            [
                593,
                601,
                "                try:\n                    sock = socket.socket(family=family, type=type, proto=proto)\n                    sock.setblocking(False)\n                    self.loop.run_until_complete(\n                        self.loop.sock_connect(sock, address))\n                except:\n                    pass\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "bf3fd31d705b80ca4bc0f263d0a74d0c16901ff4",
        "matched_blocks": [
            [
                149,
                156,
                "    try:\n        value = _decode_dataclass_field(value, field)\n    except JSONDecodeException as e:\n        errors[field.name] = e.errors\n    except _MissingException:\n        missing_fields.append(field.name)\n    else:\n        return value"
            ]
        ]
    },
    {
        "blob_id": "29494c29a43d43c4bf909ceb1816cc265b8acc9c",
        "matched_blocks": [
            [
                128,
                141,
                "\ttry:\n\t\tfor xml in (future.result() for future,errq in futures):\n\t\t\t# TODO we should have a faster way to detect errors\n\t\t\tif xml is None:\n\t\t\t\t# breaking cleanly triggers else clause\n\t\t\t\t# XXX is this really shutting down executor?\n\t\t\t\traise RuntimeError('do_parse failed: xml is None')\n\t\t\tbody.append(xml)\n\texcept BaseException as e:\n\t\tlogging.critical('do_it exception: {} {}'.format(type(e), e))\n\t\tret = 1\n\telse:\n\t\ttree = etree.ElementTree(akn)\n\t\ttree.write(fout)"
            ]
        ]
    },
    {
        "blob_id": "1000b1eb88e55b5e9ec17bbfb945f943f1d05fcc",
        "matched_blocks": [
            [
                227,
                233,
                "        try:\n            history = EnsemblSpeciesHistory.objects.get(pk=pk)\n        except EnsemblSpeciesHistory.DoesNotExist:\n            return Response({ \"error\": \"Could not find species history {}\".format(pk) }, status=status.HTTP_400_BAD_REQUEST)\n        else:\n            history.alignment_status = status\n            history.save()"
            ]
        ]
    },
    {
        "blob_id": "c3e0a73a809b449462448951b684b4f5f7f8efcd",
        "matched_blocks": [
            [
                660,
                667,
                "        try:\n            checkpoint_metadata_uri = os.path.join(uri, _CHECKPOINT_METADATA_FILE_NAME)\n            metadata = pickle.loads(read_file_from_uri(checkpoint_metadata_uri))\n        except Exception:\n            pass\n        else:\n            cls = cls._get_checkpoint_type(metadata.checkpoint_type)\n            state = metadata.checkpoint_state"
            ]
        ]
    },
    {
        "blob_id": "8cd2cc4ef6bde6bb958a5160732122d1e4d5c2af",
        "matched_blocks": [
            [
                322,
                329,
                "    try:\n        um = os.umask(0)\n        os.umask(um)\n    except AttributeError:\n        pass\n    else:\n        # Turn off any bits that are set in the umask\n        mode = mode & (~um)"
            ],
            [
                91,
                102,
                "        try:\n            f = io.open(self._datfile, 'r', encoding=\"Latin-1\")\n        except OSError:\n            if flag not in ('c', 'n'):\n                import warnings\n                warnings.warn(\"The database file is missing, the \"\n                              \"semantics of the 'c' flag will be used.\",\n                              DeprecationWarning, stacklevel=4)\n            with io.open(self._datfile, 'w', encoding=\"Latin-1\") as f:\n                self._chmod(self._datfile)\n        else:\n            f.close()"
            ],
            [
                107,
                118,
                "        try:\n            f = io.open(self._dirfile, 'r', encoding=\"Latin-1\")\n        except OSError:\n            self._modified = not self._readonly\n        else:\n            self._modified = False\n            with f:\n                for line in f:\n                    line = sanitize(line.rstrip())\n                    key, pos_and_siz_pair = eval(line, globals(), locals())\n                    key = key.encode('Latin-1')\n                    self._index[key] = pos_and_siz_pair"
            ]
        ]
    },
    {
        "blob_id": "ed377733d23fb5c6cc2ea478a613ec2ca714d70f",
        "matched_blocks": [
            [
                48,
                56,
                "    try:\n        r = 100\n        # b = a -- 1\n    except Exception as e:\n        raise ValueError(\"Input valid\") from e\n    else:\n        # b = a -- 2\n        r = 200\n        return r"
            ],
            [
                59,
                68,
                "    try:\n        r = calculate()\n    except ValueError as e:\n        print(\"Calculate Error\")\n        r = 200\n    except Exception as e:\n        print(\"Exception\")\n        return\n    else:\n        r += 10"
            ]
        ]
    },
    {
        "blob_id": "da2897495af6a0514b4c1cc5803cd5a24e8c543c",
        "matched_blocks": [
            [
                15,
                23,
                "    try:\n        r = requests.get(\"http://localhost:8000/api?\")\n    except requests.exceptions.ConnectionError:\n        return False\n    else:\n        if r.status_code == 200:\n            return True\n        else:\n            return False"
            ]
        ]
    },
    {
        "blob_id": "99c4e44f477c0bac23afd0bd0105f76f1483e7d6",
        "matched_blocks": [
            [
                25,
                31,
                "            try:\n                x_img,y_img = utils.crop(imgs_lr[i], imgs_hr[i], self.image_size, self.image_size, self.scale, is_random=True)\n            except LargeSizeException as e:\n                print(e)\n            else:\n                y_imgs.append(y_img)\n                x_imgs.append(x_img)"
            ]
        ]
    },
    {
        "blob_id": "6527d9f8210bfc9c443bb7a3461c24554de58abb",
        "matched_blocks": [
            [
                24,
                30,
                "        try:\n            self.nProcesses\n        except AttributeError:\n            self.nProcesses = 1\n        else:\n            if (not self.nProcesses) or (self.nProcesses < 1):\n                self.nProcesses = 1"
            ],
            [
                56,
                74,
                "        try:\n            if hasattr(self, 'proxySecretPath'):\n                rsp = self.k8s_client.create_job_from_yaml(yaml_content, work_spec, self.proxySecretPath, True, self.cpuAdjustRatio, self.memoryAdjustRatio)\n            elif hasattr(self, 'x509UserProxy'):\n                rsp = self.k8s_client.create_job_from_yaml(yaml_content, work_spec, self.x509UserProxy, False, self.cpuAdjustRatio, self.memoryAdjustRatio)\n            else:\n                errStr = 'No proxy specified in proxySecretPath or x509UserProxy; not submitted'\n                tmpRetVal = (False, errStr)\n        except Exception as _e:\n            errStr = 'Failed to create a JOB; {0}'.format(_e)\n            tmpRetVal = (False, errStr)\n        else:\n            work_spec.batchID = yaml_content['metadata']['name']\n\n            # set the log files\n            work_spec.set_log_file('stdout', '{0}/{1}.out'.format(self.logBaseURL, work_spec.workerID))\n\n            tmp_log.debug('Created worker {0} with batchID={1}'.format(work_spec.workerID, work_spec.batchID))\n            tmpRetVal = (True, '')"
            ]
        ]
    },
    {
        "blob_id": "61937d51bfde6945241775ba8c469abe3cd44364",
        "matched_blocks": [
            [
                266,
                271,
                "    try:\n        task = Task.lookup(task_id, session=session)\n    except (TypeError, ValueError) as e:\n        raise InvalidRequest('We could not infer the Task from the given input...') from e\n    else:\n        return session, task"
            ]
        ]
    },
    {
        "blob_id": "687a25694621f2e864b8c7dc5e552473ecff1887",
        "matched_blocks": [
            [
                79,
                85,
                "            try:\n                result = self._make_pde_rhs_numba(state)\n            except NotImplementedError:\n                backend = 'numpy'\n            else:\n                result._backend = 'numba'  # type: ignore\n                return result"
            ],
            [
                196,
                202,
                "            try:\n                sde_rhs = self._make_sde_rhs_numba(state)\n            except NotImplementedError:\n                backend = 'numpy'\n            else:\n                sde_rhs._backend = 'numba'  # type: ignore\n                return sde_rhs"
            ]
        ]
    },
    {
        "blob_id": "5923edf19d7db31a20d3a49ffcc3c7c9da07fe70",
        "matched_blocks": [
            [
                212,
                222,
                "        try:\n            exec(code, self._locals)\n        except SystemExit:\n            raise\n        except Exception:\n            self.show_traceback()\n        else:\n            if self._count == self._write_count:\n                self.write(repr(self._locals[f'_{self._count}']))\n                self.write('\\n')\n                self._count += 1"
            ],
            [
                240,
                248,
                "            try:\n                msg, (dummy_filename, lineno, offset, line) = value.args\n            except ValueError:\n                # Not the format we expect; leave it alone\n                pass\n            else:\n                # Stuff in the right filename\n                value = SyntaxError(msg, (filename, lineno, offset, line))\n                sys.last_value = value"
            ],
            [
                100,
                106,
                "                    try:\n                        line = self.raw_input(ps2 if more else ps1)\n                    except EOFError:\n                        self.write('\\n')\n                        break\n                    else:\n                        more = self.push_line(line)"
            ]
        ]
    },
    {
        "blob_id": "ef666dd55a79a37dd98a1d01931f9f8bacf94013",
        "matched_blocks": [
            [
                35,
                40,
                "        try:\n            return reader()\n        except IOError:\n            return blank.release()\n        else:\n            raise BaseException('unknown error')"
            ]
        ]
    },
    {
        "blob_id": "bdc0864f9c4ea0aedad00bc68a242828c1453bd6",
        "matched_blocks": [
            [
                5073,
                5093,
                "        try:\n            variable_dict = json.loads(request.files[\"file\"].read())\n        except Exception:\n            self.update_redirect()\n            flash(\"Missing file or syntax error.\", \"error\")\n            return redirect(self.get_redirect())\n        else:\n            suc_count = fail_count = 0\n            for k, v in variable_dict.items():\n                try:\n                    models.Variable.set(k, v, serialize_json=not isinstance(v, str))\n                except Exception as e:\n                    logging.info(\"Variable import failed: %s\", repr(e))\n                    fail_count += 1\n                else:\n                    suc_count += 1\n            flash(f\"{suc_count} variable(s) successfully updated.\")\n            if fail_count:\n                flash(f\"{fail_count} variable(s) failed to be updated.\", \"error\")\n            self.update_redirect()\n            return redirect(self.get_redirect())"
            ],
            [
                4608,
                4639,
                "            try:\n                new_conn_id = next(possible_conn_id_iter)\n            except StopIteration:\n                flash(\n                    f\"Connection {new_conn_id} can't be added because it already exists, \"\n                    f\"Please rename the existing connections\",\n                    \"warning\",\n                )\n            else:\n                dup_conn = Connection(\n                    new_conn_id,\n                    selected_conn.conn_type,\n                    selected_conn.description,\n                    selected_conn.host,\n                    selected_conn.login,\n                    selected_conn.password,\n                    selected_conn.schema,\n                    selected_conn.port,\n                    selected_conn.extra,\n                )\n\n                try:\n                    session.add(dup_conn)\n                    session.commit()\n                    flash(f\"Connection {new_conn_id} added successfully.\", \"success\")\n                except IntegrityError:\n                    flash(\n                        f\"Connection {new_conn_id} can't be added. Integrity error, \"\n                        f\"probably unique constraint.\",\n                        \"warning\",\n                    )\n                    session.rollback()"
            ],
            [
                5082,
                5088,
                "                try:\n                    models.Variable.set(k, v, serialize_json=not isinstance(v, str))\n                except Exception as e:\n                    logging.info(\"Variable import failed: %s\", repr(e))\n                    fail_count += 1\n                else:\n                    suc_count += 1"
            ]
        ]
    },
    {
        "blob_id": "8bd3e7c8d668cfc74846117b6febfca47c28fc71",
        "matched_blocks": [
            [
                246,
                265,
                "        try:\n          CheckGitVersion(_HELPER_MIN)\n        except GitVersionException:\n          log.warn(textwrap.dedent(\"\"\"\\\n              You are cloning a Google-hosted repository with a version of git\n              older than 1.7.9. If you upgrade to 1.7.9 or later, gcloud can\n              handle authentication to this repository. Otherwise, to\n              authenticate, use your Google account and the password found by\n              running the following command.\n               $ gcloud auth print-refresh-token\n              \"\"\"))\n          cmd = ['git', 'clone', self._uri, abs_repository_path]\n          log.debug('Executing %s', cmd)\n          subprocess.check_call(cmd)\n        else:\n          cmd = ['git', 'clone', self._uri, abs_repository_path,\n                 '--config',\n                 'credential.helper=\"{0}\"'.format(_GetCredentialHelper())]\n          log.debug('Executing %s', cmd)\n          subprocess.check_call(cmd)"
            ]
        ]
    },
    {
        "blob_id": "2ebc00913345ca6eff36163866e6b493e6246b0d",
        "matched_blocks": [
            [
                496,
                643,
                "        try:\n            p2pkhTransaction = True\n            derivations = self.get_tx_derivations(tx)\n            inputhasharray = []\n            hasharray = []\n            pubkeyarray = []\n\n            # Build hasharray from inputs\n            for i, txin in enumerate(tx.inputs()):\n                if txin['type'] == 'coinbase':\n                    self.give_error(\"Coinbase not supported\") # should never happen\n\n                if txin['type'] != 'p2pkh':\n                    p2pkhTransaction = False\n\n                for x_pubkey in txin['x_pubkeys']:\n                    if x_pubkey in derivations:\n                        index = derivations.get(x_pubkey)\n                        inputPath = \"%s/%d/%d\" % (self.get_derivation(), index[0], index[1])\n                        inputHash = Hash(binascii.unhexlify(tx.serialize_preimage(i)))\n                        hasharray_i = {'hash': to_hexstr(inputHash), 'keypath': inputPath}\n                        hasharray.append(hasharray_i)\n                        inputhasharray.append(inputHash)\n                        break\n                else:\n                    self.give_error(\"No matching x_key for sign_transaction\") # should never happen\n\n            # Build pubkeyarray from outputs\n            for _type, address, amount in tx.outputs():\n                assert _type == TYPE_ADDRESS\n                info = tx.output_info.get(address)\n                if info is not None:\n                    index, xpubs, m = info\n                    changePath = self.get_derivation() + \"/%d/%d\" % index\n                    changePubkey = self.derive_pubkey(index[0], index[1])\n                    pubkeyarray_i = {'pubkey': changePubkey, 'keypath': changePath}\n                    pubkeyarray.append(pubkeyarray_i)\n\n            # Special serialization of the unsigned transaction for\n            # the mobile verification app.\n            # At the moment, verification only works for p2pkh transactions.\n            if p2pkhTransaction:\n                class CustomTXSerialization(Transaction):\n                    @classmethod\n                    def input_script(self, txin, estimate_size=False):\n                        if txin['type'] == 'p2pkh':\n                            return Transaction.get_preimage_script(txin)\n                        if txin['type'] == 'p2sh':\n                            # Multisig verification has partial support, but is disabled. This is the\n                            # expected serialization though, so we leave it here until we activate it.\n                            return '00' + push_script(Transaction.get_preimage_script(txin))\n                        raise Exception(\"unsupported type %s\" % txin['type'])\n                tx_dbb_serialized = CustomTXSerialization(tx.serialize()).serialize()\n            else:\n                # We only need this for the signing echo / verification.\n                tx_dbb_serialized = None\n\n            # Build sign command\n            dbb_signatures = []\n            steps = math.ceil(1.0 * len(hasharray) / self.maxInputs)\n            for step in range(int(steps)):\n                hashes = hasharray[step * self.maxInputs : (step + 1) * self.maxInputs]\n\n                msg = {\n                    \"sign\": {\n                        \"data\": hashes,\n                        \"checkpub\": pubkeyarray,\n                    },\n                }\n                if tx_dbb_serialized is not None:\n                    msg[\"sign\"][\"meta\"] = to_hexstr(Hash(tx_dbb_serialized))\n                msg = json.dumps(msg).encode('ascii')\n                dbb_client = self.plugin.get_client(self)\n\n                if not dbb_client.is_paired():\n                    raise Exception(\"Could not sign transaction.\")\n\n                reply = dbb_client.hid_send_encrypt(msg)\n                if 'error' in reply:\n                    raise Exception(reply['error']['message'])\n\n                if 'echo' not in reply:\n                    raise Exception(\"Could not sign transaction.\")\n\n                if self.plugin.is_mobile_paired() and tx_dbb_serialized is not None:\n                    reply['tx'] = tx_dbb_serialized\n                    self.plugin.comserver_post_notification(reply)\n\n                if steps > 1:\n                    self.handler.show_message(_(\"Signing large transaction. Please be patient ...\\r\\n\\r\\n\" \\\n                                                \"To continue, touch the Digital Bitbox's blinking light for 3 seconds. \" \\\n                                                \"(Touch \" + str(step + 1) + \" of \" + str(int(steps)) + \")\\r\\n\\r\\n\" \\\n                                                \"To cancel, briefly touch the blinking light or wait for the timeout.\\r\\n\\r\\n\"))\n                else:\n                    self.handler.show_message(_(\"Signing transaction ...\\r\\n\\r\\n\" \\\n                                                \"To continue, touch the Digital Bitbox's blinking light for 3 seconds.\\r\\n\\r\\n\" \\\n                                                \"To cancel, briefly touch the blinking light or wait for the timeout.\"))\n\n                # Send twice, first returns an echo for smart verification\n                reply = dbb_client.hid_send_encrypt(msg)\n                self.handler.finished()\n\n                if 'error' in reply:\n                    if reply[\"error\"].get('code') in (600, 601):\n                        # aborted via LED short touch or timeout\n                        raise UserCancelled()\n                    raise Exception(reply['error']['message'])\n\n                if 'sign' not in reply:\n                    raise Exception(\"Could not sign transaction.\")\n\n                dbb_signatures.extend(reply['sign'])\n\n            # Fill signatures\n            if len(dbb_signatures) != len(tx.inputs()):\n                raise Exception(\"Incorrect number of transactions signed.\") # Should never occur\n            for i, txin in enumerate(tx.inputs()):\n                num = txin['num_sig']\n                for pubkey in txin['pubkeys']:\n                    signatures = list(filter(None, txin['signatures']))\n                    if len(signatures) == num:\n                        break # txin is complete\n                    ii = txin['pubkeys'].index(pubkey)\n                    signed = dbb_signatures[i]\n                    if 'recid' in signed:\n                        # firmware > v2.1.1\n                        recid = int(signed['recid'], 16)\n                        s = binascii.unhexlify(signed['sig'])\n                        h = inputhasharray[i]\n                        pk = MyVerifyingKey.from_signature(s, recid, h, curve = SECP256k1)\n                        pk = to_hexstr(point_to_ser(pk.pubkey.point, True))\n                    elif 'pubkey' in signed:\n                        # firmware <= v2.1.1\n                        pk = signed['pubkey']\n                    if pk != pubkey:\n                        continue\n                    sig_r = int(signed['sig'][:64], 16)\n                    sig_s = int(signed['sig'][64:], 16)\n                    sig = sigencode_der(sig_r, sig_s, generator_secp256k1.order())\n                    txin['signatures'][ii] = to_hexstr(sig) + '01'\n                    tx._inputs[i] = txin\n        except UserCancelled:\n            raise\n        except BaseException as e:\n            self.give_error(e, True)\n        else:\n            print_error(\"Transaction is_complete\", tx.is_complete())\n            tx.raw = tx.serialize()"
            ]
        ]
    },
    {
        "blob_id": "953f9fc2f8c41cae91dcb576a328561653318abd",
        "matched_blocks": [
            [
                76,
                92,
                "        try:\n            res = f(*args, **kwargs)\n        except Exception as e:\n            data = {\"traceback\": traceback.format_exc(), \"time_used\": time.time() - start, \"error_str\": str(e)}\n            fndata.update(data)\n            fndata.update(LOGGER.extra_log)\n            LOGGER.log(\"error\", fndata)\n            LOGGER.running_stack.pop()\n            raise\n        else:\n            time_used = time.time() - start\n            LOGGING.debug(\"%s%s Time used: %3fs\" % ('>' * len(LOGGER.running_stack), f.__name__, time_used))\n            # sys.stdout.flush()\n            fndata.update({'time_used': time_used, 'ret': res})\n            fndata.update(LOGGER.extra_log)\n            LOGGER.log('function', fndata)\n            LOGGER.running_stack.pop()"
            ]
        ]
    },
    {
        "blob_id": "517883fff7511e6a85417acd48de8b4f13d37f6e",
        "matched_blocks": [
            [
                109,
                119,
                "    try:\n        db.session.delete(department)\n        db.session.commit()\n    except IntegrityError:\n        # If department has employees handle an exception.\n        flash(\"Department that has employees cannot be deleted!\", \"danger\")\n        return redirect(url_for(\"dep.show_departments\"))\n    else:\n        # Redirect to departments page with success message.\n        flash(\"Department has been deleted!\", \"success\")\n        return redirect(url_for(\"dep.show_departments\"))"
            ]
        ]
    },
    {
        "blob_id": "7d5757978edacd53d9de4f1c02e1cef27186ab02",
        "matched_blocks": [
            [
                1204,
                1218,
                "    try:\n        log.debug('Ensuring ssh config dir \"%s\" exists', ssh_dir)\n        os.makedirs(ssh_dir)\n    except OSError as exc:\n        if exc.args[1] == 'Permission denied':\n            log.error('Unable to create directory %s: '\n                      '%s', ssh_dir, exc.args[1])\n        elif exc.args[1] == 'File exists':\n            log.debug('%s already exists, no need to create '\n                      'it', ssh_dir)\n    else:\n        # set proper ownership/permissions\n        if user:\n            os.chown(ssh_dir, uinfo['uid'], uinfo['gid'])\n            os.chmod(ssh_dir, 0o700)"
            ]
        ]
    },
    {
        "blob_id": "8e3269fafdfc4c4927faaa47a88c3a3c531bf398",
        "matched_blocks": [
            [
                36,
                41,
                "try:\n    import guppy\nexcept ImportError:\n    heapy = None\nelse:\n    heapy = guppy.hpy()"
            ]
        ]
    },
    {
        "blob_id": "24f3ab7627d981bd5f64fbdca16a526d7523f8dc",
        "matched_blocks": [
            [
                1634,
                1639,
                "            try:\n                val = keyword.value.as_const(frame.eval_ctx)\n            except nodes.Impossible:\n                frame.eval_ctx.volatile = True\n            else:\n                setattr(frame.eval_ctx, keyword.key, val)"
            ]
        ]
    },
    {
        "blob_id": "9ebb3ef4090282a4cf52fcc2b5888d18b54359f9",
        "matched_blocks": [
            [
                17,
                29,
                "    try:\n        response = opener.open(someurl)\n    except URLError as e:\n        if hasattr(e, 'reason'):\n            print('We failed to reach a server.')\n            print('Reason: ', e.reason)\n        elif hasattr(e, 'code'):\n            print('The server couldn\\'t fulfill the request.')\n            print('Error code: ', e.code)\n    else:\n        # everything is fine\n        result='ok'\n        return response"
            ]
        ]
    },
    {
        "blob_id": "a6ffdda6788bd1514e29400d0d2587bcaae60373",
        "matched_blocks": [
            [
                99,
                104,
                "        try:\n            cls.get_field_by_fieldname(attr_name)\n        except ValueError:\n            pass\n        else:\n            raise ValueError(\"'%s' is already registered\" % attr_name)"
            ]
        ]
    },
    {
        "blob_id": "e06e67a41253030171445b4954509975eab675ca",
        "matched_blocks": [
            [
                86,
                92,
                "        try:\n            s.login('', '')\n        except Exception:\n            if s.getServerName() == '':\n                raise 'Error while anonymous logging into %s'\n        else:\n            s.logoff()"
            ]
        ]
    },
    {
        "blob_id": "6ef77fd9d454902d0aaf27e42aeb911605470c42",
        "matched_blocks": [
            [
                1994,
                2004,
                "                try:\n                    self.init(tdir, workdir=wd)\n                except subprocess.CalledProcessError as e:\n                    expected = os.path.join('test cases', 'failing', t, f)\n                    relwd = relpath(self.src_root, wd)\n                    if relwd != '.':\n                        expected = os.path.join(relwd, expected)\n                    expected = '\\n' + expected + ':'\n                    self.assertIn(expected, e.output)\n                else:\n                    self.fail('configure unexpectedly succeeded')"
            ]
        ]
    },
    {
        "blob_id": "24bb1c93e94a9f3ea07ca4b69095ba78a63c236d",
        "matched_blocks": [
            [
                10,
                17,
                "        try:\n            ans = self.cache[str(key)][0]\n            self.cache[str(key)][1]+=1\n            self.cache[str(key)][2] = round(time.time() * 1000000)\n        except KeyError:\n            return -1\n        else:\n            return ans"
            ]
        ]
    },
    {
        "blob_id": "449d5c2f3a0a020d0c74ca688990cf14ec87f350",
        "matched_blocks": [
            [
                13,
                97,
                "    try:\n        username = request.session['username']\n        department = request.session['department']\n    except Exception:\n        return render(request, \"index.html\")\n    else:\n        print(r'\u9996\u9875\uff0cusername: ', username, department)\n        temp = {\"username\": username, \"department\": department}\n\n        temp_myInfo = models.UserInfo.objects.filter(username=username)  # \u7528\u6237\u4fe1\u606f\n        # temp_SystemMessage = models.UserSystemMessage.objects.filter(Receiver=username)  # \u7528\u6237\u4fe1\u606f\n        temp_SystemMessage_Unread = models.UserSystemMessage.objects.filter(Receiver=username,\n                                                                            ReadingState='\u672a\u8bfb')  # \u7528\u6237\u4fe1\u606f\n        num_SystemMessage_Unread = len(temp_SystemMessage_Unread)\n\n        # \u9884\u5904\u7406\u4efb\u52a1\u5217\u8868\n        Pretreatment_not_audited = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=0, sample_review='1',\n                                                                         TissueSampleSign=0)  # \u4efb\u52a1\u672a\u5206\u914d\u4fe1\u606f\n        Pretreatment_audited = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=1, sample_review='1',\n                                                                     TissueSampleSign=0)  # \u4efb\u52a1\u5df2\u5206\u914d\u4fe1\u606f\n\n        # DNA\u63d0\u53d6\u4efb\u52a1\u5217\u8868\n        # DNA_not_audited = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=0, TissueSampleSign=1)  # \u4efb\u52a1\u672a\u5206\u914d\u4fe1\u606f\n        temp_not_Pretreatment = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=0, sample_review='1',\n                                                                      TissueSampleSign=1)  # \u4efb\u52a1\u672a\u5206\u914d\u4fe1\u606f\n        temp_Pretreatment = models.RandDSamplePretreatmentInfo.objects.filter(Next_TaskProgress_Sign=0)  # \u4efb\u52a1\u672a\u5206\u914d\u4fe1\u606f\n        DNA_not_audited = chain(temp_not_Pretreatment, temp_Pretreatment)  # \u5408\u5e76\u6240\u6709\u6570\u636e\u8868\u6570\u636e\n        # DNA_audited = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=1, TissueSampleSign=1)  # \u4efb\u52a1\u5df2\u5206\u914d\u4fe1\u606f\n        temp_not_Pretreatment_audited = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=1,\n                                                                              sample_review='1',\n                                                                              TissueSampleSign=1)  # \u4efb\u52a1\u5df2\u5206\u914d\u4fe1\u606f\n        temp_Pretreatment_audited = models.RandDSamplePretreatmentInfo.objects.filter(\n            Next_TaskProgress_Sign=1)  # \u4efb\u52a1\u5df2\u5206\u914d\u4fe1\u606f\n        DNA_audited = chain(temp_not_Pretreatment_audited, temp_Pretreatment_audited)  # \u5408\u5e76\u6240\u6709\u6570\u636e\u8868\u6570\u636e\n\n        # \u9884\u6587\u5e93\u6784\u5efa\u4efb\u52a1\u5217\u8868\n        temp_Fin_unaud = models.clinicalSampleInfo.objects.filter(contract_review=0)  # \u8d22\u52a1\u672a\u5ba1\u6838\u4fe1\u606f\n        temp_Fin_NoPass = models.clinicalSampleInfo.objects.filter(contract_review=2)  # \u8d22\u52a1\u5ba1\u6838\u4e0d\u901a\u8fc7\u4fe1\u606f\n        PreLibCon_not_audited = models.RandDSampleDNAExtractInfo.objects.filter(Next_TaskProgress_Sign=0)  # \u4efb\u52a1\u672a\u5206\u914d\u4fe1\u606f\n        PreLibCon_audited = models.RandDSampleDNAExtractInfo.objects.filter(Next_TaskProgress_Sign=1)  # \u4efb\u52a1\u5df2\u5206\u914d\u4fe1\u606f\n\n        # \u7ec8\u6587\u5e93\u6784\u5efa\u4efb\u52a1\u5217\u8868\n        FinLibCon_not_audited = models.RandDSamplePreLibConInfo.objects.filter(Next_TaskProgress_Sign=0)  # \u4efb\u52a1\u672a\u5206\u914d\u4fe1\u606f\n        FinLibCon_audited = models.RandDSamplePreLibConInfo.objects.filter(Next_TaskProgress_Sign=1)  # \u4efb\u52a1\u5df2\u5206\u914d\u4fe1\u606f\n\n        # \u4e0a\u673a\u6d4b\u5e8f\u4efb\u52a1\u5217\u8868\n        ComputerSeq_not_audited = models.RandDSampleFinLibConInfo.objects.filter(Next_TaskProgress_Sign=0)  # \u4efb\u52a1\u672a\u5206\u914d\u4fe1\u606f\n        ComputerSeq_audited = models.RandDSampleFinLibConInfo.objects.filter(Next_TaskProgress_Sign=1)  # \u4efb\u52a1\u5df2\u5206\u914d\u4fe1\u606f\n\n        # \u5176\u4ed6\u4fe1\u606f\u5217\u8868\n        # \u4efb\u52a1\u6682\u505c\u4fe1\u606f\n        temp_Pretreatment = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=2, sample_review='1')  # \u9884\u5904\u7406\u4efb\u52a1\u6682\u505c\u4fe1\u606f\n        temp_DNAExtract = models.RandDSamplePretreatmentInfo.objects.filter(Next_TaskProgress_Sign=2)  # DNA\u63d0\u53d6\u4efb\u52a1\u6682\u505c\u4fe1\u606f\n        temp_PreLibCon = models.RandDSampleDNAExtractInfo.objects.filter(Next_TaskProgress_Sign=2)  # \u9884\u6587\u5e93\u6784\u5efa\u4efb\u52a1\u6682\u505c\u4fe1\u606f\n        temp_FinLibCon = models.RandDSamplePreLibConInfo.objects.filter(Next_TaskProgress_Sign=2)  # \u7ec8\u6587\u5e93\u6784\u5efa\u4efb\u52a1\u6682\u505c\u4fe1\u606f\n        temp_SeqCom = models.RandDSampleFinLibConInfo.objects.filter(Next_TaskProgress_Sign=2)  # \u4e0a\u673a\u6d4b\u5e8f\u4efb\u52a1\u6682\u505c\u4fe1\u606f\n        temp_suspend = chain(temp_Pretreatment, temp_DNAExtract, temp_PreLibCon, temp_FinLibCon, temp_SeqCom)  # \u5408\u5e76\u6240\u6709\u6570\u636e\u8868\u6570\u636e\n        # \u4efb\u52a1\u7ec8\u6b62\u4fe1\u606f\n        # temp_stop = models.clinicalSampleInfo.objects.filter(Next_TaskProgress_Sign=3)  # \u4efb\u52a1\u7ec8\u6b62\u4fe1\u606f\n        temp_Pretreatment_stop = models.RandDSampleInfo.objects.filter(Next_TaskProgress_Sign=3 , sample_review='1')  # \u9884\u5904\u7406\u4efb\u52a1\u7ec8\u6b62\u4fe1\u606f\n        temp_DNAExtract_stop = models.RandDSamplePretreatmentInfo.objects.filter(Next_TaskProgress_Sign=3)  # DNA\u63d0\u53d6\u4efb\u52a1\u7ec8\u6b62\u4fe1\u606f\n        temp_PreLibCon_stop = models.RandDSampleDNAExtractInfo.objects.filter(Next_TaskProgress_Sign=3)  # \u9884\u6587\u5e93\u6784\u5efa\u4efb\u52a1\u7ec8\u6b62\u4fe1\u606f\n        temp_FinLibCon_stop = models.RandDSamplePreLibConInfo.objects.filter(Next_TaskProgress_Sign=3)  # \u7ec8\u6587\u5e93\u6784\u5efa\u4efb\u52a1\u7ec8\u6b62\u4fe1\u606f\n        temp_SeqCom_stop = models.RandDSampleFinLibConInfo.objects.filter(Next_TaskProgress_Sign=3)  # \u4e0a\u673a\u6d4b\u5e8f\u4efb\u52a1\u7ec8\u6b62\u4fe1\u606f\n        temp_stop = chain(temp_Pretreatment_stop, temp_DNAExtract_stop, temp_PreLibCon_stop, temp_FinLibCon_stop,\n                          temp_SeqCom_stop)  # \u5408\u5e76\u6240\u6709\u6570\u636e\u8868\u6570\u636e\n\n        return render(request, \"modelspage/RandDExperimentalTaskAssignment.html\", {\"userinfo\": temp,\n                                                                                      \"Pretreatment_not_audited\": Pretreatment_not_audited,\n                                                                                      \"Pretreatment_audited\": Pretreatment_audited,\n                                                                                      \"DNA_not_audited\": DNA_not_audited,\n                                                                                      \"DNA_audited\": DNA_audited,\n                                                                                      \"PreLibCon_not_audited\": PreLibCon_not_audited,\n                                                                                      \"PreLibCon_audited\": PreLibCon_audited,\n                                                                                      \"FinLibCon_not_audited\": FinLibCon_not_audited,\n                                                                                      \"FinLibCon_audited\": FinLibCon_audited,\n                                                                                      \"ComputerSeq_not_audited\": ComputerSeq_not_audited,\n                                                                                      \"ComputerSeq_audited\": ComputerSeq_audited,\n                                                                                      \"Fin_unaud\": temp_Fin_unaud,\n                                                                                      \"Fin_NoPass\": temp_Fin_NoPass,\n                                                                                      \"suspend\": temp_suspend,\n                                                                                      \"stop\": temp_stop,\n                                                                                      \"myInfo\": temp_myInfo,\n                                                                                       \"SystemMessage\": temp_SystemMessage_Unread,\n                                                                                       \"num_SystemMessage_Unread\": num_SystemMessage_Unread})"
            ]
        ]
    },
    {
        "blob_id": "8c28fb51601157fcd64fda227a3c3f719d5b5f4d",
        "matched_blocks": [
            [
                67,
                87,
                "        try:\n\n            assert np.all(self.valid == other.valid)\n\n            assert np.all(self.names == other.names)\n\n            assert_allclose_quantity(self.distance, other.distance)\n\n            assert_allclose_quantity(self.wav, other.wav)\n            assert_allclose_quantity(self.nu, other.nu)\n\n            assert_allclose_quantity(self.apertures, other.apertures)\n\n            assert_allclose_quantity(self.val, other.val)\n            assert_allclose_quantity(self.unc, other.unc)\n\n        except AssertionError:\n            raise\n            return False\n        else:\n            return True"
            ],
            [
                282,
                288,
                "        try:\n            hdu_apertures = hdulist['APERTURES']\n        except KeyError:\n            pass\n        else:\n            cube.apertures = u.Quantity(hdu_apertures.data['APERTURE'],\n                                        parse_unit_safe(hdu_apertures.columns[0].unit))"
            ],
            [
                297,
                304,
                "        try:\n            hdu_unc = hdulist['UNCERTAINTIES']\n        except KeyError:\n            pass\n        else:\n            cube.unc = u.Quantity(hdu_unc.data,\n                                  parse_unit_safe(hdu_unc.header['BUNIT']),\n                                  copy=False)"
            ]
        ]
    },
    {
        "blob_id": "d7eee39604fef2837377fb81e7d77c58c31765e1",
        "matched_blocks": [
            [
                20,
                26,
                "    try:\n        print(str)\n    except UnicodeEncodeError as e:\n        # print(e.reason)\n        ptStrLiterally(str)\n    else:\n        pass"
            ],
            [
                54,
                61,
                "    try:\n        html = opener.open(url).read()\n    except urllib.error.URLError as e:\n        print(url)\n        print('No response...')\n        return None\n    else:\n        return html"
            ],
            [
                66,
                81,
                "    try:\n        html = opener.open(url).read()\n        #soup = BeautifulSoup(html.decode('utf-8'))\n        soup = BeautifulSoup(html.decode('utf-8'), \"lxml\")\n        p = soup.find('input', id='watchedeps')['value']\n    except urllib.error.URLError as e:\n        print(url)\n        print('No response...')\n        return ''\n    except TypeError as e:\n        print(url)\n        print('TyepError: NoneType')\n        print('Error: the given auth string doesn\\'t match the user id')\n        return ''\n    else:\n        return p"
            ],
            [
                94,
                101,
                "    try:\n        response = opener.open(rmlink)\n    except urllib.error.URLError as e:\n        print(rmlink)\n        print('Cant erase subject %s' % subid)\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "59f898c24b7c31d0cbe76ef107a8a875644260fd",
        "matched_blocks": [
            [
                139,
                146,
                "    try:\n        frame = _get_stack_frame(stacklevel)\n    except ValueError:\n        globals = sys.__dict__\n        lineno = 1\n    else:\n        globals = frame.f_globals\n        lineno = frame.f_lineno"
            ],
            [
                148,
                153,
                "    try:\n        eframe = _get_stack_frame(emitstacklevel)\n    except ValueError:\n        eglobals = sys.__dict__\n    else:\n        eglobals = eframe.f_globals"
            ]
        ]
    },
    {
        "blob_id": "bf5bd435e7a988088a4766cefb7f99f23b7564a6",
        "matched_blocks": [
            [
                898,
                906,
                "        try:\n            main_mod = self._main_mod_cache[filename]\n        except KeyError:\n            main_mod = self._main_mod_cache[filename] = types.ModuleType(\n                        modname,\n                        doc=\"Module created for script run in IPython\")\n        else:\n            main_mod.__dict__.clear()\n            main_mod.__name__ = modname"
            ],
            [
                2639,
                2655,
                "        try:\n            # Static input transformations\n            cell = self.input_transformer_manager.transform_cell(raw_cell)\n        except SyntaxError:\n            preprocessing_exc_tuple = sys.exc_info()\n            cell = raw_cell  # cell has to exist so it can be stored/logged\n        else:\n            if len(cell.splitlines()) == 1:\n                # Dynamic transformations - only applied for single line commands\n                with self.builtin_trap:\n                    try:\n                        # use prefilter_lines to handle trailing newlines\n                        # restore trailing newline for ast.parse\n                        cell = self.prefilter_manager.prefilter_lines(cell) + '\\n'\n                    except Exception:\n                        # don't allow prefilter errors to crash IPython\n                        preprocessing_exc_tuple = sys.exc_info()"
            ],
            [
                2892,
                2915,
                "        try:\n            try:\n                self.hooks.pre_run_code_hook()\n                #rprint('Running code', repr(code_obj)) # dbg\n                exec(code_obj, self.user_global_ns, self.user_ns)\n            finally:\n                # Reset our crash handler in place\n                sys.excepthook = old_excepthook\n        except SystemExit as e:\n            if result is not None:\n                result.error_in_exec = e\n            self.showtraceback(exception_only=True)\n            warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n        except self.custom_exceptions:\n            etype, value, tb = sys.exc_info()\n            if result is not None:\n                result.error_in_exec = value\n            self.CustomTB(etype, value, tb)\n        except:\n            if result is not None:\n                result.error_in_exec = sys.exc_info()[1]\n            self.showtraceback(running_compiled_code=True)\n        else:\n            outflag = False"
            ],
            [
                3033,
                3040,
                "        try:\n            frame = sys._getframe(depth+1)\n        except ValueError:\n            # This is thrown if there aren't that many frames on the stack,\n            # e.g. if a script called run_line_magic() directly.\n            pass\n        else:\n            ns.update(frame.f_locals)"
            ],
            [
                1412,
                1436,
                "            try:\n                obj = ns[oname_head]\n            except KeyError:\n                continue\n            else:\n                for idx, part in enumerate(oname_rest):\n                    try:\n                        parent = obj\n                        # The last part is looked up in a special way to avoid\n                        # descriptor invocation as it may raise or have side\n                        # effects.\n                        if idx == len(oname_rest) - 1:\n                            obj = self._getattr_property(obj, part)\n                        else:\n                            obj = getattr(obj, part)\n                    except:\n                        # Blanket except b/c some badly implemented objects\n                        # allow __getattr__ to raise exceptions other than\n                        # AttributeError, which then crashes IPython.\n                        break\n                else:\n                    # If we finish the for loop (no break), we got all members\n                    found = True\n                    ospace = nsname\n                    break  # namespace loop"
            ],
            [
                1482,
                1507,
                "            try:\n                # `getattr(type(obj), attrname)` is not guaranteed to return\n                # `obj`, but does so for property:\n                #\n                # property.__get__(self, None, cls) -> self\n                #\n                # The universal alternative is to traverse the mro manually\n                # searching for attrname in class dicts.\n                attr = getattr(type(obj), attrname)\n            except AttributeError:\n                pass\n            else:\n                # This relies on the fact that data descriptors (with both\n                # __get__ & __set__ magic methods) take precedence over\n                # instance-level attributes:\n                #\n                #    class A(object):\n                #        @property\n                #        def foobar(self): return 123\n                #    a = A()\n                #    a.__dict__['foobar'] = 345\n                #    a.foobar  # == 123\n                #\n                # So, a property may be returned right away.\n                if isinstance(attr, property):\n                    return attr"
            ]
        ]
    },
    {
        "blob_id": "3da8f7b040ba3e4364324d6671fd5826cd2494b7",
        "matched_blocks": [
            [
                174,
                185,
                "try:\n    from .hdfs import HDFS\nexcept ImportError:\n    pass\nelse:\n    @append.register(HDFS(JSONLines),\n                     (Iterator, object, SparkDataFrame, SchemaRDD))\n    @append.register(HDFS(JSON), (list, object))\n    @append.register(HDFS(CSV), (chunks(pd.DataFrame), pd.DataFrame, object))\n    def append_spark_to_hdfs(target, source, **kwargs):\n        tmp = convert(Temp(target.subtype), source, **kwargs)\n        return append(target, tmp, **kwargs)"
            ],
            [
                148,
                163,
                "    try:\n        try:\n            df.save(tmpd, source='org.apache.spark.sql.json', mode='overwrite')\n        except AttributeError:\n            shutil.rmtree(tmpd)\n            df.toJSON().saveAsTextFile(tmpd)\n    except:\n        raise\n    else:\n        files = glob.glob(os.path.join(tmpd, pattern))\n        with open(js.path, mode='ab') as f:\n            pipe(files,\n                 map(curry(chunk_file, chunksize=chunksize)),\n                 concat,\n                 map(f.write),\n                 toolz.count)"
            ]
        ]
    },
    {
        "blob_id": "fe8c1b110597c61d4d0d0cf4df44e625ada09bf3",
        "matched_blocks": [
            [
                8,
                13,
                "    try:\n        float(n)\n    except ValueError:\n        return False\n    else:\n        return float(n).is_integer()"
            ]
        ]
    },
    {
        "blob_id": "cb20e9e52b32e9c6326a763015d867ba85acb885",
        "matched_blocks": [
            [
                117,
                167,
                "        try:\n            self._src(*self._callable_args, **self._callable_kw)\n        except BaseException as e:\n            if isinstance(exc, string_types):\n                msg = exc\n                exc = type(e)\n\n            err = text_type(e)\n\n            if isinstance(exc, type) and issubclass(exc, BaseException):\n                if not isinstance(e, exc):\n                    raise AssertionError(\n                        '%r should raise %r, but raised %r:\\nORIGINAL EXCEPTION:\\n\\n%s' % (\n                            self._src, exc, e.__class__, traceback.format_exc(e)))\n\n                if isinstance(msg, string_types) and msg not in err:\n                    raise AssertionError('''\n                    %r raised %s, but the exception message does not\n                    match.\\n\\nEXPECTED:\\n%s\\n\\nGOT:\\n%s'''.strip() % (\n                            self._src,\n                            type(e).__name__,\n                            msg, err))\n\n            elif isinstance(msg, string_types) and msg not in err:\n                raise AssertionError(\n                    'When calling %r the exception message does not match. ' \\\n                    'Expected: %r\\n got:\\n %r' % (self._src, msg, err))\n\n            else:\n                raise e\n        else:\n            if inspect.isbuiltin(self._src):\n                _src_filename = '<built-in function>'\n            else:\n                _src_filename = _get_file_name(self._src)\n\n            if inspect.isfunction(self._src):\n                _src_lineno = _get_line_number(self._src)\n                raise AssertionError(\n                    'calling function %s(%s at line: \"%d\") with args %r and kwargs %r did not raise %r' % (\n                        self._src.__name__,\n                        _src_filename, _src_lineno,\n                        self._callable_args,\n                        self._callable_kw, exc))\n            else:\n                raise AssertionError(\n                    'at %s:\\ncalling %s() with args %r and kwargs %r did not raise %r' % (\n                        _src_filename,\n                        self._src.__name__,\n                        self._callable_args,\n                        self._callable_kw, exc))"
            ]
        ]
    },
    {
        "blob_id": "e6df5acf08fd8bbbf178c132ccb74291ca5e33b8",
        "matched_blocks": [
            [
                45,
                58,
                "        try:\n            self.driver.find_element_by_id(\"kw\").send_keys(testData)\n            self.driver.find_element_by_id(\"su\").click()\n            time.sleep(5)\n            self.assertTrue(expetData in self.driver.page_source)\n        except NoSuchElementException as e:\n            logging.error(\"\u9875\u9762\u627e\u4e0d\u5230\uff01\")\n        except AssertionError as e:\n            logging.info(\"\u65ad\u8a00\u5931\u8d25\uff01\")\n            db_data.insert_res(table,\"\u65ad\u8a00\u5931\u8d25\",testData)\n        except Exception as e:\n            logging.error(\"\u5176\u4ed6\u9519\u8bef\uff01\")\n        else:\n            db_data.insert_res(table,\"\u6210\u529f\",testData)"
            ]
        ]
    },
    {
        "blob_id": "cfe1529bc693ee2e40c16353569104d031c8bcae",
        "matched_blocks": [
            [
                145,
                188,
                "        try:\n            snmp_value1, snmp_value2, snmp_uptime_value, \\\n                snmp_error = get_snmp(\n                    DEVICE_IP,\n                    DEVICE_SNMP,\n                    aggr_interface.interface_oids[0],\n                    aggr_interface.interface_oids[1],\n                    DEVICE_UPTIME_OID\n                )\n        except Exception as error:\n            if not snmp_error:\n                snmp_error = str(error)\n            if snmp_error:\n                logger.warning(\"Error retrieving SNMP data\", snmp_error)\n                break\n        else:\n            # Total the value of our 2 interfaces\n            snmp_value = snmp_value1 + snmp_value2\n\n            # Add the raw SNMP data to a list\n            if len(aggr_interface.snmp_data) == 0:                # first time through, initialize the list\n                aggr_interface.snmp_data = [SNMPDatapoint(snmp_value, snmp_uptime_value)]\n            else:\n                aggr_interface.snmp_data.append(SNMPDatapoint(snmp_value, snmp_uptime_value))\n            # If we already have the max number of datapoints in our list, delete the oldest item\n            if len(aggr_interface.snmp_data) >= MAX_DATAPOINTS:\n                del(aggr_interface.snmp_data[0])\n\n            # If we have at least 2 samples, calculate bps by comparing the last item with the second to last item\n            if len(aggr_interface.snmp_data) > 1:\n                bps = calculate_bps(\n                    aggr_interface.snmp_data[-1].value,\n                    aggr_interface.snmp_data[-1].timeticks,\n                    aggr_interface.snmp_data[-2].value,\n                    aggr_interface.snmp_data[-2].timeticks\n                )\n                bps = round(bps, 2)\n                if len(aggr_interface.datapoints) == 0:\n                    aggr_interface.datapoints = [{\"title\": time_x_axis, \"value\": bps}]\n                else:\n                    aggr_interface.datapoints.append({\"title\": time_x_axis, \"value\": bps})\n                # If we already have the max number of datapoints, delete the oldest item.\n                if len(aggr_interface.datapoints) >= MAX_DATAPOINTS:\n                    del(aggr_interface.datapoints[0])"
            ]
        ]
    },
    {
        "blob_id": "0d307cf1b2d2df910db56e7f5bfb1b8f8f5ab2a4",
        "matched_blocks": [
            [
                77,
                92,
                "\ttry:\n\t\toutput, result = service.call('OpenSession', 'sv',\n\t\t\tALGORITHM_DH,\n\t\t\t('ay', int_to_bytes(session.my_public_key)))\n\texcept DBusErrorResponse as resp:\n\t\tif resp.name != DBUS_NOT_SUPPORTED:\n\t\t\traise\n\t\toutput, result = service.call('OpenSession', 'sv',\n\t\t\tALGORITHM_PLAIN,\n\t\t\t('s', ''))\n\t\tsession.encrypted = False\n\telse:\n\t\tsignature, value = output\n\t\tassert signature == 'ay'\n\t\tkey = int_from_bytes(value, 'big')\n\t\tsession.set_server_public_key(key)"
            ]
        ]
    },
    {
        "blob_id": "9df82940e19f038b7e3d640228efb7fbca2b4f1d",
        "matched_blocks": [
            [
                656,
                662,
                "    try:\n        root = context.root.getroot()\n    except AttributeError:\n        root = context.root\n        path = 'Q{%s}root()' % XPATH_FUNCTIONS_NAMESPACE\n    else:\n        path = '/%s' % root.tag"
            ],
            [
                919,
                924,
                "    try:\n        root = etree.XML(arg)\n    except etree.ParseError:\n        raise self.error('FODC0006')\n    else:\n        return etree.ElementTree(root)"
            ],
            [
                976,
                992,
                "                    try:\n                        character = e.attrib['character']\n                        if character in character_map:\n                            msg = 'duplicate character {!r} in character map'\n                            raise self.error('SEPM0018', msg.format(character))\n                        elif len(character) != 1:\n                            msg = 'invalid character {!r} in character map'\n                            raise self.error('SEPM0017', msg.format(character))\n\n                        character_map[character] = e.attrib['map-string']\n                    except KeyError as key:\n                        msg = \"missing {} in character map\"\n                        raise self.error('SEPM0017', msg.format(key)) from None\n                    else:\n                        if len(e.attrib) > 2:\n                            msg = \"invalid attribute in character map\"\n                            raise self.error('SEPM0017', msg)"
            ]
        ]
    },
    {
        "blob_id": "b446552ec7fe43cb5cdf9f8fa0e44c6adc24421a",
        "matched_blocks": [
            [
                535,
                540,
                "                try:\n                    product = Product.objects.get(pk=id)\n                except Product.DoesNotExist:\n                    continue\n                else:\n                    product.delete()"
            ]
        ]
    },
    {
        "blob_id": "f7876ee7e8a2e78ce0603729c772cba69f9f259d",
        "matched_blocks": [
            [
                35,
                43,
                "        try:\n            self.assertEqual(excepted, res)\n        except AssertionError as e:\n            # \u5728excel\u4e2d\u5199\u5165\u7528\u4f8b\u672a\u901a\u8fc7\n            self.excel.write_data(row=row, column=5, value=\"\u672a\u901a\u8fc7\")\n            raise e\n        else:\n            # \u5728excel\u4e2d\u5199\u5165\u7528\u4f8b\u901a\u8fc7\n            self.excel.write_data(row=row, column=5, value=\"\u901a\u8fc7\")"
            ],
            [
                65,
                73,
                "        try:\n            self.assertEqual(expected, res)\n        except AssertionError as e:\n            # \u5728excel\u4e2d\u5199\u5165\u7528\u4f8b\u672a\u901a\u8fc7\n            self.excel.write_data(row=row, column=5, value=\"\u672a\u901a\u8fc7\")\n            raise e\n        else:\n            # \u5728excel\u4e2d\u5199\u5165\u7528\u4f8b\u901a\u8fc7\n            self.excel.write_data(row=row, column=5, value=\"\u901a\u8fc7\")"
            ]
        ]
    },
    {
        "blob_id": "48f45b897c9bf17861962bc4ebf47143512923ef",
        "matched_blocks": [
            [
                29,
                35,
                "            try:\n                re = str(connect_or_obj.recv(1024), encoding=\"utf-8\")\n            except Exception as E:\n                inputs.remove(connect_or_obj)\n            else:\n                outputs.append(connect_or_obj)\n                message_dict[connect_or_obj] = re"
            ]
        ]
    },
    {
        "blob_id": "a1c37246801a248634486d255bc85009de21e17f",
        "matched_blocks": [
            [
                13,
                21,
                "        try:\n            high = int(row[4])\n            low = int(row[5])\n        except ValueError:\n            print(f\"Missing data for {current_date}\")\n        else:\n            dates.append(current_date)\n            highs.append(high)\n            lows.append(low)"
            ]
        ]
    },
    {
        "blob_id": "86d0e6e37de3946d0f3878e66ac69260e56559a0",
        "matched_blocks": [
            [
                185,
                192,
                "                try:\n                    val.shape = shape\n                except AttributeError:\n                    for val2 in reshaped:\n                        val2.shape = oldshape\n                    raise\n                else:\n                    reshaped.append(val)"
            ]
        ]
    },
    {
        "blob_id": "f2feb405e30d488e8504655bfb0a35ae18301a73",
        "matched_blocks": [
            [
                2364,
                2381,
                "        try:\n            guest.set_user_password(user, new_pass)\n        except libvirt.libvirtError as ex:\n            error_code = ex.get_error_code()\n            if error_code == libvirt.VIR_ERR_AGENT_UNRESPONSIVE:\n                LOG.debug('Failed to set password: QEMU agent unresponsive',\n                          instance_uuid=instance.uuid)\n                raise NotImplementedError()\n\n            err_msg = encodeutils.exception_to_unicode(ex)\n            msg = (_('Error from libvirt while set password for username '\n                     '\"%(user)s\": [Error Code %(error_code)s] %(ex)s')\n                   % {'user': user, 'error_code': error_code, 'ex': err_msg})\n            raise exception.InternalError(msg)\n        else:\n            # Save the password in sysmeta so it may be retrieved from the\n            # metadata service.\n            self._save_instance_password_if_sshkey_present(instance, new_pass)"
            ]
        ]
    },
    {
        "blob_id": "adeb4d8d9b7c8c0f7e2e9121da5970cdbd71f27c",
        "matched_blocks": [
            [
                140,
                172,
                "        try:\n\n            self._cursor.execute(sql, params)\n\n            rowcount = self._cursor.rowcount\n            if rowcount >= 0:\n                pmnc.log.info(\"<< OK, {0:d} record(s)\".format(rowcount))\n                if self._cursor.description and rowcount > 0:\n                    column_names = [ t[0].decode(\"ascii\") for t in self._cursor.description ]\n                    for record in self._cursor.fetchall():\n                        records.append(dict(zip(column_names, record)))\n            else:\n                pmnc.log.info(\"<< OK\")\n\n        except ProgrammingError as e:\n            try:\n                level, state, message = map(self._decode_message, e.args)\n            except:\n                state, message = \"PG800\", str(e)\n            state = state.upper()\n            pmnc.log.warning(\"<< {0:s}{1:s} !! PostgreSQL_Error(\\\"[{2:s}] {3:s}\\\") in {4:s}\".\\\n                             format(sql, \" -- ({0:s})\".format(param_list)\n                                    if param_list else \"\", state, message, trace_string()))\n            SQLResourceError.rethrow(\n                    state = state, description = message, # note that there is no code\n                    recoverable = True, terminal = state[:2] not in self._safe_states)\n        except:\n            pmnc.log.warning(\"<< {0:s}{1:s} !! {2:s}\".\\\n                             format(sql, \" -- ({0:s})\".format(param_list)\n                                    if param_list else \"\", exc_string()))\n            ResourceError.rethrow(recoverable = True)\n        else:\n            return records"
            ],
            [
                622,
                628,
                "        try:\n            pmnc.transaction.postgresql_1.execute(\"SELECT 1/0\")\n        except SQLResourceError as e:\n            assert e.code is None and e.state == \"22012\" and e.description == \"division by zero\"\n            assert e.recoverable and not e.terminal\n        else:\n            assert False"
            ],
            [
                633,
                644,
                "        try:\n            pmnc.transaction.postgresql_1.execute(\n                \"CREATE TABLE {t} (id int PRIMARY KEY)\".format(t = t),\n                \"INSERT INTO {t} VALUES ({{id}})\".format(t = t),\n                \"INSERT INTO {t} VALUES ({{id}})\".format(t = t),\n                id = 123)\n        except SQLResourceError as e:\n            assert e.code is None and e.state == \"23505\"\n            assert e.description.startswith(\"duplicate key value violates unique constraint\")\n            assert e.recoverable and not e.terminal\n        else:\n            assert False"
            ],
            [
                647,
                654,
                "        try:\n            pmnc.transaction.postgresql_1.execute(\"DROP TABLE {t}\".format(t = t))\n        except SQLResourceError as e:\n            assert e.code is None and e.state == \"42P01\"\n            assert e.description == \"table \\\"{0:s}\\\" does not exist\".format(t)\n            assert e.recoverable and not e.terminal\n        else:\n            assert False"
            ],
            [
                668,
                674,
                "        try:\n            test_type(\"time\", \"01:23:45\")\n        except ResourceError as e:\n            assert e.code is None and e.description == \"type time cannot be converted\"\n            assert not e.recoverable and e.terminal\n        else:\n            assert False"
            ],
            [
                368,
                374,
                "            try:\n                result = f(r, *args)\n            except:\n                r.rollback()\n                raise\n            else:\n                r.commit()"
            ],
            [
                444,
                450,
                "            try:\n                test_value(\"int4\", 2**31)\n            except SQLResourceError as e:\n                assert e.code is None and e.state == \"22003\" and e.description == \"integer out of range\"\n                assert e.recoverable and not e.terminal\n            else:\n                assert False"
            ],
            [
                453,
                459,
                "            try:\n                test_value(\"int4\", -2**31-1)\n            except SQLResourceError as e:\n                assert e.code is None and e.state == \"22003\" and e.description == \"integer out of range\"\n                assert e.recoverable and not e.terminal\n            else:\n                assert False"
            ],
            [
                595,
                601,
                "            try:\n                test_value(\"varchar[]\", [])\n            except SQLResourceError as e:\n                assert e.code is None and e.state == \"PG800\" and e.description == \"array has no values\"\n                assert e.recoverable and e.terminal\n            else:\n                assert False"
            ],
            [
                603,
                609,
                "            try:\n                test_value(\"varchar[]\", [ \"foo\", 123 ])\n            except SQLResourceError as e:\n                assert e.code is None and e.state == \"PG800\" and e.description == \"not all array elements are of type <class 'str'>\"\n                assert e.recoverable and e.terminal\n            else:\n                assert False"
            ]
        ]
    },
    {
        "blob_id": "de3ede33893ef62c5053251e487b7395c41e99a2",
        "matched_blocks": [
            [
                51,
                77,
                "        try:\n            #password_manager = urllib2.HTTPPasswordMgrWithDefaultRealm()\n            #password_manager.add_password(None, self.url, self.auth[0], self.auth[1])\n\n            #auth = urllib2.HTTPBasicAuthHandler(password_manager) # create an authentication handler\n            #opener = urllib2.build_opener(auth) # create an opener with the authentication handler\n            #urllib2.install_opener(opener) # install the opener...\n            start_time=time.time()\n            req = urllib2.Request(self.url+\".\"+sub, payload, self.headers)\n            handler = urllib2.urlopen(req, timeout=self.timeout)\n        except urllib2.HTTPError as e:\n            if e.code == 400: # or e.code==500:\n                response = handler.read() if handler else \"\"\n                log.error('Failed to push data to %s, error code %d, error message: %s', self.url+\".\"+sub, e.code, response)\n                raise MessageInvalidError()\n            else:  # 500 or other error\n                log.error('Failed to push data to %s, error code %d', self.url+\".\"+sub, e.code)\n                raise RemoteServerError()\n        except urllib2.URLError as e:\n            log.error(\"spent %d second to push %d bytes\",\n                      time.time()-start_time, len(payload))\n            raise Exception(\"Failed to push data to %s, HTTP error: %s\" % (self.url+\".\"+sub, e.args))\n        else:\n            # 200\n            response = handler.read()\n            log.debug(\"response %d %s\", handler.code, response)\n            handler.close()"
            ]
        ]
    },
    {
        "blob_id": "1476a08e4cc839c82fff0b0b997018ff4664d677",
        "matched_blocks": [
            [
                65,
                110,
                "    try:\n\n        db_connection = mysql.connector.connect(\n        host= \"localhost\",\n        user= \"root\",\n        passwd= \"\",\n        database=\"db_finkargo_daag\"\n        )\n    except mysql.connector.Error as err:\n        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n            return \"Usuario o clave incorrectos\", 405\n        else:\n            return \"No se pudo conectar al servidor\", 500\n    else:\n            cursor = db_connection.cursor()\n            cursor.execute(\"CREATE TABLE IF NOT EXISTS `usuarios` (`id` INT AUTO_INCREMENT PRIMARY KEY,`Nombres` VARCHAR(20), `Apellidos` VARCHAR(20),\"\n                \"`Edad` int(3), `Nacionalidad` VARCHAR(20))\")\n\n            if request.method == 'GET':\n                cursor.execute(\"SELECT * FROM usuarios\")\n                row_headers=[x[0] for x in cursor.description]\n                myresult = cursor.fetchall()\n                response = []\n                for x in myresult:\n                    response.append(dict(zip(row_headers,x)))\n                return jsonify(response)\n            if request.method == 'POST':   \n                if not request.is_json:\n                    return jsonify({\"errorMessage\": \"No se encontr\u00f3 objeto JSON en la solicitud\"}), 400\n                data =  request.data\n                r_nombres = request.json['Nombres']\n                r_apellidos = request.json['Apellidos']\n                r_edad = request.json['Edad']\n                r_nacionalidad = request.json['Nacionalidad']\n                \n                sql = \"insert into usuarios (Nombres, Apellidos, Edad, Nacionalidad) values ('%s', '%s','%d','%s')\" %(r_nombres, r_apellidos, r_edad, r_nacionalidad)\n\n                try:\n\n                        cursor.execute(sql)\n                        db_connection.commit()\n                    \n                except (MySQLdb.Error, MySQLdb.Warning) as e:\n                    db_connection.rollback()\n                    return e,400  \n                return \"Proceso realizado con exito\" "
            ],
            [
                117,
                158,
                "    try:\n\n        db_connection = mysql.connector.connect(\n        host= \"localhost\",\n        user= \"root\",\n        passwd= \"\",\n        database=\"db_finkargo_daag\"\n        )\n    except mysql.connector.Error as err:\n        if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n            return \"Usuario o clave incorrectos\", 405\n        else:\n            return \"No se pudo conectar al servidor\", 500\n    else:\n            cursor = db_connection.cursor()\n            cursor.execute(\"CREATE TABLE IF NOT EXISTS `usuarios` (`id` INT AUTO_INCREMENT PRIMARY KEY,`Nombres` VARCHAR(20), `Apellidos` VARCHAR(20),\"\n                \"`Edad` int(3), `Nacionalidad` VARCHAR(20))\")\n\n            if request.method == 'PUT':\n                if not request.is_json:\n                    return jsonify({\"errorMessage\": \"No se encontr\u00f3 objeto JSON en la solicitud\"}), 400\n                r_nombres = request.json['Nombres']\n                r_apellidos = request.json['Apellidos']\n                r_edad = request.json['Edad']\n                r_nacionalidad = request.json['Nacionalidad']\n\n                try:\n                    cursor.execute(\"UPDATE usuarios SET Nombres=%s,Apellidos=%s,Edad=%s,Nacionalidad=%s WHERE id=%s\",(r_nombres,r_apellidos,r_edad,r_nacionalidad,id))\n                    db_connection.commit()\n                except:\n                    db_connection.rollback()\n                    return \"error en la solicitud\",400  \n                return \"Proceso realizado con exito\" \n            if request.method == 'DELETE':   \n                try:\n                    cursor.execute(\"DELETE FROM usuarios WHERE id = '\"+id+\"'\")\n                    db_connection.commit()\n                    \n                except (MySQLdb.Error, MySQLdb.Warning) as e:\n                    db_connection.rollback()\n                    return e,400  \n                return \"Proceso realizado con exito\"         "
            ]
        ]
    },
    {
        "blob_id": "fed90f6926dd100b6713610ba1b01e6bcdb8133f",
        "matched_blocks": [
            [
                284,
                301,
                "            try:\n                self.start_node(i, extra_args, stderr=log_stderr, *args, **kwargs)\n                self.stop_node(i)\n            except Exception as e:\n                assert 'squorumd exited' in str(e)  # node must have shutdown\n                self.nodes[i].running = False\n                self.nodes[i].process = None\n                if expected_msg is not None:\n                    log_stderr.seek(0)\n                    stderr = log_stderr.read().decode('utf-8')\n                    if expected_msg not in stderr:\n                        raise AssertionError(\"Expected error \\\"\" + expected_msg + \"\\\" not found in:\\n\" + stderr)\n            else:\n                if expected_msg is None:\n                    assert_msg = \"squorumd should have exited with an error\"\n                else:\n                    assert_msg = \"squorumd should have exited with expected error \" + expected_msg\n                raise AssertionError(assert_msg)"
            ]
        ]
    },
    {
        "blob_id": "927b2fe90bc09f83f8e059e2b52cb49cb5721c15",
        "matched_blocks": [
            [
                72,
                85,
                "        try:\n            response = table.get_item(\n                Key={\n                    'email': self.email\n                }\n            )\n        except ClientError as e:\n            print(e.response['Error']['Message'])\n        else:\n            user = response['Item']\n            print(\"Get user succeeded:\")\n            print(user)\n            provided_password = user.get('password')\n            return verify_password(provided_password, self.password)"
            ]
        ]
    },
    {
        "blob_id": "bf342befc93f6e874f5a82c83db670ea0dcd7f9b",
        "matched_blocks": [
            [
                240,
                255,
                "    try:\n        # Explicitly open/close file to avoid ResourceWarning when\n        # tests are run in debug mode Python 3.\n        tmp = open(os.devnull, 'w')\n        p = sp.Popen([\"gcc\", \"-print-multiarch\"], stdout=sp.PIPE,\n                stderr=tmp)\n    except (OSError, DistutilsError):\n        # OSError if gcc is not installed, or SandboxViolation (DistutilsError\n        # subclass) if an old setuptools bug is triggered (see gh-3160).\n        pass\n    else:\n        triplet = str(p.communicate()[0].decode().strip())\n        if p.returncode == 0:\n            # gcc supports the \"-print-multiarch\" option\n            default_x11_lib_dirs += [os.path.join(\"/usr/lib/\", triplet)]\n            default_lib_dirs += [os.path.join(\"/usr/lib/\", triplet)]"
            ],
            [
                281,
                289,
                "    try:\n        f = __file__\n    except NameError:\n        f = sys.argv[0]\n    else:\n        sysfile = os.path.join(os.path.split(os.path.abspath(f))[0],\n                               fname)\n        if os.path.isfile(sysfile):\n            filenames.append(sysfile)"
            ],
            [
                293,
                300,
                "    try:\n        f = os.path.expanduser('~')\n    except KeyError:\n        pass\n    else:\n        user_file = os.path.join(f, fname)\n        if os.path.isfile(user_file):\n            filenames.append(user_file)"
            ]
        ]
    },
    {
        "blob_id": "32deaed41a4e6581445f42876563cf802299ebe7",
        "matched_blocks": [
            [
                17,
                22,
                "        try:\n            x = yield\n        except DemoException:  # \u7279\u522b\u5904\u7406DemoException\u5f02\u5e38\n            print('*** DemoExceptiion handled. Continuing...')\n        else:  # \u5982\u679c\u6ca1\u6709\u5f02\u5e38,\u90a3\u4e48\u663e\u793a\u63a5\u53d7\u5230\u7684\u503c\n            print('-> coroutine received: {!r}'.format(x))"
            ]
        ]
    },
    {
        "blob_id": "5570b7f2b7f760b10e2f1f04b14e793a57114f75",
        "matched_blocks": [
            [
                16,
                30,
                "try:\n    f = open(args.filename)\n    limit = args.limit\nexcept FileNotFoundError as err:\n    print(f\"Error: {err}\")\nelse:\n    with f:\n        lines = f.readlines()\n        lines.reverse()\n\n        if args.limit:\n            lines = lines[:limit]\n\n        for line in lines:\n            print(line.strip()[::-1])"
            ]
        ]
    },
    {
        "blob_id": "0cb367809e325a0dd6c531f0d61a66a4ad15a1a6",
        "matched_blocks": [
            [
                251,
                256,
                "        try:\n            obj = self.get_query_set().filter(pk=obj.pk)[0]\n        except IndexError:\n            pass\n        else:\n            self.save(obj)"
            ]
        ]
    },
    {
        "blob_id": "3024ec90b32cad54c5e971139ce41b32e6777f5b",
        "matched_blocks": [
            [
                200,
                233,
                "    try:\n        plan_res = one_shot_grasp_with_object_pose(req.object_name, req.object_scale, req.object_pose1, req.object_pose2)\n    except:\n        rospy.logerr(\"Grasp plan failed.\")\n        # plan is unsuccessful at some point\n        response.result = response.FAILURE\n    else:\n        # plan is successful\n        rospy.loginfo(\"Grasp plan successfully generated.\")\n        response.pre_grasp_trajectory = plan_res['pre_grasp_trajectory']\n        response.pre_to_grasp_trajectory = plan_res['pre_to_grasp_trajectory']\n        response.post_grasp_trajectory = plan_res['post_grasp_trajectory']\n        response.place_trajectory = plan_res['place_trajectory']\n        response.post_place_trajectory = plan_res['post_place_trajectory']\n        response.reset_trajectory = plan_res['reset_trajectory']\n\n        response.result = response.SUCCESS\n        rospy.loginfo(\"Start executing grasp plan...\")\n        exp_stage = rospy.get_param('stage')\n        gripper_success = execute_plan_close_loop_with_pub(arm_cmd_pub, gripper_cmd_pub, plan_res)\n\n        # if exp_stage == 'sim':\n        #     print('in sim stage, using publisher...')\n        #     gripper_success = execute_plan_close_loop_with_pub(arm_cmd_pub, gripper_cmd_pub, plan_res)\n        # else:\n        #     print('in real stage, using moveit...')\n        #     gripper_success = execute_plan_close_loop_with_moveit(arm_cmd_pub, gripper_cmd_pub, plan_res)\n\n\n        rospy.loginfo(\"motion planning: end of execution.\")\n        # publish update to map\n        publish_pcd()\n        if not gripper_success:\n            response.result = response.FAILURE"
            ]
        ]
    },
    {
        "blob_id": "13b774da8dcc15f01c6f64b8aa5c47de5f569201",
        "matched_blocks": [
            [
                50,
                61,
                "        try:\n            self.assertEqual(expected[\"status\"], res[\"status\"])\n            self.assertEqual(expected[\"code\"], res[\"code\"])\n            self.assertEqual(expected[\"message\"], res[\"message\"])\n        except AssertionError as e:\n            handle_logs.log.error(\"\u7528\u4f8b\u6267\u884c\u5931\u8d25\uff0c\u8bb0\u5f55\u4fe1\u606f\u4e3a-----{}-----\".format(items['title']))\n            handle_logs.log.error(e)\n            self.case_file.write_case(row=case_id, coulmn=8, value=\"\u5931\u8d25\")\n            raise e\n        else:\n            handle_logs.log.info(\"\u7528\u4f8b\u6267\u884c\u6210\u529f\uff0c\u8bb0\u5f55\u4fe1\u606f\u4e3a-----{}-----\".format(items['title']))\n            self.case_file.write_case(row=case_id, coulmn=8, value=\"\u6210\u529f\")"
            ]
        ]
    },
    {
        "blob_id": "1d3287d8a34d94ce7427dfb2d6ddfe8b151a409f",
        "matched_blocks": [
            [
                230,
                238,
                "            try:\n                self.template = self.environment.get_template(try_name)\n            except (TemplateNotFound, IOError):\n                pass\n            except Exception as e:\n                self.log.warn(\"Unexpected exception loading template: %s\", try_name, exc_info=True)\n            else:\n                self.log.info(\"Loaded template %s\", try_name)\n                break"
            ]
        ]
    },
    {
        "blob_id": "44f6e5b18d17003a26d61b4f72c2690406caa75e",
        "matched_blocks": [
            [
                247,
                255,
                "            try:\n                res = cursor.execute(sql, params or ())\n            except Exception as exc:\n                logger.exception('%s %s', sql, params)\n                if self.sql_error_handler(exc, sql, params, require_commit):\n                    raise\n            else:\n                if require_commit and self.get_autocommit():\n                    self.commit()"
            ]
        ]
    },
    {
        "blob_id": "626a8f3efe3c44a285bd894dcf720fe9a98984aa",
        "matched_blocks": [
            [
                37,
                48,
                "        try:\n            position = self.portfolio_handler.portfolio.positions[symbol]\n        except:\n            pass\n        else:\n            position_dict[\"quantity\"] = position.quantity\n            position_dict[\"unavailable_quantity\"] = position.unavailable_quantity\n            position_dict[\"available_quantity\"] = position.available_quantity\n            position_dict[\"price\"] = position.price\n            position_dict[\"total_commission\"] = position.total_commission\n            position_dict[\"avg_price\"] = position.avg_price\n            position_dict[\"market_value\"] = position.market_value"
            ]
        ]
    },
    {
        "blob_id": "58cd0a58d5ad34a28e3243417f03cf2c8feb4c52",
        "matched_blocks": [
            [
                25,
                32,
                "    try:\n        f = open(path, 'r')\n    except Exception:\n        return None\n    else:\n        for line in f:\n            one_list += line.rstrip().split(\" \")[1:]\n        f.close()"
            ]
        ]
    },
    {
        "blob_id": "45169fb537049eede06dc686a275a83ebe9d324d",
        "matched_blocks": [
            [
                139,
                149,
                "\t\t\t\ttry: \n\t\t\t\t\tuser.init()\n\t\t\t\texcept api.CaptchaNeeded:\n\t\t\t\t\tuser.vk.captchaChallenge()\n\t\t\t\texcept:\n\t\t\t\t\tcrashLog(\"iq.user.init\")\n\t\t\t\t\tresult = iqBuildError(iq, xmpp.ERR_BAD_REQUEST, _(\"Initialization failed.\"))\n\t\t\t\telse:\n\t\t\t\t\tTransport[jidFromStr] = user\n\t\t\t\t\tupdateTransportsList(Transport[jidFromStr]) #$\n\t\t\t\t\tWatcherMsg(_(\"New user registered: %s\") % jidFromStr)"
            ]
        ]
    },
    {
        "blob_id": "8abb3d060626fef1cfd0042851633fc9fcf5eeda",
        "matched_blocks": [
            [
                180,
                189,
                "            try:\n                for country in self.countries_search_text:\n                    country_object = BarrierCountry.objects.get(name__iexact=country)\n                    countries.append(country_object)\n            except BarrierCountry.DoesNotExist:\n                self.uk_barriers = []\n                self.ec_notifications = []\n            else:\n                self.uk_barriers = self.uk_barriers.filter(country__in=countries)\n                self.ec_notifications = self.ec_notifications.filter(country__in=countries)"
            ]
        ]
    },
    {
        "blob_id": "7f293477b045f48091440894cd292bda2ea352b7",
        "matched_blocks": [
            [
                2,
                9,
                "    try:\n        result = x / y\n    except ZeroDivisionError:\n        print(\"Division by zero error\")\n    except Exception as ex:\n        print(\"{}\".format(ex))\n    else:\n        print(\"result is = {}\".format(result))"
            ]
        ]
    },
    {
        "blob_id": "e0a2b0104dacc25927e765a19aa79a7ec95f55b8",
        "matched_blocks": [
            [
                19,
                42,
                "    try:\n        twitter_user = TWITTER.get_user(username)\n        db_user = (User.query.get(twitter_user.id) or\n                   User(id=twitter_user.id, name=username))\n        DB.session.add(db_user)\n        tweets = twitter_user.timeline(count=200, exclude_replies=True,\n                                       include_rts=False,\n                                       tweet_mode='extended',\n                                       since_id=db_user.newest_tweet_id)\n        if tweets:\n            db_user.newest_tweet_id = tweets[0].id\n        for tweet in tweets:\n            # calculate embedding on the full tweet\n            embedding = BASILICA.embed_sentence(tweet.full_text,\n                                                model='twitter')\n            db_tweet = Tweet(id=tweet.id, text=tweet.full_text[:300],\n                             embedding=embedding)\n            db_user.tweets.append(db_tweet)\n            DB.session.add(db_tweet)\n    except Exception as e:\n        print('Error processing {}: {}'.format(username, e))\n        raise e\n    else:\n        DB.session.commit()"
            ]
        ]
    },
    {
        "blob_id": "8f5f6ecedd756476231d966c5775b37f5126963c",
        "matched_blocks": [
            [
                156,
                161,
                "            try:\n                iter(args)\n            except TypeError:\n                fmt = [format_annotation(args, config)]\n            else:\n                fmt = [format_annotation(arg, config) for arg in args]"
            ]
        ]
    },
    {
        "blob_id": "edb0c0132192cd46eb1316baeae7a2da78a0f89f",
        "matched_blocks": [
            [
                52,
                57,
                "            try:\n                msg = c_queue.get_nowait()\n            except asyncio.QueueEmpty:\n                await asyncio.sleep(0.2)\n            else:\n                await resp.send(msg)"
            ]
        ]
    },
    {
        "blob_id": "05073c0c21276b72ee5fdccd7d1ae12855c27c0c",
        "matched_blocks": [
            [
                33,
                47,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "5f6883e8c0e6b0a1c622e7cab2a1c38ef0de001a",
        "matched_blocks": [
            [
                8,
                16,
                "try:\n    print(\"\\nAttempting anonymous login...\")\n    with FTP(\"ftp.dlptest.com\") as ftp:\n        print(f\"\\t{ftp.getwelcome()}\")\n        # A \"with\" statement will automatically close the connection when it reaches the end of the code block.\nexcept Exception as e:\n    print(f\"\\tException... {e}\")\nelse:\n    print(\"\\tSuccess!\")"
            ],
            [
                22,
                29,
                "try:\n    print(\"\\nMethod #1\\n\\tAttempting authenticated connection with login details...\")\n    with FTP(host=\"ftp.dlptest.com\", user=\"user\", passwd=\"password\") as ftp:\n        print(f\"\\t{ftp.getwelcome()}\")\nexcept Exception as e:\n    print(f\"\\tException... {e}\")\nelse:\n    print(\"\\tSuccess!\")"
            ],
            [
                31,
                41,
                "try:\n    print(\"\\nMethod #2\\n\\tAttempting authenticated connection with login details...\")\n    ftp = FTP()\n    ftp.connect(\"ftp.dlptest.com\")\n    ftp.login(\"dlpuser\", \"rNrKYTX9g7z3RgJRmxWuGHbeu\")\n    print(f\"\\t{ftp.getwelcome()}\")\n    ftp.close()\nexcept Exception as e:\n    print(f\"\\tException... {e}\")\nelse:\n    print(\"\\tSuccess!\")"
            ],
            [
                46,
                55,
                "try:\n    print(\n        \"\\nConnection with SSL/TLS\\n\\tAttempting authenticated connection with login details...\"\n    )\n    with FTP_TLS(\"ftp.dlptest.com\", \"dlpuser\", \"rNrKYTX9g7z3RgJRmxWuGHbeu\") as ftp:\n        print(f\"\\t{ftp.getwelcome()}\")\nexcept Exception as e:\n    print(f\"\\tException... {e}\")\nelse:\n    print(\"\\tSuccess!\")"
            ]
        ]
    },
    {
        "blob_id": "b16b398503da7dddc9283ef297ee1f2996fb2dc1",
        "matched_blocks": [
            [
                28,
                33,
                "try:\n    import numpy as _np\nexcept ImportError:\n    _global_np = False\nelse:\n    _global_np = True"
            ]
        ]
    },
    {
        "blob_id": "1ab07df2d4cec989d96642020c6ad40a27c362f8",
        "matched_blocks": [
            [
                6,
                11,
                "    try:\n        sys.argv[index]\n    except IndexError:\n        return ''\n    else:\n        return sys.argv[index]"
            ]
        ]
    },
    {
        "blob_id": "ca99b5cf3ba81bd26679882f2f553c50dc8dabe1",
        "matched_blocks": [
            [
                1090,
                1113,
                "        try:\n            max_length = int(self.max_length)\n            if max_length <= 0:\n                raise ValueError()\n        except TypeError:\n            return [\n                checks.Error(\n                    \"CharFields must define a 'max_length' attribute.\",\n                    hint=None,\n                    obj=self,\n                    id='fields.E120',\n                )\n            ]\n        except ValueError:\n            return [\n                checks.Error(\n                    \"'max_length' must be a positive integer.\",\n                    hint=None,\n                    obj=self,\n                    id='fields.E121',\n                )\n            ]\n        else:\n            return []"
            ],
            [
                1519,
                1542,
                "        try:\n            decimal_places = int(self.decimal_places)\n            if decimal_places < 0:\n                raise ValueError()\n        except TypeError:\n            return [\n                checks.Error(\n                    \"DecimalFields must define a 'decimal_places' attribute.\",\n                    hint=None,\n                    obj=self,\n                    id='fields.E130',\n                )\n            ]\n        except ValueError:\n            return [\n                checks.Error(\n                    \"'decimal_places' must be a non-negative integer.\",\n                    hint=None,\n                    obj=self,\n                    id='fields.E131',\n                )\n            ]\n        else:\n            return []"
            ],
            [
                1545,
                1568,
                "        try:\n            max_digits = int(self.max_digits)\n            if max_digits <= 0:\n                raise ValueError()\n        except TypeError:\n            return [\n                checks.Error(\n                    \"DecimalFields must define a 'max_digits' attribute.\",\n                    hint=None,\n                    obj=self,\n                    id='fields.E132',\n                )\n            ]\n        except ValueError:\n            return [\n                checks.Error(\n                    \"'max_digits' must be a positive integer.\",\n                    hint=None,\n                    obj=self,\n                    id='fields.E133',\n                )\n            ]\n        else:\n            return []"
            ],
            [
                1664,
                1670,
                "        try:\n            parsed = parse_duration(value)\n        except ValueError:\n            pass\n        else:\n            if parsed is not None:\n                return parsed"
            ]
        ]
    },
    {
        "blob_id": "94d95349f260143004954f60708415d49af4c291",
        "matched_blocks": [
            [
                323,
                343,
                "        try:\n            selection = int(selection)\n        except ValueError:\n            self.types_label.setText('')\n            self.enable_disable_entries(types=None)\n        else:\n            # First we check if our pin selection is a selected arduino progbar\n            progbar_selected = self.gui_progbar.scene.selectedItems()\n            if not (len(progbar_selected) == 1 and selection == int(progbar_selected[0].data.pin)):\n                self.gui_progbar.reset_selection()\n            # Then we set the labels and enable or disable necessary entries\n            self.pins_dropdown.setCurrentIndex(self.pins_dropdown.findText(str(selection)))\n            if selection == tone_pin:\n                self.types_label.setText(tone)\n                self.enable_disable_entries(types=tone)\n            elif selection in output_pins:\n                self.types_label.setText(output)\n                self.enable_disable_entries(types=output)\n            elif selection in pwm_pins:\n                self.types_label.setText(pwm)\n                self.enable_disable_entries(types=pwm)"
            ]
        ]
    },
    {
        "blob_id": "34612b6bfe10f23da813bdc293d433a1103a70bd",
        "matched_blocks": [
            [
                26,
                37,
                "    try:\n        st = cur.execute(sql)\n    except sqlite3.DatabaseError as err:\n        print(\"\u041e\u0448\u0438\u0431\u043a\u0430: \" + err)\n    else:\n        try:\n            st = st.fetchone()\n            t = st[1]\n        except:\n            return \"bad\"\n        else:\n            return \"good\""
            ],
            [
                46,
                75,
                "    try:\n        first = int(text[0])\n    except:\n        return False\n    else:\n        #try to get second number\n        st = \"\"\n        for i in text:\n            try:\n                g = int(i)\n            except:\n                if i == \"\\n\":\n                    second = int(st[::-1])\n                    st = \"\"\n                    ind = text.index(i) + 1\n                    for i in range(ind, len(text)):\n                        try:\n                            g = int(text[i])\n                        except:\n                            if st != \"\":\n                                first = int(st[::-1])\n                                return (first, second, -1 * i)\n                            else:\n                                return False\n                        else:\n                            st = st + text[i]\n                else:\n                    return False\n            else:\n                st = st + i"
            ],
            [
                31,
                37,
                "        try:\n            st = st.fetchone()\n            t = st[1]\n        except:\n            return \"bad\"\n        else:\n            return \"good\""
            ],
            [
                54,
                75,
                "            try:\n                g = int(i)\n            except:\n                if i == \"\\n\":\n                    second = int(st[::-1])\n                    st = \"\"\n                    ind = text.index(i) + 1\n                    for i in range(ind, len(text)):\n                        try:\n                            g = int(text[i])\n                        except:\n                            if st != \"\":\n                                first = int(st[::-1])\n                                return (first, second, -1 * i)\n                            else:\n                                return False\n                        else:\n                            st = st + text[i]\n                else:\n                    return False\n            else:\n                st = st + i"
            ],
            [
                121,
                130,
                "            try:\n                t = con.execute(sql).fetchall()\n            except sqlite3.DatabaseError as err:\n                print(err)\n                bot.send_message(message.from_user.id, \"some Error, ssory =)\\nnow is \" + str(id_day+1))\n            else:\n                st = \"\"\n                for i in t:\n                    st = st + str(i[1]) + \"time start: \" + str(i[3]) + \"\\ntime stop: \" + str(i[4]) + \"\\n---------------\\n\"\n                bot.send_message(message.from_user.id, st)"
            ],
            [
                88,
                94,
                "                try:\n                    cur.execute(sql)\n                except sqlite3.DatabaseError as err:\n                    print(\"\u041e\u0448\u0438\u0431\u043a\u0430 \", err)\n                else:\n                    print(message.from_user.id, \" \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445\")\n                    con.commit()"
            ],
            [
                170,
                177,
                "                    try:\n                        cur.execute(sql, st)\n                    except sqlite3.DatabaseError as err:\n                        print(err)\n                    else:\n                        con.commit()\n                        print(ms)\n                        bot.send_message(message.from_user.id, config.write_more)"
            ],
            [
                62,
                71,
                "                        try:\n                            g = int(text[i])\n                        except:\n                            if st != \"\":\n                                first = int(st[::-1])\n                                return (first, second, -1 * i)\n                            else:\n                                return False\n                        else:\n                            st = st + text[i]"
            ]
        ]
    },
    {
        "blob_id": "4a8ba21250def0e771eb0d8cfee9b9e5f35ef4b8",
        "matched_blocks": [
            [
                40,
                46,
                "            try:\n                rendered = render_template_block(\n                    node.get_parent(context), block, context)\n            except BlockNotFound:\n                pass\n            else:\n                return rendered"
            ],
            [
                31,
                37,
                "                try:\n                    rendered = _render_template_block_nodelist(\n                        getattr(node, key), block, context)\n                except:\n                    pass\n                else:\n                    return rendered"
            ]
        ]
    },
    {
        "blob_id": "d62a6da2a211fe251a044a5caababeacd87bf3f6",
        "matched_blocks": [
            [
                508,
                513,
                "        try:\n            rule.update(self.apiclient, ruleid=rule.id, permission='some_other_value')\n        except Exception:\n            pass\n        else:\n            self.fail(\"Negative test: Setting permission to 'some_other_value' should not be successful, failing\")"
            ]
        ]
    },
    {
        "blob_id": "03bc0d80849bc3264945b6fc903d9599b980d26a",
        "matched_blocks": [
            [
                34,
                39,
                "        try:\n            iterable = iter(obj)\n        except TypeError:\n            pass\n        else:\n            return list(iterable)"
            ]
        ]
    },
    {
        "blob_id": "8679566170b778a960abce634e76adaebdade2c8",
        "matched_blocks": [
            [
                484,
                497,
                "                try:\n                    sg_rule = self._create_security_group_rule(\n                        sec_group_rules_client=sec_group_rules_client,\n                        secgroup=secgroup,\n                        security_groups_client=security_groups_client,\n                        **ruleset)\n                except lib_exc.Conflict as ex:\n                    # if rule already exist - skip rule and continue\n                    msg = 'Security group rule already exists'\n                    if msg not in ex._error_string:\n                        raise ex\n                else:\n                    self.assertEqual(r_direction, sg_rule.direction)\n                    rules.append(sg_rule)"
            ]
        ]
    },
    {
        "blob_id": "7b983ca6cc89f7f0ce04caa4c852aa9565892d72",
        "matched_blocks": [
            [
                114,
                124,
                "        try:\n            line_number = int(args.get('line'))\n        except:\n            self.pc.update_output(\"'%s' is not a valid line number.\" % args.get('args'))\n        else:\n            if (line_number > 0) and (line_number <= len(self.edit_lines)):\n                self.edit_lines[line_number-1] = args.get('args')\n                self.pc.update_output('Line replaced.')\n                self.show_progress()\n            else:\n                self.pc.update_output('%s is not a valid line number.' % str(line_number))"
            ],
            [
                127,
                137,
                "        try:\n            line_number = int(args.get('line'))\n        except:\n            self.pc.update_output(\"'%s' is not a valid line number.\" % args.get('args'))\n        else:\n            if (line_number > 0) and (line_number <= len(self.edit_lines)):\n                self.edit_lines.insert(line_number-1, args.get('args'))\n                self.pc.update_output('Line replaced.\\n')\n                self.show_progress()\n            else:\n                self.pc.update_output('%s is not a valid line number.' % str(line_number))"
            ],
            [
                140,
                150,
                "        try:\n            line_number = int(args.get('line'))\n        except:\n            self.pc.update_output(\"'%s' is not a valid line number.\" % args.get('args'))\n        else:\n            if (line_number > 0) and (line_number <= len(self.edit_lines)):\n                del self.edit_lines[line_number-1]\n                self.pc.update_output('Line deleted.\\n')\n                self.show_progress()\n            else:\n                self.pc.update_output('%s is not a valid line number.' % str(line_number))"
            ]
        ]
    },
    {
        "blob_id": "0c2fddd11b78d0ae7d34b0e19aadb724ad55b1a1",
        "matched_blocks": [
            [
                65,
                71,
                "    try:\n        User.objects.get(email=request.POST['email'], password= request.POST['password'])\n    except ObjectDoesNotExist:\n        messages.error(request, \"Email and Password don't match!\")\n        isValid = False\n    else:\n        messages.error(request, \" \")"
            ]
        ]
    },
    {
        "blob_id": "4d140ed2c2c3af3fd3dac9aba25bdb930b695763",
        "matched_blocks": [
            [
                62,
                68,
                "                try:\n                    c = codecs.lookup(candidate_encoding)\n                    candidate_encoding = c.name\n                except Exception:\n                    pass\n                else:\n                    encoding = candidate_encoding"
            ]
        ]
    },
    {
        "blob_id": "25953cae325ec6628bdd04c1d2d3c3644b984ada",
        "matched_blocks": [
            [
                344,
                368,
                "        try:\n            broker = self.cluster.broker_metadata(node_id)\n            assert broker, 'Broker id %s not in current metadata' % node_id\n            log.debug(\"Initiating connection to node %s at %s:%s\",\n                      node_id, broker.host, broker.port)\n\n            with (yield from self._get_conn_lock):\n                if conn_id in self._conns:\n                    return self._conns[conn_id]\n\n                self._conns[conn_id] = yield from create_conn(\n                    broker.host, broker.port, loop=self._loop,\n                    client_id=self._client_id,\n                    request_timeout_ms=self._request_timeout_ms,\n                    ssl_context=self._ssl_context,\n                    security_protocol=self._security_protocol,\n                    on_close=self._on_connection_closed)\n        except (OSError, asyncio.TimeoutError) as err:\n            log.error('Unable connect to node with id %s: %s', node_id, err)\n            # Connection failures imply that our metadata is stale, so let's\n            # refresh\n            self.force_metadata_update()\n            return None\n        else:\n            return self._conns[conn_id]"
            ],
            [
                407,
                415,
                "        try:\n            result = yield from future\n        except asyncio.TimeoutError:\n            # close connection so it is renewed in next request\n            self._conns[(node_id, group)].close(\n                reason=CloseReason.CONNECTION_TIMEOUT)\n            raise RequestTimedOutError()\n        else:\n            return result"
            ],
            [
                454,
                479,
                "            try:\n                if not conn.connected():\n                    yield from conn.connect()\n                assert conn, 'no connection to node with id {}'.format(node_id)\n                # request can be ignored by Kafka broker,\n                # so we send metadata request and wait response\n                task = self._loop.create_task(conn.send(request))\n                yield from asyncio.wait([task], timeout=0.1, loop=self._loop)\n                try:\n                    yield from conn.send(MetadataRequest_v0([]))\n                except KafkaError:\n                    # metadata request can be cancelled in case\n                    # of invalid correlationIds order\n                    pass\n                response = yield from task\n            except KafkaError:\n                continue\n            else:\n                # To avoid having a connection in undefined state\n                if node_id != \"bootstrap\" and conn.connected():\n                    conn.close()\n                if isinstance(request, ApiVersionRequest_v0):\n                    # Starting from 0.10 kafka broker we determine version\n                    # by looking at ApiVersionResponse\n                    version = self._check_api_version_response(response)\n                return version"
            ]
        ]
    },
    {
        "blob_id": "5f1e4d12d51c79a452072faef65a11be76da4b32",
        "matched_blocks": [
            [
                682,
                687,
                "    try:\n        batch = batch.submit()\n    except aiohttp.ClientResponseError as e:\n        assert e.status == 400\n    else:\n        assert False, f'should receive a 400 Bad Request {batch.id}'"
            ],
            [
                927,
                933,
                "    try:\n        builder.submit()\n    except aiohttp.ClientResponseError as err:\n        assert err.status == 400\n        assert 'unauthorized network private' in err.message\n    else:\n        assert False"
            ]
        ]
    },
    {
        "blob_id": "e98c9e6e4e8e98f0eb86148a6604600fbb0f969e",
        "matched_blocks": [
            [
                52,
                76,
                "                try:\n                    subst1.try_add_variable('i2.2.1.2.1.1', tmp3)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 123780\n                    if len(subjects2) >= 1:\n                        tmp5 = subjects2.popleft()\n                        subst2 = Substitution(subst1)\n                        try:\n                            subst2.try_add_variable('i2.2.1.2.1.2', tmp5)\n                        except ValueError:\n                            pass\n                        else:\n                            pass\n                            # State 123781\n                            if len(subjects2) == 0:\n                                pass\n                                # State 123782\n                                if len(subjects) == 0:\n                                    pass\n                                    # 0: x**n\n                                    yield 0, subst2\n                        subjects2.appendleft(tmp5)"
            ],
            [
                62,
                75,
                "                        try:\n                            subst2.try_add_variable('i2.2.1.2.1.2', tmp5)\n                        except ValueError:\n                            pass\n                        else:\n                            pass\n                            # State 123781\n                            if len(subjects2) == 0:\n                                pass\n                                # State 123782\n                                if len(subjects) == 0:\n                                    pass\n                                    # 0: x**n\n                                    yield 0, subst2"
            ]
        ]
    },
    {
        "blob_id": "a4c6e1bdbbbd353970f2d968fcc7fa0ef546ac3c",
        "matched_blocks": [
            [
                207,
                245,
                "                try:\n                    team_donations = resolve_team_donation(\n                        db, team, provider, payer, payer_country,\n                        prorated_amount, tip, sepa_only=True,\n                    )\n                except (MissingPaymentAccount, NoSelfTipping):\n                    team_amounts = resolve_amounts(prorated_amount, {\n                        pt.id: pt.amount.convert(prorated_amount.currency)\n                        for pt in transfers\n                    })\n                    for pt in transfers:\n                        if pt.amount != team_amounts.get(pt.id):\n                            assert pt.remote_id is None and pt.status in ('pre', 'pending')\n                            updates.append((team_amounts[pt.id], pt.id))\n                else:\n                    team_donations = {d.recipient.id: d for d in team_donations}\n                    for pt in transfers:\n                        if pt.status == 'failed':\n                            continue\n                        d = team_donations.pop(pt.recipient, None)\n                        if d is None:\n                            assert pt.remote_id is None and pt.status in ('pre', 'pending')\n                            cursor.run(\"\"\"\n                                DELETE FROM payin_transfer_events\n                                 WHERE payin_transfer = %(pt_id)s\n                                   AND status = 'pending';\n                                DELETE FROM payin_transfers WHERE id = %(pt_id)s;\n                            \"\"\", dict(pt_id=pt.id))\n                        elif pt.amount != d.amount:\n                            assert pt.remote_id is None and pt.status in ('pre', 'pending')\n                            updates.append((d.amount, pt.id))\n                    n_periods = prorated_amount / tip.periodic_amount.convert(prorated_amount.currency)\n                    for d in team_donations.values():\n                        unit_amount = (d.amount / n_periods).round(allow_zero=False)\n                        prepare_payin_transfer(\n                            db, payin, d.recipient, d.destination, 'team-donation',\n                            d.amount, tip.visibility, unit_amount, tip.period,\n                            team=team.id,\n                        )"
            ]
        ]
    },
    {
        "blob_id": "9a9d9bcdd9ab53f460f6ad785cc547432607d302",
        "matched_blocks": [
            [
                379,
                395,
                "    try:\n        function(*args, **kwargs)\n    except exceptions as e:\n        error_message = str(e)\n        if message not in error_message:\n            raise AssertionError(\"Error message does not include the expected\"\n                                 \" string: %r. Observed error message: %r\" %\n                                 (message, error_message))\n    else:\n        # concatenate exception names\n        if isinstance(exceptions, tuple):\n            names = \" or \".join(e.__name__ for e in exceptions)\n        else:\n            names = exceptions.__name__\n\n        raise AssertionError(\"%s not raised by %s\" %\n                             (names, function.__name__))"
            ]
        ]
    },
    {
        "blob_id": "a05e1946471a7d54d46c499ff5899fb514a7c155",
        "matched_blocks": [
            [
                23,
                33,
                "    try:\n        import simplejson\n    except Exception:\n        try:\n            import json\n        except Exception:\n            raise Exception(\"Can not import any json library\")\n        else:\n            _jsonEnode = json.dumps\n    else:\n        _jsonEnode = simplejson.dumps"
            ],
            [
                26,
                31,
                "        try:\n            import json\n        except Exception:\n            raise Exception(\"Can not import any json library\")\n        else:\n            _jsonEnode = json.dumps"
            ]
        ]
    },
    {
        "blob_id": "5477f4628e91361da257b037777d5dca45c5d413",
        "matched_blocks": [
            [
                1386,
                1391,
                "            try:\n                equal = index.equals(other_index)\n            except NotImplementedError:\n                equal = None\n            else:\n                cache[key] = equal"
            ]
        ]
    },
    {
        "blob_id": "409b1cba66bea305247d7f650e6ca420be6dfcd5",
        "matched_blocks": [
            [
                13,
                18,
                "            try:\n                target = os.readlink(os.fsdecode(sys_path))\n            except OSError:\n                return None\n            else:\n                return os.fsencode(target)"
            ]
        ]
    },
    {
        "blob_id": "ed50985f0164adb33180ed6206519ae96c75c4f0",
        "matched_blocks": [
            [
                75,
                81,
                "    try:\n        valueobjects._process_signature(xsd_type, args, kwargs)\n    except TypeError as exc:\n        assert six.text_type(exc) == (\n            '__init__() takes at most 2 positional arguments (3 given)')\n    else:\n        assert False, \"TypeError not raised\""
            ]
        ]
    },
    {
        "blob_id": "1e8d2daf924169185d11f9ad2d0f4598b091a8b7",
        "matched_blocks": [
            [
                116,
                121,
                "                try:\n                    obj = queryset.get(pk=object_pk)\n                except Exception:  # FIXME: use stricter exception checking\n                    pass\n                else:\n                    data = to_string_function(obj)"
            ]
        ]
    },
    {
        "blob_id": "da82acbcd117e45f112e60a7143e73c3ac089d57",
        "matched_blocks": [
            [
                5,
                18,
                "try:\n    unicode = unicode\nexcept NameError:\n    # 'unicode' is undefined, must be Python 3\n    str = str\n    unicode = str\n    bytes = bytes\n    basestring = (str,bytes)\nelse:\n    # 'unicode' exists, must be Python 2\n    str = str\n    unicode = unicode\n    bytes = str\n    basestring = basestring"
            ]
        ]
    },
    {
        "blob_id": "65720ffce7c99c62c5322e92443f02ed91f12edc",
        "matched_blocks": [
            [
                117,
                122,
                "    try:\n        connection.execute(text(f\"DROP INDEX {index_name}\"))\n    except SQLAlchemyError:\n        pass\n    else:\n        success = True"
            ],
            [
                126,
                137,
                "        try:\n            connection.execute(\n                text(\n                    \"DROP INDEX {table}.{index}\".format(\n                        index=index_name, table=table_name\n                    )\n                )\n            )\n        except SQLAlchemyError:\n            pass\n        else:\n            success = True"
            ],
            [
                141,
                152,
                "        try:\n            connection.execute(\n                text(\n                    \"DROP INDEX {index} ON {table}\".format(\n                        index=index_name, table=table_name\n                    )\n                )\n            )\n        except SQLAlchemyError:\n            pass\n        else:\n            success = True"
            ]
        ]
    },
    {
        "blob_id": "6583c2a088cb32901bd7c606ef80a9fd890e52f3",
        "matched_blocks": [
            [
                116,
                121,
                "        try:\n            connection.connect((host, int(list_ports[port])))\n        except socket.error:\n            continue\n        else:\n            port_list_post.append(list_ports[port])"
            ]
        ]
    },
    {
        "blob_id": "bda08bb1e8392fe0495c5b0f7bc2ba3dc882b580",
        "matched_blocks": [
            [
                91,
                98,
                "            try:\n                os.startfile(filename)\n            except WindowsError:\n                # [Error 22] No application is associated with the specified\n                # file for this operation: '<URL>'\n                return False\n            else:\n                return True"
            ]
        ]
    },
    {
        "blob_id": "19a98956bb4d0110e8172df9ae4f9d61d6645acc",
        "matched_blocks": [
            [
                35,
                42,
                "    try:\n        __import__(project_name)\n    except ImportError:\n        pass\n    else:\n        parser.error(\"'%s' conflicts with the name of an existing \"\n            \"Python module and cannot be used as a project name. \"\n            \"Please try another name.\" % project_name)"
            ]
        ]
    },
    {
        "blob_id": "29dcc6918e6e732253f2ff0f81d976da35166127",
        "matched_blocks": [
            [
                91,
                108,
                "   try:\n      #Provide the contents of the email.\n      response = client.send_raw_email(\n          Source=SENDER,\n          Destinations=[\n              RECIPIENT\n          ],\n          RawMessage={\n              'Data':msg.as_string(),\n          }\n          # ConfigurationSetName=CONFIGURATION_SET\n      )\n   # Display an error if something goes wrong.\t\n   except ClientError as e:\n      print(e.response['Error']['Message'])\n   else:\n      print(\"Email sent! Message ID:\")\n      print(response['MessageId'])"
            ]
        ]
    },
    {
        "blob_id": "c74a079a4da583c78d6b6231f9aed74ecc76caab",
        "matched_blocks": [
            [
                19,
                24,
                "    try:\n        data['w1'].convert('fs')\n    except wt.exceptions.UnitsError:\n        assert True\n    else:\n        assert False"
            ]
        ]
    },
    {
        "blob_id": "1c5adc51107dda11e8cf58f8903523927473fb1d",
        "matched_blocks": [
            [
                188,
                193,
                "            try:\n                span = self.span_queue.get(False)\n            except queue.Empty:\n                break\n            else:\n                spans.append(span)"
            ],
            [
                204,
                209,
                "            try:\n                profile = self.profile_queue.get(False)\n            except queue.Empty:\n                break\n            else:\n                profiles.append(profile)"
            ]
        ]
    },
    {
        "blob_id": "1d4213c8de5ff44c1aa9881392ee9cb3859bca78",
        "matched_blocks": [
            [
                1061,
                1068,
                "        try:\n            self.wallet.add_payment_request(req, self.config)\n        except Exception as e:\n            self.logger.exception('Error adding payment request')\n            self.show_error(_('Error adding payment request') + ':\\n' + str(e))\n        else:\n            self.sign_payment_request(addr)\n            self.save_request_button.setEnabled(False)"
            ],
            [
                3483,
                3499,
                "        try:\n            if not self.wallet.add_transaction(tx.txid(), tx):\n                win.show_error(_(\"Transaction could not be saved.\") + \"\\n\" +\n                               _(\"It conflicts with current history.\"))\n                return False\n        except AddTransactionException as e:\n            win.show_error(e)\n            return False\n        else:\n            self.wallet.storage.write()\n            # need to update at least: history_list, utxo_list, address_list\n            self.need_update.set()\n            msg = (_(\"Transaction added to wallet history.\") + '\\n\\n' +\n                   _(\"Note: this is an offline transaction, if you want the network \"\n                     \"to see it, you need to broadcast it.\"))\n            win.msg_box(QPixmap(icon_path(\"offline_tx.png\")), None, _('Success'), msg)\n            return True"
            ],
            [
                1773,
                1780,
                "            try:\n                self.network.run_from_another_thread(self.network.broadcast_transaction(tx))\n            except TxBroadcastError as e:\n                msg = e.get_message_for_gui()\n            except BestEffortRequestFailed as e:\n                msg = repr(e)\n            else:\n                status, msg = True, tx.txid()"
            ],
            [
                2751,
                2756,
                "            try:\n                valid_privkeys = get_pk(raise_on_error=True) is not None\n            except Exception as e:\n                button.setToolTip(f'{_(\"Error\")}: {str(e)}')\n            else:\n                button.setToolTip('')"
            ]
        ]
    },
    {
        "blob_id": "293c50ad0158fd45c358786aba011c362277f48e",
        "matched_blocks": [
            [
                318,
                323,
                "        try:\n            _import(\"numpy\")\n        except ImportError:\n            pass\n        else:\n            modules.insert(1, \"numpy\")"
            ]
        ]
    },
    {
        "blob_id": "c10b64b68a73422fbdf6966007bc2b99cc7da702",
        "matched_blocks": [
            [
                172,
                202,
                "        try:\n            self.db.execute(\"\"\"SELECT * FROM students\"\"\")\n            all_rows = self.db.fetchall()\n            #print(self.l[10][0],self.l[10][1],self.l[10][2])\n            for i in range(self.num):\n            \n                flag=0\n                for row in all_rows:\n                    if self.l[i][0].lower() == row[1].lower() and self.l[i][1].lower() == row[2].lower()  and self.l[i][2].lower()== row[3].lower():\n                        flag=1\n                        break\n            \n                if flag==0:\n                \n                    if self.l[i][4]!=\"NULL\":    \n                        self.l[i][4]=hashlib.md5(str(self.rfid.get()).encode('utf-8')).hexdigest()\n                \n                    self.db.execute(\"INSERT INTO students VALUES(NULL,?,?,?,?,?,NULL)\",(self.l[i]))\n                \n                else:\n                    print(self.l[i][0],self.l[i][1], \"already in database\")\n        except:\n        \n            self.closeDb()\n            print(\"Problem importing the file. This is most likely because it is not in the correct format:\\n\\\n            surname, firstname, group, year, rfid_number. \\n\\\n            If RFID number is unavailable use NULL\")\n        \n        else:\n            self.closeDb()\n            print(\"End Import\")"
            ]
        ]
    },
    {
        "blob_id": "2f2d2f98b445b7c273a6c0c3b80e0ecc367e2b89",
        "matched_blocks": [
            [
                61,
                70,
                "    try:\n        response = urllib.request.urlopen(spec_url)\n    except urllib.error.URLError as err:\n        logger.error('Failed to get spec %s. Error: %s', spec_url, err)\n    else:\n        spec = str(response.read())\n        for marker in MARKERS:\n            if marker in spec:\n                logger.warning('%s: %s', package.name, spec_url)\n                return package"
            ],
            [
                83,
                91,
                "    try:\n        response = urllib.request.urlopen(api_url)\n    except urllib.error.URLError as err:\n        logger.error('Failed to get package info %s. Error: %s', api_url, err)\n    else:\n        response = response.read()\n        result = json.loads(response.decode())\n        branches = [pkg['collection']['branchname'] for pkg in result['packages']]\n        return package.name, [el for el in branches if el in ('el6', 'epel7')]"
            ]
        ]
    },
    {
        "blob_id": "2cd95fd2f36e95c2f5317974b9ce2f58a79cf559",
        "matched_blocks": [
            [
                44,
                53,
                "try:\n    lvlist = os.listdir('/dev/%s' % VOLUME_GROUP)\nexcept FileNotFoundError:\n    print('No volumes to delete')\nelse:\n    for logical_volume in lvlist:\n        delete_command = 'lvremove --yes /dev/%s/%s' % (VOLUME_GROUP, logical_volume)\n        p = subprocess.run(shlex.split(delete_command), stdout=subprocess.PIPE)\n    else:\n        print('%d volumes deleted' % len(lvlist))"
            ]
        ]
    },
    {
        "blob_id": "cfec69c429cf20a1391c0b96aa76a0d3dcc92545",
        "matched_blocks": [
            [
                1299,
                1305,
                "try:\n    str(b'dummy', 'ascii')\nexcept TypeError:\n    as_str = str\nelse:\n    def as_str(x):\n        return str(x, 'ascii')"
            ],
            [
                1214,
                1231,
                "        try:\n            dtype = testelement.dtype\n            # goto the \"else:\" clause.  Sorry.\n        except AttributeError:\n            try:\n                # Try a Python array.array.\n                bitdepth = 8 * testelement.itemsize\n            except AttributeError:\n                # We can't determine it from the array element's\n                # datatype, use a default of 8.\n                bitdepth = 8\n        else:\n            # If we got here without exception, we now assume that\n            # the array is a numpy array.\n            if dtype.kind == 'b':\n                bitdepth = 1\n            else:\n                bitdepth = 8 * dtype.itemsize"
            ]
        ]
    },
    {
        "blob_id": "4f03dcbb3a4981e832ea2ada8019b8427ffa6e1e",
        "matched_blocks": [
            [
                11,
                19,
                "try:\n    mode = int(input(\"Select the generator mode: \"))\nexcept ValueError:\n    print(\"Error. Invalid option.\")\n    exit(1)\nelse:\n    if not (1 <= mode <= 2):\n        print(\"Error. Invalid option.\")\n        exit(1)"
            ],
            [
                26,
                34,
                "    try:\n        samples = int(samples)\n    except ValueError:\n        print(\"Error. Invalid option.\")\n        exit(1)\n    else:\n        if samples < 0:\n            print(\"Error. Invalid option.\")\n            exit(1)"
            ]
        ]
    },
    {
        "blob_id": "c555387b5fe8713bfdedfc225d1114519b15a6b6",
        "matched_blocks": [
            [
                25,
                33,
                "    try:\n        selected_choice=question.choice_set.get(pk=request.POST['choice'])\n    except(KeyError,Choice.DoesNotExist):\n        return render(request,'polls/detail.html',{'question':question,\n        'error_message':'You didnt select a choice'},)\n    else:\n        selected_choice.votes+=1\n        selected_choice.save()\n        return HttpResponseRedirect(reverse('polls:results',args=(question_id,)))"
            ]
        ]
    },
    {
        "blob_id": "8f4f9c3470d82a64089f824501c629cf2f4a11f0",
        "matched_blocks": [
            [
                932,
                937,
                "  try:\n    concrete_aval(x)\n  except TypeError:\n    return False\n  else:\n    return True"
            ],
            [
                562,
                575,
                "    try:\n      attr = getattr(self.aval, name)\n    except KeyError as err:\n      raise AttributeError(\n          \"{} has no attribute {}\".format(self.__class__.__name__, name)\n      ) from err\n    else:\n      t = type(attr)\n      if t is aval_property:\n        return attr.fget(self)\n      elif t is aval_method:\n        return types.MethodType(attr.fun, self)\n      else:\n        return attr"
            ]
        ]
    },
    {
        "blob_id": "6efba6e8ac827a39cfa14b756ed24204b789cd58",
        "matched_blocks": [
            [
                3952,
                3961,
                "            try:\n                location_id = form.location_id\n            except:\n                pass\n            else:\n                ttable = s3db.sit_presence\n                query = (ptable.pe_id == note.pe_id) & \\\n                        (ttable.uuid == ptable.uuid) & \\\n                        (ttable.location_id == location_id) & \\\n                        (ttable.timestmp == note.timestmp)"
            ]
        ]
    },
    {
        "blob_id": "7a1a8c81f100d92753a7c4c855b5075b01d3f969",
        "matched_blocks": [
            [
                234,
                244,
                "        try:\n            logger.debug('Checking \"%s\"', rse)\n            output = consistency(rse, delta, configuration, cache_dir,\n                                 results_dir)\n            if output:\n                process_output(output)\n        except:\n            success = False\n            class_, desc = sys.exc_info()[0:2]\n        else:\n            success = True"
            ]
        ]
    },
    {
        "blob_id": "d9d8d108b0e4724e37827247112eb08e0ee40bc7",
        "matched_blocks": [
            [
                36,
                42,
                "        try:  \n            rtfHandler = logging.BaseRotatingHandler(  \n                            filename, maxBytes=10*1024*1024, backupCount=5)  \n        except Exception as reason:  \n            self.error(\"%s\" % reason)  \n        else:  \n            self.addHandler(rtfHandler)  "
            ]
        ]
    },
    {
        "blob_id": "ae0f31c3cf9e06b3d49a8f2c5b69bc2ef35d3621",
        "matched_blocks": [
            [
                227,
                244,
                "        try:\n            coloredLine = self.interpreter.lastColorizedLine(source)\n        except:\n            # We couldn't do it.  Strange.  Oh well, just add the character.\n            self.terminal.write(ch)\n        else:\n            # Success!  Clear the source on this line.\n            self.terminal.eraseLine()\n            self.terminal.cursorBackward(len(self.lineBuffer) +\n                    len(self.ps[self.pn]) - 1)\n\n            # And write a new, colorized one.\n            self.terminal.write(self.ps[self.pn] + coloredLine)\n\n            # And move the cursor to where it belongs\n            n = len(self.lineBuffer) - self.lineBufferIndex\n            if n:\n                self.terminal.cursorBackward(n)"
            ]
        ]
    },
    {
        "blob_id": "e158544d2e4449e49cbef749a6dd22ea76ab9ae2",
        "matched_blocks": [
            [
                128,
                136,
                "        try:\n            values[0]  # test if scalar\n        except TypeError:\n            newvmin = values\n            newvmax = values\n        else:\n            finites = np.isfinite(values)\n            newvmin = np.min(values[finites])\n            newvmax = np.max(values[finites])"
            ]
        ]
    },
    {
        "blob_id": "254b39836b581460441fc658e6f0419e540ea63d",
        "matched_blocks": [
            [
                93,
                101,
                "        try:\n            st = os.stat(fn)\n        except OSError:\n            # File most likely does not exist\n            pass\n        else:\n            # XXX What about other special files? (sockets, devices...)\n            if stat.S_ISFIFO(st.st_mode):\n                raise SpecialFileError(\"`%s` is a named pipe\" % fn)"
            ]
        ]
    },
    {
        "blob_id": "68f7317461017bdbc5cc013287b3b3c2a0e5fa13",
        "matched_blocks": [
            [
                277,
                282,
                "    try:\n        value = data[key]\n    except KeyError:\n        return None\n    else:\n        return value and int(value)"
            ]
        ]
    },
    {
        "blob_id": "767c595ccda8fb692218e3c929131dccec9cc691",
        "matched_blocks": [
            [
                161,
                169,
                "    try:\n        # pylint: disable-next=import-outside-toplevel\n        import MySQLdb.converters as MySQLdb_converters\n    except ImportError:\n        pass\n    else:\n        MySQLdb_converters.conversions[\n            HAFakeDatetime\n        ] = MySQLdb_converters.DateTime2literal"
            ]
        ]
    },
    {
        "blob_id": "2579e1ddd9447025a1155119df8e7f7ec3185f44",
        "matched_blocks": [
            [
                110,
                116,
                "        try:\n            iterable = self.app(env, my_start_response)\n        except Exception:\n            self.publish_counter(env, input_proxy.bytes_received, 0)\n            raise\n        else:\n            return iter_response(iterable)"
            ]
        ]
    },
    {
        "blob_id": "bd3b3d45311a3acf29007751bcf7d26209d85391",
        "matched_blocks": [
            [
                45,
                78,
                "        try:\n            subst1.try_add_variable('i2.2.1.2.2.2.1.0', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 43336\n            if len(subjects) >= 1 and isinstance(subjects[0], Pow):\n                tmp2 = subjects.popleft()\n                subjects3 = deque(tmp2._args)\n                # State 43337\n                if len(subjects3) >= 1:\n                    tmp4 = subjects3.popleft()\n                    subst2 = Substitution(subst1)\n                    try:\n                        subst2.try_add_variable('i2.2.1.2.2.2.1.1', tmp4)\n                    except ValueError:\n                        pass\n                    else:\n                        pass\n                        # State 43338\n                        if len(subjects3) >= 1 and subjects3[0] == Integer(2):\n                            tmp6 = subjects3.popleft()\n                            # State 43339\n                            if len(subjects3) == 0:\n                                pass\n                                # State 43340\n                                if len(subjects) == 0:\n                                    pass\n                                    # 0: g*x**2\n                                    yield 0, subst2\n                            subjects3.appendleft(tmp6)\n                    subjects3.appendleft(tmp4)\n                subjects.appendleft(tmp2)"
            ],
            [
                80,
                116,
                "        try:\n            subst1.try_add_variable('i2.2.1.2.2.2.1.0_1', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 43348\n            if len(subjects) >= 1:\n                tmp8 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i2.2.1.2.2.2.1.1', tmp8)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 43349\n                    if len(subjects) == 0:\n                        pass\n                        # 1: f*x\n                        yield 1, subst2\n                subjects.appendleft(tmp8)\n            if len(subjects) >= 1:\n                tmp10 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i2.2.1.2.2.2.1.0', tmp10)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 55141\n                    if len(subjects) == 0:\n                        pass\n                        # 2: x*f\n                        yield 2, subst2\n                subjects.appendleft(tmp10)"
            ],
            [
                90,
                100,
                "                try:\n                    subst2.try_add_variable('i2.2.1.2.2.2.1.1', tmp8)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 43349\n                    if len(subjects) == 0:\n                        pass\n                        # 1: f*x\n                        yield 1, subst2"
            ],
            [
                105,
                115,
                "                try:\n                    subst2.try_add_variable('i2.2.1.2.2.2.1.0', tmp10)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 55141\n                    if len(subjects) == 0:\n                        pass\n                        # 2: x*f\n                        yield 2, subst2"
            ],
            [
                59,
                76,
                "                    try:\n                        subst2.try_add_variable('i2.2.1.2.2.2.1.1', tmp4)\n                    except ValueError:\n                        pass\n                    else:\n                        pass\n                        # State 43338\n                        if len(subjects3) >= 1 and subjects3[0] == Integer(2):\n                            tmp6 = subjects3.popleft()\n                            # State 43339\n                            if len(subjects3) == 0:\n                                pass\n                                # State 43340\n                                if len(subjects) == 0:\n                                    pass\n                                    # 0: g*x**2\n                                    yield 0, subst2\n                            subjects3.appendleft(tmp6)"
            ]
        ]
    },
    {
        "blob_id": "ea8002c7df09e620bcf2f15740bfc4e9bd72a65b",
        "matched_blocks": [
            [
                151,
                156,
                "        try:\n            team = Team.objects.get(sport=sport, user=user)\n        except Team.DoesNotExist:\n            return super().dispatch(request, *args, **kwargs)\n        else:  \n            return redirect(team.get_absolute_url())"
            ],
            [
                57,
                62,
                "            try:\n                team = Team.objects.get(user=user, sport=sport)\n            except Team.DoesNotExist:\n                self.object = None\n            else:\n                self.object = team"
            ]
        ]
    },
    {
        "blob_id": "1181b639354080f4efa652e95729190cdfb5fc52",
        "matched_blocks": [
            [
                153,
                158,
                "            try:\n                in_q.get(block=False)\n            except multiprocessing.queues.Empty:\n                pass\n            else:\n                raise AssertionError(\"In queue not empty\")"
            ],
            [
                159,
                164,
                "            try:\n                out_q.get(block=False)\n            except multiprocessing.queues.Empty:\n                pass\n            else:\n                raise AssertionError(\"Out queue not empty\")"
            ]
        ]
    },
    {
        "blob_id": "ff0a0d7d665c8a4db5f15803896426c20f65776c",
        "matched_blocks": [
            [
                220,
                235,
                "            try:\n                # RFC 7230 section 3.3.2 specifies multiple content lengths can\n                # be sent in a single Content-Length header\n                # (e.g. Content-Length: 42, 42). This line ensures the values\n                # are all valid ints and that as long as the `set` length is 1,\n                # all values are the same. Otherwise, the header is invalid.\n                lengths = set([int(val) for val in length.split(',')])\n                if len(lengths) > 1:\n                    raise InvalidHeader(\"Content-Length contained multiple \"\n                                        \"unmatching values (%s)\" % length)\n                length = lengths.pop()\n            except ValueError:\n                length = None\n            else:\n                if length < 0:\n                    length = None"
            ]
        ]
    },
    {
        "blob_id": "5b45c0e8fbfce8d8502acdfa68ad9a70da2ebb1a",
        "matched_blocks": [
            [
                246,
                251,
                "    try:\n        key = ProjectKey.objects.filter(project=project)[0]\n    except ProjectKey.DoesNotExist:\n        context[asvar] = None\n    else:\n        context[asvar] = key.get_dsn()"
            ]
        ]
    },
    {
        "blob_id": "8ba11f2ef590038ba7088d6471103e17aea99a38",
        "matched_blocks": [
            [
                90,
                101,
                "    try:\n        urn = d_included[\"actor\"][\"urn\"]\n    except KeyError:\n        return \"\"\n    except TypeError:\n        return \"None\"\n    else:\n        urn_id = urn.split(\":\")[-1]\n        if \"company\" in urn:\n            return f\"{base_url}/company/{urn_id}\"\n        elif \"member\" in urn:\n            return f\"{base_url}/in/{urn_id}\""
            ],
            [
                115,
                122,
                "    try:\n        urn = d_included[\"updateMetadata\"][\"urn\"]\n    except KeyError:\n        return \"\"\n    except TypeError:\n        return \"None\"\n    else:\n        return f\"{base_url}/feed/update/{urn}\""
            ]
        ]
    },
    {
        "blob_id": "f5ccd83f94604ab09e3beb254c26de02425f7e1e",
        "matched_blocks": [
            [
                481,
                489,
                "        try:\n            result = function.func(*args)\n        except BaseException as e:\n            raise CalculatorError(\n                'Exception running %s(%s): %s' %\n                (function.name, ', '.join(map(str, args)), e))\n        else:\n            self._finalize(result, modifiers, nPop=nArgs)\n            return True, result"
            ],
            [
                535,
                575,
                "        try:\n            value = eval(command, globals(), self._variables)\n        except BaseException as e:\n            err = str(e)\n            errors.append('Could not eval(%r): %s' % (command, err))\n            if (self._splitLines and\n                    err.startswith(\n                        'unexpected EOF while parsing (<string>, line 1)')):\n                possibleWhiteSpace = True\n\n            try:\n                value = EngNumber(command)\n            except decimal.InvalidOperation:\n                try:\n                    exec(command, globals(), self._variables)\n                except BaseException as e:\n                    err = str(e)\n                    errors.append('Could not exec(%r): %s' % (command, err))\n                    if (not possibleWhiteSpace and self._splitLines and\n                            err.startswith(\n                                'unexpected EOF while parsing (<string>, '\n                                'line 1)')):\n                        possibleWhiteSpace = True\n\n                    if possibleWhiteSpace:\n                        errors.append('Did you accidentally include '\n                                      'whitespace in a command line?')\n                    raise CalculatorError(*errors)\n                else:\n                    self.debug('exec(%r) worked.' % command)\n                    return True, self.NO_VALUE\n            else:\n                self.debug('EngNumber(%s) worked: %r' % (command, value))\n                count = 1 if count is None else count\n                self._finalize(value, modifiers=modifiers, repeat=count)\n                return True, value\n        else:\n            self.debug('eval %s worked: %r' % (command, value))\n            count = 1 if count is None else count\n            self._finalize(value, modifiers=modifiers, repeat=count)\n            return True, value"
            ],
            [
                176,
                187,
                "            try:\n                function = self._functions[longName]\n            except KeyError:\n                self.err('Long function name %r is unknown' % longName)\n            else:\n                for shortName in shortNames:\n                    if shortName not in self._functions:\n                        # self.err('Long name %r alias %r' %\n                        # (longName, shortName))\n                        self._functions[shortName] = function\n                    else:\n                        self.report(shortName, 'already known')"
            ],
            [
                210,
                216,
                "            try:\n                self._functions[longName]\n            except KeyError:\n                self._functions[longName] = Function(\n                    module.__name__, func.__name__, func, nArgs)\n            else:\n                self.err('Long function name %r is already set' % longName)"
            ],
            [
                333,
                338,
                "            try:\n                iterator = iter(result)\n            except TypeError:\n                pass\n            else:\n                result = list(iterator)"
            ],
            [
                355,
                379,
                "            try:\n                command, modifiers, count = next(commands)\n            except UnknownModifiersError as e:\n                self.err('Unknown modifiers: %s' % ', '.join(e.args))\n                return False\n            except IncompatibleModifiersError as e:\n                self.err('Incompatible modifiers: %s' % e.args[0])\n                return False\n            except CalculatorError as e:\n                self.err('Incompatible modifiers: %s' % e.args[0])\n                return False\n            except StopIteration:\n                break\n            else:\n                if not self._executeOneCommand(command, modifiers, count):\n                    # Print a debug message if there were pending commands\n                    # that did not get run at all.\n                    try:\n                        command, modifiers, count = next(commands)\n                    except StopIteration:\n                        pass\n                    else:\n                        self.debug('Ignoring commands from %r on due to '\n                                   'previous error' % command)\n                    return False"
            ],
            [
                126,
                136,
                "                try:\n                    line = input(prompt)\n                except ValueError as e:\n                    if str(e) == 'I/O operation on closed file.':\n                        # The user may have typed 'quit()'.\n                        self.report()\n                        break\n                    else:\n                        raise\n                else:\n                    self.execute(line)"
            ],
            [
                545,
                570,
                "            try:\n                value = EngNumber(command)\n            except decimal.InvalidOperation:\n                try:\n                    exec(command, globals(), self._variables)\n                except BaseException as e:\n                    err = str(e)\n                    errors.append('Could not exec(%r): %s' % (command, err))\n                    if (not possibleWhiteSpace and self._splitLines and\n                            err.startswith(\n                                'unexpected EOF while parsing (<string>, '\n                                'line 1)')):\n                        possibleWhiteSpace = True\n\n                    if possibleWhiteSpace:\n                        errors.append('Did you accidentally include '\n                                      'whitespace in a command line?')\n                    raise CalculatorError(*errors)\n                else:\n                    self.debug('exec(%r) worked.' % command)\n                    return True, self.NO_VALUE\n            else:\n                self.debug('EngNumber(%s) worked: %r' % (command, value))\n                count = 1 if count is None else count\n                self._finalize(value, modifiers=modifiers, repeat=count)\n                return True, value"
            ],
            [
                372,
                378,
                "                    try:\n                        command, modifiers, count = next(commands)\n                    except StopIteration:\n                        pass\n                    else:\n                        self.debug('Ignoring commands from %r on due to '\n                                   'previous error' % command)"
            ],
            [
                548,
                565,
                "                try:\n                    exec(command, globals(), self._variables)\n                except BaseException as e:\n                    err = str(e)\n                    errors.append('Could not exec(%r): %s' % (command, err))\n                    if (not possibleWhiteSpace and self._splitLines and\n                            err.startswith(\n                                'unexpected EOF while parsing (<string>, '\n                                'line 1)')):\n                        possibleWhiteSpace = True\n\n                    if possibleWhiteSpace:\n                        errors.append('Did you accidentally include '\n                                      'whitespace in a command line?')\n                    raise CalculatorError(*errors)\n                else:\n                    self.debug('exec(%r) worked.' % command)\n                    return True, self.NO_VALUE"
            ]
        ]
    },
    {
        "blob_id": "3fd6449d9848cc0f9d76778c6916138106af709e",
        "matched_blocks": [
            [
                43,
                54,
                "        try:\n            downloaded_file_name = await borg.download_media(\n                reply_message,\n                Config.TMP_DOWNLOAD_DIRECTORY\n            )\n        except Exception as e:\n            await event.edit(str(e))\n            return\n        else:\n            await event.edit(\"sending to ReMove.BG\")\n            output_file_name = ReTrieveFile(downloaded_file_name)\n            os.remove(downloaded_file_name)"
            ]
        ]
    },
    {
        "blob_id": "54c9a65d15786c181c4f835eedac784926e7b84a",
        "matched_blocks": [
            [
                167,
                174,
                "    try:\n        caller = sys._getframe(stacklevel)\n    except ValueError:\n        globals = sys.__dict__\n        lineno = 1\n    else:\n        globals = caller.f_globals\n        lineno = caller.f_lineno"
            ]
        ]
    },
    {
        "blob_id": "5d29915d5f7cd34df4d2e63ba62cad9a4c9d0dff",
        "matched_blocks": [
            [
                93,
                124,
                "            try:\n                controller = await get_controller(\n                    self.hass,\n                    host=self.config[CONF_HOST],\n                    username=self.config[CONF_USERNAME],\n                    password=self.config[CONF_PASSWORD],\n                    port=self.config[CONF_PORT],\n                    site=self.config[CONF_SITE_ID],\n                    verify_ssl=self.config[CONF_VERIFY_SSL],\n                )\n\n                sites = await controller.sites()\n\n            except AuthenticationRequired:\n                errors[\"base\"] = \"faulty_credentials\"\n\n            except CannotConnect:\n                errors[\"base\"] = \"service_unavailable\"\n\n            else:\n                self.site_ids = {site[\"_id\"]: site[\"name\"] for site in sites.values()}\n                self.site_names = {site[\"_id\"]: site[\"desc\"] for site in sites.values()}\n\n                if (\n                    self.reauth_config_entry\n                    and self.reauth_config_entry.unique_id in self.site_names\n                ):\n                    return await self.async_step_site(\n                        {CONF_SITE_ID: self.reauth_config_entry.unique_id}\n                    )\n\n                return await self.async_step_site()"
            ]
        ]
    },
    {
        "blob_id": "d54a2d06f3ed577fa85f60af8b66e7fbf080d4e3",
        "matched_blocks": [
            [
                399,
                422,
                "    try:\n        pointing = get_pointing(obsstart, obsend, engdb_url=engdb_url,\n                                tolerance=tolerance, reduce_func=reduce_func)\n    except ValueError as exception:\n        if not allow_default:\n            raise\n        else:\n            logger.warning(\n                'Cannot retrieve telescope pointing.'\n                ' Default pointing parameters will be used.'\n                '\\nException is {}'.format(exception)\n            )\n    else:\n        # compute relevant WCS information\n        logger.info('Successful read of engineering quaternions:')\n        logger.info('\\tPointing = {}'.format(pointing))\n        try:\n            wcsinfo, vinfo = calc_wcs(pointing, siaf, **transform_kwargs)\n        except Exception as e:\n            logger.warning(\n                'WCS calculation has failed and will be skipped.'\n                'Default pointing parameters will be used.'\n                '\\nException is {}'.format(e)\n            )"
            ]
        ]
    },
    {
        "blob_id": "1ec86efb2239491e398123fb720b5039fb31d93a",
        "matched_blocks": [
            [
                39,
                47,
                "        try:\n            config = YamlConf(configFile)\n        except PenError:\n            userAgents = [\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)\",\n                \"Mozilla/5.0 (Windows; U; Windows NT 5.2)Gecko/2008070208 Firefox/3.0.1\",\n                \"Opera/9.27 (Windows NT 5.2; U; zh-cn)\",\n                \"Mozilla/5.0 (Macintosh; PPC Mac OS X; U; en)Opera 8.0)\"]\n        else:\n            userAgents = [x['User-Agent'] for x in config]"
            ],
            [
                56,
                62,
                "        try:\n            with open(configFile, \"r\") as _file:\n                config = yaml.load(_file)[engine]\n        except IOError:\n            raise SearchEngineError(\"read searchengine configuration file 'searchengine.yaml' failed\")\n        else:\n            return config"
            ]
        ]
    },
    {
        "blob_id": "08553be1bc9ff6ee1fc0811a4732271a5f5b3073",
        "matched_blocks": [
            [
                51,
                56,
                "        try:\n            self.pillow_processor.process_change(None, change)\n        except Exception:\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "f75d9363d3f58cb2e0d6affc103f3d42ab2fe867",
        "matched_blocks": [
            [
                1344,
                1353,
                "    try:\n        machine_snapshot_commit, machine_snapshot = MachineSnapshotCommit.objects.commit_machine_snapshot_tree(tree)\n    except Exception:\n        logger.exception(\"Could not commit machine snapshot\")\n        save_dead_letter(tree, \"machine snapshot commit error\")\n    else:\n        if machine_snapshot_commit:\n            post_inventory_events(machine_snapshot_commit.serial_number,\n                                  inventory_events_from_machine_snapshot_commit(machine_snapshot_commit))\n        return machine_snapshot"
            ],
            [
                1361,
                1374,
                "    try:\n        request = EnrollmentSecret.objects.verify(model, secret,\n                                                  user_agent, public_ip_address,\n                                                  serial_number, udid,\n                                                  meta_business_unit,\n                                                  **kwargs)\n    except EnrollmentSecretVerificationFailed as e:\n        post_enrollment_secret_verification_failure(model,\n                                                    user_agent, public_ip_address, serial_number,\n                                                    e.err_msg, e.enrollment_secret)\n        raise\n    else:\n        post_enrollment_secret_verification_success(request, model)\n        return request"
            ]
        ]
    },
    {
        "blob_id": "8993e224fbae79032ccd18aebf3257469ecf128d",
        "matched_blocks": [
            [
                41,
                57,
                "    try:\n\n        fp = open(f, \"rb\")\n\n        try:\n            p = PcfFontFile.PcfFontFile(fp)\n        except SyntaxError:\n            fp.seek(0)\n            p = BdfFontFile.BdfFontFile(fp)\n\n        p.save(f)\n\n    except (SyntaxError, IOError):\n        print(\"failed\")\n\n    else:\n        print(\"OK\")"
            ]
        ]
    },
    {
        "blob_id": "75a5ec813821b7205fb5db2c1ff865688cba1888",
        "matched_blocks": [
            [
                115,
                130,
                "            try:\n                # Does path already exist in the list?\n                index = combined_list.index(path)\n            except ValueError:\n                # Add path to combined_list since it doesn't exist.\n                combined_list.insert(last_insert_index, path)\n            else:\n                if index > last_insert_index:\n                    warnings.warn(\n                        'Detected duplicate Media files in an opposite order:\\n'\n                        '%s\\n%s' % (combined_list[last_insert_index], combined_list[index]),\n                        MediaOrderConflictWarning,\n                    )\n                # path already exists in the list. Update last_insert_index so\n                # that the following elements are inserted in front of this one.\n                last_insert_index = index"
            ],
            [
                1056,
                1062,
                "                try:\n                    date_value = datetime.date(int(y), int(m), int(d))\n                except ValueError:\n                    return '%s-%s-%s' % (y, m, d)\n                else:\n                    date_value = datetime_safe.new_date(date_value)\n                    return date_value.strftime(input_format)"
            ],
            [
                1015,
                1020,
                "                try:\n                    d = datetime.datetime.strptime(value, input_format)\n                except ValueError:\n                    pass\n                else:\n                    year, month, day = d.year, d.month, d.day"
            ]
        ]
    },
    {
        "blob_id": "33bca2f934b26984b4c280f4d6284adba7ff2eae",
        "matched_blocks": [
            [
                20,
                42,
                "        try:\n            query = \"\"\"\n            WITH goldEquipe AS (\n                SELECT gold, numEp \n                FROM LesResultats JOIN LesEpreuves USING (numep) \n                WHERE formeEp='par equipe'\n                    OR formeEp='par couple'\n            ) \n            SELECT DISTINCT numEq, AVG(ageSp) AS AgeMoyen \n            FROM goldEquipe G JOIN LesEquipiers E ON (G.gold = E.numEq) JOIN LesSportifs USING (numSp) \n            GROUP BY numEq, numEp;\n            \"\"\"\n\n\n            cursor = self.data.cursor()\n            result = cursor.execute(query)\n        except Exception as e:\n            self.ui.table_age_or_equipe.setRowCount(0)\n            display.refreshLabel(self.ui.label_age_or_equipe, \"Impossible d'afficher les r\u00e9sultats : \" + repr(e))\n        else:\n            i = display.refreshGenericData(self.ui.table_age_or_equipe, result)\n            if i == 0:\n                display.refreshLabel(self.ui.table_age_or_equipe, \"Aucun r\u00e9sultat\")"
            ]
        ]
    },
    {
        "blob_id": "e944671405354385e353be2e74a966df6d6b1984",
        "matched_blocks": [
            [
                148,
                153,
                "        try:\n            ix = int(x)\n        except:\n            return False\n        else:\n            return ix >= 0"
            ]
        ]
    },
    {
        "blob_id": "55846d10634384288599005ef999a8646607ec79",
        "matched_blocks": [
            [
                18,
                23,
                "\t\ttry:\n\t\t\th=Team1_encoder.transform([hey])[0]\n\t\texcept ValueError:\n\t\t\th=random.randint(0,465)\n\t\telse:\n\t\t\th=Team1_encoder.transform([hey])[0]"
            ],
            [
                26,
                31,
                "\t\ttry:\n\t\t\th=Team2_encoder.transform([hey])[0]\n\t\texcept ValueError:\n\t\t\th=random.randint(0,465)\n\t\telse:\n\t\t\th=Team2_encoder.transform([hey])[0]"
            ],
            [
                34,
                39,
                "\t\ttry:\n\t\t\th=ba1_encoder.transform([hey])[0]\n\t\texcept ValueError:\n\t\t\th=random.randint(0,465)\n\t\telse:\n\t\t\th=ba1_encoder.transform([hey])[0]"
            ],
            [
                42,
                47,
                "\t\ttry:\n\t\t\th=ba2_encoder.transform([hey])[0]\n\t\texcept ValueError:\n\t\t\th=random.randint(0,465)\n\t\telse:\n\t\t\th=ba2_encoder.transform([hey])[0]"
            ],
            [
                50,
                55,
                "\t\ttry:\n\t\t\th=bo_encoder.transform([hey])[0]\n\t\texcept ValueError:\n\t\t\th=random.randint(0,465)\n\t\telse:\n\t\t\th=bo_encoder.transform([hey])[0]"
            ]
        ]
    },
    {
        "blob_id": "018babb8f42d8e1ef0bffa8854a4fbc056a769f4",
        "matched_blocks": [
            [
                249,
                260,
                "            try:\n                page_count = import_pages(import_data, parent_page)\n            except LookupError as e:\n                messages.error(request, _(\n                    \"Import failed: %(reason)s\") % {'reason': e}\n                )\n            else:\n                messages.success(request, ungettext(\n                    \"%(count)s page imported.\",\n                    \"%(count)s pages imported.\",\n                    page_count) % {'count': page_count}\n                )"
            ]
        ]
    },
    {
        "blob_id": "937ba0bd6ba6d97907592bcc6f32b79e8c411331",
        "matched_blocks": [
            [
                881,
                889,
                "        try:\n            main_mod = self._main_mod_cache[filename]\n        except KeyError:\n            main_mod = self._main_mod_cache[filename] = types.ModuleType(\n                        py3compat.cast_bytes_py2(modname),\n                        doc=\"Module created for script run in IPython\")\n        else:\n            main_mod.__dict__.clear()\n            main_mod.__name__ = modname"
            ],
            [
                2625,
                2641,
                "        try:\n            # Static input transformations\n            cell = self.input_transformer_manager.transform_cell(raw_cell)\n        except SyntaxError:\n            preprocessing_exc_tuple = sys.exc_info()\n            cell = raw_cell  # cell has to exist so it can be stored/logged\n        else:\n            if len(cell.splitlines()) == 1:\n                # Dynamic transformations - only applied for single line commands\n                with self.builtin_trap:\n                    try:\n                        # use prefilter_lines to handle trailing newlines\n                        # restore trailing newline for ast.parse\n                        cell = self.prefilter_manager.prefilter_lines(cell) + '\\n'\n                    except Exception:\n                        # don't allow prefilter errors to crash IPython\n                        preprocessing_exc_tuple = sys.exc_info()"
            ],
            [
                2861,
                2884,
                "        try:\n            try:\n                self.hooks.pre_run_code_hook()\n                #rprint('Running code', repr(code_obj)) # dbg\n                exec(code_obj, self.user_global_ns, self.user_ns)\n            finally:\n                # Reset our crash handler in place\n                sys.excepthook = old_excepthook\n        except SystemExit as e:\n            if result is not None:\n                result.error_in_exec = e\n            self.showtraceback(exception_only=True)\n            warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n        except self.custom_exceptions:\n            etype, value, tb = sys.exc_info()\n            if result is not None:\n                result.error_in_exec = value\n            self.CustomTB(etype, value, tb)\n        except:\n            if result is not None:\n                result.error_in_exec = sys.exc_info()[1]\n            self.showtraceback()\n        else:\n            outflag = 0"
            ],
            [
                3000,
                3007,
                "        try:\n            frame = sys._getframe(depth+1)\n        except ValueError:\n            # This is thrown if there aren't that many frames on the stack,\n            # e.g. if a script called run_line_magic() directly.\n            pass\n        else:\n            ns.update(frame.f_locals)"
            ],
            [
                1403,
                1428,
                "            try:\n                obj = ns[oname_head]\n            except KeyError:\n                continue\n            else:\n                #print 'oname_rest:', oname_rest  # dbg\n                for idx, part in enumerate(oname_rest):\n                    try:\n                        parent = obj\n                        # The last part is looked up in a special way to avoid\n                        # descriptor invocation as it may raise or have side\n                        # effects.\n                        if idx == len(oname_rest) - 1:\n                            obj = self._getattr_property(obj, part)\n                        else:\n                            obj = getattr(obj, part)\n                    except:\n                        # Blanket except b/c some badly implemented objects\n                        # allow __getattr__ to raise exceptions other than\n                        # AttributeError, which then crashes IPython.\n                        break\n                else:\n                    # If we finish the for loop (no break), we got all members\n                    found = True\n                    ospace = nsname\n                    break  # namespace loop"
            ],
            [
                1468,
                1493,
                "            try:\n                # `getattr(type(obj), attrname)` is not guaranteed to return\n                # `obj`, but does so for property:\n                #\n                # property.__get__(self, None, cls) -> self\n                #\n                # The universal alternative is to traverse the mro manually\n                # searching for attrname in class dicts.\n                attr = getattr(type(obj), attrname)\n            except AttributeError:\n                pass\n            else:\n                # This relies on the fact that data descriptors (with both\n                # __get__ & __set__ magic methods) take precedence over\n                # instance-level attributes:\n                #\n                #    class A(object):\n                #        @property\n                #        def foobar(self): return 123\n                #    a = A()\n                #    a.__dict__['foobar'] = 345\n                #    a.foobar  # == 123\n                #\n                # So, a property may be returned right away.\n                if isinstance(attr, property):\n                    return attr"
            ]
        ]
    },
    {
        "blob_id": "c1a99d5d3eb7e2582c6cfee3f83604d59d555fbb",
        "matched_blocks": [
            [
                42,
                47,
                "        try:\n            database.delete_graph(name=graph)\n        except Exception as err:\n            print(\"delete graph '{}' error. Error: {}\".format(graph, err))\n        else:\n            print(\"delete graph '{}' ok...\".format(graph))"
            ],
            [
                106,
                111,
                "        try:\n            database.delete_collection(name=edge)\n        except Exception as err:\n            print(\"delete edge '{}' error. Error: {}\".format(edge, err))\n        else:\n            print(\"delete edge '{}' ok...\".format(edge))"
            ],
            [
                162,
                167,
                "        try:\n            database.delete_collection(name=collection)\n        except Exception as err:\n            print(\"delete collection '{}' error. Error: {}\".format(collection, err))\n        else:\n            print(\"delete collection '{}' ok...\".format(collection))"
            ]
        ]
    },
    {
        "blob_id": "ecace4c734f76d585f96bb14587426610ba0bccd",
        "matched_blocks": [
            [
                35,
                49,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'blogApp/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('blogApp:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "af2f708f88f67eea61adbc5b0172d4df821a5c20",
        "matched_blocks": [
            [
                207,
                220,
                "        try:\n            response = self.__base.get(headers=headers, redirect_limit=redirect_limit, **kwargs)\n        except (ClientError, ServerError) as error:\n            if error.status_code == UNAUTHORIZED:\n                raise AuthorizationFailed(self.uri.string)\n            if isinstance(error, JSONResponse):\n                content = dict(error.content, request=error.request, response=error)\n            else:\n                content = {}\n            message = content.pop(\"message\", \"HTTP GET returned response %s\" % error.status_code)\n            raise_from(GraphError(message, **content), error)\n        else:\n            self.__last_get_response = response\n            return response"
            ],
            [
                232,
                244,
                "        try:\n            response = self.__base.put(body, headers, **kwargs)\n        except (ClientError, ServerError) as error:\n            if error.status_code == UNAUTHORIZED:\n                raise AuthorizationFailed(self.uri.string)\n            if isinstance(error, JSONResponse):\n                content = dict(error.content, request=error.request, response=error)\n            else:\n                content = {}\n            message = content.pop(\"message\", \"HTTP PUT returned response %s\" % error.status_code)\n            raise_from(GraphError(message, **content), error)\n        else:\n            return response"
            ],
            [
                256,
                268,
                "        try:\n            response = self.__base.post(body, headers, **kwargs)\n        except (ClientError, ServerError) as error:\n            if error.status_code == UNAUTHORIZED:\n                raise AuthorizationFailed(self.uri.string)\n            if isinstance(error, JSONResponse):\n                content = dict(error.content, request=error.request, response=error)\n            else:\n                content = {}\n            message = content.pop(\"message\", \"HTTP POST returned response %s\" % error.status_code)\n            raise_from(GraphError(message, **content), error)\n        else:\n            return response"
            ],
            [
                279,
                291,
                "        try:\n            response = self.__base.delete(headers, **kwargs)\n        except (ClientError, ServerError) as error:\n            if error.status_code == UNAUTHORIZED:\n                raise AuthorizationFailed(self.uri.string)\n            if isinstance(error, JSONResponse):\n                content = dict(error.content, request=error.request, response=error)\n            else:\n                content = {}\n            message = content.pop(\"message\", \"HTTP DELETE returned response %s\" % error.status_code)\n            raise_from(GraphError(message, **content), error)\n        else:\n            return response"
            ]
        ]
    },
    {
        "blob_id": "9f0702d8f80072a9d519973ad6a65e8f13883cf9",
        "matched_blocks": [
            [
                115,
                120,
                "    try:\n        compute_distance(input_1, input_3, 2)\n    except:\n        pass\n    else:\n        raise AssertionError(\"Different size matrices did not trigger error\")"
            ],
            [
                261,
                267,
                "    try:\n        find_most_distant(input_sample, N, num_params, k_choices)\n    except:\n        pass\n    else:\n        raise AssertionError(\"Test did not fail when number of \\\n                             combinations exceeded system size\")"
            ]
        ]
    },
    {
        "blob_id": "ee1f512d8cdc9f044ea1da3793c50847db6eee2a",
        "matched_blocks": [
            [
                407,
                412,
                "        try:\n            cherrypy.tools.numerify.on\n        except AttributeError:\n            pass\n        else:\n            raise AssertionError('Tool.on did not error as it should have.')"
            ],
            [
                415,
                420,
                "        try:\n            cherrypy.tools.numerify.on = True\n        except AttributeError:\n            pass\n        else:\n            raise AssertionError('Tool.on did not error as it should have.')"
            ]
        ]
    },
    {
        "blob_id": "802caa784aff470ce4839a56761cdd49d43d388a",
        "matched_blocks": [
            [
                39,
                51,
                "        try:\n            r1=requests.get(m,headers=headers,timeout=0.3)\n        except error.URLError as e1:\n            print(e1.reason)\n        except error.HTTPError as e2:\n            print(e2.reason)\n        else:\n            if r1.status_code == 200:\n                path = root + m.split(\"/\")[-1]\n                with open(path, \"wb\") as f:\n                    f.write(r1.content)\n                    number2=number2+1\n                    print(f\"\u5199\u5165\u7b2c{number2}\u4e2a\u6587\u4ef6\u6210\u529f!\")"
            ]
        ]
    },
    {
        "blob_id": "67053034d879feacaa464af9b9b60cd915df29fc",
        "matched_blocks": [
            [
                41,
                55,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "f6381c3f62606a2ae4b07c51be27b5b7306906b0",
        "matched_blocks": [
            [
                59,
                68,
                "    try:\n        response = requests.get(url, params=query, timeout=timeout)\n    except Exception:\n        # add later log file\n        pass\n    else:\n        if response and response.ok:\n            if json_view:\n                return response.json()\n            return response.text"
            ]
        ]
    },
    {
        "blob_id": "c00b74b92aab6dc6d807f842ea1939e4613cb799",
        "matched_blocks": [
            [
                323,
                330,
                "    try:\n      cached_value = getattr(instance, self.cache_attr)\n    except AttributeError:\n      value = self.fget(instance)\n      setattr(instance, self.cache_attr, value if value is not instance else self._self)\n      return value\n    else:\n      return cached_value if cached_value is not self._self else instance"
            ],
            [
                380,
                386,
                "      try:\n        cached_key, cached_value = getattr(self, cache_attr)\n      except AttributeError:\n        pass\n      else:\n        if cached_key == key:\n          return self if cached_value is _self else cached_value"
            ],
            [
                1063,
                1068,
                "      try:\n        items.remove(item)\n      except ValueError:\n        pass\n      else:\n        isect.append(item)"
            ]
        ]
    },
    {
        "blob_id": "14bdb06d5bb95f9fbbc5ff0de051c6d5130fe37d",
        "matched_blocks": [
            [
                4,
                11,
                "    try:\n        f = open(my_file,'r',encoding='UTF-8-SIG')\n    except:\n        print('Error\uff01Please reenter the path')\n        my_file = input(\"input the path of the file:\")\n        continue\n    else: \n        break"
            ]
        ]
    },
    {
        "blob_id": "a7700a712ddd8d21a4439696f5d2596ebfcf4142",
        "matched_blocks": [
            [
                90,
                101,
                "        try:\n            autonomous_pkg = importlib.import_module(autonomous_pkgname)\n        except ImportError as e:\n            if e.name not in [autonomous_pkgname, autonomous_pkgname.split(\".\")[0]]:\n                raise\n\n            # Don't kill the robot because they didn't create an autonomous package\n            logger.warning(\"Cannot load the '%s' package\", autonomous_pkgname)\n        else:\n            if hasattr(autonomous_pkg, \"__file__\"):\n                modules_path = os.path.dirname(os.path.abspath(autonomous_pkg.__file__))\n                modules = glob(os.path.join(modules_path, \"*.py\"))"
            ]
        ]
    },
    {
        "blob_id": "57502ecd1d88cf997c4b70a179256c8d58f69ed6",
        "matched_blocks": [
            [
                22,
                33,
                "try:\n    from twisted.protocols.tls import TLSMemoryBIOFactory\nexcept ImportError:\n    # Either pyOpenSSL isn't installed, or it is too old for this code to work.\n    # The reactor won't provide IReactorSSL.\n    TLSMemoryBIOFactory = None\n    _extraInterfaces = ()\n    warnings.warn(\n        \"pyOpenSSL 0.10 or newer is required for SSL support in iocpreactor. \"\n        \"It is missing, so the reactor will not support SSL APIs.\")\nelse:\n    _extraInterfaces = (interfaces.IReactorSSL,)"
            ]
        ]
    },
    {
        "blob_id": "392389de4ebf5837a6ad2ea78f224cec46c031e7",
        "matched_blocks": [
            [
                376,
                390,
                "                try:\n                    check_call_to_file(execcmd(src), actual,\n                                       stdin=open(str(infile), 'r'), timeout=self.config['timelimit'])\n                except TimeoutExpired:\n                    result = 'TLE'\n                except CalledProcessError:\n                    result = 'RE'\n                else:\n                    process = run(\n                        execcmd(checker, [str(infile), str(actual), str(expected)]), stdout=PIPE, stderr=STDOUT)\n                    checker_output = process.stdout\n                    if process.returncode:\n                        result = 'WA'\n                    else:\n                        result = 'AC'"
            ]
        ]
    },
    {
        "blob_id": "56a6d7bdd10e6663f11c0637dc2cb7ce3b4484c7",
        "matched_blocks": [
            [
                246,
                267,
                "            try:\n                async with self.session.get(f\"{self.website_link}/api/teachers/?format=json\") as response:\n                    data = json.loads(await response.read())\n\n            except Exception as e:\n                await channel.send(\"**No!**\")\n            else:\n\n                # Checks whether new cards were fetched from the website\n                if not data:\n                    return await channel.send(\"**No cards available to update!**\")\n\n                # Clears the classes channel\n                await self.clear_classes_channel(ctx.guild)\n                sorted_weekdays = await self.sort_weekdays(data)\n                for day, classes in sorted_weekdays.items():\n                    await channel.send(embed=discord.Embed(\n                        title=day,\n                        color=discord.Color.green()))\n                    for teacher_class in classes:\n                        msg = await channel.send(teacher_class)\n                        await asyncio.sleep(0.5)"
            ],
            [
                485,
                511,
                "            try:\n                r, u = await self.client.wait_for(\n                    'reaction_add', timeout=60,\n                    check=lambda r, u: u.id == ctx.author.id and msg.id == r.message.id and str(r.emoji) in ['\u2b05\ufe0f', '\u27a1\ufe0f', '\ud83d\uded1']\n                    )\n            except asyncio.TimeoutError:\n                await msg.remove_reaction('\u2b05\ufe0f', self.client.user)\n                await msg.remove_reaction('\u27a1\ufe0f', self.client.user)\n                await msg.remove_reaction('\ud83d\uded1', self.client.user)\n                return\n\n            else:\n                if str(r.emoji) == '\u27a1\ufe0f':\n                    await msg.remove_reaction(r, u)\n                    if index + 1 < len(data):\n                        index += 1\n                    continue\n                elif str(r.emoji) == '\u2b05\ufe0f':\n                    await msg.remove_reaction(r, u)\n                    if index > 0:\n                        index -= 1\n                    continue\n                elif str(r.emoji) == '\ud83d\uded1':\n                    await msg.remove_reaction('\u2b05\ufe0f', self.client.user)\n                    await msg.remove_reaction('\u27a1\ufe0f', self.client.user)\n                    await msg.remove_reaction('\ud83d\uded1', self.client.user)\n                    await msg.remove_reaction('\ud83d\uded1', u)"
            ]
        ]
    },
    {
        "blob_id": "4881449379a695c4149118e1d99d44aff9893ba9",
        "matched_blocks": [
            [
                407,
                430,
                "        try:\n            result = await app(  # type: ignore[func-returns-value]\n                self.scope, self.receive, self.send\n            )\n        except BaseException as exc:\n            msg = \"Exception in ASGI application\\n\"\n            self.logger.error(msg, exc_info=exc)\n            if not self.response_started:\n                await self.send_500_response()\n            else:\n                self.transport.close()\n        else:\n            if result is not None:\n                msg = \"ASGI callable should return None, but returned '%s'.\"\n                self.logger.error(msg, result)\n                self.transport.close()\n            elif not self.response_started and not self.disconnected:\n                msg = \"ASGI callable returned without starting response.\"\n                self.logger.error(msg)\n                await self.send_500_response()\n            elif not self.response_complete and not self.disconnected:\n                msg = \"ASGI callable returned without completing response.\"\n                self.logger.error(msg)\n                self.transport.close()"
            ]
        ]
    },
    {
        "blob_id": "6e88b985684f882129ced8b4a3f4b089b162634b",
        "matched_blocks": [
            [
                31,
                36,
                "        try:  \n            day_type = int(content)  \n        except ValueError:  \n            return -1  \n        else:  \n            return day_type  "
            ]
        ]
    },
    {
        "blob_id": "dff30fcd28076ed38a5900ae38a8f1fee17e81e7",
        "matched_blocks": [
            [
                53,
                63,
                "    try:\n        code = re.search(exp, str1).group(1)\n        item_c = str2 + '-' + code\n    except Exception:\n        pass\n        # print(\"\u7f51\u5740\u63d0\u53d6code\u9519\u8bef\")\n    else:\n        result['item_code'] = item_c\n        if url:\n            muti_page = url.format(code)\n            result['m_p_u'] = muti_page"
            ]
        ]
    },
    {
        "blob_id": "689af6ea35199c964a9ea2a94f271c7e8d336d4d",
        "matched_blocks": [
            [
                23,
                33,
                "            try:\n                self.put(item, block=block, timeout=timeout)\n\n            except Queue.Full:\n                try:\n                    self.get_nowait()\n                except Queue.Empty:\n                    pass\n\n            else:\n                break"
            ]
        ]
    },
    {
        "blob_id": "bd7ae759e1b554b45f9f64006950c113633b77d5",
        "matched_blocks": [
            [
                206,
                215,
                "    try:\n        index = int(str(event.get_message()).strip())\n        config = Config()\n        config.del_subscribe(event.group_id, 'group',\n                             **state['sub_table'][index])\n    except Exception as e:\n        logger.warning(e)\n        await del_sub_cmd.reject('\u5220\u9664\u9519\u8bef')\n    else:\n        await del_sub_cmd.finish('\u5220\u9664\u6210\u529f')"
            ]
        ]
    },
    {
        "blob_id": "81c733dff8f66ec5565030091b464a5983f59166",
        "matched_blocks": [
            [
                64,
                75,
                "        try:\n            config.read(repo_config)\n            config.set('paths', 'default', url.secret)\n            with open(repo_config, 'w') as config_file:\n                config.write(config_file)\n        except (OSError, configparser.NoSectionError) as exc:\n            logger.warning(\n                'Could not switch Mercurial repository to %s: %s', url, exc,\n            )\n        else:\n            cmd_args = make_command('update', '-q', rev_options.to_args())\n            self.run_command(cmd_args, cwd=dest)"
            ]
        ]
    },
    {
        "blob_id": "eac58c5c03b7ab9050d3193746a20cb1e83c733e",
        "matched_blocks": [
            [
                418,
                423,
                "    try:\n        next(iter(self[0].select(context)))\n    except StopIteration:\n        yield True\n    else:\n        yield False"
            ],
            [
                428,
                433,
                "    try:\n        next(iter(self[0].select(context)))\n    except StopIteration:\n        yield False\n    else:\n        yield True"
            ],
            [
                557,
                562,
                "    try:\n        next(results)\n    except StopIteration:\n        yield item\n    else:\n        raise self.error('FORG0003')"
            ],
            [
                568,
                578,
                "    try:\n        item = next(results)\n    except StopIteration:\n        raise self.error('FORG0004') from None\n    else:\n        yield item\n        while True:\n            try:\n                yield next(results)\n            except StopIteration:\n                break"
            ],
            [
                584,
                594,
                "    try:\n        item = next(results)\n    except StopIteration:\n        raise self.error('FORG0005') from None\n    else:\n        try:\n            next(results)\n        except StopIteration:\n            yield item\n        else:\n            raise self.error('FORG0005')"
            ],
            [
                718,
                734,
                "    try:\n        python_pattern = translate_pattern(pattern, flags, self.parser.xsd_version)\n        pattern = re.compile(python_pattern, flags=flags)\n    except (re.error, RegexError):\n        raise self.error('FORX0002', \"Invalid regular expression %r\" % pattern)\n    else:\n        if pattern.search(''):\n            msg = \"Regular expression %r matches zero-length string\"\n            raise self.error('FORX0003', msg % pattern.pattern)\n        elif REPLACEMENT_PATTERN.search(replacement) is None:\n            raise self.error('FORX0004', \"Invalid replacement string %r\" % replacement)\n        else:\n            for g in range(pattern.groups, -1, -1):\n                if '$%d' % g in replacement:\n                    replacement = re.sub(r'(?<!\\\\)\\$%d' % g, r'\\\\g<%d>' % g, replacement)\n\n        return pattern.sub(replacement, input_string).replace('\\\\$', '$')"
            ],
            [
                750,
                758,
                "    try:\n        python_pattern = translate_pattern(pattern, flags, self.parser.xsd_version)\n        pattern = re.compile(python_pattern, flags=flags)\n    except (re.error, RegexError):\n        raise self.error('FORX0002', \"Invalid regular expression %r\" % pattern) from None\n    else:\n        if pattern.search(''):\n            msg = \"Regular expression %r matches zero-length string\"\n            raise self.error('FORX0003', msg % pattern.pattern)"
            ],
            [
                589,
                594,
                "        try:\n            next(results)\n        except StopIteration:\n            yield item\n        else:\n            raise self.error('FORG0005')"
            ],
            [
                1364,
                1376,
                "        try:\n            doc = context.documents[uri]\n        except (KeyError, TypeError):\n            if self.symbol == 'doc':\n                url_parts = urlsplit(uri)\n                if is_local_url_scheme(url_parts.scheme) \\\n                        and os.path.isdir(url_parts.path.lstrip(':')):\n                    raise self.error('FODC0005', 'document URI is a directory')\n                raise self.error('FODC0002')\n            return False\n        else:\n            if doc is None:\n                raise self.error('FODC0002')"
            ]
        ]
    },
    {
        "blob_id": "4b6a5c4968c8c8a0a9bf267bd3f1c3aecb9a91cd",
        "matched_blocks": [
            [
                27,
                272,
                "try:\n    ### Read json file ###\n    with open(r'/inputVolume/analysis_input.yaml') as file:\n        inputYAML = yaml.load(file, Loader=yaml.FullLoader)\n        logger.debug(\"Reading analysis_input.yaml file...\")\nexcept FileNotFoundError:\n    logger.error(\"Please provide your analysis input file and mount to the container. '-v $(pwd)/*YOURINPUT.yaml*:/analysis_input.yaml' \")\n\nelse:\n    ### Select variables ###\n    sel_col = inputYAML['variables']\n    exl_col = inputYAML['exclude_variables']\n    to_num = inputYAML['variables_to_numeric']\n    \n    if sel_col == \"all\":\n        sel_df = df\n        if exl_col != False:\n            sel_df = sel_df.drop(exl_col, axis=1)\n        col = sel_df.columns\n\n    else:\n        # check_contain = all(elem in all_col  for elem in sel_col)\n        # if check_contain == True:\n        try:\n            sel_df = df[sel_col]\n            col = sel_col\n        # elif check_contain == False:\n        except:\n            logger.error('Mismatch between data columns and selected columns. Please make sure to only select columns that exist in the dataset!')\n            sys.exit(\"Execution interrupted!\")\n        \n        \n    ### For checking data types ###\n    sel_df.dtypes.to_csv('/output/dataType', header=False)\n\n    # Convert to numeric, string will be converted to Nan\n    if to_num == True:\n        sel_df = sel_df.apply(pd.to_numeric,errors='coerce')\n        logger.warning(\"All features are forced to numberic types. Strings become Nan. This might cause analysis mistakes.\")\n\n\n    ### Customize features (sum) ###\n    customize_fea = inputYAML['customize_features']\n    if customize_fea == True:\n        try:\n            combined_df = MLmodel.sum_features(sel_df)\n        except KeyError:\n            logger.error(\"Features you used in MLmodel.sum_features function are not in the dataset! \")\n            sys.exit(\"Execution interrupted!\")\n    else:\n        combined_df = sel_df\n\n\n    ############# Main executions #############\n    file_name = inputYAML['taskName']\n    ctrl_var = inputYAML['control_var']\n\n\n    ### 1.Overview on combined data ###\n    #############################\n    ### For checking missings ###\n    #############################\n    checkMissing = inputYAML['check_missing']\n    if checkMissing == True:\n        func.check_missing(combined_df, col, file_name)\n\n    ###################################\n    ### For getting some basic info ###\n    ###################################\n    basicInfo = inputYAML['basic_Information']\n    if basicInfo == True:\n        func.data_describe(combined_df, col, file_name)\n\n\n    #######################################\n    ### Function for correlation matrix ###\n    #######################################\n    CorrMatrix = inputYAML['correlation_matrix']\n    if CorrMatrix == True:\n        func.corr_Matrix(combined_df[col], file_name)\n\n    existFile = \"output/%s_Corr.csv\" %file_name\n    if os.path.exists(existFile):\n        os.remove(existFile)\n\n    ######################################\n    ### Function for distribution plot ###\n    ######################################\n    dist_plot = inputYAML[\"distribution_plot\"]\n    if dist_plot == True:\n        if ctrl_var == False:\n            # ### Write to tables (generated too many numbers) ###\n            # for c in range(0,len(col)):\n            #     df_dist = func.dist_Plot(combined_df,col[c],ctrl_var)\n            #     if c == 0:\n            #         save_dist = df_dist\n            #     else: \n            #         save_dist = pd.concat([save_dist,df_dist],axis=1, join='inner')\n\n            # outputFile = \"output/Dist_tables/%s_Dist.csv\" %file_name\n            # os.makedirs(os.path.dirname(outputFile), exist_ok=True)\n            \n            # if os.path.exists(outputFile) == False:\n            #     with open(outputFile, 'w') as f:\n            #         save_dist.to_csv(f)\n            # elif os.path.exists(outputFile) == True:\n            #     with open(outputFile, 'a') as f:\n            #         save_dist.to_csv(f)\n            # ##################### END  ########################\n            for c in range(0,len(col)):\n                func.dist_Plot(combined_df,col[c],ctrl_var)\n\n\n        elif ctrl_var in col:\n            list_value = list(Counter(combined_df[ctrl_var]).keys())\n            if len(list_value) < 6:\n                for i_value in list_value:\n                    ctrl_combined_df = combined_df[combined_df[ctrl_var]==i_value]\n                    for c in range(0,len(col)):\n                        if ctrl_var != col[c]:\n                            func.dist_Plot(ctrl_combined_df,col[c], str(ctrl_var+'_'+str(i_value)) )\n            else: \n                logger.error(\"Sorry, control variable has too many different values! Please choose categorical variable as control\")\n                sys.exit(\"Execution interrupted!\")\n            \n        else:\n            logger.error(\"Please give one variable name or False to 'control_var'.\")\n            sys.exit(\"Execution interrupted!\")\n        \n        logger.debug('Distribution plot is done')\n\n\n    logger.info(\"Basic info took {runtime:.4f}s to run\".format(runtime=(time.time() - start_time0)))\n\n\n    ##### 2. Machine Learning Models #####\n    task = inputYAML['task'].lower()\n    logger.debug('Start training models ... ...')\n\n    if task != False: \n\n        start_time1 = time.time()\n        ### Get parameters users set ###\n        kFold = inputYAML['k_fold/split_ratio']\n        scoring = inputYAML['evaluation_methods']\n\n        ### set up restrictions for inputs ###\n        scoring_reg = [\"neg_mean_absolute_error\",\"neg_mean_squared_error\",\"neg_mean_squared_log_error\",\"r2\"]\n        scoring_cls = ['precision', 'recall', 'f1', 'roc_auc']\n\n        ### Check inputed scoring  ### \n        if task == 'regression':\n            if all(item in scoring_reg  for item in scoring):\n                logger.debug(\"Regression evaluation metrics are fine!\")\n            else:\n                logger.error(\"Sorry, so far we only support mean_absolute_error, mean_squared_error, mean_squared_log_error, r2 to evaluation regression models.\")\n                sys.exit(\"Execution interrupted!\")\n\n        elif task == 'classification':\n            if all(item in scoring_cls  for item in scoring):\n                logger.debug(\"Classification evaluation metrics are fine!\")\n            else:\n                logger.error(\"Sorry, so far we only support Precision, Recall, F1-score, ROC to evaluation classification models.\")\n                sys.exit(\"Execution interrupted!\")\n        \n        else:\n            logger.error(\"Task needs to be either classification or regression\")\n            exit()\n\n\n        logger.debug('Start checking if training and target features are in the dataset.')\n        try: \n            model_name, training_features, target_feature = MLmodel.defineFeatures()\n        except KeyError:\n            logger.error(\"Some training and target features are in the dataset! Please check MLmodel.defineFeatures function!\")\n            sys.exit(\"Execution interrupted!\")\n\n\n        if len(model_name) != len(training_features):\n            logger.error(\"Length of models names needs to match with length of training features.\")\n            sys.exit(\"Execution interrupted!\")\n\n\n        ### First, check if values are in the datasets before training models ###\n        for set_f in training_features: \n            for each_f in set_f:\n                if each_f not in combined_df.columns:\n                    logger.debug(\"{feature} is not in the dataset\".format(feature=each_f))\n                    logger.error(\"Please provide existing training features from the dataset!\")\n                    sys.exit(\"Execution interrupted!\")\n\n        for each_t in target_feature: \n            if each_t not in combined_df.columns:\n                logger.debug(\"{feature} is not in the dataset\".format(feature=each_f))\n                logger.error(\"Please provide existing target features from the dataset!\")\n                sys.exit(\"Execution interrupted!\")\n\n        logger.info('All training and target features are in the dataset.')\n\n\n        #########################################\n        ######### Choose and run models #########\n        #########################################\n\n        ### for save resutls ###\n        result_list = [] \n        cnt = 0\n\n        for m in range(0, len(model_name)): \n            logger.debug('Start training {model} ... ...'.format(model=model_name[m]))\n            start_time_each = time.time()\n            model = MLmodel.defineMLModels(model_name[m])\n\n            model_name, training_features, target_feature = MLmodel.defineFeatures()\n            num_training  = len(target_feature)\n\n            for i_training in range(0, num_training):\n                model_setting = [m, i_training]\n                model_name, features, target, target_name = MLmodel.customizeFeatures(combined_df, model_setting, model_name, training_features, target_feature)\n\n\n                ### If use cross validation ###\n                if kFold <= 1 and kFold > 0:\n                    results = func.splitDataTraining(task, model, features, target, kFold, scoring)\n                    \n\n                elif kFold > 2 and type(kFold)==int:\n                    results = cross_validate(model, features, target, scoring=scoring, cv=kFold, error_score=np.nan, return_estimator=True, return_train_score=True)\n\n                else:\n                    logger.error(\"K-Fold has to be an integer (>=3) or 1 (the whole dataset will be training set) or 0-1 as a split ratio (testing/dataset)\")\n                    sys.exit(\"Execution interrupted!\")\n\n                ### Write output results ###\n                if cnt == (len(model_name) * num_training) - 1:\n                    save_file = True\n                else:\n                    save_file = False\n\n                result_list = MLmodel.writeOutput(kFold, model_name, m, results, result_list, training_features, target_name, save_file)\n                \n                cnt = cnt + 1\n            logger.info(\"{model} training took {runtime:.4f} to run.\".format(model=model_name[m], runtime=(time.time() - start_time_each)))\n        \n        ### Write output results ###\n        logger.info(\"In total, all models training took {runtime:.4f} to run. \".format(runtime=(time.time() - start_time1)))"
            ]
        ]
    },
    {
        "blob_id": "9c91e73a5440b8c28e4620927f5a5026b41dba99",
        "matched_blocks": [
            [
                8,
                13,
                "    try:\n        password_validation.validate_password(raw_password)\n    except ValidationError as error:\n        return False, error\n    else:\n        return True, None"
            ]
        ]
    },
    {
        "blob_id": "562eda0497c7dd4801e908d1744d596c47d8f90e",
        "matched_blocks": [
            [
                470,
                516,
                "        try:\n            await self.send(\n                message, destination=self.recipient, from_mod=True, anonymous=anonymous\n            )\n        except Exception:\n            logger.info(error(\"Message delivery failed:\"), exc_info=True)\n            tasks.append(\n                message.channel.send(\n                    embed=discord.Embed(\n                        color=discord.Color.red(),\n                        description=\"Your message could not be delivered as \"\n                        \"the recipient is only accepting direct \"\n                        \"messages from friends, or the bot was \"\n                        \"blocked by the recipient.\",\n                    )\n                )\n            )\n        else:\n            # Send the same thing in the thread channel.\n            tasks.append(\n                self.send(\n                    message,\n                    destination=self.channel,\n                    from_mod=True,\n                    anonymous=anonymous,\n                )\n            )\n\n            tasks.append(\n                self.bot.api.append_log(\n                    message,\n                    self.channel.id,\n                    type_=\"anonymous\" if anonymous else \"thread_message\",\n                )\n            )\n\n            # Cancel closing if a thread message is sent.\n            if self.close_task is not None:\n                await self.cancel_closure()\n                tasks.append(\n                    self.channel.send(\n                        embed=discord.Embed(\n                            color=discord.Color.red(),\n                            description=\"Scheduled close has been cancelled.\",\n                        )\n                    )\n                )"
            ]
        ]
    },
    {
        "blob_id": "240c7a5db792100cdded40de9a6e31501a6f65a2",
        "matched_blocks": [
            [
                171,
                175,
                "            try:\n                if os.path.exists(child.full_path):\n                    os.rmdir(child.full_path)\n            except OSError: pass\n            else: self.children.remove(child)"
            ]
        ]
    },
    {
        "blob_id": "2aaf31265651a1a86a4a57fa4b00d31c00cd1627",
        "matched_blocks": [
            [
                205,
                216,
                "            try:\n                response = self.req.get(summaryurl, headers=self.headers)\n                if response.status_code == 429:\n                    raise GarminConnectTooManyRequestsError(\"Too many requests\")\n\n                self.logger.debug(\"Statistics response code %s\", response.status_code)\n                response.raise_for_status()\n            except requests.exceptions.HTTPError as err:\n                self.logger.debug(\"Exception occurred during statistics retrieval, relogin without effect: %s\" % err)\n                raise GarminConnectConnectionError(\"Error connecting\") from err\n            else:\n                resp_json = response.json()"
            ]
        ]
    },
    {
        "blob_id": "506fb47d1bff8cf2385fe642e25b7f08b9059884",
        "matched_blocks": [
            [
                21,
                30,
                "\ttry:\n\t\t_create_unverified_https_context = ssl._create_unverified_context\n\texcept AttributeError:\n\t\t# Legacy Python that doesn't verify HTTPS certificates by default\n\t\tpass\n\telse:\n\t\t# Handle target environment that doesn't support HTTPS verification\n\t\tssl._create_default_https_context = _create_unverified_https_context\n\t\t# eventlet.green.ssl do use create_default_content\n\t\tssl.create_default_context = _create_unverified_https_context"
            ]
        ]
    },
    {
        "blob_id": "a2d3e2843cd09ddb4df7e1798d8510d5409ff5ff",
        "matched_blocks": [
            [
                43,
                51,
                "\ttry:\n\t\tk = (n[1] - n[3])/(n[0] - n[2])\n\t\tb = (n[0] * n[3] + n[1] * n[2]) / (n[0] + n[2])\n\t\t\n\texcept ZeroDivisionError:\n\t\tpass\n\telse:\n\t\tif n[4] * k + b == float(n[5]) and n[6] * k + b == float(n[7]):\n\t\t\treturn 2"
            ]
        ]
    },
    {
        "blob_id": "df5e06d13ea53b7df8931114f4e84d072684bbc2",
        "matched_blocks": [
            [
                37,
                48,
                "    try:\n        _, resulting_hash = setup(path)\n    except (KeyError, ValueError) as exc:\n        # emit stacktrace to logfile\n        logger.exception(\"failed to rehash configuration.\")\n        # if you have access to mecha's configuration file, you have access to its logs.\n        # no need to defer this to the top-level exception handler.\n        await context.reply(f\"unable to rehash configuration file see logfile for details.\")\n\n    else:\n        # no errors, respond status OK with the first octet of the hash.\n        await context.reply(f\"rehashing completed successfully. ({resulting_hash[:8]}) \")"
            ]
        ]
    },
    {
        "blob_id": "0fb0f85f3464682eaa2704fe97fe870f721bc42d",
        "matched_blocks": [
            [
                260,
                265,
                "        try:\n            self.encoder()\n        except NotImplementedError:\n            logging.info(\"Encoder is not implemented,giving raw output.\")\n        else:\n            dataset = dataset.map(lambda *args: self.encoder(*args))"
            ]
        ]
    },
    {
        "blob_id": "4802483d78f2dce57654e4d31f152e239e562f11",
        "matched_blocks": [
            [
                30,
                36,
                "    try:\n        with open(file_name, 'r') as myfile:\n          data = myfile.read()\n    except FileNotFoundError:\n        print (\"FileNotFoundError: \" + file_name)\n    else:\n        print (\"File reading error: \" + file_name)"
            ]
        ]
    },
    {
        "blob_id": "2497814f690f6cac292000955eb0ef93d79bf08d",
        "matched_blocks": [
            [
                1229,
                1240,
                "    try:\n      existing = self._types[pyname]\n    except KeyError:\n      entry = self._create_child_entry(pyname, cpp_name)\n      self._types[pyname] = entry\n    else:\n      desired_cpp_names = [cpp_name]\n      existing_cpp_names = existing._cpp_names  # pylint: disable=protected-access\n      if existing_cpp_names != desired_cpp_names:\n        raise ValueError(\n            'Python type {!r}: existing C++ types {!r} don\\'t match desired '\n            'types {!r}'.format(pyname, existing_cpp_names, desired_cpp_names))"
            ],
            [
                1259,
                1265,
                "    try:\n      existing = self._types[pyname]\n    except KeyError:\n      entry = self._create_child_entry(pyname, cpp_name)\n      self._types[pyname] = entry\n    else:\n      existing.add_cpp_type(cpp_name)"
            ],
            [
                1272,
                1279,
                "    try:\n      existing = self._types[pyname]\n    except KeyError:\n      entry = self._create_child_entry(pyname, None)\n      self._types[pyname] = entry\n      return entry\n    else:\n      return existing"
            ]
        ]
    },
    {
        "blob_id": "1f2dc7418bd62fb9ce1a55b0590218738640eb02",
        "matched_blocks": [
            [
                219,
                225,
                "        try:\n            u, v, _ = self.edge_index[key]\n        except KeyError as e:\n            raise KeyError(f'Invalid edge key {key!r}') from e\n        else:\n            del self.edge_index[key]\n            self._cls.remove_edge(u, v, key)"
            ],
            [
                399,
                423,
                "            try:\n                v = next(nodes)\n            except StopIteration:\n                # If there are no more new nodes to consider, then we *should*\n                # meet the break condition (b) from the paper:\n                #   (b) every node of G^i is in D^i and E^i is a branching\n                # Construction guarantees that it's a branching.\n                assert(len(G) == len(B))\n                if len(B):\n                    assert(is_branching(B))\n\n                if self.store:\n                    self.graphs.append(G.copy())\n                    self.branchings.append(B.copy())\n\n                    # Add these to keep the lengths equal. Element i is the\n                    # circuit at level i that was merged to form branching i+1.\n                    # There is no circuit for the last level.\n                    self.circuits.append([])\n                    self.minedge_circuit.append(None)\n                break\n            else:\n                if v in D:\n                    # print(\"v in D\", v)\n                    continue"
            ]
        ]
    },
    {
        "blob_id": "e85013d8cdae3fe121c2aab1eeada224ddca8b2e",
        "matched_blocks": [
            [
                367,
                372,
                "        try:\n            raise ValueError('foo')\n        except ValueError:\n            self.client.captureException()\n        else:\n            self.fail('Exception should have been raised')"
            ]
        ]
    },
    {
        "blob_id": "f509d61c42fd4e09736506f61b65a6d588813204",
        "matched_blocks": [
            [
                107,
                113,
                "    try:\n        Dobby.load_extension(f\"dobby.exts.{ext}\")\n    except Exception as e:\n        print(f'**Error when loading extension {ext}:**\\n{type(e).__name__}: {e}')\n    else:\n        if 'debug' in sys.argv[1:]:\n            print(f'Loaded {ext} extension.')"
            ],
            [
                470,
                491,
                "    try:\n        with redirect_stdout(stdout):\n            ret = await func()\n    except Exception as e:\n        value = stdout.getvalue()\n        await ctx.send(f'```py\\n{value}{traceback.format_exc()}\\n```')\n    else:\n        value = stdout.getvalue()\n        try:\n            await ctx.message.add_reaction('\\u2705')\n        except:\n            pass\n        if ret is None:\n            if value:\n                paginator = commands.Paginator(prefix='```py')\n                for line in textwrap.wrap(value, 80):\n                    paginator.add_line(line.rstrip().replace('`', '\\u200b`'))\n                for p in paginator.pages:\n                    await ctx.send(p)\n        else:\n            ctx.bot._last_result = ret\n            await ctx.send(f'```py\\n{value}{ret}\\n```')"
            ],
            [
                119,
                127,
                "        try:\n            ctx.bot.unload_extension(f\"dobby.exts.{ext}\")\n            ctx.bot.load_extension(f\"dobby.exts.{ext}\")\n        except Exception as e:\n            error_title = _('**Error when loading extension')\n            await ctx.send(f'{error_title} {ext}:**\\n'\n                           f'{type(e).__name__}: {e}')\n        else:\n            await ctx.send(_('**Extension {ext} Loaded.**\\n').format(ext=ext))"
            ],
            [
                867,
                873,
                "                try:\n                    await destination.send(embed=embeddraft)\n                except discord.HTTPException:\n                    failed += 1\n                    logger.info('Announcement Delivery Failure: {} - {}'.format(destination.name, guild))\n                else:\n                    sent += 1"
            ]
        ]
    },
    {
        "blob_id": "ace0c793df344ee3d16d8b97ce61547ac0670a0d",
        "matched_blocks": [
            [
                554,
                563,
                "                try:\n                    crt_local, = glob(join(\"deploy\", \"*.crt\"))\n                    key_local, = glob(join(\"deploy\", \"*.key\"))\n                except ValueError:\n                    parts = (crt_file, key_file, env.domains[0])\n                    sudo(\"openssl req -new -x509 -nodes -out %s -keyout %s \"\n                         \"-subj '/CN=%s' -days 3650\" % parts)\n                else:\n                    upload_template(crt_local, crt_file, use_sudo=True)\n                    upload_template(key_local, key_file, use_sudo=True)"
            ]
        ]
    },
    {
        "blob_id": "105d4e73013823786f73822183897416e7e6d3e7",
        "matched_blocks": [
            [
                46,
                51,
                "            try:\n                keyfile = self.find_attic_keyfile()\n            except KeyfileNotFoundError:\n                logger.warning(\"no key file found for repository\")\n            else:\n                self.convert_keyfiles(keyfile, dryrun)"
            ],
            [
                285,
                290,
                "            try:\n                keyfile = self.find_borg0xx_keyfile()\n            except KeyfileNotFoundError:\n                logger.warning(\"no key file found for repository\")\n            else:\n                self.move_keyfiles(keyfile, dryrun)"
            ]
        ]
    },
    {
        "blob_id": "505fd4076806055c676188958c3dd778e792e7ce",
        "matched_blocks": [
            [
                95,
                101,
                "    try:\n        log_fd\n    except NameError:\n        pass\n    else:\n        log_fd.write(message + u\"\\n\")\n        log_fd.flush()"
            ]
        ]
    },
    {
        "blob_id": "79d2d7e1e1faba7d6c94883f29e01293b580434f",
        "matched_blocks": [
            [
                127,
                133,
                "        try:\n            res = torch.load(path_data)\n        except Exception as ex:\n            exp = ex\n            time.sleep(delta * random.random())\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "0cea8acea13bd4893ea43bd4ed1b9ba145ae2ef3",
        "matched_blocks": [
            [
                741,
                746,
                "            try:\n                iterable = iter(data)\n            except TypeError:\n                pass\n            else:\n                return sorted(iterable)"
            ]
        ]
    },
    {
        "blob_id": "cfffb928dd17b54c411a485b5ae009481e2a32e6",
        "matched_blocks": [
            [
                75,
                81,
                "        try:\n            x = int(input('Stitch limit > '))\n            assert x >= 1\n        except (KeyError, AssertionError):\n            print(\"\\nERROR: Invalid Input, Limit must greater than or equal to 1.\\n\")\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "96005790378d6d9083513a1e624cac02aaf72eec",
        "matched_blocks": [
            [
                104,
                129,
                "        try:\n            if frame:\n                myFrame = frame\n            else:\n                myFrame = self.getFrame(self.frameName)\n\n            while readyCount < self.busyTuner and timeLeft > 0:\n                try:\n                    doc = myFrame.document\n                except:\n                    continue  # if the document never gets itself together this will timeout\n\n                if self._ie.Busy == False and self._docGetReadyState(doc) == 'complete':\n                    readyCount += 1\n                else:\n                    readyCount = 0\n\n                time.sleep(0.05)\n                timeLeft -= 1\n        except:\n            (ErrorType, ErrorValue, ErrorTB) = sys.exc_info()\n            print(sys.exc_info())\n            traceback.print_exc(ErrorTB)\n            return False\n        else:\n            return True"
            ],
            [
                145,
                165,
                "        try:\n            while readyCount < self.busyTuner and timeLeft > 0:\n                try:\n                    doc = self._ie.Document\n                except:\n                    continue  # if the document never gets itself together this will timeout\n\n                if self._ie.Busy == False and self._docGetReadyState(doc) == 'complete':\n                    readyCount += 1\n                else:\n                    readyCount = 0\n\n                time.sleep(0.05)\n                timeLeft -= 1\n        except:\n            (ErrorType, ErrorValue, ErrorTB) = sys.exc_info()\n            print(sys.exc_info())\n            traceback.print_exc(ErrorTB)\n            return False\n        else:\n            return True"
            ],
            [
                463,
                472,
                "        try:\n            myElements = self.getElementsList(tag, filter=None, elementList=None)\n            return myElements[indexNum]\n        except:\n            (ErrorType, ErrorValue, ErrorTB) = sys.exc_info()\n            print(sys.exc_info())\n            traceback.print_exc(ErrorTB)\n            return None\n        else:\n            return None"
            ],
            [
                1846,
                1853,
                "        try:\n            win32gui.MessageBox(0, string, \"Pausing test...\", 0)\n        except:\n            (ErrorType, ErrorValue, ErrorTB) = sys.exc_info()\n            print(sys.exc_info())\n            traceback.print_exc(ErrorTB)\n        else:\n            return True"
            ],
            [
                1863,
                1871,
                "        try:\n            self._ie.Quit()\n        except:\n            (ErrorType, ErrorValue, ErrorTB) = sys.exc_info()\n            print(sys.exc_info())\n            traceback.print_exc(ErrorTB)\n            return False\n        else:\n            return True"
            ],
            [
                1907,
                1915,
                "        try:\n            self._ie.Refresh()\n        except:\n            (ErrorType, ErrorValue, ErrorTB) = sys.exc_info()\n            print(sys.exc_info())\n            traceback.print_exc(ErrorTB)\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "12ff0de8ffb7139a9da152ffb634eeac61e1e12a",
        "matched_blocks": [
            [
                17,
                118,
                "try:\n    from calendarserver.tools.agent import AgentRealm\n    from calendarserver.tools.agent import InactivityDetector\n    from twistedcaldav.test.util import TestCase\n    from twisted.internet.task import Clock\n    from twisted.web.resource import IResource\n    from twisted.web.resource import ForbiddenResource\n\nexcept ImportError:\n    pass\n\nelse:\n    class FakeRecord(object):\n\n        def __init__(self, shortName):\n            self.shortNames = [shortName]\n\n    class AgentTestCase(TestCase):\n\n        def test_AgentRealm(self):\n            realm = AgentRealm(\"root\", [\"abc\"])\n\n            # Valid avatar\n            _ignore_interface, resource, ignored = realm.requestAvatar(\n                FakeRecord(\"abc\"), None, IResource\n            )\n            self.assertEquals(resource, \"root\")\n\n            # Not allowed avatar\n            _ignore_interface, resource, ignored = realm.requestAvatar(\n                FakeRecord(\"def\"), None, IResource\n            )\n            self.assertTrue(isinstance(resource, ForbiddenResource))\n\n            # Interface unhandled\n            try:\n                realm.requestAvatar(FakeRecord(\"def\"), None, None)\n            except NotImplementedError:\n                pass\n            else:\n                self.fail(\"Didn't raise NotImplementedError\")\n\n    class InactivityDectectorTestCase(TestCase):\n\n        def test_inactivity(self):\n            clock = Clock()\n\n            self.inactivityReached = False\n\n            def becameInactive():\n                self.inactivityReached = True\n\n            id = InactivityDetector(clock, 5, becameInactive)\n\n            # After 3 seconds, not inactive\n            clock.advance(3)\n            self.assertFalse(self.inactivityReached)\n\n            # Activity happens, pushing out the inactivity threshold\n            id.activity()\n            clock.advance(3)\n            self.assertFalse(self.inactivityReached)\n\n            # Time passes without activity\n            clock.advance(3)\n            self.assertTrue(self.inactivityReached)\n\n            id.stop()\n\n            # Verify a timeout of 0 does not ever fire\n            id = InactivityDetector(clock, 0, becameInactive)\n            self.assertEquals(clock.getDelayedCalls(), [])\n\n    class FakeRequest(object):\n\n        def getClientIP(self):\n            return \"127.0.0.1\"\n\n    class FakeOpenDirectory(object):\n\n        def returnThisRecord(self, response):\n            self.recordResponse = response\n\n        def getUserRecord(self, ignored, username):\n            return self.recordResponse\n\n        def returnThisAuthResponse(self, response):\n            self.authResponse = response\n\n        def authenticateUserDigest(\n            self, ignored, node, username, challenge, response, method\n        ):\n            return self.authResponse\n\n        ODNSerror = \"Error\"\n\n    class FakeCredentials(object):\n\n        def __init__(self, username, fields):\n            self.username = username\n            self.fields = fields\n            self.method = \"POST\""
            ],
            [
                52,
                57,
                "            try:\n                realm.requestAvatar(FakeRecord(\"def\"), None, None)\n            except NotImplementedError:\n                pass\n            else:\n                self.fail(\"Didn't raise NotImplementedError\")"
            ]
        ]
    },
    {
        "blob_id": "2fea730fbc2ed8ead8cdf20b0fe1527890efd6c7",
        "matched_blocks": [
            [
                193,
                200,
                "                try:\n                    M = len(self.indptr) - 1\n                    N = self.indices.max() + 1\n                except:\n                    raise ValueError('unable to infer matrix dimensions')\n                else:\n                    R,C = self.blocksize\n                    self.shape = (M*R,N*C)"
            ]
        ]
    },
    {
        "blob_id": "41812c6d4cc481ed2d7caedd0323b6ca88aa5b06",
        "matched_blocks": [
            [
                61,
                80,
                "        try:\n            info = await validate_input(self.hass, user_input)\n        except CannotConnect:\n            errors[\"base\"] = \"cannot_connect\"\n        except InvalidAuth:\n            errors[\"base\"] = \"invalid_auth\"\n        except Exception:  # pylint: disable=broad-except\n            _LOGGER.exception(\"Unexpected exception\")\n            errors[\"base\"] = \"unknown\"\n        else:\n\n            unique_id = info[\"customer_id\"]\n            await self.async_set_unique_id(unique_id)\n            self._abort_if_unique_id_configured()\n\n            return self.async_create_entry(\n                title=info[\"title\"],\n                data=user_input,\n                options=user_input,\n            )"
            ],
            [
                110,
                120,
                "            try:\n                info = await validate_input(self.hass, user_input)\n            except CannotConnect:\n                errors[\"base\"] = \"cannot_connect\"\n            except InvalidAuth:\n                errors[\"base\"] = \"invalid_auth\"\n            except Exception:  # pylint: disable=broad-except\n                _LOGGER.exception(\"Unexpected exception\")\n                errors[\"base\"] = \"unknown\"\n            else:\n                return self.async_create_entry(title=info[\"title\"], data=user_input)"
            ]
        ]
    },
    {
        "blob_id": "41c10352bc8fbef7d8d8f3bb4060e8703ddcdbca",
        "matched_blocks": [
            [
                799,
                808,
                "        try:\n            await asyncio.wait_for(interface.ready, timeout)\n        except BaseException as e:\n            self.logger.info(f\"couldn't launch iface {server} -- {repr(e)}\")\n            await interface.close()\n            return\n        else:\n            with self.interfaces_lock:\n                assert server not in self.interfaces\n                self.interfaces[server] = interface"
            ],
            [
                912,
                919,
                "        try:\n            await self.broadcast_transaction(tx)\n        except Exception as e:\n            self.logger.info(f'error: could not broadcast {name} {tx.txid()}, {str(e)}')\n            return False\n        else:\n            self.logger.info(f'success: broadcasting {name} {tx.txid()}')\n            return True"
            ]
        ]
    },
    {
        "blob_id": "dece0de38d388908615b7dfa117a5a0a64cc883f",
        "matched_blocks": [
            [
                5,
                10,
                "        try:\n            iterable = iter(o)\n        except TypeError:\n            pass\n        else:\n            return list(iterable)"
            ]
        ]
    },
    {
        "blob_id": "ce228e388e03e513a212179a0c88c60eeade94ab",
        "matched_blocks": [
            [
                28,
                37,
                "        try:\n            img_value = mc.pyvector()\n            self.mclient.Get(fn, img_value)\n            img_value_str = mc.ConvertBuffer(img_value)\n            img = pil_loader(img_value_str)\n        except:\n            print('Read image failed ({})'.format(fn))\n            return None\n        else:\n            return img"
            ]
        ]
    },
    {
        "blob_id": "885ef53bdcb3fe1c4d4b09f227f049a9f4407eaf",
        "matched_blocks": [
            [
                296,
                308,
                "    try:\n        exec(source_code, global_vars, local_vars)\n    except SyntaxError as err:\n        error_class = err.__class__.__name__\n        detail = err.args[0]\n        line_number = err.lineno\n    except Exception as err:\n        error_class = err.__class__.__name__\n        detail = err.args[0]\n        cl, exc, tb = sys.exc_info()\n        line_number = traceback.extract_tb(tb)[-1][1]\n    else:\n        return results"
            ]
        ]
    },
    {
        "blob_id": "3e6274f68a32a64cdaad8f145058730bafa63415",
        "matched_blocks": [
            [
                233,
                248,
                "    try:\n        # Explicitly open/close file to avoid ResourceWarning when\n        # tests are run in debug mode Python 3.\n        tmp = open(os.devnull, 'w')\n        p = sp.Popen([\"gcc\", \"-print-multiarch\"], stdout=sp.PIPE,\n                stderr=tmp)\n    except (OSError, DistutilsError):\n        # OSError if gcc is not installed, or SandboxViolation (DistutilsError\n        # subclass) if an old setuptools bug is triggered (see gh-3160).\n        pass\n    else:\n        triplet = str(p.communicate()[0].decode().strip())\n        if p.returncode == 0:\n            # gcc supports the \"-print-multiarch\" option\n            default_x11_lib_dirs += [os.path.join(\"/usr/lib/\", triplet)]\n            default_lib_dirs += [os.path.join(\"/usr/lib/\", triplet)]"
            ],
            [
                274,
                282,
                "    try:\n        f = __file__\n    except NameError:\n        f = sys.argv[0]\n    else:\n        sysfile = os.path.join(os.path.split(os.path.abspath(f))[0],\n                               fname)\n        if os.path.isfile(sysfile):\n            filenames.append(sysfile)"
            ],
            [
                286,
                293,
                "    try:\n        f = os.path.expanduser('~')\n    except KeyError:\n        pass\n    else:\n        user_file = os.path.join(f, fname)\n        if os.path.isfile(user_file):\n            filenames.append(user_file)"
            ]
        ]
    },
    {
        "blob_id": "e348f06c33c9ec3c83ccc95715ffab26b936fbaf",
        "matched_blocks": [
            [
                17,
                22,
                "try:\n    count = int(input(\"Give me a number:\"))\nexcept ValueError:\n    print(\"Thats not a number\")\nelse:\n    print(count * \"hello world\")"
            ]
        ]
    },
    {
        "blob_id": "f89f1ded358f684cfea5a04737b4a6369bd9f99b",
        "matched_blocks": [
            [
                38,
                53,
                "            try: \n                row_new, col_new = int(row_new), int(col_new)\n            \n            #if err\n            except ValueError as err:\n                print (\"err : \", err) \n\n            #if true, do this code\n            else:\n                \n                #if valid do it\n                if (knight.valid_move(possible_moves, row_new, col_new)):\n                    quit_inner_loop= True\n                #not valid, cannot move\n                else:\n                    print(\"not possible! Knight can only move in L\\n\")"
            ],
            [
                73,
                81,
                "        try: \n            row_new, col_new = int(row_new), int(col_new)\n        except ValueError as err:\n            print (\"err : \", err) \n        else:\n            #reset\n            knight.reset_board(row_new, col_new)\n            #show tour\n            knight.show_tour()"
            ]
        ]
    },
    {
        "blob_id": "cb57c6ba8f92e88518798d39afee69873a5fab85",
        "matched_blocks": [
            [
                114,
                119,
                "    try:\n        _, extension = filename.split(os.extsep, 1)\n    except ValueError:\n        six.raise_from(ValueError('no extension found in \"{}\"'.format(filepath)), None)\n    else:\n        return extension"
            ],
            [
                204,
                213,
                "        try:\n            chunk = obj.read(1)\n        except TypeError:  # read() doesn't take an argument\n            pass  # fall through to read & cast full stream\n        else:\n            if chunk and isinstance(chunk, bytes):  # contents are indeed bytes\n                reset_stream(obj)\n                return obj, None\n            else:\n                pass  # fall through to read & cast full stream"
            ],
            [
                229,
                235,
                "        try:\n            cloudpickle.dump(obj, bytestream)\n        except pickle.PicklingError:  # can't be handled by cloudpickle\n            pass\n        else:\n            bytestream.seek(0)\n            return bytestream, \"cloudpickle\""
            ],
            [
                249,
                255,
                "        try:\n            pickle.dump(obj, bytestream)\n        except pickle.PicklingError:  # can't be handled by pickle\n            six.raise_from(pickle.PicklingError(\"unable to serialize artifact\"), None)\n        else:\n            bytestream.seek(0)\n            return bytestream, \"pickle\""
            ],
            [
                238,
                247,
                "            try:\n                maybe_dependency(\"joblib\").dump(obj, bytestream)\n            except (\n                NameError,  # joblib not installed\n                pickle.PicklingError,\n            ):  # can't be handled by joblib\n                pass\n            else:\n                bytestream.seek(0)\n                return bytestream, \"joblib\""
            ]
        ]
    },
    {
        "blob_id": "d49e94360c568a42c2ce86ca6eb04f7da27d752b",
        "matched_blocks": [
            [
                316,
                321,
                "        try:\n            [_ for _ in nikto_parser._parse_db_line(line)]\n        except TypeError:\n            self.assertTrue(True)\n        else:\n            self.assertTrue(False)"
            ]
        ]
    },
    {
        "blob_id": "84579276ee1fb2606f7bcec64999a267eb075557",
        "matched_blocks": [
            [
                100,
                118,
                "    try:\n        encoded_img = np.fromstring(base64.b64decode(img), dtype = np.uint8)\n        img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n    except:\n        print('Open Error! Try again!')\n    else:\n        image, boxes, scores, classes = _decode.detect_image(img, True)\n        cv2.imwrite('predict.png',image)\n        with open('predict.png', 'rb') as img:\n            base64_string = base64.b64encode(img.read()).decode('utf-8')\n        count = collections.Counter(classes)\n        for key in tuple(count.keys()):  # \ub515\uc154\ub108\ub9ac \ud0a4 \uc774\ub984 \ubcc0\uacbd\n            count[jpy_classes[key]] = count.pop(key)\n\n        for key, value in count.items():\n            total += int(key[str(key).find('_') + 1:]) * value\n        result['result'] = count\n        result['total'] = total\n        result['image'] = base64_string"
            ],
            [
                154,
                172,
                "    try:\n        encoded_img = np.fromstring(base64.b64decode(img), dtype = np.uint8)\n        img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n    except:\n        print('Open Error! Try again!')\n    else:\n        image, boxes, scores, classes = _decode.detect_image(img, True) # predict \ubd80\ubd84\n        cv2.imwrite('predict.png',image)\n        with open('predict.png', 'rb') as img:\n            base64_string = base64.b64encode(img.read()).decode('utf-8')\n        count = collections.Counter(classes)\n        for key in tuple(count.keys()):  # \ub515\uc154\ub108\ub9ac \ud0a4 \uc774\ub984 \ubcc0\uacbd\n            count[krw_classes[key]] = count.pop(key)\n\n        for key, value in count.items():\n            total += int(key[str(key).find('_') + 1:]) * value\n        result['result'] = count\n        result['total'] = total\n        result['image'] = base64_string"
            ],
            [
                210,
                226,
                "    try:\n        image = cv2.imread(img)\n    except:\n        print('Open Error! Try again!')\n    else:\n        image, boxes, scores, classes = _decode.detect_image(image, True)\n        count = collections.Counter(classes)\n\n        for key in tuple(count.keys()):  # \ub515\uc154\ub108\ub9ac \ud0a4 \uc774\ub984 \ubcc0\uacbd\n            count[jpy_classes[key]] = count.pop(key)\n\n        for key, value in count.items():\n            total += int(key[str(key).find('_') + 1:]) * value\n        result['result'] = count\n        result['total'] = total\n        result['image'] = image\n        cv2.imwrite('result.png', image)"
            ]
        ]
    },
    {
        "blob_id": "5ebbe15bb9911e1201fd9360f032057df9bbc092",
        "matched_blocks": [
            [
                2663,
                2668,
                "        try:\n          dtype = input_list[0].dtype.base_dtype.name\n        except AttributeError:\n          pass\n        else:\n          self._set_dtype_policy(policy.Policy(dtype))"
            ]
        ]
    },
    {
        "blob_id": "2bb5fac73616b4a37023a254b2c2a5b63c8534af",
        "matched_blocks": [
            [
                12,
                21,
                "        try:\n            user = User.objects.get(username__iexact=credentials[\"username\"])\n        except (User.DoesNotExist, KeyError):\n            return None\n        else:\n            try:\n                if user.check_password(credentials[\"password\"]):\n                    return user\n            except KeyError:\n               return None "
            ],
            [
                27,
                37,
                "        try:\n            email_address = qs.get(email__iexact=credentials[\"username\"])\n        except (EmailAddress.DoesNotExist, KeyError):\n            return None\n        else:\n            user = email_address.user\n            try:\n                if user.check_password(credentials[\"password\"]):\n                    return user\n            except KeyError:\n                return None"
            ]
        ]
    },
    {
        "blob_id": "e3c17f28895491dcec2aebc562527606feb1b6ad",
        "matched_blocks": [
            [
                47,
                55,
                "        try:\n            data = response.json()\n        except ValueError:\n            response.raise_for_status()\n            raise\n        else:\n            if not data['success']:\n                raise Exception(data['error'])\n            return data['result']"
            ]
        ]
    },
    {
        "blob_id": "3544d7018fdd62c91f6a55c55590d3a100adfe92",
        "matched_blocks": [
            [
                33,
                80,
                "    try:\n        clean_name = filename.split('.')[0]\n        custom_config = {\n            'name': 'HFT' + '_' + config['market']['design'] + '_' + clean_name,\n            'display_name': 'High Frequency Trading ' + config['market']['design'] + ' ' + clean_name,\n            'exchange_host': config['market']['matching-engine-host'],\n            'number_of_groups': config['group']['number-of-groups'],\n            'players_per_group': config['group']['players-per-group'],\n            'speed_cost': config['parameters']['speed-cost'],\n            'num_demo_participants': config['demo']['number-of-participants'],\n            'fundamental_price': config['parameters']['fundamental-price'],\n            'initial_spread': config['parameters']['initial-spread'],\n            'max_spread': config['parameters']['max-spread'],\n            'initial_endowment': config['parameters']['initial-endowment'],\n            'session_length': config['parameters']['session-length'],\n            'app_sequence': ['hft_bcs']\n            }\n\n    except KeyError as e:\n        raise e\n        print('Failed to read custom configs %s.' % filename)\n        print('Check keys in config file.')\n    except: \n        print('Failed to read custom configs %s.' % filename)\n    else:\n        cfg_dir = os.path.join(os.getcwd(), config['files']['dir'], config['files']['folder'])\n        all_files = find_all(cfg_dir, '.csv')\n        for k, v in config['files']['investors'].items():\n            label = 'investors' + '_' + k\n            csv_name = collect.extract_name(v)\n            if csv_name not in all_files:\n                h = collect.headers(my_token) \n                data = collect.get(v, h)\n                collect.write(data, cfg_dir, csv_name)\n                print('Downloaded: %s.' % csv_name)\n            path = os.path.join(cfg_dir, csv_name)\n            custom_config.update({label: path})\n        for k, v in config['files']['jumps'].items():\n            label = 'jumps' + '_' + k\n            csv_name = collect.extract_name(v)\n            if csv_name not in all_files:\n                h = collect.headers(my_token) \n                data = collect.get(v, h)\n                collect.write(data, cfg_dir, csv_name)\n                print('Downloaded: %s.' % csv_name)\n            path = os.path.join(cfg_dir, csv_name)\n            custom_config.update({label: path})\n        print('Read custom configs %s.' % filename)"
            ],
            [
                20,
                26,
                "        try:\n            config = yaml.load(f)\n        except yaml.YAMLError as e:\n            config = False\n            raise (e)\n        else:\n            print('Found a custom config: %s.' % filename)"
            ]
        ]
    },
    {
        "blob_id": "9c4146cf8d2c46ce68c4b555792e4dfbf0abee79",
        "matched_blocks": [
            [
                1686,
                1693,
                "        try:\n            info = await self.downloader.extract_info(player.playlist.loop, search_query, download=False, process=True)\n\n        except Exception as e:\n            await self.safe_edit_message(search_msg, str(e), send_if_fail=True)\n            return\n        else:\n            await self.safe_delete_message(search_msg)"
            ]
        ]
    },
    {
        "blob_id": "e452bc13a03434c9d222f4461d20512f8a37aa01",
        "matched_blocks": [
            [
                167,
                177,
                "            try:\n                ncs_file_id = gcstools.get_objectId_at(self.time, product=\"ABI-L1b-RadC\", channel=channel)\n                rad_file = gcstools.copy_fromgcs(gcstools.GOES_PUBLIC_BUCKET, ncs_file_id, \"SatFiles/SatFile-\" + channel)\n\n                if VERBOSE_PRINT_MODE:\n                    print(\"Downloaded\", rad_file)\n\n            except:\n                return None\n            else:\n                return rad_file"
            ]
        ]
    },
    {
        "blob_id": "bd48767328d1904968baef929946d37d9b971dcd",
        "matched_blocks": [
            [
                170,
                176,
                "        try:\n            with df:\n                pass\n        except DiskFileNotOpen:\n            pass\n        else:\n            self.fail(\"Expected DiskFileNotOpen exception\")"
            ]
        ]
    },
    {
        "blob_id": "97c37aff4c9011d545041e6eae31ed60bd41ca37",
        "matched_blocks": [
            [
                41,
                48,
                "    try:\n        import torch\n    except ImportError:\n        pass\n    else:\n        torch.manual_seed(i)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(i)"
            ]
        ]
    },
    {
        "blob_id": "030e9dc5ed85b0863ffe3bb3c6bf471241706409",
        "matched_blocks": [
            [
                39,
                44,
                "        try:\n            retry(func)\n        except ClientError:\n            self.assertEqual(self.count, 5)\n        else:\n            self.fail(\"should have raised\")"
            ]
        ]
    },
    {
        "blob_id": "bac7da100bdffb4311f4f9773f9d16c5da4d46e5",
        "matched_blocks": [
            [
                887,
                893,
                "            try:\n                attr = getattr(self.model, name)\n            except AttributeError:\n                pass\n            else:\n                if isinstance(attr, property):\n                    names.append(name)"
            ]
        ]
    },
    {
        "blob_id": "0b72ded122399b000404bb6e0054f0f87a596751",
        "matched_blocks": [
            [
                238,
                250,
                "    try:\n        interpolate_ratio = float(interpolate_ratio)\n    except ValueError:\n        raise TypeError(\n            'Interpolate ratio is required to be a floating value.'\n            ' Conversion to float failed!'\n        )\n    else:\n        if interpolate_ratio > 1:\n            raise ValueError(\n                'Interpolate ratio should be Less than 1. '\n                'This is Interpolation. Not Extrapolation!'\n            )"
            ]
        ]
    },
    {
        "blob_id": "b7fdb6135f4d585564d5eac66ab930117025d742",
        "matched_blocks": [
            [
                10,
                15,
                "try:\n    import pymemcache\nexcept ImportError:\n    raise unittest.SkipTest(\"pymemcache is not installed\")\nelse:\n    del pymemcache"
            ],
            [
                81,
                89,
                "        try:\n            long\n        except NameError:\n            # python3\n            value = 100\n            expected_flags = memcache_lib.Flags.INTEGER\n        else:\n            value = long(100)\n            expected_flags = memcache_lib.Flags.LONG"
            ],
            [
                282,
                290,
                "        try:\n            long\n        except NameError:\n            # python3\n            value = 100\n            expected_flags = memcache_lib.PickleFlags.INTEGER\n        else:\n            value = long(100)\n            expected_flags = memcache_lib.PickleFlags.LONG"
            ]
        ]
    },
    {
        "blob_id": "eed2e86fcf85dea9d880cf25ac34ebad175a8ab3",
        "matched_blocks": [
            [
                109,
                116,
                "        try:\n            t = datetime.datetime.strptime(time_str, format)\n        except ValueError:\n            pass\n        else:\n            if scope == \"microsecond\":\n                t = t.replace(microsecond=microsecond)\n            return scope, t"
            ]
        ]
    },
    {
        "blob_id": "92c996b35a9a82edeafc7279ddc9bbebf54bbefc",
        "matched_blocks": [
            [
                691,
                696,
                "    try:\n        only_stage_int = int(args.only_stage)\n    except (ValueError, TypeError):\n        pass\n    else:\n        args.only_stage = only_stage_int"
            ],
            [
                436,
                441,
                "            try:\n                stage.select_params(selections, error_on_missing=True)\n            except KeyError:\n                pass\n            else:\n                successes += 1"
            ]
        ]
    },
    {
        "blob_id": "1b9178570ae0be6f917bce187507f570c3f43967",
        "matched_blocks": [
            [
                193,
                211,
                "    try:\n        bot.load_extension(f\"cogs.{extension}\")\n    except commands.errors.ExtensionNotFound:\n        return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc744 \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\")\n    except commands.errors.ExtensionAlreadyLoaded:\n        return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc740 \uc774\ubbf8 \ubd88\ub7ec\uc640\uc84c\uc2b5\ub2c8\ub2e4.\")\n    except commands.errors.NoEntryPointError:\n        return await ctx.send('\ud574\ub2f9 \ubaa8\ub4c8\uc5d0 setup() \ud568\uc218\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\"')\n    except commands.errors.ExtensionFailed:\n        return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc758 setup() \uc2e4\ud589\uc5d0 \uc2e4\ud328\ud588\uc2b5\ub2c8\ub2e4.\")\n    except Exception as e:\n        logger.exception(f\"Error while load cog {extension}\")\n        return await ctx.send(\n            \"\ubaa8\ub4c8\uc5d0 \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud588\uc2b5\ub2c8\ub2e4!\"\n            + f\"\\n > Exception Type : {type(e)}\"\n            + f\"\\n > Exception Content : {e}\"\n        )\n    else:\n        return await ctx.send(f\"> {extension} \ubaa8\ub4c8\uc744 \ub85c\ub4dc\ud588\uc2b5\ub2c8\ub2e4.\")"
            ],
            [
                218,
                230,
                "    try:\n        bot.unload_extension(f\"cogs.{extension}\")\n    except commands.errors.ExtensionNotLoaded:\n        return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc774 \ub85c\ub4dc\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n    except Exception as e:\n        logger.exception(f\"Error while load cog {extension}\")\n        return await ctx.send(\n            \"\ubaa8\ub4c8\uc5d0 \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud588\uc2b5\ub2c8\ub2e4!\"\n            + f\"\\n > Exception Type : {type(e)}\"\n            + f\"\\n > Exception Content : {e}\"\n        )\n    else:\n        return await ctx.send(f\"> {extension} \ubaa8\ub4c8\uc744 \uc5b8\ub85c\ub4dc\ud588\uc2b5\ub2c8\ub2e4.\")"
            ],
            [
                118,
                129,
                "        try:\n            with open(\n                file=config_file_name, mode=\"wt\", encoding=\"utf-8\"\n            ) as bot_config_file:\n                print(f\"token={token}\")\n                bot_config_file.write(f\"token={token}\")\n        except Exception as e:\n            print(\"[save_datas] > \uc624\ub958\uac00 \ubc1c\uc0dd\ud588\uc2b5\ub2c8\ub2e4!\")\n            print(e.with_traceback(e.__traceback__))\n            return \"**config.txt** \ud30c\uc77c\uc744 \uc800\uc7a5\ud558\ub294\ub370 \uc2e4\ud328\ud588\uc2b5\ub2c8\ub2e4!\", e\n        else:\n            print(f\"[save_datas] > {config_file_name}\ub97c \uc800\uc7a5\ud588\uc2b5\ub2c8\ub2e4!\")"
            ],
            [
                236,
                254,
                "        try:\n            bot.reload_extension(f\"cogs.{extension}\")\n        except commands.errors.ExtensionNotLoaded:\n            return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc774 \ub85c\ub4dc\ub418\uc9c0 \uc54a\uc558\uc2b5\ub2c8\ub2e4.\")\n        except commands.errors.ExtensionNotFound:\n            return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc744 \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\")\n        except commands.errors.NoEntryPointError:\n            return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc5d0 setup() \ud568\uc218\uac00 \uc5c6\uc2b5\ub2c8\ub2e4.\")\n        except commands.errors.ExtensionFailed:\n            return await ctx.send(\"\ud574\ub2f9 \ubaa8\ub4c8\uc758 setup() \uc2e4\ud589\uc5d0 \uc2e4\ud328\ud588\uc2b5\ub2c8\ub2e4.\")\n        except Exception as e:\n            logger.exception(f\"Error while load cog {extension}\")\n            return await ctx.send(\n                \"\ubaa8\ub4c8\uc5d0 \ubb38\uc81c\uac00 \ubc1c\uc0dd\ud588\uc2b5\ub2c8\ub2e4!\"\n                + f\"\\n > Exception Type : {type(e)}\"\n                + f\"\\n > Exception Content : {e}\"\n            )\n        else:\n            return await ctx.send(f\"> {extension} \ubaa8\ub4c8\uc744 \ub9ac\ub85c\ub4dc\ud588\uc2b5\ub2c8\ub2e4.\")"
            ]
        ]
    },
    {
        "blob_id": "cd535ee8c303fe947981ddd6240054a900435ce8",
        "matched_blocks": [
            [
                885,
                893,
                "            try:\n                raw_tx = self.network.run_from_another_thread(\n                    self.network.get_transaction(tx_hash, timeout=10))\n            except RequestTimedOut as e:\n                self.print_error(f'getting input txn from network timed out for {tx_hash}')\n                if not ignore_timeout:\n                    raise e\n            else:\n                tx = Transaction(raw_tx)"
            ],
            [
                1410,
                1416,
                "                try:\n                    addr2 = bitcoin.pubkey_to_address(txin_type, pubkey)\n                except NotImplementedError:\n                    pass\n                else:\n                    if self.db.has_imported_address(addr2):\n                        break"
            ]
        ]
    },
    {
        "blob_id": "c82fba8ab01d1d077471b17f9aead11553d75109",
        "matched_blocks": [
            [
                52,
                61,
                "        try:\n            get_credential = keyring.get_credential\n        except AttributeError:\n            pass\n        else:\n            logger.debug(\"Getting credentials from keyring for %s\", url)\n            cred = get_credential(url, username)\n            if cred is not None:\n                return cred.username, cred.password\n            return None"
            ]
        ]
    },
    {
        "blob_id": "2c45e21fffb55b1cad5bb77986402eea7d2ac6d4",
        "matched_blocks": [
            [
                86,
                99,
                "          try:\n            logger.info('\\nDownloading {}'.format(bootstrap_url))\n            # TODO: Capture the stdout of the fetcher, instead of letting it output\n            # to the console directly.\n            fetcher.download(bootstrap_url,\n                             listener=fetcher.ProgressListener().wrap(checksummer),\n                             path_or_fd=temp_path,\n                             timeout_secs=opts.bootstrap_fetch_timeout_secs)\n            logger.info('sha1: {}'.format(checksummer.checksum))\n          except fetcher.Error as e:\n            workunit.set_outcome(WorkUnit.FAILURE)\n            raise self.Error('Problem fetching the coursier bootstrap jar! {}'.format(e))\n          else:\n            workunit.set_outcome(WorkUnit.SUCCESS)"
            ]
        ]
    },
    {
        "blob_id": "a528ab42b50817339d31b862bfcedf826beed8cd",
        "matched_blocks": [
            [
                322,
                327,
                "    try:\n        q = L.before(p)\n    except ValueError:\n        print(\"Task: 4 Test:1 Correctly has an exception\")\n    else:\n        print(\"Task: 4 Test:1 Wrong! No exception\")"
            ],
            [
                328,
                333,
                "    try:\n        q = L2.before(p)\n    except ValueError:\n        print(\"Task: 4 Test:2 Correctly has an exception\")\n    else:\n        print(\"Task: 4 Test:2 Wrong! No exception\")"
            ],
            [
                336,
                344,
                "    try:\n        p = L.after(p)\n        p2 = L2.after(p2)\n        L += L2\n        p = L.before(p)\n    except ValueError:\n        print(\"Task: 4 Test:3 Wrong! There should be no exception\")\n    else:\n        print(\"Task: 4 Test:3 Correct, no exception\")"
            ],
            [
                345,
                350,
                "    try:\n        p2 = L2.before(p2)\n    except ValueError:\n        print(\"Task: 4 Test:4 Correctly has an exception\")\n    else:\n        print(\"Task: 4 Test:4 Wrong! No exception\")"
            ]
        ]
    },
    {
        "blob_id": "a0e16324ae6472e17a500fc003f29167c60af0f1",
        "matched_blocks": [
            [
                208,
                216,
                "        try:\n            TRADING_ENVIRONMENTS[environment]\n\n        except KeyError as err:  # noqa F841\n            logger.error(\"unkown environment %s\", environment)\n            raise KeyError(\"Unknown environment: {}\".format(environment))\n\n        else:\n            self.environment = environment"
            ]
        ]
    },
    {
        "blob_id": "7d460e74d46fd859249367c10120406c2cf0c1df",
        "matched_blocks": [
            [
                2,
                9,
                "\ttry:\n\t\tresult = m/n\n\texcept ZeroDivisionError:\n\t\tprint(\"not devided by zero\")\n\texcept:\n\t\tprint(\"raise error not by zerodivision\")\n\telse:\n\t\treturn result"
            ]
        ]
    },
    {
        "blob_id": "048eb7259bc442fe98c5f467df45c137bb3725cd",
        "matched_blocks": [
            [
                165,
                174,
                "        try:\n            subprocess = _subprocesses[self._executable]\n        except KeyError:\n            # Fine it was already removed from the cache.\n            pass\n        else:\n            # In the `!=` case there is already a new subprocess in place\n            # and we don't need to do anything here anymore.\n            if subprocess == self:\n                del _subprocesses[self._executable]"
            ],
            [
                150,
                155,
                "            try:\n                evaluator_id = self._evaluator_deletion_queue.pop()\n            except IndexError:\n                break\n            else:\n                self._send(evaluator_id, None)"
            ]
        ]
    },
    {
        "blob_id": "132f9d82eb8b31115fe7d76fe9d57fb3439e4fa5",
        "matched_blocks": [
            [
                85,
                100,
                "            try:\n                traversal = f.result()\n            except Exception as e:\n                future.set_exception(e)\n            else:\n                self.traversers = iter(traversal.traversers)\n                self.side_effects = traversal.side_effects\n                if cb:\n                    try:\n                        result = cb(self)\n                    except Exception as e:\n                        future.set_exception(e)\n                    else:\n                        future.set_result(result)\n                else:\n                    future.set_result(self)"
            ],
            [
                93,
                98,
                "                    try:\n                        result = cb(self)\n                    except Exception as e:\n                        future.set_exception(e)\n                    else:\n                        future.set_result(result)"
            ]
        ]
    },
    {
        "blob_id": "a7cd0c227a128b7a39f4db49d9085443bd6a2ca1",
        "matched_blocks": [
            [
                49,
                55,
                "        try:\n            wlbt.ConnectAny()\n        except wlbt.WalabotError as err:\n            input(\"- Connect Walabot and press 'Enter'.\")\n        else:\n            print('- Connection to Walabot established.')\n            return"
            ]
        ]
    },
    {
        "blob_id": "644f53da5330e99d42a57e2457baa4815d3cc52f",
        "matched_blocks": [
            [
                11,
                16,
                "try:\n    from .manager import GPUManager\nexcept ImportError as err:\n    print(err); gm = None\nelse:\n    gm = GPUManager()"
            ]
        ]
    },
    {
        "blob_id": "b563563bd985a3f9d737ea973f8314bd6fb8f40d",
        "matched_blocks": [
            [
                72,
                78,
                "        try:\n            tomlkit.parse(fp.read())\n        except ValueError:\n            # the file should be a requirements.txt if it not a TOML document.\n            return True\n        else:\n            return False"
            ]
        ]
    },
    {
        "blob_id": "ec5ec92df1c63c92af59fdcac77a7c240973bb0c",
        "matched_blocks": [
            [
                661,
                669,
                "        try:\n            requests.get(httpbin('relative-redirect', '50'))\n        except TooManyRedirects as e:\n            url = httpbin('relative-redirect', '20')\n            assert e.request.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 30\n        else:\n            pytest.fail('Expected redirect to raise TooManyRedirects but it did not')"
            ],
            [
                674,
                682,
                "        try:\n            s.get(httpbin('relative-redirect', '50'))\n        except TooManyRedirects as e:\n            url = httpbin('relative-redirect', '45')\n            assert e.request.url == url\n            assert e.response.url == url\n            assert len(e.response.history) == 5\n        else:\n            pytest.fail('Expected custom max number of redirects to be respected but was not')"
            ]
        ]
    },
    {
        "blob_id": "edbda326ea8cc86ed561de36cac7f9cfb7b215e5",
        "matched_blocks": [
            [
                255,
                260,
                "        try:\n            txId  = self.nodes[0].sendtoaddress(self.nodes[2].getnewaddress(), \"1f-4\")\n        except JSONRPCException as e:\n            assert(\"Invalid amount\" in e.error['message'])\n        else:\n            raise AssertionError(\"Must not parse invalid amounts\")"
            ]
        ]
    },
    {
        "blob_id": "67c750936dd4d66c5c4351cd71e8a30ae957b72b",
        "matched_blocks": [
            [
                8,
                20,
                "    try:\n        logger.debug('Main started.', extra={'main_name': main_name})\n        main_func(*args, **kwargs)\n    except Exception as e:\n        logger.critical('Unexpected exception in main.', exc_info=True, extra={\n            'main_name': main_name,\n            'event_type': EventType.TASK_CRASHED,\n            'exc_str': str(e),\n        })\n        logger.debug('Main finished: BAD.', extra={'main_name': main_name})\n        os._exit(1)\n    else:\n        logger.debug('Main finished: OK.', extra={'main_name': main_name})"
            ]
        ]
    },
    {
        "blob_id": "dd0084f18096bbc345a7cefa0fbf77bc8227e4d4",
        "matched_blocks": [
            [
                2414,
                2442,
                "        try:\n            d = c()\n            d._check_version()\n            pkgdep.append(d)\n        except DependencyException as e:\n            pkg_exc.append(e)\n            mlog.debug(str(e))\n        else:\n            pkg_exc.append(None)\n            details = d.log_details()\n            if details:\n                details = '(' + details + ') '\n            if 'language' in kwargs:\n                details += 'for ' + d.language + ' '\n\n            # if the dependency was found\n            if d.found():\n\n                info = []\n                if d.version:\n                    info.append(mlog.normal_cyan(d.version))\n\n                log_info = d.log_info()\n                if log_info:\n                    info.append('(' + log_info + ')')\n\n                mlog.log(type_text, mlog.bold(display_name), details + 'found:', mlog.green('YES'), *info)\n\n                return d"
            ],
            [
                1625,
                1633,
                "            try:\n                v = self.traceparser.vars[cmake]\n            except KeyError:\n                pass\n            else:\n                if len(v) == 1:\n                    return v[0]\n                elif v:\n                    return v"
            ]
        ]
    },
    {
        "blob_id": "f41d0214026ead1d8003886b6a76d15d7f9fd2d8",
        "matched_blocks": [
            [
                284,
                292,
                "            try:\n                method = router.allow_relation\n            except AttributeError:\n                # If the router doesn't have a method, skip to the next one.\n                pass\n            else:\n                allow = method(obj1, obj2, **hints)\n                if allow is not None:\n                    return allow"
            ],
            [
                264,
                272,
                "                try:\n                    method = getattr(router, action)\n                except AttributeError:\n                    # If the router doesn't have a method, skip to the next one.\n                    pass\n                else:\n                    chosen_db = method(model, **hints)\n                    if chosen_db:\n                        return chosen_db"
            ]
        ]
    },
    {
        "blob_id": "308265d321cee40072f7e45374d65e6f3a7d9041",
        "matched_blocks": [
            [
                44,
                53,
                "        try:\n            print('Start conversion to PDF')\n            wbs = excel.Workbooks.Open(newpath)\n            ws_index_list = [1]\n            wbs.WorkSheets(ws_index_list).Select()\n            wbs.ActiveSheet.ExportAsFixedFormat(0, completeName)\n        except com_error as e:\n            print('failed.')\n        else:\n            print('Succeeded.')"
            ]
        ]
    },
    {
        "blob_id": "1d3cd26709b6bfcfdb5df341574e0135c7dc84bc",
        "matched_blocks": [
            [
                245,
                273,
                "        try:\n            config.read(fabspath)\n        except:\n            self.statuslabel.set('File not in searchable format.')\n            self.status.config(background='red')\n        else:\n            self.mylist.delete(0, tk.END)\n            buf = io.StringIO()\n            searchkey = self.searchentry.get()\n            p = re.compile(searchkey)\n            searchres = configparser.ConfigParser()\n            for section in config.sections():\n                res = p.search(section)\n                if res is not None:\n                    if not section in searchres.sections():\n                        searchres.add_section(section)\n                    for k, v in config.items(section):\n                        searchres[section][k] = v\n                else:\n                    for k, v in config.items(section):\n                        res = p.search(k)\n                        if res is not None:\n                            if not section in searchres.sections():\n                                searchres.add_section(section)\n                            searchres[section][k]=v\n            searchres.write(buf)\n            c = buf.getvalue()\n            self.mylist.insert(tk.END, *c.splitlines())\n            buf.close()"
            ]
        ]
    },
    {
        "blob_id": "e63d5ee85f51bfe2e1f5687b3c76cef9d7f939f3",
        "matched_blocks": [
            [
                35,
                49,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "19dfd7afce5f0ba00fcd323c17c738d28bc345b3",
        "matched_blocks": [
            [
                123,
                143,
                "        try:\n            self.session.begin()\n\n            def _parse_master(master):\n                return '%s:%d' % (master.host, master.port)\n            masters = six.moves.map(_parse_master, self.masters)\n\n            domain_values = {\n                'designate_id': zone['id'],\n                'name': zone['name'].rstrip('.'),\n                'master': ','.join(masters),\n                'type': 'SLAVE',\n                'account': context.tenant\n            }\n\n            self._create(tables.domains, domain_values)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                self.session.rollback()\n        else:\n            self.session.commit()"
            ]
        ]
    },
    {
        "blob_id": "d3238509ecaea8d3e0a51a8943890b4578e5a8da",
        "matched_blocks": [
            [
                31,
                38,
                "    try:\n        int1 = int(value1)\n        int2 = int(value2)\n    except ValueError:\n        print(\"Please input two integer values\")\n    else:\n        result = int1 + int2\n        print(f\"Final result: {result}\")"
            ],
            [
                45,
                52,
                "    try:\n        int1 = int(value1)\n        int2 = int(value2)\n    except ValueError:\n        return(\"Please input two integer values\")\n    else:\n        result = int1 + int2\n        return(f\"Final result: {result}\")"
            ]
        ]
    },
    {
        "blob_id": "604c1e106f08e0be7286bba0d9ef1a3bc66b63e5",
        "matched_blocks": [
            [
                150,
                159,
                "        try:\n            response = req.get(self.base_url, params=self.params)\n            response.raise_for_status()\n        except HTTPError as http_err:\n            print('An http error occurred during the request: {}'.format(http_err))\n        except Exception as err:\n            print('An error occurred during the request: {}'.format(err))\n        else:\n            results = response.json()['results']\n            elevation_list = [result['elevation'] for result in results]"
            ]
        ]
    },
    {
        "blob_id": "3ac5c2036716fd233c20c1b5d0ed1d8bf60ea49a",
        "matched_blocks": [
            [
                372,
                383,
                "            try:\n                key.name = file_key\n                key.set_contents_from_string(filedata, headers, replace=True,\n                                             policy=self.default_acl)\n            except boto.exception.S3CreateError as e:\n                print(\"Failed: %s\" % e)\n            except Exception as e:\n                print(e)\n                raise\n            else:\n                self.upload_count += 1\n                self.uploaded_files.append(file_key)"
            ]
        ]
    },
    {
        "blob_id": "6f402e70790e857a892dd3c982f152b9d2b8fa41",
        "matched_blocks": [
            [
                106,
                111,
                "            try:\n                index = self._keys.index(key)\n            except ValueError:\n                raise KeyError(key)\n            else:\n                return self._fields[index]"
            ]
        ]
    },
    {
        "blob_id": "00e9e6495348ce4b459ed1169c43d36365bff6c5",
        "matched_blocks": [
            [
                24,
                33,
                "\t\ttry:\n\t\t\tkey = _winreg.CreateKey(_winreg.HKEY_CURRENT_USER,os.path.join(\"Volatile Environment\"))\n\t\t\t_winreg.SetValueEx(key, \"SYSTEMROOT\", 0, _winreg.REG_SZ,tempfile.gettempdir())\n\t\t\t_winreg.CloseKey(key)\n\t\texcept Exception as error:\n\t\t\tprint_error(\"Unable to create registry keys, exception was raised: {}\".format(error))\n\t\t\treturn False\n\t\telse:\n\t\t\tprint_success(\"Successfully created SYSTEMROOT key containing a new temp directory ({})\".format(\n\t\t\t\tos.path.join(tempfile.gettempdir())))"
            ],
            [
                86,
                93,
                "\t\ttry:\n\t\t\tkey = _winreg.CreateKey(_winreg.HKEY_CURRENT_USER, os.path.join(\"Volatile Environment\"))\n\t\t\t_winreg.DeleteValue(key, \"SYSTEMROOT\")\n\t\texcept Exception as error:\n\t\t\tprint_error(\"Unable to cleanup\")\n\t\t\treturn False\n\t\telse:\n\t\t\tprint_success(\"Successfully cleaned up, enjoy!\")"
            ]
        ]
    },
    {
        "blob_id": "606e7c9ee0d79351ab7e217de6f5110a63244578",
        "matched_blocks": [
            [
                59,
                65,
                "\t\ttry:\n\t\t\textension = petition.a['href']\n\t\texcept:\n\t\t\tcontinue\n\t\telse:\n\t\t\tTitles.append(smart_str(petition.a.get_text()))\n\t\t\tLinks.append(urljoin(\"https://petitions.whitehouse.gov\", str(extension)))"
            ]
        ]
    },
    {
        "blob_id": "1af7478a5ccc39c7e8958468814792161a1bd6df",
        "matched_blocks": [
            [
                61,
                66,
                "    try:\n      st = os.stat('rms.csv')\n    except FileNotFoundError:\n      fresh = True\n    else:\n      fresh = st.st_size == 0"
            ],
            [
                25,
                32,
                "      try:\n        yield RM(section, title, debug=debug, id=NEXT_ID)\n      except Exception as e:\n        row = '{}\\t{}\\n'.format(title, section_ix)\n        f_fail.write(row)\n        print('Exception:', e)\n      else:\n        NEXT_ID += 1"
            ]
        ]
    },
    {
        "blob_id": "0293deed129fef72391995067a35140aba165530",
        "matched_blocks": [
            [
                121,
                186,
                "        try:\n            nom_cible = arguments.split(\" \")[1]\n        except IndexError:\n            # Le joueur n'a pas donn\u00e9 de cible\n            if statut == CIBLE_OBLIGATOIRE:\n                acteur << \"|err|Vous devez pr\u00e9ciser une cible.|ff|\"\n                return\n            personnages = [p for p in acteur.salle.personnages if \\\n                    not p.est_mort()]\n            for personnage in personnages:\n                if acteur.est_masculin():\n                    if personnage is acteur:\n                        personnage << self.independant[\"aim\"]\n                    else:\n                        personnage.envoyer(formater(self.independant[\"oim\"]),\n                                acteur=acteur)\n                else:\n                    if personnage is acteur:\n                        personnage << self.independant[\"aif\"]\n                    else:\n                        personnage.envoyer(formater(self.independant[\"oif\"]),\n                                acteur=acteur)\n        else:\n            # Le joueur a pr\u00e9cis\u00e9 une cible\n            if statut == SANS_CIBLE:\n                acteur << \"|err|Cette attitude n'accepte pas de cible.|ff|\"\n                return\n            cible = None\n            personnages = [p for p in acteur.salle.personnages if \\\n                    not p.est_mort()]\n            for personnage in personnages:\n                nom_perso = personnage.get_nom_pour(acteur)\n                if acteur.peut_voir(personnage) and contient(nom_perso,\n                        nom_cible):\n                    cible = personnage\n            if cible is None:\n                acteur << \"|err|Vous ne voyez pas cette personne ici.|ff|\"\n                return\n            personnages = [p for p in acteur.salle.personnages if \\\n                    not p.est_mort()]\n            for personnage in personnages:\n                if acteur.est_masculin():\n                    if personnage is acteur:\n                        personnage.envoyer(formater(self.dependant[\"adm\"]),\n                                cible=cible)\n                    elif personnage is cible:\n                        personnage.envoyer(formater(self.dependant[\"idm\"]),\n                                acteur=acteur)\n                    else:\n                        personnage.envoyer(formater(self.dependant[\"odm\"]),\n                                acteur=acteur, cible=cible)\n                else:\n                    if personnage is acteur:\n                        personnage.envoyer(formater(self.dependant[\"adf\"]),\n                                cible=cible)\n                    elif personnage is cible:\n                        personnage.envoyer(formater(self.dependant[\"idf\"]),\n                                acteur=acteur)\n                    else:\n                        personnage.envoyer(formater(self.dependant[\"odf\"]),\n                                acteur=acteur, cible=cible)\n\n            if getattr(cible, \"script\", None):\n                cible.script[\"attitude\"].executer(cle=self.cle,\n                        personnage=acteur, pnj=cible,\n                        salle=personnage.salle)"
            ]
        ]
    },
    {
        "blob_id": "b98b5daca8f6e76fde1e08f8c2ad2abf8451feeb",
        "matched_blocks": [
            [
                62,
                76,
                "        try:\n            self.assertEqual(expected[\"code\"], res[\"code\"])\n            self.assertEqual(expected[\"msg\"], res[\"msg\"])\n            # \u6570\u636e\u5e93\u6821\u9a8c\n\n        except AssertionError as e:\n            print(\"\u9884\u671f\u7ed3\u679c\uff1a\", expected)\n            print(\"\u5b9e\u9645\u7ed3\u679c\uff1a\", res)\n            self.excel.write_data(row=row, column=8, value=\"\u672a\u901a\u8fc7\")\n            log.error(\"\u7528\u4f8b\uff1a{}\uff0c\u6267\u884c\u672a\u901a\u8fc7\".format(case[\"title\"]))\n            log.exception(e)\n            raise e\n        else:\n            self.excel.write_data(row=row, column=8, value=\"\u901a\u8fc7\")\n            log.info(\"\u7528\u4f8b\uff1a{}\uff0c\u6267\u884c\u672a\u901a\u8fc7\".format(case[\"title\"]))"
            ]
        ]
    },
    {
        "blob_id": "0cd8d0352aac4503bd838149359039fdf014e5b4",
        "matched_blocks": [
            [
                5419,
                5451,
                "        try:\n            np_res = np.power(to_np(base), to_np(np_exponent))\n            expected = torch.from_numpy(np_res) if isinstance(np_res, np.ndarray) else torch.tensor(np_res, dtype=base.dtype)\n        except ValueError as e:\n            err_msg = \"Integers to negative integer powers are not allowed.\"\n            self.assertEqual(str(e), err_msg)\n            out = torch.empty_like(base)\n            test_cases = [\n                lambda: base.pow(exponent),\n                lambda: base.pow_(exponent),\n                lambda: torch.pow(base, exponent),\n                lambda: torch.pow(base, exponent, out=out)\n            ]\n            for test_case in test_cases:\n                self.assertRaisesRegex(RuntimeError, err_msg, test_case)\n        else:\n            if isinstance(base, torch.Tensor):\n                actual = base.pow(exponent)\n                self.assertEqual(actual, expected.to(actual))\n                actual = base.clone()\n                if torch.can_cast(torch.result_type(base, exponent), base.dtype):\n                    actual2 = actual.pow_(exponent)\n                    self.assertEqual(actual, expected)\n                    self.assertEqual(actual2, expected)\n                else:\n                    self.assertRaisesRegex(RuntimeError, \"can't be cast\", lambda: actual.pow_(exponent))\n\n            actual = torch.pow(base, exponent)\n            self.assertEqual(actual, expected.to(actual))\n\n            actual2 = torch.pow(base, exponent, out=actual)\n            self.assertEqual(actual, expected.to(actual))\n            self.assertEqual(actual2, expected.to(actual))"
            ]
        ]
    },
    {
        "blob_id": "379920506f00a6100b9cf62b9c2416deb7b29b6f",
        "matched_blocks": [
            [
                660,
                667,
                "        try:\n            self.session.query(n1kv_models_v2.NetworkProfile).filter_by(\n                name=TEST_NETWORK_PROFILE['name']).one()\n        except s_exc.NoResultFound:\n            pass\n        else:\n            self.fail(\"Network Profile (%s) was not deleted\" %\n                      TEST_NETWORK_PROFILE['name'])"
            ],
            [
                740,
                747,
                "        try:\n            self.session.query(n1kv_models_v2.PolicyProfile).filter_by(\n                name=TEST_POLICY_PROFILE['name']).one()\n        except s_exc.NoResultFound:\n            pass\n        else:\n            self.fail(\"Policy Profile (%s) was not deleted\" %\n                      TEST_POLICY_PROFILE['name'])"
            ]
        ]
    },
    {
        "blob_id": "533a8674b5a0ea2d97c2032ad2269f7fe0835047",
        "matched_blocks": [
            [
                19,
                25,
                "\ttry:\n\t\tctx.check_tool('gcc')\n\t\tctx.check_cc(fragment='#include <gmp.h>\\nint main() {return 0;}\\n', uselib_store='GMP', lib='gmp')\n\texcept ctx.errors.ConfigurationError:\n\t\tctx.env.TRY_CGO = False\n\telse:\n\t\tctx.env.TRY_CGO = True"
            ]
        ]
    },
    {
        "blob_id": "aa5ad0a5045753fc57b1083cc7045dfdbed8480e",
        "matched_blocks": [
            [
                50,
                55,
                "        try:\n            first = next(contents)\n        except StopIteration:\n            return []\n        else:\n            return itertools.chain([first], contents)"
            ]
        ]
    },
    {
        "blob_id": "2beb5a9ca0b208f66b18b9b86dfdf1fe835c37a2",
        "matched_blocks": [
            [
                3,
                12,
                "    try:\n        pinfo = proc.as_dict(attrs=['name'])\n        \n    except psutil.NoSuchProcess:\n        pass\n    else:\n        # print(pinfo)\n        # print(\"coolio\")\n        if \"chrome.exe\" in pinfo: \n            print(\"found chrome\")"
            ]
        ]
    },
    {
        "blob_id": "493107f6249f3b275d36a9559c591ac5500a86a2",
        "matched_blocks": [
            [
                389,
                414,
                "        try:\n            callableObj(*args, **kwargs)\n        except excClass:\n            exc = sys.exc_info()[1]     # current exception\n            excMsg = str(exc)\n            if not msg:\n                # No message provided: any message is fine.\n                return\n            elif excMsg == msg:\n                # Message provided, and we got the right message: it passes.\n                return\n            else:\n                # Message provided, and it didn't match: fail!\n                raise self.failureException(\n                    \"Right exception, wrong message: got '%s' expected '%s'\" %\n                    (excMsg, msg)\n                    )\n        else:\n            if hasattr(excClass, '__name__'):\n                excName = excClass.__name__\n            else:\n                excName = str(excClass)\n            raise self.failureException(\n                \"Expected to raise %s, didn't get an exception at all\" %\n                excName\n                )"
            ]
        ]
    },
    {
        "blob_id": "30418f7fe776be05b32b38ce805283a468acc4a1",
        "matched_blocks": [
            [
                200,
                206,
                "        try:\n            dados.to_sql(con=con, name= table, if_exists='append')\n        except Exception as erro_insere:\n            print(\"Erro na inser\u00e7\u00e3o de dados.\")\n            print(erro_insere)\n        else:\n            print(\"Dados inseridos com sucesso!\")"
            ]
        ]
    },
    {
        "blob_id": "0d397371234c9823008e948ebac04d9d4d94813f",
        "matched_blocks": [
            [
                70,
                84,
                "      try:\n\n            open(name + \".txt\", \"r\")\n\n      except:\n\n            user = Account(name, pw, 0, \"\u521b\u5efa\u8d26\u6237\")\n            \n            user.record()\n\n            tkinter.messagebox.showinfo(\"\u63d0\u793a\", \"\u5403\u9897\u7cd6\")\n    \n      else:\n\n            tkinter.messagebox.showinfo(\"\u63d0\u793a\", \"\u5c0f\u670b\u53cb\u5403\u9897\u7cd6\u6e05\u9192\u4e00\u4e0b\")"
            ],
            [
                92,
                213,
                "      try:\n\n            f1 = open(name + \".txt\", \"r\")\n\n      except:\n\n            tkinter.messagebox.showinfo(\"\u63d0\u793a\", \"\u5c0f\u670b\u53cb\u5403\u9897\u7cd6\u6e05\u9192\u4e00\u4e0b\")\n    \n      else:\n\n            lines = f1.readlines()\n\n            line = lines[len(lines) - 1]\n\n            lineList = line.split(\",\")\n\n            password1=lineList[1]\n\n            if pw == password1:\n\n                balance1 = int(lineList[2])\n\n                user = Account(name, pw, balance1, \"\u767b\u5f55\u8d26\u6237\")\n\n                user.record()\n\n                tkinter.messagebox.showinfo(\"\u63d0\u793a\", \"\u5403\u9897\u7cd6\")\n\n                def checkMoney():\n\n                    user.check()\n                    user.record()\n\n                def savein():\n\n                    def savein2():\n\n                        money = entry10.get()\n\n                        money1 = int(money)\n\n                        user.save(money1)\n                        user.record()\n\n                        tkinter.messagebox.showinfo(\"\u63d0\u793a\", \"\u5b58\u50a8\u5b8c\u6210\")\n\n                        windows3.destroy()\n\n                    windows3 = tkinter.Tk()\n                    \n                    windows3.geometry(\"300x400\")\n                    \n                    label10 = tkinter.Label(windows3, text=\"\u5c0f\u670b\u53cb\u8981\u5b58\u591a\u5c11\u94b1\uff1f\", font=(\"\u6977\u4f53\",20))\n\n                    label10.pack(pady=20)\n\n                    entry10 = tkinter.Entry(windows3, font=(\"\u6977\u4f53\", 15))\n\n                    entry10.pack(pady=40)\n\n                    button10 = tkinter.Button(windows3, text=\"\u786e\u5b9a\", font=(\"\u6977\u4f53\", 15), command=savein2)\n\n                    button10.pack(pady=20)\n\n\n                def saveout():\n\n                    def saveout2():\n\n                        money2 = entry10.get()\n\n                        money3 = int(money2)\n\n                        user.withdraw(money3)\n\n                        user.record()\n\n                        tkinter.messagebox.showinfo(\"\u63d0\u793a\", \"\u53d6\u51fa\u5b8c\u6210\")\n\n                        windows3.destroy()\n\n                    windows3 = tkinter.Tk()\n                    \n                    windows3.geometry(\"300x400\")\n                    \n                    label10 = tkinter.Label(windows3, text=\"\u5c0f\u670b\u53cb\u8981\u53d6\u591a\u5c11\u94b1\uff1f\", font=(\"\u6977\u4f53\",20))\n\n                    label10.pack(pady=20)\n\n                    entry10 = tkinter.Entry(windows3, font=(\"\u6977\u4f53\", 15))\n\n                    entry10.pack(pady=40)\n\n                    button10 = tkinter.Button(windows3, text=\"\u786e\u5b9a\", font=(\"\u6977\u4f53\", 15), command=saveout2)\n\n                    button10.pack(pady=20)\n\n                window.destroy()\n\n                windows1=tkinter.Tk()\n\n                windows1.geometry(\"400x500\")\n\n                label4 = tkinter.Label(windows1, text=\"\u671d\u4fde\u94f6\u884c\", font=(\"\u6977\u4f53\",20))\n\n                label4.pack(pady=25)\n\n                button3 = tkinter.Button(windows1, text=\"\u67e5\u8be2\u91d1\u989d\", font=(\"\u6977\u4f53\", 15), width=25, command=checkMoney)\n\n                button3.pack(pady=12.5)\n\n                button4 = tkinter.Button(windows1, text=\"\u5b58\u94b1\", font=(\"\u6977\u4f53\", 15), width=25, command=savein)\n\n                button4.pack(pady=12.5)\n\n                button5 = tkinter.Button(windows1, text=\"\u53d6\u94b1\", font=(\"\u6977\u4f53\", 15), width=25, command=saveout)\n\n                button5.pack(pady=12.5)\n\n            else:\n\n                tkinter.messagebox.showinfo(\"\u63d0\u793a\", \"\u5c0f\u670b\u53cb\u5403\u9897\u7cd6\u6e05\u9192\u4e00\u4e0b\")"
            ]
        ]
    },
    {
        "blob_id": "912e0ef322d0210628742b89e0e9105897dc42f6",
        "matched_blocks": [
            [
                87,
                105,
                "    try:\n        result = pm.execute_notebook(\n            str(notebook_path / 'visualize.ipynb'),\n            str(results_path / ('visualize_%s_%s.ipynb' % (model_name, roi))),\n            parameters={'model_name': model_name,\n                        'roi': roi,\n                        'data_path': str(data_path),\n                        'fits_path': str(fits_path),\n                        'models_path': str(models_path),\n                        'fit_format': fit_format},\n            nest_asyncio=True)\n    except pm.PapermillExecutionError as e:\n        exception = '%s: %s' % (e.ename, e.evalue)\n    except Exception as e:\n        exception = str(e.split('\\n')[-1:])\n    else:\n        # Possible exception that was raised\n        # (or `None` if notebook completed successfully)\n        exception = str(result['metadata']['papermill']['exception'])"
            ]
        ]
    },
    {
        "blob_id": "74bdf10a442a66171caeec169fd0210e6291f897",
        "matched_blocks": [
            [
                717,
                726,
                "            try:\n                md_body = self.markup_body_for_title()\n            except NotImplementedError:\n                from warnings import warn\n                warn(_(\"PageBaseWithTitle subclass '%s' does not implement \"\n                        \"markdown_body_for_title()\")\n                        % type(self).__name__)\n            else:\n                from course.content import extract_title_from_markup\n                title = extract_title_from_markup(md_body)"
            ]
        ]
    },
    {
        "blob_id": "5035085d5fa98c6c8c83762321e5b68fd61cc965",
        "matched_blocks": [
            [
                103,
                114,
                "        try:\n            if mods is True:\n                self.c.execute('UPDATE apb_news_feed SET ShowMods = 1 WHERE ID = ?', [ctx.message.guild.id])\n                desc = 'Enabled moderators in news feed.'\n            else:\n                self.c.execute('UPDATE apb_news_feed SET ShowMods = 0 WHERE ID = ?', [ctx.message.guild.id])\n                desc = 'Disabled moderators in news feed.'\n        except Exception as e:\n            await ctx.send(embed=discord.Embed(title='Error', description=str(e), color=0xFF0000))\n        else:\n            self.connection.commit()\n            await self.apb_e(ctx, 'News Feed', description=desc)"
            ],
            [
                118,
                124,
                "        try:\n            self.c.execute('UPDATE apb_news_feed SET PostID = ? WHERE ID = ?', (post, ctx.message.guild.id))\n        except Exception as e:\n            await ctx.send(embed=discord.Embed(title='Error', description=str(e), color=0xFF0000))\n        else:\n            self.connection.commit()\n            await self.apb_e(ctx, 'News Feed', description='ID set to {}.'.format(post))"
            ],
            [
                133,
                139,
                "        try:\n            self.c.execute('DELETE FROM apb_news_feed WHERE ID = ?', [ctx.message.guild.id])\n        except Exception as e:\n            await ctx.send(embed=discord.Embed(title='Error', description=str(e), color=0xFF0000))\n        else:\n            self.connection.commit()\n            await self.apb_e(ctx, 'News Feed', 'Channel removed from this server.')"
            ],
            [
                143,
                155,
                "        try:\n            id = await utils.api_request(self.API_URL + 'tracker?limit=1')\n            self.c.execute('INSERT INTO apb_news_feed VALUES (?, ?, ?, ?)', \n                          (ctx.message.guild.id, ctx.message.channel.id, id[0]['p_id'], 1))\n        except sqlite3.IntegrityError as e:\n            self.c.execute('UPDATE apb_news_feed SET ChannelID = ? WHERE ID = ?', (ctx.message.channel.id, ctx.message.guild.id))\n            self.connection.commit()\n            await self.apb_e(ctx, 'News Feed', 'APB news Feed channel updated.')\n        except Exception as e:\n            await ctx.send(embed=discord.Embed(title='Error', description=str(e), color=0xFF0000))\n        else:\n            self.connection.commit()\n            await self.apb_e(ctx, 'News Feed', 'Channel set.')"
            ],
            [
                270,
                281,
                "                        try:\n                            await channel.send(embed=e)\n                        except discord.Forbidden:\n                            print(\"[DEBUG][nf] [{0}] No permissions in {1}\".format(guild, channel))\n                            continue\n                        except discord.HTTPException as e:\n                            print(\"[DEBUG][nf]HTTPError in {0} - {1}\".format(guild, str(e)))\n                            continue\n                        else:\n                            await asyncio.sleep(1)\n                            self.c.execute('UPDATE apb_news_feed SET PostID = ? WHERE ID = ?', (post['p_id'], server[0]))\n                            self.connection.commit()"
            ]
        ]
    },
    {
        "blob_id": "44fe79fbb348c1d9c0af23119b431138ca98e895",
        "matched_blocks": [
            [
                1735,
                1756,
                "    try:\n        # execute the command\n        log(\"Running cmd: {}\".format(cmd), lg.DEBUG)\n        command_line_process = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT\n        )\n        process_output, _ = command_line_process.communicate()\n        # process_output is now a string, not a file\n        log(process_output.decode(\"utf-8\"), lg.DEBUG)\n    except subprocess.CalledProcessError as exception:\n        log(\"Exception occured: \" + str(exception), lg.ERROR)\n        log(\"Trnsidf.exe failed\", lg.ERROR)\n        return False\n    else:\n        # Send trnsidf log to logger\n        pre, ext = os.path.splitext(idf)\n        log_file = pre + \".log\"\n        if os.path.isfile(log_file):\n            with open(log_file, \"r\") as f:\n                log(f.read(), lg.DEBUG)\n\n        return True"
            ]
        ]
    },
    {
        "blob_id": "80a26aad0a1f115f682e53ed5d47c9cbfd137809",
        "matched_blocks": [
            [
                4,
                11,
                "try:\n    from ansible_collections.ansible.utils.plugins.module_utils.common.argspec_validate import (\n        AnsibleArgSpecValidator,\n    )\nexcept ImportError:\n    ANSIBLE_UTILS_IS_INSTALLED = False\nelse:\n    ANSIBLE_UTILS_IS_INSTALLED = True"
            ]
        ]
    },
    {
        "blob_id": "236b2156772d0785fdcae77e42fa711d3fe46373",
        "matched_blocks": [
            [
                259,
                266,
                "        try:\n            self.getpeername()\n        except socket_error as e:\n            if e.errno != errno.ENOTCONN:\n                raise\n            connected = False\n        else:\n            connected = True"
            ]
        ]
    },
    {
        "blob_id": "79dab1b313f7161b197acacc9b5826ced4062250",
        "matched_blocks": [
            [
                279,
                287,
                "                try:\n                    func, args, comment = CMakeGrammar.parse_line(line)\n                except IncompleteStatementError as e:\n                    try:\n                        line = self.input.merge()\n                    except InputExhaustedError as iee:\n                        raise IncompleteStatementError(line)\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "bfdefe08dd0b296dabddf7eb07fcae3b98757968",
        "matched_blocks": [
            [
                997,
                1008,
                "    try:\n        np.zeros(tuple(), dtype=a.dtype).astype(bool)\n    except ValueError:\n        ######################################################\n        # Handle special cases where conversion to bool does #\n        # not work correctly.                                #\n        #                                                    #\n        # xref: https://github.com/numpy/numpy/issues/9479   #\n        ######################################################\n        return a.map_blocks(_isnonzero_vec, dtype=bool)\n    else:\n        return a.astype(bool)"
            ]
        ]
    },
    {
        "blob_id": "e5244ed55ad0d20c3eb61669a0c798d2268e73a3",
        "matched_blocks": [
            [
                360,
                390,
                "        try:\n            op_impl._exec(\n                self.new_table.insert(inline=True).from_select(\n                    list(\n                        k\n                        for k, transfer in self.column_transfers.items()\n                        if \"expr\" in transfer\n                    ),\n                    select(\n                        [\n                            transfer[\"expr\"]\n                            for transfer in self.column_transfers.values()\n                            if \"expr\" in transfer\n                        ]\n                    ),\n                )\n            )\n            op_impl.drop_table(self.table)\n        except:\n            op_impl.drop_table(self.new_table)\n            raise\n        else:\n            op_impl.rename_table(\n                self.temp_table_name, self.table.name, schema=self.table.schema\n            )\n            self.new_table.name = self.table.name\n            try:\n                for idx in self._gather_indexes_from_both_tables():\n                    op_impl.create_index(idx)\n            finally:\n                self.new_table.name = self.temp_table_name"
            ],
            [
                521,
                541,
                "        try:\n            if const.name in self.col_named_constraints:\n                col, const = self.col_named_constraints.pop(const.name)\n\n                for col_const in list(self.columns[col.name].constraints):\n                    if col_const.name == const.name:\n                        self.columns[col.name].constraints.remove(col_const)\n            else:\n                const = self.named_constraints.pop(const.name)\n        except KeyError:\n            if _is_type_bound(const):\n                # type-bound constraints are only included in the new\n                # table via their type object in any case, so ignore the\n                # drop_constraint() that comes here via the\n                # Operations.implementation_for(alter_column)\n                return\n            raise ValueError(\"No such constraint: '%s'\" % const.name)\n        else:\n            if isinstance(const, PrimaryKeyConstraint):\n                for col in const.columns:\n                    self.columns[col.name].primary_key = False"
            ]
        ]
    },
    {
        "blob_id": "c1df6bee7a57594a891bdba1e1db902dc79666e4",
        "matched_blocks": [
            [
                932,
                937,
                "                try:\n                    super(ErrorThread, self).run()\n                except Exception as e:\n                    self.err = e\n                else:\n                    self.err = None"
            ]
        ]
    },
    {
        "blob_id": "26e92b9177678434ca48a40592272521fdbbe32c",
        "matched_blocks": [
            [
                211,
                221,
                "                try:\n                    name_dict = self._input[group][name]\n                except KeyError:\n                    self._input[group][name] = node_dict.copy()\n                else:\n                    try:\n                        name_dict[tag].append(node_dict[tag])\n                    except AttributeError:\n                        name_dict[tag] = [self._input[group][name][tag], node_dict[tag]]\n                    except KeyError:\n                        name_dict.update(node_dict.copy())"
            ]
        ]
    },
    {
        "blob_id": "97fdf50452f500aacfe6aa9f9f4ad50ff5c7afa8",
        "matched_blocks": [
            [
                1129,
                1141,
                "            try:\n                port = support.find_unused_port()\n                f = self.loop.create_server(TestMyProto, host=None, port=port)\n                server = self.loop.run_until_complete(f)\n            except OSError as ex:\n                if ex.errno == errno.EADDRINUSE:\n                    try_count += 1\n                    self.assertGreaterEqual(5, try_count)\n                    continue\n                else:\n                    raise\n            else:\n                break"
            ],
            [
                1426,
                1432,
                "            try:\n                self.loop.call_soon(f.cancel)\n                yield from f\n            except asyncio.CancelledError:\n                res = 'cancelled'\n            else:\n                res = None"
            ],
            [
                591,
                599,
                "                try:\n                    sock = socket.socket(family=family, type=type, proto=proto)\n                    sock.setblocking(False)\n                    self.loop.run_until_complete(\n                        self.loop.sock_connect(sock, address))\n                except:\n                    pass\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "cf8a07d53af33d06af5399179b10a8f8e3555698",
        "matched_blocks": [
            [
                66,
                79,
                "    try:\n        user = User.objects.get(email=resp['email'])\n    except User.DoesNotExist:\n        new_user = User(\n            email=resp['email'],\n            token=generate_random_state(),\n            uclapi_token=uclapi_token\n        )\n        new_user.save()\n        token = new_user.token\n    else:\n        user.uclapi_token = uclapi_token\n        user.save()\n        token = user.token"
            ]
        ]
    },
    {
        "blob_id": "d90feeec0cf1e25edfe727db09975732e8a0dda1",
        "matched_blocks": [
            [
                22,
                46,
                "    try:\n        x = int(x)\n    except ValueError:\n        print(\"Parameter Error\")\n    else:\n        a = x - 3500\n        if a <= 0:\n            x = 0\n        elif a <= 1500:\n            x = a*0.03\n        elif a <= 4500:\n            x = a*0.10 - 105\n        elif a <= 9000:\n            x = a*0.20 - 555\n        elif a <= 35000:\n            x = a*0.25 - 1005\n        elif a <= 55000:\n            x = a*0.30 - 2755\n        elif a <= 80000:\n            x = a*0.35 - 5505\n        else:\n            x = a*0.45 - 13505\n        # print(format(x,\".2f\"))\n        result = format(a-x,\".2f\")\n        return result"
            ]
        ]
    },
    {
        "blob_id": "b38817766b89821af82682c902835de7d8f40f4e",
        "matched_blocks": [
            [
                125,
                154,
                "                try:\n                    hints = get_type_hints(func)\n                except NameError as exc:\n                    if forward_refs_policy is ForwardRefPolicy.ERROR:\n                        raise\n\n                    typename = str(exc).split(\"'\", 2)[1]\n                    for param in self.signature.parameters.values():\n                        if param.annotation == typename:\n                            break\n                    else:\n                        raise\n\n                    func_name = function_name(func)\n                    if forward_refs_policy is ForwardRefPolicy.GUESS:\n                        if param.name in self.arguments:\n                            argtype = self.arguments[param.name].__class__\n                            if param.annotation == argtype.__qualname__:\n                                func.__annotations__[param.name] = argtype\n                                msg = ('Replaced forward declaration {!r} in {} with {!r}'\n                                       .format(param.annotation, func_name, argtype))\n                                # warn(TypeHintWarning(msg))\n                                continue\n\n                    msg = 'Could not resolve type hint {!r} on {}: {}'.format(\n                        param.annotation, function_name(func), exc)\n                    # warn(TypeHintWarning(msg))\n                    del func.__annotations__[param.name]\n                else:\n                    break"
            ]
        ]
    },
    {
        "blob_id": "cc6235a3bc1a7e6fbd38b073bc939afc294370fa",
        "matched_blocks": [
            [
                134,
                170,
                "    try:\n        #Provide the contents of the email.\n        sndmessage = {\"Subject\" : {\"Data\" : SUBJECT}, \"Body\" : {\"Html\":{\"Data\": message}}}\n        print(SENDER,\"Is the sender \")\n        resp = client.send_email(Source = SENDER, Destination = {\"ToAddresses\":[RECIPIENT]},Message = sndmessage)\n        # response = client.send_email(\n        #     Destination={\n        #         'ToAddresses': [\n        #             RECIPIENT,\n        #         ],\n        #     },\n        #     Message={\n        #         'Body': {\n        #             'Html': {\n        #                 'Charset': CHARSET,\n        #                 'Data': BODY_TEXT,\n        #             },\n        #             # 'Text': {\n        #             #     'Charset': CHARSET,\n        #             #     'Data': BODY_TEXT,\n        #             # },\n        #         },\n        #         'Subject': {\n        #             'Charset': CHARSET,\n        #             'Data': SUBJECT,\n        #         },\n        #     },\n        #     Source=SENDER,\n        #     # If you are not using a configuration set, comment or delete the\n        #     # following line\n        #     #ConfigurationSetName=CONFIGURATION_SET,\n        # )\n    # Display an error if something goes wrong.\t\n    except ClientError as e:\n        print(e.response['Error']['Message'])\n    else:\n        print(\"Email sent! Message ID:\"),"
            ]
        ]
    },
    {
        "blob_id": "9ccf726a27b27f4a0c424dd9ae299bdcb0d028d1",
        "matched_blocks": [
            [
                68,
                80,
                "        try:\n            mapping = self.federation_api.get_mapping_from_idp_and_protocol(\n                identity_provider, protocol)\n            utils.validate_groups(group_ids, mapping['id'], self.identity_api)\n\n        except Exception:\n            # NOTE(topol): Diaper defense to catch any exception, so we can\n            # send off failed authentication notification, raise the exception\n            # after sending the notification\n            send_notification(taxonomy.OUTCOME_FAILURE)\n            raise\n        else:\n            send_notification(taxonomy.OUTCOME_SUCCESS)"
            ],
            [
                99,
                125,
                "        try:\n            mapped_properties = self._apply_mapping_filter(identity_provider,\n                                                           protocol,\n                                                           assertion)\n\n            group_ids = mapped_properties['group_ids']\n            if not user_id:\n                user_id = parse.quote(mapped_properties['name'])\n\n        except Exception:\n            # NOTE(topol): Diaper defense to catch any exception, so we can\n            # send off failed authentication notification, raise the exception\n            # after sending the notification\n            outcome = taxonomy.OUTCOME_FAILURE\n            notifications.send_saml_audit_notification('authenticate', context,\n                                                       user_id, group_ids,\n                                                       identity_provider,\n                                                       protocol, token_id,\n                                                       outcome)\n            raise\n        else:\n            outcome = taxonomy.OUTCOME_SUCCESS\n            notifications.send_saml_audit_notification('authenticate', context,\n                                                       user_id, group_ids,\n                                                       identity_provider,\n                                                       protocol, token_id,\n                                                       outcome)"
            ]
        ]
    },
    {
        "blob_id": "7106bdd7bd76b366f3a5012cc3defca666dde15c",
        "matched_blocks": [
            [
                87,
                94,
                "        try:\n            key = self.request.POST[\"button-pressed\"]\n        except:\n            # Going back\n            return reverse( self.success_view_back )\n        else:\n            if key == self.submit_back:\n                return reverse( self.success_view_back )"
            ]
        ]
    },
    {
        "blob_id": "5d332208a35402181ac92cc431f0b48bcfe862f3",
        "matched_blocks": [
            [
                429,
                454,
                "            try:\n                PdfTranstorm(['-o', os.path.join(con.get_filepath(), \"Input/StudentEssay\", title + '.txt'), '-t', 'text',\n                              os.path.join(stuessay_folder_path, title + '.pdf')])\n            except FileNotFoundError:\n                print('not found error')\n                print(name)\n                print(title)\n                not_found[name] = title\n            except pdfminer.pdfparser.PDFSyntaxError:\n                print('type error')\n                print(name)\n                print(title)\n                type_error[name] = title\n            except pdfminer.pdfdocument.PDFTextExtractionNotAllowed:\n                print('type error')\n                print(name)\n                print(title)\n                type_error[name] = title\n            except KeyError:\n                print('type error')\n                print(name)\n                print(title)\n                type_error[name] = title\n            else:\n                print(name)\n                print(title)"
            ],
            [
                461,
                477,
                "            try:\n                translate_text_filepath = os.path.join(con.get_filepath(), \"Input/StudentEssay\", title + '_en' + '.txt')\n                translate_file = open(translate_text_filepath, encoding='utf-8')\n            except FileNotFoundError:\n                print('********File not found:*********')\n                print(sname)\n                print(title)\n            else:\n                translate_text = translate_file.read()[0:10000]\n\n                # store to the database\n                student = Student.objects.get(pk=id)\n                essay = StudentEssay(student=student, student_essay_title=title, student_essay_text=translate_text)\n                essay.save()\n                print('#########Save file:###########')\n                print(name)\n                print(title)"
            ]
        ]
    },
    {
        "blob_id": "f4b104fbb804cced47dea3c5e3e4161237f09897",
        "matched_blocks": [
            [
                121,
                127,
                "        try:\n            self.config_updater.add_network(network)\n        except AttributeError:\n            pass\n        else:\n            if self.started():\n                self.wpa_supplicant_interface.add_network(network)"
            ],
            [
                130,
                137,
                "        try:\n            self.config_updater.remove_network(network)\n        except AttributeError:\n            pass\n        else:\n            if self.started():\n                self.wpa_supplicant_interface.remove_network(\n                    self.find_network_path(network))"
            ],
            [
                247,
                254,
                "        try:\n            self.start_network_connection(network)\n            self.wait_untill_connection_complete()\n            self.check_correct_connection(network)\n        except RuntimeError:\n            return False\n        else:\n            return True"
            ]
        ]
    },
    {
        "blob_id": "2d2d33b1f96726237fe2033b2cfd6180cb799052",
        "matched_blocks": [
            [
                83,
                88,
                "\t\t\ttry:\n\t\t\t\tobj = Resource(context, obj, obj[path[0]])\n\t\t\texcept KeyError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tyield path.popleft(), obj, False"
            ]
        ]
    },
    {
        "blob_id": "d6d303cedd84db4470ca30532c6d89f672112ebe",
        "matched_blocks": [
            [
                70,
                80,
                "    try:\n        result = graph.extend_access_token(fb_client_id, fb_secret)\n    except facebook.GraphAPIError as e:\n        token_fail()\n        return None\n    else:\n        token = result['access_token']\n        graph.access_token = token\n        with open('token.txt', 'w') as f:\n            f.write(token)\n        return graph"
            ]
        ]
    },
    {
        "blob_id": "48d29e49f638e23330bba5f940d018e15dbbec3f",
        "matched_blocks": [
            [
                1262,
                1267,
                "        try:\n            tmp = __import__('pywikibot.site', fromlist=[interface])\n        except ImportError:\n            raise ValueError('Invalid interface name: {0}'.format(interface))\n        else:\n            interface = getattr(tmp, interface)"
            ]
        ]
    },
    {
        "blob_id": "e92679c255ce676bae7e6868834fe6023ca5f1ac",
        "matched_blocks": [
            [
                3,
                12,
                "        try:\n            pos = pos.split(',')\n            x = int(pos[0])\n            y = int(pos[1])\n        except ValueError:\n            print(\"Ingrese una posicion valida: {}\".format(err))\n            return False\n        else:\n            if x < len(tab) and y < len(tab):\n                return True"
            ]
        ]
    },
    {
        "blob_id": "91aaf6d522486538a0edfd27de42e4a83a77f21e",
        "matched_blocks": [
            [
                37,
                42,
                "        try:\n            self.connection.connect()\n        except socket.error:\n            self.connected = False\n        else:\n            self.connected = True"
            ]
        ]
    },
    {
        "blob_id": "66fb18b232e15f8099bca9f755e4890ec7409310",
        "matched_blocks": [
            [
                407,
                437,
                "            try:\n                function = pickle.loads(serialized_function)\n            except Exception:\n                # If an exception was thrown when the remote function was\n                # imported, we record the traceback and notify the scheduler\n                # of the failure.\n                traceback_str = format_error_message(traceback.format_exc())\n                # Log the error message.\n                push_error_to_driver(\n                    self._worker,\n                    ray_constants.REGISTER_REMOTE_FUNCTION_PUSH_ERROR,\n                    \"Failed to unpickle the remote function '{}' with \"\n                    \"function ID {}. Traceback:\\n{}\".format(\n                        function_name, function_id.hex(), traceback_str),\n                    job_id=job_id)\n            else:\n                # The below line is necessary. Because in the driver process,\n                # if the function is defined in the file where the python\n                # script was started from, its module is `__main__`.\n                # However in the worker process, the `__main__` module is a\n                # different module, which is `default_worker.py`\n                function.__module__ = module\n                self._function_execution_info[job_id][function_id] = (\n                    FunctionExecutionInfo(\n                        function=function,\n                        function_name=function_name,\n                        max_calls=max_calls))\n                # Add the function to the function table.\n                self._worker.redis_client.rpush(\n                    b\"FunctionTable:\" + function_id.binary(),\n                    self._worker.worker_id)"
            ],
            [
                772,
                801,
                "            try:\n                if is_class_method(method):\n                    method_returns = method(*args)\n                else:\n                    method_returns = method(actor, *args)\n            except Exception as e:\n                # Save the checkpoint before allowing the method exception\n                # to be thrown, but don't save the checkpoint for actor\n                # creation task.\n                if (isinstance(actor, ray.actor.Checkpointable)\n                        and self._worker.actor_task_counter != 1):\n                    self._save_and_log_checkpoint(actor)\n                raise e\n            else:\n                # Handle any checkpointing operations before storing the\n                # method's return values.\n                # NOTE(swang): If method_returns is a pointer to the actor's\n                # state and the checkpointing operations can modify the return\n                # values if they mutate the actor's state. Is this okay?\n                if isinstance(actor, ray.actor.Checkpointable):\n                    # If this is the first task to execute on the actor, try to\n                    # resume from a checkpoint.\n                    if self._worker.actor_task_counter == 1:\n                        if actor_imported:\n                            self._restore_and_log_checkpoint(actor)\n                    else:\n                        # Save the checkpoint before returning the method's\n                        # return values.\n                        self._save_and_log_checkpoint(actor)\n                return method_returns"
            ]
        ]
    },
    {
        "blob_id": "7fb1431805a2635501a50347f3d7057d774baf73",
        "matched_blocks": [
            [
                125,
                132,
                "                    try:\n                        index = int(index)\n                    except ValueError:\n                        datalist = \"\"\n                    else:\n                        # @ToDo: Check permissions to the Resource & do\n                        # something different if no permission\n                        datalist = self._datalist(r, widgets[index], **attr)"
            ],
            [
                140,
                147,
                "                    try:\n                        index = int(index)\n                    except ValueError:\n                        datalist = \"\"\n                    else:\n                        # @ToDo: Check permissions to the Resource & do\n                        # something different if no permission\n                        datatable = self._datatable(r, widgets[index], **attr)"
            ]
        ]
    },
    {
        "blob_id": "112fd981158748991a48d8ebb03eccee576aac14",
        "matched_blocks": [
            [
                182,
                206,
                "    try:\n        new_venue=Venue(\n                        name=form.name.data,\n                        city=form.city.data,\n                        state=form.state.data,\n                        address=form.address.data,\n                        phone=form.phone.data,\n                        website=form.website.data,\n                        facebook_link=form.facebook_link.data,\n                        image_link=form.image_link.data,\n                        seeking_talent=form.seeking_talent.data,\n                        talent_description=form.talent_description.data,\n                        genres=form.genres.data\n        )\n        db.session.add(new_venue)\n        db.session.commit()\n        flash('Venue ' + form.name.data + ' was successfully listed!')\n    except ValueError as e:  # FIXME melhorar essa exception\n        print(e)\n        flash('An error occurred. Venue ' + form.name.data + ' could not be listed.')\n    else:\n        message = []\n        for f, e in form.errors.items():\n            message.append(f + ' ' + '|'.join(e))\n        flash('Errors ' + str(message))"
            ]
        ]
    },
    {
        "blob_id": "dc3da40a24b2c90af1c89062bab67142c5a9f5b4",
        "matched_blocks": [
            [
                321,
                338,
                "        try:\n            gc_transport = self._transport._collect\n        except AttributeError:\n            _timeo = socket.getdefaulttimeout()\n            socket.setdefaulttimeout(socket_timeout)\n            try:\n                self._close()\n            except socket.timeout:\n                pass\n            finally:\n                socket.setdefaulttimeout(_timeo)\n        else:\n            gc_transport(self._connection)\n            if self._transport:\n                self._transport.client = None\n                self._transport = None\n            self.declared_entities.clear()\n            self._connection = None"
            ],
            [
                875,
                891,
                "                try:\n                    R = self._resource.get(block=block, timeout=timeout)\n                except Empty:\n                    self._add_when_empty()\n                else:\n                    try:\n                        R = self.prepare(R)\n                    except BaseException:\n                        if isinstance(R, lazy):\n                            # no evaluated yet, just put it back\n                            self._resource.put_nowait(R)\n                        else:\n                            # evaluted so must try to release/close first.\n                            self.release(R)\n                        raise\n                    self._dirty.add(R)\n                    break"
            ]
        ]
    },
    {
        "blob_id": "95f240d772e4fc8a6220a0ea7f1493ffbde2014d",
        "matched_blocks": [
            [
                87,
                98,
                "            try:\n                if int(time.time() % 30) == 0:\n                    # Set a 30 second ping to keep connection alive\n                    self.ws.ping(\"keepalive\")\n                data = self.ws.recv()\n                msg = json.loads(data)\n            except ValueError as e:\n                self.on_error(e)\n            except Exception as e:\n                self.on_error(e)\n            else:\n                self.on_message(msg)"
            ]
        ]
    },
    {
        "blob_id": "50f104e0f6bb819ed7e3260cd1671e57d0744183",
        "matched_blocks": [
            [
                48,
                72,
                "                try:\n                    subst1.try_add_variable('i2.2.1.1', tmp3)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 37236\n                    if len(subjects2) >= 1:\n                        tmp5 = subjects2.popleft()\n                        subst2 = Substitution(subst1)\n                        try:\n                            subst2.try_add_variable('i2.2.1.2', tmp5)\n                        except ValueError:\n                            pass\n                        else:\n                            pass\n                            # State 37237\n                            if len(subjects2) == 0:\n                                pass\n                                # State 37238\n                                if len(subjects) == 0:\n                                    pass\n                                    # 0: x**j\n                                    yield 0, subst2\n                        subjects2.appendleft(tmp5)"
            ],
            [
                58,
                71,
                "                        try:\n                            subst2.try_add_variable('i2.2.1.2', tmp5)\n                        except ValueError:\n                            pass\n                        else:\n                            pass\n                            # State 37237\n                            if len(subjects2) == 0:\n                                pass\n                                # State 37238\n                                if len(subjects) == 0:\n                                    pass\n                                    # 0: x**j\n                                    yield 0, subst2"
            ]
        ]
    },
    {
        "blob_id": "8dd3bb853f8f0ec562974058a226e570a8bb1911",
        "matched_blocks": [
            [
                6,
                14,
                "\t\ttry:\n\t\t\tans = yield i\n\t\texcept GeneratorExit:\n\t\t\tprint('--closing--')\n\t\t\traise\n\t\texcept Exception as e:\n\t\t\tprint('--yield raised %r' %e)\n\t\telse:\n\t\t\tprint('---yield return %s---'%ans)"
            ]
        ]
    },
    {
        "blob_id": "207c577ed1ee76edafe72b980b2ea2969cde7e9b",
        "matched_blocks": [
            [
                116,
                126,
                "    try:\n        (ret, err) = gdaltest.runexternal_out_and_err('curl')\n    except :\n        print('no curl executable')\n    else:\n        #make sure script is responding\n        handle = gdaltest.gdalurlopen(\"http://puma.nerc.ac.uk/cgi-bin/cf-checker.pl\")\n        if handle is not None:\n            success = True\n        else:\n            print('script not responding')"
            ]
        ]
    },
    {
        "blob_id": "3cb40ddc889b811b456775bfa2e352fa0859f757",
        "matched_blocks": [
            [
                64,
                71,
                "try:\n\tfrom xml.sax import make_parser\n\tfrom xml.sax.handler import ContentHandler\nexcept ImportError:\n\thas_xml = False\n\tContentHandler = object\nelse:\n\thas_xml = True"
            ],
            [
                636,
                667,
                "\ttry:\n\t\tif self.environ.get('QT5_XCOMPILE'):\n\t\t\tself.fatal('QT5_XCOMPILE Disables pkg-config detection')\n\t\tself.check_cfg(atleast_pkgconfig_version='0.1')\n\texcept self.errors.ConfigurationError:\n\t\tfor i in self.qt5_vars:\n\t\t\tuselib = i.upper()\n\t\t\tif Utils.unversioned_sys_platform() == 'darwin':\n\t\t\t\t# Since at least qt 4.7.3 each library locates in separate directory\n\t\t\t\tfwk = i.replace('Qt5', 'Qt')\n\t\t\t\tframeworkName = fwk + '.framework'\n\n\t\t\t\tqtDynamicLib = os.path.join(env.QTLIBS, frameworkName, fwk)\n\t\t\t\tif os.path.exists(qtDynamicLib):\n\t\t\t\t\tenv.append_unique('FRAMEWORK_' + uselib, fwk)\n\t\t\t\t\tenv.append_unique('FRAMEWORKPATH_' + uselib, env.QTLIBS)\n\t\t\t\t\tself.msg('Checking for %s' % i, qtDynamicLib, 'GREEN')\n\t\t\t\telse:\n\t\t\t\t\tself.msg('Checking for %s' % i, False, 'YELLOW')\n\t\t\t\tenv.append_unique('INCLUDES_' + uselib, os.path.join(env.QTLIBS, frameworkName, 'Headers'))\n\t\t\telse:\n\t\t\t\tfor j in ('', 'd'):\n\t\t\t\t\tk = '_DEBUG' if j == 'd' else ''\n\t\t\t\t\tret = self.find_single_qt5_lib(i + j, uselib + k, env.QTLIBS, qtincludes, force_static)\n\t\t\t\t\tif not force_static and not ret:\n\t\t\t\t\t\tret = self.find_single_qt5_lib(i + j, uselib + k, env.QTLIBS, qtincludes, True)\n\t\t\t\t\tself.msg('Checking for %s' % (i + j), ret, 'GREEN' if ret else 'YELLOW')\n\telse:\n\t\tpath = '%s:%s:%s/pkgconfig:/usr/lib/qt5/lib/pkgconfig:/opt/qt5/lib/pkgconfig:/usr/lib/qt5/lib:/opt/qt5/lib' % (\n\t\t\tself.environ.get('PKG_CONFIG_PATH', ''), env.QTLIBS, env.QTLIBS)\n\t\tfor i in self.qt5_vars_debug + self.qt5_vars:\n\t\t\tself.check_cfg(package=i, args='--cflags --libs', mandatory=False, force_static=force_static, pkg_config_path=path)"
            ],
            [
                139,
                159,
                "\t\ttry:\n\t\t\treturn moc_cache[h_node]\n\t\texcept KeyError:\n\t\t\ttsk = moc_cache[h_node] = Task.classes['moc'](env=self.env, generator=self.generator)\n\t\t\ttsk.set_inputs(h_node)\n\t\t\ttsk.set_outputs(m_node)\n\t\t\ttsk.env.append_unique('MOC_FLAGS', '-i')\n\n\t\t\tif self.generator:\n\t\t\t\tself.generator.tasks.append(tsk)\n\n\t\t\t# direct injection in the build phase (safe because called from the main thread)\n\t\t\tgen = self.generator.bld.producer\n\t\t\tgen.outstanding.appendleft(tsk)\n\t\t\tgen.total += 1\n\n\t\t\treturn tsk\n\n\t\telse:\n\t\t\t# remove the signature, it must be recomputed with the moc task\n\t\t\tdelattr(self, 'cache_sig')"
            ],
            [
                168,
                176,
                "\t\ttry:\n\t\t\t# compute the signature once to know if there is a moc file to create\n\t\t\tself.signature()\n\t\texcept KeyError:\n\t\t\t# the moc file may be referenced somewhere else\n\t\t\tpass\n\t\telse:\n\t\t\t# remove the signature, it must be recomputed with the moc task\n\t\t\tdelattr(self, 'cache_sig')"
            ],
            [
                445,
                450,
                "\t\ttry:\n\t\t\tself.check(features='qt5 cxx', use=uses, uselib_store='qt5', cxxflags=flag, fragment=frag, msg=msg)\n\t\texcept self.errors.ConfigurationError:\n\t\t\tpass\n\t\telse:\n\t\t\tbreak"
            ],
            [
                491,
                503,
                "\t\ttry:\n\t\t\tlst = Utils.listdir('/usr/local/Trolltech/')\n\t\texcept OSError:\n\t\t\tpass\n\t\telse:\n\t\t\tif lst:\n\t\t\t\tlst.sort()\n\t\t\t\tlst.reverse()\n\n\t\t\t\t# keep the highest version\n\t\t\t\tqtdir = '/usr/local/Trolltech/%s/' % lst[0]\n\t\t\t\tqtbin = os.path.join(qtdir, 'bin')\n\t\t\t\tpaths.append(qtbin)"
            ],
            [
                510,
                524,
                "\t\ttry:\n\t\t\tqmake = self.find_program(qmk, path_list=paths)\n\t\texcept self.errors.ConfigurationError:\n\t\t\tpass\n\t\telse:\n\t\t\ttry:\n\t\t\t\tversion = self.cmd_and_log(qmake + ['-query', 'QT_VERSION']).strip()\n\t\t\texcept self.errors.WafError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tif version:\n\t\t\t\t\tnew_ver = version.split('.')\n\t\t\t\t\tif new_ver > prev_ver:\n\t\t\t\t\t\tcand = qmake\n\t\t\t\t\t\tprev_ver = new_ver"
            ],
            [
                528,
                539,
                "\t\ttry:\n\t\t\tself.find_program('qtchooser')\n\t\texcept self.errors.ConfigurationError:\n\t\t\tpass\n\t\telse:\n\t\t\tcmd = self.env.QTCHOOSER + ['-qt=5', '-run-tool=qmake']\n\t\t\ttry:\n\t\t\t\tversion = self.cmd_and_log(cmd + ['-query', 'QT_VERSION'])\n\t\t\texcept self.errors.WafError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tcand = cmd"
            ],
            [
                515,
                524,
                "\t\t\ttry:\n\t\t\t\tversion = self.cmd_and_log(qmake + ['-query', 'QT_VERSION']).strip()\n\t\t\texcept self.errors.WafError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tif version:\n\t\t\t\t\tnew_ver = version.split('.')\n\t\t\t\t\tif new_ver > prev_ver:\n\t\t\t\t\t\tcand = qmake\n\t\t\t\t\t\tprev_ver = new_ver"
            ],
            [
                534,
                539,
                "\t\t\ttry:\n\t\t\t\tversion = self.cmd_and_log(cmd + ['-query', 'QT_VERSION'])\n\t\t\texcept self.errors.WafError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tcand = cmd"
            ],
            [
                553,
                559,
                "\t\t\ttry:\n\t\t\t\tret = self.find_program(f, path_list=paths)\n\t\t\texcept self.errors.ConfigurationError:\n\t\t\t\tpass\n\t\t\telse:\n\t\t\t\tenv[var]=ret\n\t\t\t\tbreak"
            ]
        ]
    },
    {
        "blob_id": "8492ab1885125bf4d93aea0f397a3fc3038c96f0",
        "matched_blocks": [
            [
                247,
                282,
                "\t\t\ttry:\n\t\t\t\tdevice = ConnectHandler(**self.connectionData)\n\t\t\texcept ssh_exception.NetMikoAuthenticationException:\n\t\t\t\tself.log['flag'], self.log['description'] = 'ERROR', 'BAD_AUTH'\n\t\t\texcept ssh_exception.NetMikoTimeoutException:\n\t\t\t\tself.log['flag'], self.log['description'] = 'ERROR', 'TIMEOUT'\n\t\t\texcept ValueError:\n\t\t\t\tself.log['flag'], self.log['description'] = 'ERROR', 'VALUE'\n\t\t\texcept ConnectionRefusedError:\n\t\t\t\tself.log['flag'], self.log['description'] = 'ERROR', 'REFUSED'\n\t\t\texcept paramiko.ssh_exception.SSHException:\n\t\t\t\tself.log['flag'], self.log['description'] = 'ERROR', 'SSH'\n\t\t\telse:\n\t\t\t\tif device:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tif mode == 'CONFIGURE':\n\t\t\t\t\t\t\tself.log['output'] = [{'in':self.input , 'out': device.send_config_set(self.input)}]\n\t\t\t\t\t\telif mode == 'SHOW':\n\t\t\t\t\t\t\tdevice.enable()\n\t\t\t\t\t\t\tt_outs = []\n\t\t\t\t\t\t\tcmds = self.input.splitlines()\n\t\t\t\t\t\t\tfor cmd in cmds:\n\t\t\t\t\t\t\t\twhile True:\n\t\t\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\t\t\tt_out = {'in':cmd, 'out':device.send_command_expect(cmd)}\n\t\t\t\t\t\t\t\t\texcept IOError:\n\t\t\t\t\t\t\t\t\t\tprint('{0} - Trying Again - \\\"{1}\\\"'.format(self.id, cmd))\n\t\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t\tt_outs.append(t_out)\n\t\t\t\t\t\t\tself.log['output'] = t_outs\n\t\t\t\t\t\tself.log['flag'], self.log['description'] = 'PASS', 'ADMINISTERED'\n\t\t\t\t\texcept ValueError:\n\t\t\t\t\t\tself.log['flag'], self.log['description'] = 'ERROR', 'MANUAL_REQUIRED'\n\t\t\t\t\tfinally:\n\t\t\t\t\t\tdevice.disconnect()"
            ],
            [
                270,
                275,
                "\t\t\t\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\t\t\t\tt_out = {'in':cmd, 'out':device.send_command_expect(cmd)}\n\t\t\t\t\t\t\t\t\texcept IOError:\n\t\t\t\t\t\t\t\t\t\tprint('{0} - Trying Again - \\\"{1}\\\"'.format(self.id, cmd))\n\t\t\t\t\t\t\t\t\telse:\n\t\t\t\t\t\t\t\t\t\tbreak"
            ]
        ]
    },
    {
        "blob_id": "0743fab55b7760c26dc13b3922aea2a97eec77c6",
        "matched_blocks": [
            [
                4,
                13,
                "    try:\n      for filePath in filePaths:\n        files.append(open(filePath))\n        files[-1].__enter__()\n    except:\n      for file in files:\n        file.close()\n      raise\n    else:\n      return super(Files, cls).__new__(cls, files)"
            ]
        ]
    },
    {
        "blob_id": "407b3f94215afed0e227e50576eb5621eeda8a80",
        "matched_blocks": [
            [
                120,
                127,
                "    try:\n        import psyco\n        psyco.full()\n    except ImportError:\n        #print(\"(psyco not found)\")\n        pass\n    else:\n        print(\"(using psyco)\")"
            ]
        ]
    },
    {
        "blob_id": "da33ecd6cb5985519aebc9f35185190401aabb93",
        "matched_blocks": [
            [
                211,
                217,
                "        try:\n            i = rule.index(pattern)\n        except ValueError:\n            return False\n        else:\n            rule[i:i+1] = replacement\n            return True"
            ],
            [
                319,
                330,
                "        try:\n            i = rule.index(\"%%LOGTYPE%%\")\n        except ValueError:\n            pass\n        else:\n            if log_denied == \"off\":\n                return \"\"\n            if log_denied in [ \"unicast\", \"broadcast\", \"multicast\" ]:\n                rule[i:i+1] = [ \"-m\", \"pkttype\", \"--pkt-type\",\n                                self._log_denied ]\n            else:\n                rule.pop(i)"
            ],
            [
                234,
                244,
                "            try:\n                i = rule.index(\"%%LOGTYPE%%\")\n            except ValueError:\n                pass\n            else:\n                if log_denied == \"off\":\n                    continue\n                if log_denied in [ \"unicast\", \"broadcast\", \"multicast\" ]:\n                    rule[i:i+1] = [ \"-m\", \"pkttype\", \"--pkt-type\", log_denied ]\n                else:\n                    rule.pop(i)"
            ],
            [
                520,
                525,
                "            try:\n                int(ret_args[idx+2])\n            except Exception:\n                pass\n            else:\n                ret_args.pop(idx+2)"
            ],
            [
                190,
                204,
                "                try:\n                    i = rule.index(opt)\n                except ValueError:\n                    pass\n                else:\n                    if len(rule) > i and \",\" in rule[i+1]:\n                        # For all items in the comma separated list in index\n                        # i of the rule, a new rule is created with a single\n                        # item from this list\n                        processed = True\n                        items = rule[i+1].split(\",\")\n                        for item in items:\n                            _rule = rule[:]\n                            _rule[i+1] = item\n                            out_rules.append(_rule)"
            ],
            [
                249,
                256,
                "                try:\n                    i = rule.index(opt)\n                except ValueError:\n                    pass\n                else:\n                    if len(rule) >= i+1:\n                        rule.pop(i)\n                        table = rule.pop(i)"
            ]
        ]
    },
    {
        "blob_id": "2f74550eee3b61364afe945ef1a2305a830feba9",
        "matched_blocks": [
            [
                32,
                37,
                "        try:\n            GroupMember.objects.create(user=self.request.user, group=group)\n        except IntegrityError:\n            messages.warning(self.request, 'Warning already a member!')\n        else:\n            messages.success(self.request, 'You are now a member!')"
            ],
            [
                47,
                56,
                "        try:\n            membership = models.GroupMember.objects.filter(\n                user=self.request.user,\n                group__slug = self.kwargs.get('slug')\n            ).get()\n        except models.GroupMember.DoesNotExist:\n            messages.warning(self.request, 'Sorry you are not in this group!')\n        else:\n            membership.delete()\n            messages.success(self.request, 'You have left the group!')"
            ]
        ]
    },
    {
        "blob_id": "c7f23e04c537d3542ee5b97a31d971acef2abc92",
        "matched_blocks": [
            [
                1710,
                1715,
                "            try:\n                f = open(filename, \"wb\")\n            except UnicodeEncodeError:\n                pytest.skip(\"No unicode file names on this system\")\n            else:\n                f.close()"
            ]
        ]
    },
    {
        "blob_id": "826e0cec2f2c532e1a1a11b0b59549a07ebdb131",
        "matched_blocks": [
            [
                54,
                61,
                "    try:\n        parser.feed(response.text)\n        parser.close()\n    except AssertionError as exc:\n        print(f\"failed on {url}: {exc}\", file=sys.stderr)\n        return None\n    else:\n        return parser.title"
            ]
        ]
    },
    {
        "blob_id": "6a11cd0704d373ae0318e5fa1158159b20680a53",
        "matched_blocks": [
            [
                12,
                21,
                "try:\n    lines = open(args.file_name, \"r\").readlines()\n    line = lines[args.line_number-1]\nexcept IndexError:\n    print(\n        f\"Error: file '{args.file_name}' doesn't have {args.line_number} lines.\")\nexcept IOError as err:\n    print(f\"Error: {err}\")\nelse:\n    print(line)"
            ]
        ]
    },
    {
        "blob_id": "c0395ae8c764be3538ff42329cb0ec8ce6c29320",
        "matched_blocks": [
            [
                127,
                132,
                "        try:\n            body.decode(encoding)\n        except Exception:\n            pass\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "c4002149a9e54b72ec67810a5c0b0c42b4a02a9c",
        "matched_blocks": [
            [
                902,
                918,
                "    try:\n        args = parser.parse_args()\n    except SystemExit:\n        print()\n        print(\"| Tidak ada nama folder yang diberikan!\")\n        print(\"| Usage: python tubes.py <nama_folder>\")\n        quit(0)\n    else:\n        folder = args.nama_folder\n        path = f\"{os.getcwd()}\\{folder}\"  # os.getcwd() menghasilkan current working directory\n        try:\n            os.chdir(path)  # change current working directory\n        except FileNotFoundError:\n            print(\"Folder tidak ditemukan!\")\n            quit(0)\n        else:\n            return folder"
            ],
            [
                656,
                668,
                "        try :\n            jml = int(input(\"Jumlah: \"))\n        except ValueError:\n            print(\"Masukan tidak valid!\")\n            return arr_m, arr_ch\n        else:\n            if jml > int(arr_m[r_idx][3]) and jml>0:\n                print(f\"Permintaan tidak dapat dipenuhi\")\n                print(f\"Jumlah item tersisa : {arr_m[r_idx][3]}\")\n                return arr_m, arr_ch\n            elif jml<=0:\n                print(\"Masukan tidak valid!\")\n                return arr_m, arr_ch"
            ],
            [
                912,
                918,
                "        try:\n            os.chdir(path)  # change current working directory\n        except FileNotFoundError:\n            print(\"Folder tidak ditemukan!\")\n            quit(0)\n        else:\n            return folder"
            ],
            [
                456,
                464,
                "            try:\n                np = int(input(\"Masukan nomor peminjaman: \"))\n            except ValueError:\n                return arr2\n            else:\n                if np >= 1 and np <= (len(arr_IDGL)):\n                    break\n                else:\n                    print(\"Masukan salah!\")"
            ]
        ]
    },
    {
        "blob_id": "cff687a347f49ee8992090cf8a85cbf4532d8cb3",
        "matched_blocks": [
            [
                41,
                55,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "3e4d99f36c8c903cccb781857fee3486693f6ec6",
        "matched_blocks": [
            [
                36,
                49,
                "try:\n    for i in range(len(chunked_tweet_ids)):\n        with r.connect(**rdb_config) as conn:\n            for tweet in api.statuses_lookup(chunked_tweet_ids[i]):\n                r.table('tweets').get(tweet._json['id_str']).update(\n                    {\n                        'retweet_count': tweet._json['retweet_count'],\n                        'favorite_count': tweet._json['favorite_count']\n                    }\n                ).run(conn)\nexcept Exception as e:\n  logging.warning(\"Error updating Tweets. Error message: %s\", e)\nelse:\n    logging.info(\"Successfully updated %i Tweets\",  len(tweet_ids))"
            ]
        ]
    },
    {
        "blob_id": "22859e0b853568f75ae6bbc76b5c61b6efa9d418",
        "matched_blocks": [
            [
                3185,
                3196,
                "                try:\n                    d, canceller = self.liveMessages[m.id]\n                except KeyError:\n                    self.controller.messageReceived(m, self)\n                else:\n                    del self.liveMessages[m.id]\n                    canceller.cancel()\n                    # XXX we shouldn't need this hack\n                    try:\n                        d.callback(m)\n                    except:\n                        log.err()"
            ]
        ]
    },
    {
        "blob_id": "47d0e5c6b547de20522174c63798dfbb17512f28",
        "matched_blocks": [
            [
                54,
                66,
                "            try:\n                p = Popen(['msgfmt', po, '-o', mo],\n                    stdout=PIPE, stderr=PIPE)\n            except OSError:\n                raise SkipTest  # most likely msgfmt was not found\n            else:\n                stdout, stderr = p.communicate()\n                if p.returncode != 0:\n                    print(stdout)\n                    print(stderr)\n                    assert False, \\\n                        'msgfmt exited with return code %s' % p.returncode\n                assert mo.isfile(), 'msgfmt failed'"
            ]
        ]
    },
    {
        "blob_id": "2bd8cd32bed4a8f740e40a2060a83cf5fca54860",
        "matched_blocks": [
            [
                32,
                39,
                "        try:\n            driver.Driver.find_alert(self._driver, 10)\n        except:\n            print('alert_check error')\n        else:\n            alert = driver.Driver.switch_alert(self._driver)\n            print('alert message: \"' + alert.text + '\"')\n            alert.accept()"
            ]
        ]
    },
    {
        "blob_id": "fe2ee0f64ec32b9f652e28d29290c7c783b2b564",
        "matched_blocks": [
            [
                6,
                11,
                "            try:\n                return float(input(msg))\n            except ValueError:\n                print(\"You must enter a number!\")\n            else:\n                break"
            ]
        ]
    },
    {
        "blob_id": "1964e0c84997dc06216559dea1e176820e36b65f",
        "matched_blocks": [
            [
                135,
                142,
                "            try:\n                from wsgiref import validate\n            except ImportError:\n                warnings.warn(\n                    'Error importing wsgiref. The validator will not run.')\n            else:\n                # wraps the app in the validator\n                app = validate.validator(app)"
            ],
            [
                532,
                538,
                "                try:\n                    pid = self.get_pid()\n                except IOError:\n                    # Assume the subprocess deleted the pidfile on shutdown.\n                    pass\n                else:\n                    os.waitpid(pid, 0)"
            ]
        ]
    },
    {
        "blob_id": "599fa0522ac0ba238bcc71cb79861ed29fe9e974",
        "matched_blocks": [
            [
                150,
                163,
                "    try:\n        utils.execute('e2fsck',\n                      '-fp',\n                      image,\n                      check_exit_code=[0, 1, 2],\n                      run_as_root=run_as_root)\n    except processutils.ProcessExecutionError as exc:\n        LOG.debug(\"Checking the file system with e2fsck has failed, \"\n                  \"the resize will be aborted. (%s)\", exc)\n    else:\n        utils.execute('resize2fs',\n                      image,\n                      check_exit_code=check_exit_code,\n                      run_as_root=run_as_root)"
            ]
        ]
    },
    {
        "blob_id": "a21cd50ff84bf17e33ed4d8b5dbd364b0385e51f",
        "matched_blocks": [
            [
                57,
                65,
                "        try:\n            weights = fc_state_dict[weights_key]\n        except Exception as e:\n            print(e)\n        else:\n            assert weights.size() == torch.Size([self.classnum, self.feat_dim]), \\\n                'weights.size can not match with (classnum, feat_dim)'\n            self.centers = weights\n            print('Fetch the center from fc-layer was finished ...')"
            ]
        ]
    },
    {
        "blob_id": "c023f7da0edb784a6a86eb4c386d6660cc631898",
        "matched_blocks": [
            [
                460,
                496,
                "    try:\n        fh = fp.fileno()\n        fp.flush()\n    except (AttributeError, io.UnsupportedOperation):\n        # compress to Python file-compatible object\n        for e, b, o, a in tile:\n            e = Image._getencoder(im.mode, e, a, im.encoderconfig)\n            if o > 0:\n                fp.seek(o, 0)\n            e.setimage(im.im, b)\n            if e.pushes_fd:\n                e.setfd(fp)\n                l, s = e.encode_to_pyfd()\n            else:\n                while True:\n                    l, s, d = e.encode(bufsize)\n                    fp.write(d)\n                    if s:\n                        break\n            if s < 0:\n                raise IOError(\"encoder error %d when writing image file\" % s)\n            e.cleanup()\n    else:\n        # slight speedup: compress to real file object\n        for e, b, o, a in tile:\n            e = Image._getencoder(im.mode, e, a, im.encoderconfig)\n            if o > 0:\n                fp.seek(o, 0)\n            e.setimage(im.im, b)\n            if e.pushes_fd:\n                e.setfd(fp)\n                l, s = e.encode_to_pyfd()\n            else:\n                s = e.encode_to_file(fh, bufsize)\n            if s < 0:\n                raise IOError(\"encoder error %d when writing image file\" % s)\n            e.cleanup()"
            ],
            [
                375,
                405,
                "            try:\n                try:\n                    fp = io.BytesIO(self.data)\n                    im = Image.open(fp)\n                finally:\n                    fp.close()  # explicitly close the virtual file\n            except IOError:\n                # traceback.print_exc()\n                pass  # not enough data\n            else:\n                flag = hasattr(im, \"load_seek\") or hasattr(im, \"load_read\")\n                if flag or len(im.tile) != 1:\n                    # custom load code, or multiple tiles\n                    self.decode = None\n                else:\n                    # initialize decoder\n                    im.load_prepare()\n                    d, e, o, a = im.tile[0]\n                    im.tile = []\n                    self.decoder = Image._getdecoder(\n                        im.mode, d, a, im.decoderconfig\n                        )\n                    self.decoder.setimage(im.im, e)\n\n                    # calculate decoder offset\n                    self.offset = o\n                    if self.offset <= len(self.data):\n                        self.data = self.data[self.offset:]\n                        self.offset = 0\n\n                self.image = im"
            ]
        ]
    },
    {
        "blob_id": "43b471d1eae663e9bfda27660210e8c6236673ee",
        "matched_blocks": [
            [
                31,
                45,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the question voting form.\n        return render(request, 'polls/detail.html', {\n            'question': question,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(question.id,)))"
            ]
        ]
    },
    {
        "blob_id": "09810c5937252a8983b9b1eaddcb8cb182a2ab12",
        "matched_blocks": [
            [
                14,
                27,
                "try:\n    from config import AD_DOMAIN, ADPASSWORD, ADUSERNAME, ADNameServer\n    # AD_USER is use for API call and CMD_AD_USER for command\n    # r-string is use for raw string to stop pytest and flake8 complaining\n    # about \\\n    AD_USER = fr\"AD01\\{ADUSERNAME.lower()}\"\n    CMD_AD_USER = fr\"AD01\\\\{ADUSERNAME.lower()}\"\nexcept ImportError:\n    Reason = 'ADNameServer AD_DOMAIN, ADPASSWORD, or/and ADUSERNAME are missing in config.py\"'\n    pytestmark = pytest.mark.skip(reason=Reason)\nelse:\n    from auto_config import dev_test\n    # comment pytestmark for development testing with --dev-test\n    pytestmark = pytest.mark.skipif(dev_test, reason='Skip for testing')"
            ]
        ]
    },
    {
        "blob_id": "5fe352bc92d7249ee71507d26e8b27a873a44490",
        "matched_blocks": [
            [
                6,
                12,
                "    try:\n        f = open(arg, 'r')\n    except OSError:\n        print('cannot open', arg)\n    else:\n        print(arg, 'has', len(f.readlines()), 'lines')\n        f.close()"
            ]
        ]
    },
    {
        "blob_id": "75375f2b0a1c113596793e9bea0c212b8406f687",
        "matched_blocks": [
            [
                8,
                13,
                "    try:\n        dollars = float(input(\"Enter change owed: \"))\n    except ValueError:\n        pass\n    else:\n        break"
            ]
        ]
    },
    {
        "blob_id": "ef72f3b184bba8de7108df9b0ba9079212eab48c",
        "matched_blocks": [
            [
                256,
                262,
                "        try:\n            raise scanner.NeutronModuleNotFound(name=\"foo\")\n        except Exception as e:\n            self.assertEqual(\"Unable to find Neutron module 'foo'\",\n                             e.msg)\n        else:\n            self.fail(\"Expected exception did not occur\")"
            ]
        ]
    },
    {
        "blob_id": "606e40173bb24cbf9d4f95a5b261acd0d044934f",
        "matched_blocks": [
            [
                220,
                243,
                "                try:\n                    exception = application_instance.exception()\n                except CancelledError:\n                    # Future cancellation. We can ignore this.\n                    pass\n                else:\n                    if exception:\n                        if isinstance(exception, KeyboardInterrupt):\n                            # Protocol is asking the server to exit (likely during test)\n                            self.stop()\n                        else:\n                            exception_output = \"{}\\n{}{}\".format(\n                                exception,\n                                \"\".join(traceback.format_tb(\n                                    exception.__traceback__,\n                                )),\n                                \"  {}\".format(exception),\n                            )\n                            logger.error(\n                                \"Exception inside application: %s\",\n                                exception_output,\n                            )\n                            if not disconnected:\n                                protocol.handle_exception(exception)"
            ]
        ]
    },
    {
        "blob_id": "f1171065a79e816e713b83f5876b78b8b5296740",
        "matched_blocks": [
            [
                46,
                55,
                "        try:\n            #\u4fdd\u5b58excel\n            workbook.save(out_path)\n        except Exception as e:\n            logging.error('\u5bfc\u51fa\u6570\u636e\u5230excel\u5931\u8d25\uff1a{}'.format(e))\n        else:\n            logging.info('\u5bfc\u51fa\u6210\u529f')\n            #\u6570\u636e\u5e93\u8fde\u63a5\u5173\u95ed\u4e8c\u8fde\n            mysqldb.curclose()\n            mysqldb.close()"
            ]
        ]
    },
    {
        "blob_id": "4fcf71cdb3b42a16125cd3a567cfe813df97948d",
        "matched_blocks": [
            [
                22,
                40,
                "    try:\n        token = auth_api.get_refreshed_token(data[\"token\"])\n        org = dir_api.org(data[\"org_id\"], token=token)\n    except (jose.exceptions.JWTError, KeyError):\n        data[\"org_name\"] = log.format(\"Missing/invalid token\", color=\"red\", bold=False)\n    except api.UnauthorizedResponse:\n        data[\"org_name\"] = log.format(\n            \"Unauthorized token, cannot fetch org details\", color=\"red\", bold=False\n        )\n    except urllib.error.URLError:\n        data[\"org_name\"] = log.format(\n            \"Invalid URL, cannot fetch org details\", color=\"red\", bold=False\n        )\n    except (api.InvalidResponse, api.UnauthorizedResponse, PermissionError):\n        data[\"org_name\"] = log.format(\n            \"Invalid token, cannot fetch org details\", color=\"red\", bold=False\n        )\n    else:\n        data[\"org_name\"] = org[\"name\"]"
            ],
            [
                273,
                303,
                "            try:\n                pipe_api = api.Pipeline()\n                org_pipelines = pipe_api.list()\n            except urllib.error.URLError:\n                print(\n                    \"Warning: could not connect to Conducto servers to delete programs; they will be deleted after their retention period expires.\",\n                    file=sys.stderr,\n                )\n            except (api.InvalidResponse, api.UnauthorizedResponse, PermissionError):\n                print(\n                    \"Warning: unauthorized connecting to Conducto servers to delete programs; they will be deleted after their retention period expires.\",\n                    file=sys.stderr,\n                )\n            except Exception as e:\n                print(\n                    f\"Warning: unknown error connecting to Conducto servers to delete programs; {str(e)}\",\n                    file=sys.stderr,\n                )\n            else:\n                hostname = socket.gethostname()\n                pl = constants.PipelineLifecycle\n                for pipedata in org_pipelines:\n                    meta_host = pipedata.get(\"meta\", {}).get(\"hostname\", None)\n                    is_my_local = (\n                        pipedata[\"status\"] in pl.local\n                        and pipedata[\"pipeline_id\"] in local_pipelines\n                        and meta_host == hostname\n                    )\n                    if is_my_local:\n                        log.debug(f\"archiving {pipedata['pipeline_id']}\")\n                        pipe_api.archive(pipedata[\"pipeline_id\"])"
            ]
        ]
    },
    {
        "blob_id": "c55d7e21b155df85decbb4db71b4bff34ba005ab",
        "matched_blocks": [
            [
                21,
                57,
                "try: import pytz  # @UnusedImport\nexcept ImportError: pass\nelse:\n    from pytz import all_timezones\n    from ally.core.http.impl.processor.time_zone import TIME_ZONE, CONTENT_TIME_ZONE\n    from .processor_time_zone import default_time_zone\n\n    # --------------------------------------------------------------------\n    \n    VERIFY_TIME_ZONE = Name(TIME_ZONE.name) & VERIFY_CATEGORY\n    VERIFY_CONTENT_TIME_ZONE = Name(CONTENT_TIME_ZONE.name) & VERIFY_CATEGORY\n\n    # --------------------------------------------------------------------\n    \n    @ioc.before(definitions)\n    def updateDefinitionsForTimeZone():\n        defin(category=CATEGORY_HEADER, name=TIME_ZONE.name)\n        defin(category=CATEGORY_HEADER, name=CONTENT_TIME_ZONE.name)\n        \n    @ioc.before(errors)\n    def updateDefinitionErrorForTimeZone():\n        error(TIME_ZONE_ERROR.code, VERIFY_TIME_ZONE | VERIFY_CONTENT_TIME_ZONE, 'The time zone headers')\n        \n    @ioc.before(updateDescriptionsForHeaders)\n    def updateDescriptionsForTimeZone():\n        sample, curr = [], None\n        for tz in all_timezones:\n            if curr != tz[:1]:\n                sample.append(tz)\n                curr = tz[:1]\n\n        # This is based on @see: updateDefinitionsForTimeZone().\n        desc(Name(TIME_ZONE.name),\n             'the time zone to render the time stamps in, as an example:\\n%(sample)s',\n             'the default time zone is %(default)s', sample=sample, default=default_time_zone())\n        desc(Name(CONTENT_TIME_ZONE.name),\n             'same as \\'%(name)s\\' but for parsed content', name=TIME_ZONE.name)"
            ]
        ]
    },
    {
        "blob_id": "70d79955bc6a0c1c85b69b4bd25c4cd38ba5ee4b",
        "matched_blocks": [
            [
                356,
                369,
                "            try:\n                retval = lecture_best.download(filepath=filepath, quiet=True, callback=self.show_progress)\n            except KeyboardInterrupt:\n                sys.stdout.write (fc + sd + \"\\n[\" + fr + sb + \"-\" + fc + sd + \"] : \" + fr + sd + \"User Interrupted..\\n\")\n                sys.exit(0)\n            else:\n                msg     = retval.get('msg')\n                if msg == 'already downloaded':\n                    sys.stdout.write (fc + sd + \"[\" + fm + sb + \"*\" + fc + sd + \"] : \" + fg + sd + \"Lecture : '%s' \" % (lecture_title) + fy + sb + \"(already downloaded).\\n\")\n                elif msg == 'download':\n                    sys.stdout.write (fc + sd + \"[\" + fm + sb + \"+\" + fc + sd + \"] : \" + fg + sd + \"Downloaded  (%s)\\n\" % (lecture_title))\n                else:\n                    sys.stdout.write (fc + sd + \"[\" + fm + sb + \"*\" + fc + sd + \"] : \" + fg + sd + \"Lecture : '%s' \" % (lecture_title) + fc + sb + \"(download skipped).\\n\")\n                    sys.stdout.write (fc + sd + \"[\" + fr + sb + \"-\" + fc + sd + \"] : \" + fr + sd + \"{}\\n\".format(msg))"
            ],
            [
                36,
                41,
                "                try:\n                    f.write('{}\\n'.format(lecture.url))\n                except Exception as e:\n                    retVal = {'status' : 'False', 'msg' : 'Python3 Exception : {}'.format(e)}\n                else:\n                    retVal = {'status' : 'True', 'msg' : 'download'}"
            ],
            [
                45,
                50,
                "                try:\n                    f.write('{}\\n'.format(lecture.url))\n                except Exception as e:\n                    retVal = {'status' : 'False', 'msg' : 'Python2 Exception : {}'.format(e)}\n                else:\n                    retVal = {'status' : 'True', 'msg' : 'download'}"
            ],
            [
                335,
                350,
                "                try:\n                    retval = subtitles.download(filepath=filepath, quiet=True, callback=self.show_progress)\n                except KeyboardInterrupt:\n                    sys.stdout.write (fc + sd + \"\\n[\" + fr + sb + \"-\" + fc + sd + \"] : \" + fr + sd + \"User Interrupted..\\n\")\n                    sys.exit(0)\n                else:\n                    msg     = retval.get('msg')\n                    if msg == 'already downloaded':\n                        sys.stdout.write (fc + sd + \"[\" + fm + sb + \"*\" + fc + sd + \"] : \" + fg + sd + \"Subtitle : '%s' \" % (title) + fy + sb + \"(already downloaded).\\n\")\n                        self.convert(filename=filename)\n                    elif msg == 'download':\n                        sys.stdout.write (fc + sd + \"[\" + fm + sb + \"+\" + fc + sd + \"] : \" + fg + sd + \"Downloaded  (%s)\\n\" % (title))\n                        self.convert(filename=filename)\n                    else:\n                        sys.stdout.write (fc + sd + \"[\" + fm + sb + \"*\" + fc + sd + \"] : \" + fg + sd + \"Subtitle : '%s' \" % (title) + fc + sb + \"(download skipped).\\n\")\n                        sys.stdout.write (fc + sd + \"[\" + fr + sb + \"-\" + fc + sd + \"] : \" + fr + sd + \"{}\\n\".format(msg))"
            ],
            [
                313,
                326,
                "                    try:\n                        retval = assets.download(filepath=filepath, quiet=True, callback=self.show_progress)\n                    except KeyboardInterrupt:\n                        sys.stdout.write (fc + sd + \"\\n[\" + fr + sb + \"-\" + fc + sd + \"] : \" + fr + sd + \"User Interrupted..\\n\")\n                        sys.exit(0)\n                    else:\n                        msg     = retval.get('msg')\n                        if msg == 'already downloaded':\n                            sys.stdout.write (fc + sd + \"[\" + fm + sb + \"*\" + fc + sd + \"] : \" + fg + sd + \"Asset : '%s' \" % (assets.filename) + fy + sb + \"(already downloaded).\\n\")\n                        elif msg == 'download':\n                            sys.stdout.write (fc + sd + \"[\" + fm + sb + \"+\" + fc + sd + \"] : \" + fg + sd + \"Downloaded  (%s)\\n\" % (assets.filename))\n                        else:\n                            sys.stdout.write (fc + sd + \"[\" + fm + sb + \"*\" + fc + sd + \"] : \" + fg + sd + \"Asset : '%s' \" % (assets.filename) + fc + sb + \"(download skipped).\\n\")\n                            sys.stdout.write (fc + sd + \"[\" + fr + sb + \"-\" + fc + sd + \"] : \" + fr + sd + \"{}\\n\".format(msg))"
            ]
        ]
    },
    {
        "blob_id": "c1ab5fa5f7f00692f52740a91812acb31ab96c66",
        "matched_blocks": [
            [
                180,
                202,
                "            try:\n                infor_dic['msg_raw_id'] = sig_state_result.group(1)\n                infor_dic['sig_name'] = sig_state_result.group(2).lower()\n                content_str = sig_state_result.group(3)\n            except:\n                raise Exception('parse sig state error! line = %s' % str(cnt + 1))\n            else:\n                temp_list = content_str.strip().split('\"')\n                temp_list.pop()\t#\u5220\u6389\";\"\n\n                key_list = []\n                val_list = []\n\n                cnt1 = 0\n                while cnt1 < len(temp_list) / 2:\n                    key = temp_list[2 * cnt1 + 0].strip()\n                    key_list.append(key)\n\n                    val = temp_list[2 * cnt1 + 1].strip()\n                    val_list.append(val)\n                    cnt1 += 1\n\n                infor_dic['state_dic'] = dict(zip(key_list, val_list))"
            ]
        ]
    },
    {
        "blob_id": "d5682a3ac3a2dd25ab8551f9a222c515f0ef39c2",
        "matched_blocks": [
            [
                27,
                33,
                "try:\n    pkg_resources.get_distribution('Products.Archetypes')\nexcept pkg_resources.DistributionNotFound:\n    HAS_ARCHETYPES = False\nelse:\n    from collective.atrfc822.fields import iterFields\n    HAS_ARCHETYPES = True"
            ],
            [
                36,
                52,
                "try:\n    pkg_resources.get_distribution('plone.dexterity')\n    from plone.app.dexterity.behaviors.metadata import IDublinCore\n    from plone.app.dexterity.behaviors.metadata import DublinCore\nexcept pkg_resources.DistributionNotFound:\n    HAS_DEXTERITY = False\n\n    class IDexterityFTI(object):\n        \"\"\"Mock\"\"\"\n\n    class IDexterityContent(object):\n        \"\"\"Mock\"\"\"\nelse:\n    from plone.dexterity.interfaces import IDexterityFTI\n    from plone.dexterity.interfaces import IDexterityContent\n    from plone.dexterity.utils import iterSchemata\n    HAS_DEXTERITY = True"
            ],
            [
                55,
                62,
                "try:\n    pkg_resources.get_distribution('plone.app.contenttypes')\nexcept pkg_resources.DistributionNotFound:\n    HAS_PAC = False\nelse:\n    from plone.app.contenttypes.behaviors.leadimage import ILeadImage\n    alsoProvides(ILeadImage['image'], IPrimaryField)\n    HAS_PAC = True"
            ]
        ]
    },
    {
        "blob_id": "c936f1c418ea6c456cf0dd6c2b5cec291e39acf2",
        "matched_blocks": [
            [
                18,
                48,
                "        try:\n            mo = MemberOrganisation.objects.get(slug=mo_slug)\n        except MemberOrganisation.DoesNotExist:\n            pass\n        else:\n            product_templates = ProductTemplate.objects.filter(member_organisation_id=mo.pk)\n            product_attributes = set()\n            for template in product_templates:\n                product_attributes |= set(template.attributes.all().values_list('pk', flat=True))\n\n            # delete attributes\n            ProductAttribute.objects.filter(id__in=product_attributes).delete()\n\n            # delete templates\n            product_templates_count = product_templates.count()\n            product_templates.delete()\n\n            if IMPORT_DEBUG and product_templates_count:\n                print('{attr} ProductAttribute and {c} ProductTemplate related to {mo} are removed'\n                      .format(attr=len(product_attributes), c=product_templates_count, mo=mo_slug))\n\n            # delete orphaned attributes\n            product_attributes = ProductAttribute.objects.filter(member_organisation_id=mo.pk)\n            product_attributes_count = product_attributes.count()\n            product_attributes.delete()\n            if IMPORT_DEBUG and product_attributes_count:\n                print('{attr} orphaned ProductAttribute related to {mo} are removed'\n                      .format(attr=product_attributes_count, mo=mo_slug))\n\n            # delete prod packaging too\n            ProductPackaging.objects.filter(member_organisation=mo.pk).delete()"
            ]
        ]
    },
    {
        "blob_id": "f3b268991c4522ba57f9aa869c1ae1dbea8c1e1f",
        "matched_blocks": [
            [
                2,
                13,
                "    try:\n        if listname in thedict:\n            l = thedict[listname]\n            print(\"%s already has %d elements.\" % (listname, len(l)))\n        else:\n            thedict[listname] = []\n            print(\"Created %s.\" % listname)\n\n    except KeyError:\n        print(\"your list doesn't exist yet\")\n    else:\n        thedict[listname].append(element)"
            ]
        ]
    },
    {
        "blob_id": "4a8e75faab481c89f697e468241dc944b98ee689",
        "matched_blocks": [
            [
                2482,
                2489,
                "        try:\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT VERSION() LIKE '%MariaDB%'\")\n            val = cursor.fetchone()[0]\n        except:\n            raise\n        else:\n            return bool(val)"
            ]
        ]
    },
    {
        "blob_id": "044671e9ea845335b6db84082d7ba355c08ca3fa",
        "matched_blocks": [
            [
                169,
                175,
                "        try:\n            creder = Credentialer(raw=ims)\n        except ShortageError as e:\n            raise e\n        else:\n            del ims[:creder.size]\n            break"
            ]
        ]
    },
    {
        "blob_id": "726e067767a6d38da564279f2bc6a9685ab0f66a",
        "matched_blocks": [
            [
                12,
                19,
                "try:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n   \n    pass\nelse:\n    \n    ssl._create_default_https_context = _create_unverified_https_context"
            ]
        ]
    },
    {
        "blob_id": "8cd075875477791bfda459c5f6be816ef64bf010",
        "matched_blocks": [
            [
                42,
                61,
                "        try:\n            oauth_user = OAuthQQUser.objects.get(openid=openid)\n        except OAuthQQUser.DoesNotExist:\n            # \u5982\u679c\u6ca1\u6709\u627e\u5230\u8bb0\u5f55 openid \u672a\u7ed1\u5b9a\u5546\u57ce\u7528\u6237  \u5c55\u793a\u7ed1\u5b9a\u9875\u9762\n            # openid \u662f\u660e\u6587  Sdasdasdasdasy7iyw432 => \u660e\u6587  \u53ef\u9006 \u7b7e\u540d\u7684\u7b97\u6cd5\n            context = {'access_token_openid': generate_access_token(openid)}\n            return render(request, 'oauth_callback.html', context=context)\n        else:\n            # \u627e\u5230\u8bb0\u5f55  \u767b\u5f55\n            # \u72b6\u6001\u4fdd\u6301\n            login(request, oauth_user.user)\n\n            next = request.GET.get('state')\n\n            response = redirect(next)\n\n            response.set_cookie('username', oauth_user.user.username, max_age=3600 * 24)\n\n            # \u54cd\u5e94\u7ed3\u679c \u91cd\u5b9a\u5411\u5230\u9996\u9875\n            return response"
            ],
            [
                88,
                96,
                "        try:\n            user = User.objects.get(mobile=mobile)\n        except User.DoesNotExist:\n            # \u5982\u679c\u4e0d\u5b58\u5728, \u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u7528\u6237\n            user = User.objects.create_user(username=mobile, password=password, mobile=mobile)\n        else:\n            # \u5982\u679c\u5b58\u5728,\u6821\u9a8c\u5bc6\u7801\n            if not user.check_password(password):\n                return render(request, 'oauth_callback.html', {'account_errmsg': '\u8d26\u53f7\u6216\u8005\u5bc6\u7801\u9519\u8bef'})"
            ]
        ]
    },
    {
        "blob_id": "97a0402d0191bcee625dbe16aa80705f69e1f165",
        "matched_blocks": [
            [
                237,
                247,
                "            try:\n                # Try activating rlcompleter, because it's handy.\n                import readline\n            except ImportError:\n                pass\n            else:\n                # We don't have to wrap the following import in a 'try', because\n                # we already know 'readline' was imported successfully.\n                import rlcompleter\n                readline.set_completer(rlcompleter.Completer(imported_objects).complete)\n                readline.parse_and_bind(\"tab:complete\")"
            ]
        ]
    },
    {
        "blob_id": "bb6ed16e46147ae26334eb1887d999ed562ed82f",
        "matched_blocks": [
            [
                30,
                37,
                "    try:\n        os.chmod(path, S_IREAD)\n        with open(os.path.join(path, 'testfile.txt'), 'w') as file:\n            pass\n    except OSError:\n        ABLE_TO_PREVENT_WRITE = True\n    else:\n        ABLE_TO_PREVENT_WRITE = False"
            ]
        ]
    },
    {
        "blob_id": "a66ade3a91d06c1201bed658399df960870bbe74",
        "matched_blocks": [
            [
                477,
                482,
                "        try:\n            self._closeSocket(True)\n        except AttributeError:\n            pass\n        else:\n            self._collectSocketDetails()"
            ],
            [
                1155,
                1198,
                "        try:\n            client, address = listener.accept()\n        except OSError as e:\n            if e.args[0] in (EWOULDBLOCK, EAGAIN):\n                # No more clients.\n                return\n            elif e.args[0] == EPERM:\n                # Netfilter on Linux may have rejected the\n                # connection, but we get told to try to accept()\n                # anyway.\n                continue\n            elif e.args[0] == EMFILE and reservedFD.available():\n                # Linux and other UNIX-like operating systems return\n                # EMFILE when a process has reached its soft limit of\n                # file descriptors.  The reserved file descriptor is\n                # available, so it can be released to free up a\n                # descriptor for use by listener.accept()'s clients.\n                # Each client socket will be closed until the listener\n                # returns EAGAIN.\n                logger.info(\n                    \"EMFILE encountered;\" \" releasing reserved file descriptor.\"\n                )\n                # The following block should not run arbitrary code\n                # that might acquire its own file descriptor.\n                with reservedFD:\n                    clientsToClose = _accept(logger, accepts, listener, reservedFD)\n                    for clientToClose, closedAddress in clientsToClose:\n                        clientToClose.close()\n                        logger.info(\n                            \"EMFILE recovery:\" \" Closed socket from {address}\",\n                            address=closedAddress,\n                        )\n                    logger.info(\"Re-reserving EMFILE recovery file descriptor.\")\n                return\n            elif e.args[0] in _ACCEPT_ERRORS:\n                logger.info(\n                    \"Could not accept new connection ({acceptError})\",\n                    acceptError=errorcode[e.args[0]],\n                )\n                return\n            else:\n                raise\n        else:\n            yield client, address"
            ],
            [
                969,
                979,
                "            try:\n                fileDescriptor = self._fileFactory()\n            except OSError as e:\n                if e.errno == EMFILE:\n                    self._log.failure(\n                        \"Could not reserve EMFILE recovery file descriptor.\"\n                    )\n                else:\n                    raise\n            else:\n                self._fileDescriptor = fileDescriptor"
            ]
        ]
    },
    {
        "blob_id": "22ab57b357e0f71a237346053a156a4c9b1a6648",
        "matched_blocks": [
            [
                170,
                175,
                "        try:\n            result = data.decode()\n        except:\n            result = None\n        else:\n            result=result.split(\" \",1)"
            ]
        ]
    },
    {
        "blob_id": "437b7eb669d6086754cb781e70affdc0daf4c124",
        "matched_blocks": [
            [
                31,
                36,
                "        try:\n            int(name[2:-1])\n        except:\n            pass\n        else:\n            return True"
            ],
            [
                54,
                60,
                "            try:\n                nick = ctx.message.author.nick\n            except:\n                nick = ctx.message.author.name\n            else:\n                if nick is None:\n                    nick = ctx.message.author.name"
            ],
            [
                65,
                71,
                "                try:\n                    nick = ctx.message.author.nick\n                except:\n                    nick = user.name\n                else:\n                    if nick is None:\n                        nick = ctx.message.author.name"
            ]
        ]
    },
    {
        "blob_id": "827c2c3670f74dcae606c9b47443825613d8aa11",
        "matched_blocks": [
            [
                34,
                39,
                "try:\n    from .tortoise_ import tortoise_implementation\nexcept ImportError:\n    pass\nelse:\n    implementations.append(tortoise_implementation)"
            ]
        ]
    },
    {
        "blob_id": "c0f62fe98e660723259186a00c7ae9ae40a8d0f9",
        "matched_blocks": [
            [
                9,
                20,
                "        try:\n            # accepting the pcap file\n            pcap_input = input(\"Submit the location of the pcap file: \")\n            # Converts relative path into full path\n            fullPath = os.path.join(os.getcwd(), pcap_input)\n            # Reading the pcap\n            pcap = rdpcap(fullPath)\n            return pcap\n        except BaseException:\n            print(\" Error 404..... Pcap not found!! \")\n        else:\n            break"
            ],
            [
                53,
                60,
                "        try:\n            req_opcode = filter_packets(int(choice))\n            opcode_handling(pcap, req_opcode)\n            return None\n        except BaseException:\n            print(\"Trying to test my patience? Good luck baby! \")\n        else:\n            break"
            ]
        ]
    },
    {
        "blob_id": "255fd794666d6dc504c261877489e3b7ee872bbe",
        "matched_blocks": [
            [
                75,
                95,
                "            try:\n                # ask user to make choice and show the default value as well\n                choice = int(\n                    input(\"\\nSelect your car model (1,2), default [%s]: \" % defid)\n                )\n                # choice is assigned to user choice  or default value\n                choice = choice or defid\n                carinfo = carinfolist[choice - 1]\n            except IndexError:\n                print(\"\\nInvalid Selection!\")\n                continue\n            except ValueError:\n                if not choice:  # check if choice empty string (user press 'Enter')\n                    carinfo = carinfolist[int(defid - 1)]\n                    break\n                else:\n                    print(\"\\nInvalid Input!\")\n                    continue\n            else:\n                # print(carinfo)\n                return carinfo"
            ]
        ]
    },
    {
        "blob_id": "9b97c3e7ea9e41ffbc45b8c498367f691295fa0e",
        "matched_blocks": [
            [
                92,
                106,
                "        try:\n            future = self.async_futures[correlation_id]  # type: asyncio.Future\n        except KeyError:\n            pass\n        else:\n            payload = self.deserialize(message.body)\n\n            if message.type == 'result':\n                future.set_result(payload)\n            elif message.type == 'error':\n                future.set_exception(payload)\n            elif message.type == 'call':\n                future.set_exception(asyncio.TimeoutError(\"Message timed-out\", message))\n            else:\n                future.set_exception(RuntimeError(\"Unknown message type %r\" % message.type))"
            ]
        ]
    },
    {
        "blob_id": "573b1dc7aba33616134017c467b51f6691588f5e",
        "matched_blocks": [
            [
                224,
                237,
                "    try:\n        results = await asyncio.wait_for(task, timeout=10)\n    except asyncio.TimeoutError:\n        await client.say(\"Error: request timed out\")\n    else:\n        if results:\n            shuffle(results)\n            msg = \"Search results...\\n\"\n            for r in results[:3]:\n                msg += r.gifv if hasattr(r, \"gifv\") else r.link\n                msg += \"\\n\"\n            await client.say(msg)\n        else:\n            await client.say(\"Your search terms gave no results.\")"
            ],
            [
                1944,
                1949,
                "    try:\n        arg = random.randint(1, 10)\n    except ValueError:\n        await client.say(\"Invalid number\")\n    else:\n        await client.say('The correct answer is ' + str(arg))"
            ]
        ]
    },
    {
        "blob_id": "a276d1443a4c898e0bf1ef8ba216c5af284454de",
        "matched_blocks": [
            [
                415,
                421,
                "            try:\n                next(gen)  # call function\n            except StopIteration:  # only one statement\n                pass\n            else:\n                key, _ = parse_key_combo(key_combo)\n                self._key_release_generators[key] = gen"
            ]
        ]
    },
    {
        "blob_id": "03261493884969455f6d192c3f44af79bdfcb7dd",
        "matched_blocks": [
            [
                25,
                33,
                "    try:\n        app_path = args[0]\n    except IndexError:\n        raise SystemExit(\"Usage: app_test_runner.py [path-to-app] [app-test-case]\")\n    else:\n        if app_path.endswith(\"/\"):\n            app_path = app_path[:-1]\n        parent_dir, app_name = os.path.split(app_path)\n        sys.path.insert(0, parent_dir)"
            ]
        ]
    },
    {
        "blob_id": "1599d5ab9fcfb738d83207abb71616a4daca035e",
        "matched_blocks": [
            [
                42,
                51,
                "    try:\n        selected_choice = p.choice_set.get(pk = request.POST['choice'])\n    except(KeyError,Choice.DoesNotExist):\n        return render(request,'polls/detail.html',\n                      {'question': p,\n                        'error_message':'\u4f60\u6ca1\u6709\u9009\u62e9\uff01',})\n    else:\n        selected_choice.votes +=1\n        selected_choice.save()\n        return HttpResponseRedirect(reverse('polls:results',args=(p.id,)))"
            ]
        ]
    },
    {
        "blob_id": "2d3076fce51d1027021afc1571ccdcb1c6c302b9",
        "matched_blocks": [
            [
                34,
                53,
                "    try:\n        git_log = subprocess.check_output(\n            [\"git\", \"log\", \"-1\", \"--pretty=%h %ai\"]\n        ).decode(\"utf-8\")\n        git_diff = (\n            subprocess.check_output([\"git\", \"diff\", \".\"])\n            + subprocess.check_output([\"git\", \"diff\", \"--cached\", \".\"])\n        ).decode(\"utf-8\")\n    except subprocess.CalledProcessError:  # git calls failed\n        # we already have a version file, let's use it\n        if version_file.is_file():\n            return version_file.name\n        # otherwise just return the version information\n        else:\n            return version\n    else:\n        git_version = \"{}: ({}) {}\".format(\n            version, \"UNCLEAN\" if git_diff else \"CLEAN\", git_log.rstrip()\n        )\n        print(f\"parsed git version info as: {git_version!r}\")"
            ]
        ]
    },
    {
        "blob_id": "6ef575794be04cc2faf6c4f9aeee59ee8dd6a38e",
        "matched_blocks": [
            [
                1230,
                1236,
                "            try:\n                oput = self.functions[fun].__outputter__\n            except (KeyError, AttributeError, TypeError):\n                pass\n            else:\n                if isinstance(oput, six.string_types):\n                    load['out'] = oput"
            ]
        ]
    },
    {
        "blob_id": "d65c17fddc35eb48ebcf9a7d8ecbd2a03b37978e",
        "matched_blocks": [
            [
                52,
                57,
                "\t\t\ttry:\n\t\t\t\tself.cursor.execute('INSERT INTO tagNames (tag) VALUES (?)', (tagName,))\n\t\t\texcept sqlite3.IntegrityError as ie:\n\t\t\t\tdupCount += 1\n\t\t\telse:\n\t\t\t\tinsertCount += 1"
            ]
        ]
    },
    {
        "blob_id": "dca7c890a77b8433d91ab700cb8b5679adc218d2",
        "matched_blocks": [
            [
                260,
                278,
                "        try:\n            for char in find_all_by_type(reg, Other.Literal):\n                if 'a' <= char.data <= 'z' or 'A' <= char.data <= 'Z':\n                    raise Break()\n\n            # This part only checks ranges, because the single characters were\n            # already checked directly above.\n            import string\n            alpha = set(map(ord, string.ascii_letters))\n            for cc in find_all_by_type(reg, Other.CharClass):\n                for char in cc.chars:\n                    if isinstance(char, CharRange):\n                        this_range = set(range(char.codepoint_a, char.codepoint_b))\n                        if this_range & alpha:\n                            raise Break()\n        except Break:\n            pass\n        else:\n            errs.append((num, level, directives[0].start, msg % 'i'))"
            ]
        ]
    },
    {
        "blob_id": "0fbc76d0300d598b7281028957299fbf30355f1c",
        "matched_blocks": [
            [
                83,
                90,
                "            try:\n                mask = self.layer.to_mask()\n            except IncompatibleAttribute:\n                # The following includes a call to self.clear()\n                self.disable(\"Subset cannot be applied to this data\")\n                return\n            else:\n                self._enabled = True"
            ]
        ]
    },
    {
        "blob_id": "ec39f36408bc828cb3003430794d6d972ffe2c43",
        "matched_blocks": [
            [
                5,
                10,
                "        try:\n            q = int(input(\"Factorial of: \"))\n        except:\n            print (\"Please input an integer!\")\n        else:\n            return q"
            ]
        ]
    },
    {
        "blob_id": "52ada6edf1b3aa170fb3fff2cbca5c5286d9264c",
        "matched_blocks": [
            [
                78,
                86,
                "        try:\n            if not self.legacy:\n                gluid = retrieve_gluid(self.dbfile) if self.usedb else self.gluid\n                binascii.a2b_base64(gluid)\n        except:\n            showerror(\"Error\", \"Bad decryption key\")\n        else:\n            self.go_next = True\n            self.destroy()"
            ]
        ]
    },
    {
        "blob_id": "6658fb6f56dc5bf5fb43ea7f23f03b85f7bdc8bd",
        "matched_blocks": [
            [
                18,
                25,
                "    try:\n        selected_choice = question.choice_set.get(pk=request.POST['choice'])\n    except(KeyError, Choice.DoesNotExist):\n        return render(request, 'polls/detail.html', {'question': question, 'error_message': \"You didn`t select a choice.\"})\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        return HttpResponseRedirect(reverse('polls:results', args=(question_id,)))"
            ]
        ]
    },
    {
        "blob_id": "76e7802e9dd9160acd1e64769b89a2688543cc71",
        "matched_blocks": [
            [
                26,
                31,
                "            try:\n                self._entry[key]\n            except KeyError:\n                pass  # This is a link that leads nowhere.\n            else:\n                valid_keys.append(key)"
            ]
        ]
    },
    {
        "blob_id": "7cd000559400fe32194070d58464cca0aa9ce297",
        "matched_blocks": [
            [
                25,
                49,
                "        try:\n            from rosidl_generator_py import import_type_support\n            module = import_type_support('nav_msgs')\n        except ImportError:\n            import logging\n            import traceback\n            logger = logging.getLogger(\n                'nav_msgs.msg.MapMetaData')\n            logger.debug(\n                'Failed to import needed modules for type support:\\n' +\n                traceback.format_exc())\n        else:\n            cls._CREATE_ROS_MESSAGE = module.create_ros_message_msg__msg__map_meta_data\n            cls._CONVERT_FROM_PY = module.convert_from_py_msg__msg__map_meta_data\n            cls._CONVERT_TO_PY = module.convert_to_py_msg__msg__map_meta_data\n            cls._TYPE_SUPPORT = module.type_support_msg__msg__map_meta_data\n            cls._DESTROY_ROS_MESSAGE = module.destroy_ros_message_msg__msg__map_meta_data\n\n            from builtin_interfaces.msg import Time\n            if Time.__class__._TYPE_SUPPORT is None:\n                Time.__class__.__import_type_support__()\n\n            from geometry_msgs.msg import Pose\n            if Pose.__class__._TYPE_SUPPORT is None:\n                Pose.__class__.__import_type_support__()"
            ]
        ]
    },
    {
        "blob_id": "6c9eb0edf0a54aecf151d42485ed501689cc2171",
        "matched_blocks": [
            [
                2108,
                2114,
                "        try:\n            entity = inspect(argument)\n        except sa_exc.NoInspectionAvailable:\n            pass\n        else:\n            if hasattr(entity, \"mapper\"):\n                return entity"
            ]
        ]
    },
    {
        "blob_id": "87ab68ad4f53266913c451ae4e3913018abb2b9c",
        "matched_blocks": [
            [
                446,
                451,
                "    try:\n        str_to_etree(xml_str)\n    except xml.etree.ElementTree.ParseError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "c06271bb752a2c4dc70750e4e08dce60ecb0e69f",
        "matched_blocks": [
            [
                84,
                89,
                "\t\t\ttry:\n\t\t\t\topen(temp)\n\t\t\texcept FileNotFoundError:\n\t\t\t\tprint(\"file does not exist\")\n\t\t\telse:\n\t\t\t\treturn temp"
            ]
        ]
    },
    {
        "blob_id": "3a7bdda39741debb75955c2f59f63452671e3ca7",
        "matched_blocks": [
            [
                12,
                17,
                "    try:\n        s.decode('ascii')\n    except UnicodeDecodeError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "c26b8aa6536d91d003c6e93a96c012aadcbfaffb",
        "matched_blocks": [
            [
                124,
                129,
                "        try:\n            num= int(num)\n        except ValueError:\n            return True\n        else:\n            return False"
            ],
            [
                67,
                82,
                "                    try:\n                        self.driver.get(url)\n                        WebDriverWait(self.driver, 10).until(\n                            EC.presence_of_element_located(\n                                (By.CSS_SELECTOR, '#mainsrp-itemlist > div > div > div:nth-child(1) > div'))\n                        )\n                    except Exception as e:\n                        if 'TimeoutException' in str(e):\n                            count += 1\n                            time.sleep(1)\n                            log.info('TimeoutException in get next page')\n                            pass\n                        if count > 3:\n                            break\n                    else:\n                        break"
            ]
        ]
    },
    {
        "blob_id": "18ea1a3b36d880daac335394ef41d0779e3a6053",
        "matched_blocks": [
            [
                9,
                23,
                "    try:\n        arquivo = open('teste.txt', 'r')\n        texto = arquivo.read()\n        lista = [1, 10]\n        divisao = 10 / 0\n        numero = lista[1]\n        #x = a\n    except ZeroDivisionError:\n        print('N\u00e3o \u00e9 possivel realizer uma divis\u00e3o por zero')\n    except IndexError:\n        print('Indice fora do limite')\n    except Exception as ex:\n        print('Erro desconhecido. Erro: {}'.format(ex))\n    else:\n        print('Executa qdo n\u00e3o ocorrer erro!!!')"
            ]
        ]
    },
    {
        "blob_id": "6d3233ea17960c8419729cc7a62c2ef74e643b96",
        "matched_blocks": [
            [
                203,
                228,
                "                try:\n                    eprint(f\"  - Getting meta info from {kp_infores_curie}\")\n                    with requests_cache.disabled():\n                        kp_response = requests.get(f\"{kp_endpoint_url}/meta_knowledge_graph\", timeout=10)\n                except requests.exceptions.Timeout:\n                    eprint(f\"      Timed out when trying to hit {kp_infores_curie}'s /meta_knowledge_graph endpoint \"\n                          f\"(waited 10 seconds)\")\n                except Exception:\n                    eprint(f\"      Ran into a problem getting {kp_infores_curie}'s meta info\")\n                else:\n                    if kp_response.status_code == 200:\n                        try:\n                            kp_meta_kg = kp_response.json()\n                        except:\n                            eprint(f\"Skipping {kp_infores_curie} because they returned invalid JSON\")\n                            kp_meta_kg = \"Failed\"\n\n                        if type(kp_meta_kg) != dict:\n                            eprint(f\"Skipping {kp_infores_curie} because they returned an invalid meta knowledge graph\")\n                        else:\n                            meta_map[kp_infores_curie] = {\"predicates\": self._convert_meta_kg_to_meta_map(kp_meta_kg),\n                                                          \"prefixes\": {category: meta_node[\"id_prefixes\"]\n                                                                       for category, meta_node in kp_meta_kg[\"nodes\"].items()}}\n                    else:\n                        eprint(f\"Unable to access {kp_infores_curie}'s /meta_knowledge_graph endpoint \"\n                              f\"(returned status of {kp_response.status_code} for URL {kp_endpoint_url})\")"
            ]
        ]
    },
    {
        "blob_id": "f46c0d42a1b014a532d6d37256150393003385ca",
        "matched_blocks": [
            [
                37,
                43,
                "try:\n    close1 = float(data[f'{today}']['4. close'])\nexcept KeyError:\n    close1 = float(data[f'{yesterday}']['4. close'])\n    close2 = float(data[f'{before_yesterday}']['4. close'])\nelse:\n    close2 = float(data[f'{yesterday}']['4. close'])"
            ]
        ]
    },
    {
        "blob_id": "6e4289026030119202f64bfa871835808ea19650",
        "matched_blocks": [
            [
                408,
                416,
                "                try:\n                    with RBDVolumeProxy(self, t, read_only=True,\n                                        client=client.cluster,\n                                        ioctx=client.ioctx) as v:\n                        size = v.size()\n                except self.rbd.ImageNotFound:\n                    LOG.debug(\"Image %s is not found.\", t)\n                else:\n                    total_provisioned += size"
            ]
        ]
    },
    {
        "blob_id": "35b15ab9bd1d359723840ece845816fca72000c5",
        "matched_blocks": [
            [
                468,
                478,
                "            try:\n                ax = charting.cycle_time_scatterplot(\n                    cycle_data_sliced,\n                    percentiles=quantiles,\n                    title=args.charts_scatterplot_title\n                )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_scatterplot, bbox_inches='tight', dpi=300)"
            ],
            [
                483,
                493,
                "            try:\n                ax = charting.cycle_time_histogram(\n                    cycle_data_sliced,\n                    percentiles=quantiles,\n                    title=args.charts_histogram_title\n                )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_histogram, bbox_inches='tight', dpi=300)"
            ],
            [
                498,
                514,
                "            try:\n                if args.points:\n                    ax = charting.cfd(\n                        cfd_data_stackable_sliced,\n                        title=args.charts_cfd_title,\n                        pointscolumn=args.points\n                    )\n                else:\n                    ax = charting.cfd(\n                        cfd_data_sliced,\n                        title=args.charts_cfd_title\n                    )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_cfd, bbox_inches='tight', dpi=300)"
            ],
            [
                519,
                528,
                "            try:\n                ax = charting.throughput_trend_chart(\n                    daily_throughput_data,\n                    title=args.charts_throughput_title\n                )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_throughput, bbox_inches='tight', dpi=300)"
            ],
            [
                533,
                555,
                "            try:\n                if args.points:\n                    ax = charting.burnup(\n                        cfd_data_sliced,\n                        backlog_column=backlog_column,\n                        done_column=done_column,\n                        title=args.charts_burnup_title,\n                        sized = 'Sized'\n                    )\n                else:\n                    ax = charting.burnup(\n                        cfd_data_sliced,\n                        backlog_column=backlog_column,\n                        done_column=done_column,\n                        title=args.charts_burnup_title,\n                        sized=''\n                    )\n\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_burnup, bbox_inches='tight', dpi=300)"
            ],
            [
                565,
                598,
                "            try:\n                if args.points:\n                    ax = charting.burnup_forecast(\n                        cfd_data_sliced,\n                        daily_throughput_data,\n                        trials=trials,\n                        target=target,\n                        backlog_column=backlog_column,\n                        done_column=done_column,\n                        percentiles=quantiles,\n                        deadline=deadline,\n                        deadline_confidence=deadline_confidence,\n                        title=args.charts_burnup_forecast_title,\n                        sized='Sized'\n                    )\n                else:\n                    ax = charting.burnup_forecast(\n                        cfd_data_sliced,\n                        daily_throughput_data,\n                        trials=trials,\n                        target=target,\n                        backlog_column=backlog_column,\n                        done_column=done_column,\n                        percentiles=quantiles,\n                        deadline=deadline,\n                        deadline_confidence=deadline_confidence,\n                        title=args.charts_burnup_forecast_title,\n                        sized=''\n                    )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_burnup_forecast, bbox_inches='tight', dpi=300)"
            ],
            [
                603,
                614,
                "            try:\n                ax = charting.wip_chart(\n                    q.cfd(cycle_data[cycle_data[backlog_column] >= (datetime.date.today() - datetime.timedelta(weeks=(args.charts_wip_window or 6)))]),\n                    start_column=committed_column,\n                    end_column=final_column,\n                    title=args.charts_wip_title\n                )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_wip, bbox_inches='tight', dpi=300)"
            ],
            [
                619,
                631,
                "            try:\n                ax = charting.ageing_wip_chart(\n                    cycle_data,\n                    start_column=committed_column,\n                    end_column=final_column,\n                    done_column=done_column,\n                    title=args.charts_ageing_wip_title\n                )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_ageing_wip, bbox_inches='tight', dpi=300)"
            ],
            [
                636,
                647,
                "            try:\n                ax = charting.net_flow_chart(\n                    q.cfd(cycle_data[cycle_data[backlog_column] >= (datetime.date.today() - datetime.timedelta(weeks=(args.charts_net_flow_window or 6)))]),\n                    start_column=committed_column,\n                    end_column=done_column,\n                    title=args.charts_net_flow_title\n                )\n            except charting.UnchartableData as e:\n                print(\"** WARNING: Did not draw chart:\", e)\n            else:\n                fig = ax.get_figure()\n                fig.savefig(args.charts_net_flow, bbox_inches='tight', dpi=300)"
            ]
        ]
    },
    {
        "blob_id": "a5beb263c9fa0069b8b9ef256681716929079437",
        "matched_blocks": [
            [
                28,
                33,
                "        try:\n            self.post_user = User.objects.prefetch_related('posts').get(username__iexact=self.kwargs.get('username'))\n        except User.DoesNotExist:\n            raise Http404\n        else:\n            return self.post_user.posts.all()"
            ]
        ]
    },
    {
        "blob_id": "430ada24ba2979d1dc90a260c575a23f647ee5a8",
        "matched_blocks": [
            [
                6,
                12,
                "try:\n    result = getMean(my_list2)\nexcept  ZeroDivisionError as detail:\n    print(\"(Error): {}\".format(float('nan')))\n    print(\"(Error): {}\".format(detail))\nelse:\n    print(\"(The mean is): {}\".format(result))"
            ]
        ]
    },
    {
        "blob_id": "dad06d2d6f13da3e55ca72d96adbfd5d95ea2eb6",
        "matched_blocks": [
            [
                142,
                159,
                "        try:\n            runnlet.wait()\n        except OSError as exc:\n            if exc.errno == errno.EINTR:\n                # this is the OSError(4) caused by the signalhandler.\n                # ignore and go back to waiting on the runner\n                continue\n            raise\n        except KeyboardInterrupt:\n            print()  # looks nicer with the ^C e.g. bash prints in the terminal\n            try:\n                service_runner.stop()\n            except KeyboardInterrupt:\n                print()  # as above\n                service_runner.kill()\n        else:\n            # runner.wait completed\n            break"
            ]
        ]
    },
    {
        "blob_id": "0085c6cb9a123ccabfdf39b59ffea34d56255b69",
        "matched_blocks": [
            [
                10,
                17,
                "try:\n    fh = open(\"check.txt\", \"w\")\n    print(fh.write(\"Hello from Exception!\"))\nexcept BaseException as exception:\n    print(\"Error while working with file: \", exception )    \nelse:\n    print(\"File operation is success!\")\n    fh.close()"
            ],
            [
                20,
                27,
                "try:\n    fh = open(\"check.txt\", \"r\")\n    print(fh.read())\nexcept IOError as exception:\n    print(\"Error while working with file: \", exception )    \nelse:\n    print(\"File operation is success!\")\n    fh.close()"
            ]
        ]
    },
    {
        "blob_id": "63a81ae4e923ce800616af2fae0237f6c5fd8ed4",
        "matched_blocks": [
            [
                91,
                97,
                "        try:\n            self.g[10, 10] = \"foo\"\n        except KeyError:\n            return True\n        else:\n            raise AssertionError(\"__setitem__ should raise KeyError for \"\n                                 \"an invalid location\")"
            ],
            [
                111,
                116,
                "        try:\n            self.g[10, 10]\n        except KeyError:\n            return True\n        else:\n            raise AssertionError(\"Was able to retrieve an invalid location\")"
            ]
        ]
    },
    {
        "blob_id": "c67c6aa5d5f63958801f1bc6b365fa8cf502cda7",
        "matched_blocks": [
            [
                10,
                15,
                "    try:\n        __import__(module_name)\n    except ImportError:\n        return False\n    else:\n        return True"
            ]
        ]
    },
    {
        "blob_id": "7264806facacbd28ac4651c3e266a350d7fbe10f",
        "matched_blocks": [
            [
                26,
                42,
                "    try:\n        # NOTE: request.POST['choice'] lets you access submitted data by key\n        # name.\n        selected_choice = p.choice_set.get(pk=request.POST['choice'])\n    except (KeyError, Choice.DoesNotExist):\n        # Redisplay the poll voting form.\n        return render(request, 'polls/detail.html', {\n            'poll': p,\n            'error_message': \"You didn't select a choice.\",\n        })\n    else:\n        selected_choice.votes += 1\n        selected_choice.save()\n        # NOTE: Always return an HttpResponseRedirect after successfully dealing\n        # with POST data. This prevents data from being posted twice if a\n        # user hits the Back button.\n        return HttpResponseRedirect(reverse('polls:results', args=(p.id,)))"
            ]
        ]
    },
    {
        "blob_id": "c7ca9255f049b438dd84d8b022b5bc7d85416f2b",
        "matched_blocks": [
            [
                1056,
                1064,
                "        try:\n            repo = git.Repo(module_checkout_abspath)\n            if repo != self.repo:\n                return repo\n            # END handle repo uninitialized\n        except (InvalidGitRepositoryError, NoSuchPathError) as e:\n            raise InvalidGitRepositoryError(\"No valid repository at %s\" % module_checkout_abspath) from e\n        else:\n            raise InvalidGitRepositoryError(\"Repository at %r was not yet checked out\" % module_checkout_abspath)"
            ]
        ]
    },
    {
        "blob_id": "d30f23f4aeb03c288a115f71e953bcba46ae8e9f",
        "matched_blocks": [
            [
                22,
                35,
                "    try:\n        target = system.getFood(food)\n    except SearchError as er:\n        raise(er)\n    else:\n        for i in target.ingredientsMenu.keys():\n            info[i] = target.ingredientsMenu[i]\n        for a in target.addOn.keys():\n            info[a] = target.addOnMenu[a]\n        \n        info[food] = target.price\n        if not info:\n            raise SearchError('food')  \n        return info"
            ],
            [
                392,
                400,
                "            try:\n                id = int(id)\n            except:\n                error = 'No such order'\n            else:\n                try:\n                    system.deleteOrder(id)\n                except SearchError as er:\n                    error = str(er)"
            ],
            [
                219,
                232,
                "            try:\n                num = int(request.form[f'quantity{target}'])\n                assert(num >= 0)\n            except:\n                error = \"Please insert positive integer\"\n            else:\n                if target == 'Ingredients':\n                    target = request.form['Ingredients']\n                \n                # delete the item is quantity is 0    \n                if num == 0:\n                    cart.deleteFood(target)\n                else:\n                    cart.addFood(target,num, OVER_WRITE)"
            ],
            [
                405,
                415,
                "            try:\n                id = int(id)\n            except:\n                error = 'No such order'\n            else:\n                try:\n                    order = system.getNextOrder(None,id)\n                except SearchError as er:\n                    error = str(er)\n                else:\n                    order.updateOrder('Preparing')"
            ],
            [
                470,
                478,
                "            try:\n                quantity = int(quantity)\n            except Exception as er:\n                error = str(er)\n            else:\n                try:\n                    stock.increaseQuantity(food,quantity)\n                except Exception as er:\n                    error = str(er)"
            ],
            [
                121,
                128,
                "                try:\n                    order = system.getNextOrder(None, id)\n                except (SearchError, ValueError) as er:\n                    return render_template('home.html', name=system.name, form=request.form, checkStatus=True,error=str(er))\n                \n                # if no error occur, redirect to order detail page\n                else:\n                    return redirect(url_for('order_details', id=id, todo='checkStatus'))"
            ],
            [
                190,
                195,
                "                try:\n                    order = system.confirmOrder(order)\n                except StockError as er:\n                    error = str(er)\n                else:\n                    return redirect(url_for('order_details', id=id, todo='checkStatus'))"
            ],
            [
                306,
                316,
                "                try:\n                    quantity = int(request.form['quantity'])\n                    assert(quantity > 0)\n                except:\n                    error = \"Please insert positive integer.\"\n                else:\n                    # add or delete quantity\n                    if request.form['action'] == 'Add':\n                        cart.addFood(request.form['size'],quantity)\n                    elif request.form['action'] == 'Delete':\n                        cart.deleteFood(request.form['size'], quantity)"
            ],
            [
                410,
                415,
                "                try:\n                    order = system.getNextOrder(None,id)\n                except SearchError as er:\n                    error = str(er)\n                else:\n                    order.updateOrder('Preparing')"
            ],
            [
                420,
                430,
                "            try:\n                id = int(id)\n            except:\n                error = 'No such order'\n            else:\n                try:\n                    order = system.getNextOrder(None,id)\n                except SearchError as er:\n                    error = str(er)\n                else:\n                    order.updateOrder('Ready')"
            ],
            [
                133,
                144,
                "                try:\n                    order = system.getNextOrder(None, id)\n                except (SearchError, ValueError) as er:\n                    return render_template('home.html', name=system.name,form=request.form, continueOrder=True, error=str(er))\n                \n                # if no error occur and the order is not submitted, redirect to order detail page\n                else:\n                    if order.orderStatus != 'Not Submitted':\n                        er = \"Your order has been submitted, please go to 'Check Status'\"\n                        return render_template('home.html', name=system.name, form=request.form, continueOrder=True, error=er)\n                    else:\n                        return redirect(url_for('order_details', id=id, todo='continueOrder'))"
            ],
            [
                425,
                430,
                "                try:\n                    order = system.getNextOrder(None,id)\n                except SearchError as er:\n                    error = str(er)\n                else:\n                    order.updateOrder('Ready')"
            ],
            [
                262,
                270,
                "                try:\n                    quantity = int(request.form['quantity'])\n                    assert(quantity > 0)\n\n                except Exception as er:\n                    error = \"Please insert positive integer\"\n                    finish = False\n                else:\n                    order.addFood(new_food, quantity)"
            ]
        ]
    },
    {
        "blob_id": "0343cfa5e10add514b57184c645306a1a736455c",
        "matched_blocks": [
            [
                8,
                15,
                "        try:\n            if isinstance(obj, Decimal):\n                return str(obj)\n            iterable = iter(obj)\n        except TypeError:\n            pass\n        else:\n            return list(iterable)"
            ]
        ]
    },
    {
        "blob_id": "654a6565e52dcca6b432fa37962d8ba0ed6287ab",
        "matched_blocks": [
            [
                148,
                173,
                "    try:\n        tree.label()\n    except AttributeError:\n        return\n    else:\n        if(tree.height() <= 2):\n            # if its a leaf then return the vector\n            a = torch.Tensor(get_embed(tree[0]))\n            return torch.Tensor([0]), a, torch.Tensor([0])\n        else:\n            try:\n                sl, pl, ll = compute_gtscore(tree[0], model)\n                sr, pr, lr = compute_gtscore(tree[1], model)\n                s, p, logprob = model(pl,pr)\n                tlist = []\n                tlist.append(tree.label())\n                gt_val = torch.Tensor(tlist)\n                gt_val = gt_val.long()\n                logprob = logprob.unsqueeze(dim=0)\n                # gt_val = gt_val.unsqueeze(dim=0)\n                loss = F.nll_loss(logprob, gt_val)\n                s = s + sr + sl\n                loss = loss + ll + lr\n                return s, p, loss\n            except:\n                return"
            ]
        ]
    },
    {
        "blob_id": "c37fddbe72a4bf5e7895fef5d2695c5dec44a3c9",
        "matched_blocks": [
            [
                106,
                112,
                "            try:\n                event = q.get(block=True, timeout=.1)\n            except Queue.Empty: #timeout\n                self._automat.tick()\n            else:\n                print(\"feed\", event)\n                self._automat.feed(event)"
            ]
        ]
    },
    {
        "blob_id": "7f9aa27dd0f36f7362f9c5656ffc1908cc26425e",
        "matched_blocks": [
            [
                47,
                57,
                "            try:\n                res = cmd_execution.get()\n            except Exception:\n                logging.getLogger('HWR').exception(\"%s: execution failed\", str(self.userName()))\n                self.emit('commandFailed', (str(self.name()), ))\n            else: \n                if isinstance(res, gevent.GreenletExit):\n                    # command aborted\n                    self.emit('commandFailed', (str(self.name()), ))\n                else:\n                    self.emit('commandReplyArrived', (str(self.name()), res))"
            ]
        ]
    },
    {
        "blob_id": "0ef8473c99c2f9c9e2fcf17154cad02e4d977c67",
        "matched_blocks": [
            [
                46,
                60,
                "    try:\n        ip_start_range = int(ip_start_range)\n        ip_end_range = int(ip_end_range)\n    except ValueError:\n        colors.error('Please enter a valid number for the IP range')\n        LOGGER.error('[-] Please enter a valid number for the IP range')\n        sys.exit(1)\n    else:\n        if ip_start_range > 0 and ip_end_range < 255 and\\\n           ip_start_range < ip_end_range:\n            return ip_start_range, ip_end_range\n        else:\n            colors.error('Please enter a valid IP range')\n            LOGGER.error('[-] Please enter a valid IP range')\n            sys.exit(1)"
            ]
        ]
    },
    {
        "blob_id": "d410b5c2b143e9f9d985ec0b627448b1cba193b1",
        "matched_blocks": [
            [
                349,
                356,
                "        try:\n            c.execute(\"SELECT lagg_physnic FROM network_lagginterfacemembers\")\n        except sqlite3.OperationalError:\n            pass\n        else:\n            for interface in c:\n                if interface[0] in self._NIClist:\n                    self._NIClist.remove(interface[0])"
            ],
            [
                388,
                411,
                "            try:\n                sql = \"\"\"\n                    SELECT\n                        int_interface\n\n                    FROM\n                        network_interfaces as ni\n\n                    INNER JOIN\n                        network_alias as na\n                    ON\n                        na.alias_interface_id = ni.id\n                \"\"\"\n                c.execute(sql)\n\n            except sqlite3.OperationalError:\n                pass\n\n            else:\n                aliased_nics = [x[0] for x in c]\n                niclist = copy.deepcopy(self._NIClist)\n                for interface in niclist:\n                    if interface not in aliased_nics:\n                        self._NIClist.remove(interface)"
            ],
            [
                414,
                424,
                "            try:\n                # Exclude any configured interfaces\n                c.execute(\"SELECT int_interface FROM network_interfaces \"\n                          \"WHERE int_ipv4address != '' OR int_dhcp != '0' \"\n                          \"OR int_ipv6auto != '0' OR int_ipv6address != ''\")\n            except sqlite3.OperationalError:\n                pass\n            else:\n                for interface in c:\n                    if interface[0] in self._NIClist:\n                        self._NIClist.remove(interface[0])"
            ],
            [
                378,
                385,
                "                try:\n                    c.execute(\"SELECT vlan_pint FROM network_vlan\")\n                except sqlite3.OperationalError:\n                    pass\n                else:\n                    for interface in c:\n                        if interface[0] in self._NIClist:\n                            self._NIClist.remove(interface[0])"
            ]
        ]
    },
    {
        "blob_id": "f9eaa0f0a66e2bb27e808e16822bb671347c20c7",
        "matched_blocks": [
            [
                462,
                469,
                "                try:\n                    # TODO: Buffer decoded content, weakref does remove it too\n                    #       early (directly after this method)\n                    self.raw.decode(self.header_encoding)\n                except UnicodeError as e:\n                    self._encoding = e\n                else:\n                    self._encoding = self.header_encoding"
            ],
            [
                475,
                480,
                "                try:\n                    self.raw.decode(charset)\n                except UnicodeError as e:\n                    self._encoding = e\n                else:\n                    self._encoding = charset"
            ]
        ]
    },
    {
        "blob_id": "2887674fd327f7ea82e55a35f8ac312537e7f891",
        "matched_blocks": [
            [
                415,
                423,
                "                try:\n                    prev = previous_results[title1][title2]\n                except KeyError:\n                    pass\n                else:\n                    options.stdout.write(\n                        \"%s\\t%s\\t%s\\n\" % ((title1, title2, prev)))\n                    nupdated += 1\n                    continue"
            ]
        ]
    },
    {
        "blob_id": "18d0c452a168071397bbeb88977040fcd1c467ae",
        "matched_blocks": [
            [
                66,
                71,
                "        try:\n            q1.foo\n        except AttributeError:\n            pass\n        else:\n            self.fail('Not a copy, but reference.')"
            ]
        ]
    },
    {
        "blob_id": "dae3eb32ca4d2ebbaaf7162e74135de0adc35570",
        "matched_blocks": [
            [
                557,
                577,
                "                try:\n                    while readed_size < self.filesize:\n                        data = fp.read(self.__buffer_size)\n                        conn.send(data)\n                        readed_size += len(data)\n                        self.filestatus[self.cur_user][self.filename]['readed_size'] = readed_size\n                        json.dump(self.filestatus, fp2)\n                        fp2.flush()\n                        fp2.truncate()\n                        fp2.seek(0, 0)\n                except ConnectionResetError as e:\n                    print(e)\n                    print(e.__class__.__name__)\n                    pass\n                else:\n                    self.filestatus[self.cur_user].pop(self.filename)\n                    if not self.filestatus[self.cur_user]:\n                        self.filestatus.pop(self.cur_user)\n                        json.dump(self.filestatus, fp2)\n                        fp2.flush()\n                        fp2.truncate()"
            ]
        ]
    },
    {
        "blob_id": "528f58fbdb3bd3a30ce1c4966725941e2dc4258d",
        "matched_blocks": [
            [
                373,
                381,
                "            try:\n                self._transport.pause_reading()\n            except NotImplementedError:\n                # The transport can't be paused.\n                # We'll just have to buffer all data.\n                # Forget the transport so we don't keep trying.\n                self._transport = None\n            else:\n                self._paused = True"
            ]
        ]
    },
    {
        "blob_id": "bc3651bacd3c05a22ee9c095606c675210bc6201",
        "matched_blocks": [
            [
                57,
                82,
                "    try:\n        os.mkdir(outdir)\n    except FileExistsError as error:\n        print(\"Folder {} already exists.\".format(outdir))\n    else:\n\n        ##for trimmomatic results\n        base_Ffile = os.path.basename(forward_reads)\n        base_Rfile = os.path.basename(reverse_reads)\n\n        forward_paired = outdir+base_Ffile.replace('.','_paried.')\n        forward_unpaired = outdir+base_Ffile.replace('.','_unparied.')\n        reverse_paired = outdir+base_Rfile.replace('.','_paried.')\n        reverse_unpaired = outdir+base_Rfile.replace('.','_unparied.')\n\n        #trimmomatic\n        run_trimmomatic(\n            forward_reads,reverse_reads,\n            forward_paired,forward_unpaired,\n            reverse_paired,reverse_unpaired\n        )\n\n        #FastQC\n        run_fastqc(forward_paired,reverse_paired,outdir)\n        #spades.py\n        run_spades(forward_paired,reverse_paired,outdir)"
            ]
        ]
    },
    {
        "blob_id": "98606b34f0f360839a2e67be0e4e03be2e2b294c",
        "matched_blocks": [
            [
                115,
                125,
                "                    try:\n                        validator.validate(cleaned_data[answer])\n                    except forms.ValidationError:\n                        if i + 1 == len(instance_idx.matchers):\n                            # last one, and we flunked -> not valid\n                            import sys\n                            tp, e, _ = sys.exc_info()\n                            self.add_error(field_name_idx, e)\n                    else:\n                        # Found one that will take the input. Good enough.\n                        break"
            ]
        ]
    },
    {
        "blob_id": "4f7d33984f4de1a2db5ca3fc534dcc10909e1f06",
        "matched_blocks": [
            [
                60,
                68,
                "    try:\n        import base.deployment as deployment\n    except ImportError:\n        pass\n    else:\n        for attr in (\"version\", \"image_id\", \"instance_id\", \"setup_at\"):\n            val = getattr(deployment, attr, None)\n            if val is not None:\n                deployment_info[attr] = val"
            ]
        ]
    },
    {
        "blob_id": "142a382ea690881135b0a88507324fa95aafeb8f",
        "matched_blocks": [
            [
                47,
                65,
                "    try:\n        \n        for directory in directory_list: \n\n            if (path.exists(output_dir+directory) == True):\n\n                shutil.rmtree(output_dir+directory)\n                os.mkdir(output_dir+directory)\n                os.system(\" cp \" + dtd_path + \" \" + output_dir+directory)\n\n            else:\n\n                os.mkdir(output_dir+directory)\n                os.system(\" cp \" + dtd_path + \" \" + output_dir+directory)\n\n    except OSError:\n        print (\"Creation of directories failed\\n\")\n    else:\n        print (\"Directories have been successfully created\")"
            ]
        ]
    },
    {
        "blob_id": "42f01a54eaab93cadd4d8a8fe4c1924c4618ad51",
        "matched_blocks": [
            [
                515,
                520,
                "        try:\n            self._get_base_conf(conf, eval_deferred=False)\n        except MissingBaseKeyError:\n            return False\n        else:\n            return True"
            ],
            [
                1390,
                1396,
                "            try:\n                val = self.get_key(key, eval_deferred=eval_deferred)\n            # If the source of that key does not exist, we just ignore it\n            except KeyError:\n                pass\n            else:\n                mapping[key] = val"
            ],
            [
                1970,
                1977,
                "            try:\n                conf_path = kwargs_key_map[param]\n            except KeyError:\n                continue\n            else:\n                default = param_desc.default\n                if default is not param_desc.empty:\n                    set_nested_key(default_conf, conf_path, default)"
            ],
            [
                606,
                615,
                "            try:\n                closest_match = difflib.get_close_matches(\n                    word=str(key),\n                    possibilities=self._key_map.keys(),\n                    n=1,\n                )[0]\n            except IndexError:\n                closest_match = ''\n            else:\n                closest_match = f', maybe you meant \"{closest_match}\" ?'"
            ],
            [
                792,
                799,
                "                try:\n                    # Do not add the default source, to avoid overriding user\n                    # configuration with the default one.\n                    conf = conf_cls.from_yaml_map(conf_path, add_default_src=False)\n                except TopLevelKeyError:\n                    continue\n                else:\n                    conf_list.append((conf, conf_path))"
            ]
        ]
    },
    {
        "blob_id": "270c5dd17e8442121cca9ba61fd81bd73a493591",
        "matched_blocks": [
            [
                306,
                324,
                "        try:\n            send_domain_registration_email(dom_req.new_user_username,\n                    dom_req.domain, dom_req.activation_guid,\n                    request.user.get_full_name())\n        except Exception:\n            context.update({\n                'current_page': {'page_name': _('Oops!')},\n                'error_msg': _('There was a problem with your request'),\n                'error_details': sys.exc_info(),\n                'show_homepage_link': 1,\n            })\n            return render(request, 'error.html', context)\n        else:\n            context.update({\n                'requested_domain': dom_req.domain,\n                'current_page': {'page_name': ('Confirmation Email Sent')},\n            })\n            return render(request, 'registration/confirmation_sent.html',\n                context)"
            ]
        ]
    },
    {
        "blob_id": "1be1bbed7d3387625c039c4ccd2ba612719d214c",
        "matched_blocks": [
            [
                63,
                70,
                "                try:\n                    json_response = await response.json()\n                    item = self.entity_mapper[query_mode](**json_response)\n                except Exception as e:\n                    print(f'Error: {e}')\n                    # print(f'Response: {response}')\n                else:\n                    results.append(item)"
            ]
        ]
    },
    {
        "blob_id": "3fdf8ab51b2d81d0c9d8d3ef330ace98c6745a8e",
        "matched_blocks": [
            [
                137,
                143,
                "        try:\n            minfo = client.get_master_account().get('master')\n        except (client.exceptions.AccessDeniedException,\n                client.exceptions.ResourceNotFoundException):\n            info['master'] = {}\n        else:\n            info['master'] = minfo"
            ]
        ]
    },
    {
        "blob_id": "0f36b6bdb8493ca2f323b7a397d0a97376b2c11a",
        "matched_blocks": [
            [
                290,
                297,
                "    try:\n        rbcp.write_registers(ip_address, address = 0x1ad, length = 1, id = 10, data = speed_data)\n    except socket.error as e:\n        sys.exit(e)\n    except Exception as e:\n        sys.exit(e)\n    else:\n        print(\"speed data write done\")"
            ]
        ]
    },
    {
        "blob_id": "702a70db4abd20986ee29956d55f77c6c0a6fe65",
        "matched_blocks": [
            [
                167,
                177,
                "    try:\n        payload = await ctx.bot.wait_for('raw_reaction_add', check=check, timeout=timeout)\n    except asyncio.TimeoutError:\n        await try_clear_reactions(msg)\n        return None\n    else:\n        await try_clear_reactions(msg)\n        if payload.emoji.name == '\ud83d\udc4d':\n            return True\n        else:\n            return False"
            ],
            [
                104,
                123,
                "        try:\n            payload = await ctx.bot.wait_for('raw_reaction_add', timeout=timeout, check=check)\n        except asyncio.TimeoutError:\n            return await try_clear_reactions(msg)\n        else:\n            head = return_head(head, payload.emoji.name)\n            if head is True:\n                return await try_clear_reactions(msg)\n\n            if head is False:\n                await try_clear_reactions(msg)\n                return await msg.edit(content=None, embed=closed_embed)\n\n            elif isinstance(head, int):\n                try:\n                    await msg.remove_reaction(payload.emoji, ctx.author)\n                except discord.errors.Forbidden:\n                    pass\n\n                await msg.edit(embed=embed_list[head])"
            ],
            [
                276,
                302,
                "        try:\n            reaction, user = await ctx.bot.wait_for('reaction_add', check=check, timeout=timeout)\n        except asyncio.TimeoutError:\n            await msg.delete()\n            return\n        else:\n            emoji = reaction.emoji\n            if emoji == Emoji.X:\n                await msg.delete()\n                return\n            else:\n                if emoji in nums:\n                    await msg.delete()\n                    return embeds[head][0][nums[emoji]]\n                else:\n                    head = adjust_head(head, emoji)\n                    next_embed = embeds[head][1]\n                    next_embed.set_footer(text=f\"Page {head+1}/{len(embeds)}\")\n                    await msg.edit(embed=next_embed)\n                    try:\n                        await msg.clear_reactions()\n                    except discord.errors.Forbidden:\n                        pass\n                    else:\n                        to_react = get_reactions()\n                        for reaction in to_react:\n                            await msg.add_reaction(reaction)"
            ],
            [
                295,
                302,
                "                    try:\n                        await msg.clear_reactions()\n                    except discord.errors.Forbidden:\n                        pass\n                    else:\n                        to_react = get_reactions()\n                        for reaction in to_react:\n                            await msg.add_reaction(reaction)"
            ]
        ]
    },
    {
        "blob_id": "45728b5ac6694d187009cdbb0893ba43526df2f6",
        "matched_blocks": [
            [
                39,
                46,
                "    try:\n        target = db.sql_query_value(\n            \"SELECT targetURL FROM jurl WHERE shortURL = ?\", [key]\n        )\n    except TypeError:\n        redirect(default_url)\n    else:\n        redirect(target)"
            ]
        ]
    },
    {
        "blob_id": "5a048eca0b0b68213f036cc2a7992adaa4a0cfed",
        "matched_blocks": [
            [
                483,
                490,
                "    try:\n        fileok = isfile(filename)\n    except TypeError:\n        raise TypeError('filename must be a string')\n    else:\n        if not fileok:\n            raise IOError('[Errno 2] No such file or directory: ' +\n                          repr(filename))"
            ],
            [
                863,
                876,
                "    try:\n        seqarr, _, _ = msa._getArray(), msa.numResidues(), msa.numSequences()\n    except AttributeError:\n        try:\n            msa.getFormat(), msa.getFilename(), msa.getFilter()\n        except AttributeError:\n            raise ValueError('msa must be an MSA or MSAFile instance, not '\n                             .format(type(msa).__name__))\n        else:\n            seqiter = msa\n\n    else:\n        seqiter = msa\n        fast = True"
            ],
            [
                395,
                405,
                "        try:\n            result = filter('TEST_TITLE', 'SEQUENCE-WITH-GAPS')\n        except Exception as err:\n            raise TypeError('filter function must not raise exceptions, '\n                            'e.g. ' + str(err))\n        else:\n            try:\n                result = result or not result\n            except Exception as err:\n                raise ValueError('filter function must return a boolean, '\n                                 'e.g. ' + str(err))"
            ],
            [
                91,
                97,
                "            try:\n                torf = isfile(msa)\n            except:\n                pass\n            else:\n                if torf:\n                    self._filename = filename = msa"
            ],
            [
                99,
                104,
                "            try:\n                msa.lower, msa.strip\n            except AttributeError:\n                pass\n            else:\n                self._filename = filename = msa"
            ],
            [
                422,
                436,
                "            try:\n                seq[slice]\n            except Exception:\n                arr = fromstring(seq, '|S1')\n                try:\n                    arr[slice]\n                except Exception:\n                    raise TypeError('invalid slice: ' + repr(slice))\n                else:\n                    self._slice = slice\n                    self._slicer = lambda seq, slc=slice: fromstring(seq,\n                                                        '|S1')[slc].tostring()\n            else:\n                self._slice = slice\n                self._slicer = lambda seq, slc=slice: seq[slc]"
            ],
            [
                866,
                872,
                "        try:\n            msa.getFormat(), msa.getFilename(), msa.getFilter()\n        except AttributeError:\n            raise ValueError('msa must be an MSA or MSAFile instance, not '\n                             .format(type(msa).__name__))\n        else:\n            seqiter = msa"
            ],
            [
                426,
                433,
                "                try:\n                    arr[slice]\n                except Exception:\n                    raise TypeError('invalid slice: ' + repr(slice))\n                else:\n                    self._slice = slice\n                    self._slicer = lambda seq, slc=slice: fromstring(seq,\n                                                        '|S1')[slc].tostring()"
            ]
        ]
    },
    {
        "blob_id": "cc5b182b31c15e0834f851a86264418069dace1b",
        "matched_blocks": [
            [
                1249,
                1263,
                "    try :\n      constraint_groups = occupancy_selections(\n        model = model,\n        constrain_correlated_3d_groups=True,\n        log=null_out())\n    except Sorry as s :\n      if (i_file == 0):\n        raise\n      else :\n        assert (\"Inconsistent occupancies\" in str(s)), str(s)\n    else :\n      if (i_file == 1):\n        raise Exception_expected\n      else :\n        assert (len(constraint_groups) == 1)"
            ]
        ]
    },
    {
        "blob_id": "324b400d9ddcc89c488b9ff5ea8d861eccab41f4",
        "matched_blocks": [
            [
                289,
                300,
                "        try:\n            result = opener.open(req)\n        except urllib.error.HTTPError as e:\n            if self.show_response:\n                data = e.fp.read()\n            result = e.code, e.msg\n        except urllib.error.URLError as e:\n            result = 500, str(e)\n        else:\n            if self.show_response:\n                data = self._read_pypi_response(result)\n            result = 200, 'OK'"
            ]
        ]
    },
    {
        "blob_id": "6aafd571209d20f20d00c13c28a6c81f2c322441",
        "matched_blocks": [
            [
                21,
                33,
                "        try:\n            self.driver.find_element_by_id(\"kw\").send_keys(testdata)\n            self.driver.find_element_by_id(\"u\").click()\n            time.sleep(2)\n            self.assertIn(expectdata,self.driver.page_source)\n\n        except NoSuchElementException as e:\n            logger.info(\"\u9875\u9762\u5143\u7d20\u4e0d\u5b58\u5728\"+str(traceback.format_exc()))\n        except AssertionError as e:\n            logger.error(\"\u641c\u7d22%s,\u671f\u671b%s,\u5931\u8d25\"%(testdata,expectdata))\n            raise AssertionError\n        else:\n            logger.info(\"\u641c\u7d22%s,\u671f\u671b%s,\u901a\u8fc7\"%(testdata,expectdata))"
            ]
        ]
    },
    {
        "blob_id": "d576110ecd23c07acd4b33cab5b13a7230b6cca4",
        "matched_blocks": [
            [
                175,
                196,
                "try:\n    f = open(\"coverage.txt\", \"r\")\nexcept IOError:\n    print(\"coverage.txt is not found.\")\nelse:\n    file_name = f.readline()[:-1]\n    f.close()\n\n    if os.path.exists(file_name):\n        pass\n    else:\n        print(file_name + \" is not found.\")\n        sys.exit(1)\n\n    pyc_file_name = file_name + \"c\"\n    if os.path.exists(pyc_file_name):\n        pass\n    else:\n        print(pyc_file_name + \" is not found.\")\n        sys.exit(1)\n\n    analyse_file(file_name, pyc_file_name)"
            ]
        ]
    },
    {
        "blob_id": "0883a336eabbfc3aa5798faff0315921cf307092",
        "matched_blocks": [
            [
                285,
                296,
                "        try:\n            with self.modulewatcher.lock:\n                # Actually run the user's analysis!\n                execfile(self.filepath, sandbox, sandbox)\n        except:\n            traceback_lines = traceback.format_exception(*sys.exc_info())\n            del traceback_lines[1]\n            message = ''.join(traceback_lines)\n            sys.stderr.write(message)\n            return False\n        else:\n            return True"
            ],
            [
                313,
                326,
                "            try:\n                plot = self.plots[fig]\n            except KeyError:\n                # If we don't already have this figure, make a window\n                # to put it in:\n                self.new_figure(fig, identifier)\n            else:\n                if not plot.is_shown:\n                    plot.show()\n                    plot.update_window_size()\n                plot.set_window_title(identifier, self.filepath)\n                if plot.lock_axes:\n                    plot.restore_axis_limits()\n                plot.draw()"
            ]
        ]
    },
    {
        "blob_id": "445cee4ced19d187b52c5337b3428623190cbb8e",
        "matched_blocks": [
            [
                347,
                353,
                "        try:\n            cycle = next(cycles)\n        except StopIteration:\n            pass\n        else:\n            raise GraphCyclicError(\n                'Graph is not acyclic, contains a cycle {}'.format(cycle))"
            ]
        ]
    },
    {
        "blob_id": "3fe780544828d005a2690a32b588fea217096f21",
        "matched_blocks": [
            [
                51,
                59,
                "    try:\n      exec(\"{} = dir({})\".format(\"objectDefList\", objName), _zcUserQueryNameSpace, execResult)\n    except:\n      self.interpreter.logPythonOutput(\"Fail to run dir on \" + objName)\n      self.interpreter.logPythonOutput(traceback.format_exc())\n      return None\n    else:\n      objectDefList = execResult['objectDefList']\n      return [completion for completion in execResult['objectDefList'] if completion.startswith(methodName)]"
            ]
        ]
    },
    {
        "blob_id": "34cb2b4b02b23893a122f73ed94d8cb0a7fcab44",
        "matched_blocks": [
            [
                18,
                28,
                "        try:\n            int(selection)\n        except: #throws error if not a numeric option\n            print('Not a valid option.')\n        else:\n            if int(selection) == 1:\n                thank_you()\n            elif int(selection) == 2:\n                report()\n            elif int(selection) == 3:\n                SystemExit(0)"
            ]
        ]
    },
    {
        "blob_id": "41e300847c5eac43c1250343921802e526aa852a",
        "matched_blocks": [
            [
                426,
                449,
                "        try:\n            _aws('rds', 'create-db-instance',\n                 '--region', REGION,\n                 '--db-instance-identifier', db_id,\n                 '--vpc-security-group-ids', sg_ids[0], sg_ids[1],\n                 '--db-instance-class', self.instance_class,\n                 '--port', str(self.port),\n                 '--allocated-storage', str(self.allocated_storage),\n                 '--db-name', db_name,\n                 '--engine', 'mysql',\n                 '--master-username', username,\n                 '--master-user-password', password)\n        except AWSError:\n            log_err(format_exc())\n            self.failed_creates.add(req)\n        else:\n            self.pending[req] = {\n                'id': db_id,\n                'host': None,\n                'port': self.port,\n                'database': db_name,\n                'username': username,\n                'password': password,\n            }"
            ]
        ]
    },
    {
        "blob_id": "387709ceec1cd708efad58885ceba08d4c913c14",
        "matched_blocks": [
            [
                512,
                521,
                "                try:\n                    crt_local, = glob(join(\"deploy\", \"*.crt\"))\n                    key_local, = glob(join(\"deploy\", \"*.key\"))\n                except ValueError:\n                    parts = (crt_file, key_file, env.domains[0])\n                    sudo(\"openssl req -new -x509 -nodes -out %s -keyout %s \"\n                         \"-subj '/CN=%s' -days 3650\" % parts)\n                else:\n                    upload_template(crt_local, crt_file, use_sudo=True)\n                    upload_template(key_local, key_file, use_sudo=True)"
            ]
        ]
    },
    {
        "blob_id": "08f08d145768b9b85e56889ade23cadae6723b39",
        "matched_blocks": [
            [
                349,
                356,
                "                try:\n                    argtype, argname = fieldarg.split(None, 1)\n                except ValueError:\n                    pass\n                else:\n                    types.setdefault(typename, {})[argname] = \\\n                        [nodes.Text(argtype)]\n                    fieldarg = argname"
            ]
        ]
    },
    {
        "blob_id": "687b758174620b81a7696316b491631ecf6724a7",
        "matched_blocks": [
            [
                20,
                26,
                "        try:\n            query = State.objects.get(slug__iexact=slug)\n        except State.DoesNotExist:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n        else:\n            serializer = StateSerializer(query, context={'request': request})\n            return Response(serializer.data)"
            ],
            [
                31,
                39,
                "        try:\n            query = State.objects.get(slug__iexact=slug)\n        except State.DoesNotExist:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n        else:\n            serializer = LocalGovernmentAreaSerializer(\n                query.lgas.all(), many=True, context={'request': request}\n            )\n            return Response(serializer.data)"
            ]
        ]
    },
    {
        "blob_id": "01fb37b7d5d16a167a3f98e0b2b0c9ed7a36cd06",
        "matched_blocks": [
            [
                45,
                66,
                "        try:\n            subst1.try_add_variable('i2.2.1.4.1.0_1', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 94884\n            if len(subjects) >= 1:\n                tmp2 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i2.2.1.4.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 94885\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*d\n                        yield 0, subst2\n                subjects.appendleft(tmp2)"
            ],
            [
                68,
                89,
                "        try:\n            subst1.try_add_variable('i2.4.1.0_1', S(1))\n        except ValueError:\n            pass\n        else:\n            pass\n            # State 95169\n            if len(subjects) >= 1:\n                tmp5 = subjects.popleft()\n                subst2 = Substitution(subst1)\n                try:\n                    subst2.try_add_variable('i2.4.1.0', tmp5)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 95170\n                    if len(subjects) == 0:\n                        pass\n                        # 1: x*f\n                        yield 1, subst2\n                subjects.appendleft(tmp5)"
            ],
            [
                55,
                65,
                "                try:\n                    subst2.try_add_variable('i2.2.1.4.1.0', tmp2)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 94885\n                    if len(subjects) == 0:\n                        pass\n                        # 0: x*d\n                        yield 0, subst2"
            ],
            [
                78,
                88,
                "                try:\n                    subst2.try_add_variable('i2.4.1.0', tmp5)\n                except ValueError:\n                    pass\n                else:\n                    pass\n                    # State 95170\n                    if len(subjects) == 0:\n                        pass\n                        # 1: x*f\n                        yield 1, subst2"
            ]
        ]
    }
]